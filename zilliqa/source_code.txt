Project Path: zilliqa

Source Tree:

```txt
zilliqa
├── Cargo.toml
├── benches
│   └── it.rs
├── build.rs
├── src
│   ├── api
│   │   ├── admin.rs
│   │   ├── debug.rs
│   │   ├── erigon.rs
│   │   ├── eth.rs
│   │   ├── mod.rs
│   │   ├── net.rs
│   │   ├── ots.rs
│   │   ├── subscription_id_provider.rs
│   │   ├── to_hex.rs
│   │   ├── trace.rs
│   │   ├── txpool.rs
│   │   ├── types
│   │   │   ├── admin.rs
│   │   │   ├── eth.rs
│   │   │   ├── filters.rs
│   │   │   ├── mod.rs
│   │   │   ├── ots.rs
│   │   │   ├── txpool.rs
│   │   │   └── zil.rs
│   │   ├── web3.rs
│   │   └── zilliqa.rs
│   ├── bin
│   │   ├── convert-key.rs
│   │   └── zilliqa.rs
│   ├── blockhooks.rs
│   ├── cfg.rs
│   ├── consensus.rs
│   ├── constants.rs
│   ├── contracts
│   │   └── mod.rs
│   ├── crypto.rs
│   ├── db.rs
│   ├── error.rs
│   ├── exec.rs
│   ├── health.rs
│   ├── inspector.rs
│   ├── lib.rs
│   ├── message.rs
│   ├── node.rs
│   ├── node_launcher.rs
│   ├── p2p_node.rs
│   ├── pool.rs
│   ├── precompiles
│   │   ├── bls_verify.rs
│   │   ├── mod.rs
│   │   ├── pop_verify.rs
│   │   └── scilla.rs
│   ├── range_map.rs
│   ├── schnorr.rs
│   ├── scilla.rs
│   ├── scilla_proto.rs
│   ├── serde_util.rs
│   ├── state.rs
│   ├── sync.rs
│   ├── test_util.rs
│   ├── time.rs
│   ├── transaction.rs
│   └── zq1_proto.rs
└── tests
    └── it
        ├── admin.rs
        ├── consensus.rs
        ├── debug.rs
        ├── eth.rs
        ├── main.rs
        ├── ots.rs
        ├── persistence.rs
        ├── staking.rs
        ├── sync.rs
        ├── trace.rs
        ├── txpool.rs
        ├── unreliable.rs
        ├── web3.rs
        └── zil.rs

```

`zilliqa/Cargo.toml`:

```toml
[package]
name = "zilliqa"
version.workspace = true
authors.workspace = true
edition.workspace = true
license.workspace = true

[lib]
name = "zilliqa"
path = "src/lib.rs"

[[bin]]
name = "zilliqa"
path = "src/bin/zilliqa.rs"

[features]
# Enable tests which assert contract bytecode is correct and reproducible. Enabled in CI.
test_contract_bytecode = []
# Enable fake implementation of `ResponseChannel`, so tests can construct response channels.
fake_response_channel = []
# Enable fake implementation of `std::time::SystemTime` for deterministic tests.
fake_time = []

[build-dependencies]
anyhow = { version = "1.0.98", features = ["backtrace"] }
vergen = { version = "8.3.2", features = ["git", "git2"] }

[dependencies]
alloy = { version = "0.12.4", default-features = false, features = ["consensus", "eips", "json-abi", "dyn-abi", "k256", "rlp", "rpc-types", "rpc-types-trace", "serde", "sol-types"] }
anyhow = { version = "1.0.98", features = ["backtrace"] }
async-trait = "0.1.88"
base64 = "0.22.1"
bincode = "1.3.3"
bitvec = { version = "1.0.1", features = ["serde"] }
bs58 = "0.5.1"
bytes = "1.10.0"
clap = { version = "4.5.40", features = ["derive"] }
eth_trie = {path =  "../eth-trie.rs"}
ethabi = "18.0.0"
futures = "0.3.31"
hex = { version = "0.4.3", features = ["serde"] }
http = "1.3.1"
hyper = "1.6.0"
itertools = "0.14.0"
jsonrpsee = { version = "0.24.8", features = ["jsonrpsee-http-client", "server"] }
k256 = {version = "0.13.4", features = ["serde", "pem"] }
libp2p = { version = "0.56.0", features = ["cbor", "dns", "gossipsub", "macros", "tokio", "request-response", "kad", "identify", "serde", "autonat", "tcp", "noise", "yamux"] }
lz4 = "1.28"
once_cell = "1.21.3"
opentelemetry = { version = "0.28.0", features = ["metrics"] }
opentelemetry_sdk = { version = "0.28.0", features = ["rt-tokio"] }
opentelemetry-otlp = { version = "0.28.0", default-features = true, features = ["grpc-tonic", "metrics"] }
paste = "1.0.15"
prost = "0.14.1"
rand = "0.8.5"
rand_chacha = "0.3.1"
revm = { version = "19.6.0", features = ["optional_eip3607", "optional_no_base_fee"] }
revm-inspectors = { version = "0.16.0", features = ["js-tracer"] }
rusqlite = { version = "0.37.0", features = ["bundled", "trace"] }
serde = { version = "1.0.219", features = ["derive", "rc"] }
serde_bytes = "0.11.17"
serde_json = { version = "1.0.140", features = ["raw_value","arbitrary_precision"] }
sha2 = "0.10.8"
sha3 = "0.10.8"
tempfile = "3.19.1"
time = { version = "0.3.41", features = ["formatting", "macros"] }
tokio = { version = "1.46.1", features = ["macros", "rt-multi-thread", "signal", "sync"] }
tokio-stream = "0.1.17"
toml = "0.8.23"
tower = "0.4.13"
tower-http = { version = "0.6.6", features = ["cors"] }
tracing = "0.1.41"
tracing-subscriber = { version = "0.3.18", features = ["env-filter", "json"] }
cbor4ii = { version = "1.0.0", features = ["serde1"] }
scilla-parser = "2.0.0"
scopeguard = "1.2.0"
blsful = { git = "https://github.com/JamesHinshelwood/agora-blsful", branch = "update-blstrs"}
bech32 = "0.11.0"
cfg-if = "1.0.1"
serde_repr = "0.1.19"
thiserror = "2.0.12"
lru-mem = "0.3.0"
opentelemetry-semantic-conventions = { version = "0.28.0", features = ["semconv_experimental"] }
semver = "1.0.23"
foundry-compilers = { version = "0.14.1", features = ["svm-solc"] }
reth-ipc = { git = "https://github.com/paradigmxyz/reth", version = "1.3.12" }
parking_lot = { version = "0.12.4", features = ["send_guard"] }
dashmap = "6.1.0"

[dev-dependencies]
alloy = { version = "0.12.4", default-features = false, features = ["network", "rand", "signers", "signer-local"] }
async-trait = "0.1.88"
criterion = "0.5.1"
ethers = { version = "2.0.14", default-features = false, features = ["legacy"] }
fs_extra = "1.3.0"
indicatif = "0.17.11"
pprof = { version = "0.15.0", default-features = false, features = ["criterion", "flamegraph"] }
primitive-types = { version = "0.12.2" }
ureq = "3.0.12"
zilliqa = { path = ".", default-features = false, features = ["fake_response_channel", "fake_time"] }
zilliqa-macros = { path = "../zilliqa-macros" }

[[bench]]
name = "it"
harness = false

```

`zilliqa/benches/it.rs`:

```rs
use std::{env, iter, path::PathBuf, sync::Arc, time::Duration};

use alloy::{
    consensus::TxLegacy,
    dyn_abi::JsonAbiExt,
    network::TxSignerSync,
    primitives::{Address, U256},
    signers::local::LocalSigner,
};
use bitvec::{bitarr, order::Msb0};
use criterion::{BatchSize, Criterion, Throughput, black_box, criterion_group, criterion_main};
use eth_trie::{MemoryDB, Trie};
use itertools::Itertools;
use k256::elliptic_curve::sec1::ToEncodedPoint;
use libp2p::PeerId;
use pprof::criterion::{Output, PProfProfiler};
use prost::Message;
use revm::primitives::{Bytes, TxKind};
use sha2::{Digest, Sha256};
use tempfile::tempdir;
use tokio::sync::mpsc;
use zilliqa::{
    cfg::{Amount, GenesisDeposit, NodeConfig},
    consensus::Consensus,
    crypto::{Hash, SecretKey},
    db::Db,
    exec::zil_contract_address,
    message::{Block, ExternalMessage, MAX_COMMITTEE_SIZE, Proposal, QuorumCertificate, Vote},
    node::{MessageSender, RequestId},
    schnorr,
    sync::SyncPeers,
    test_util::{ScillaServer, compile_contract},
    time::{self, SystemTime},
    transaction::{
        EvmGas, ScillaGas, SignedTransaction, TxZilliqa, VerifiedTransaction, ZilAmount,
    },
    zq1_proto::{Code, Data, Nonce, ProtoTransactionCoreInfo},
};

fn process_empty(c: &mut Criterion) {
    tracing_subscriber::fmt::init();

    let mut group = c.benchmark_group("process-empty");
    group.throughput(Throughput::Elements(1));
    group
        .sample_size(500)
        .measurement_time(Duration::from_secs(10));

    let secret_key = SecretKey::new().unwrap();
    let peer_id = secret_key.to_libp2p_keypair().public().to_peer_id();
    let (outbound_message_sender, _a) = mpsc::unbounded_channel();
    let (local_message_sender, _b) = mpsc::unbounded_channel();
    let (reset_timeout_sender, _c) = mpsc::unbounded_channel();
    let message_sender = MessageSender {
        our_shard: 0,
        our_peer_id: peer_id,
        outbound_channel: outbound_message_sender,
        local_channel: local_message_sender,
        request_id: RequestId::default(),
    };
    let db = Db::new::<PathBuf>(None, 0, 1024, None).unwrap();
    let mut consensus = Consensus::new(
        secret_key,
        toml::from_str(&format!(
            r#"
                consensus.rewards_per_hour = "1"
                consensus.blocks_per_hour = 1
                consensus.minimum_stake = "1"
                consensus.eth_block_gas_limit = 1000000000
                consensus.gas_price = "1"
                consensus.genesis_accounts = [
                    [
                        "0x0000000000000000000000000000000000000000",
                        "1",
                    ],
                ]
                consensus.genesis_deposits = [
                    [
                        "{}",
                        "12D3KooWF4Zba8M8gkXS6aUe8oPa3stW5N17aX3eknSjW6bGAefe",
                        "1",
                        "0x0000000000000000000000000000000000000001",
                        "0x0000000000000000000000000000000000000001",
                    ],
                ]
            "#,
            secret_key.node_public_key()
        ))
        .unwrap(),
        message_sender,
        reset_timeout_sender,
        Arc::new(db),
        Arc::new(SyncPeers::new(peer_id)),
    )
    .unwrap();

    let genesis = consensus.get_block_by_view(0).unwrap().unwrap();
    let mut state = consensus.state().at_root(genesis.state_root_hash().into());
    let mut parent_hash = genesis.hash();
    let mut proposals = (1..).map(|view| {
        // The reward per block above is configured to 1. The consensus algorithm splits this reward between the
        // proposer and the cosigners, rounding down. Effectively this means no rewards are issued to anyone with this
        // configuration. However, the reward code will still unconditionally mutate the state trie to apply this zero
        // reward. Therefore, to calculate a correct state root hash we need to ensure the state trie includes an empty
        // entry for the rewarded and zero addresses, even if they never actually changes from the default account.
        let reward_address: Address = "0x0000000000000000000000000000000000000001"
            .parse()
            .unwrap();
        state.mutate_account(reward_address, |_| Ok(())).unwrap();
        state.mutate_account(Address::ZERO, |_| Ok(())).unwrap();

        let vote = Vote::new(
            secret_key,
            parent_hash,
            secret_key.node_public_key(),
            view - 1,
        );
        let qc = QuorumCertificate::new(
            &[vote.signature()],
            bitarr![u8, Msb0; 1; MAX_COMMITTEE_SIZE],
            parent_hash,
            view - 1,
        );

        let mut empty_trie = eth_trie::EthTrie::new(Arc::new(MemoryDB::new(true)));
        let empty_root_hash = Hash(empty_trie.root_hash().unwrap().into());

        let block = Block::from_qc(
            secret_key,
            view,
            view,
            qc,
            None,
            state.root_hash().unwrap(),
            empty_root_hash,
            empty_root_hash,
            vec![],
            SystemTime::UNIX_EPOCH,
            EvmGas(0),
            EvmGas(0),
        );
        parent_hash = block.hash();

        Proposal::from_parts(block, vec![])
    });

    group.bench_function("process-empty", |b| {
        b.iter(|| {
            let proposal = proposals.next().unwrap();
            let view = proposal.view();
            consensus
                .receive_block(PeerId::random(), black_box(proposal))
                .unwrap();
            consensus
                .get_block_by_view(black_box(view))
                .unwrap()
                .expect("missing block");
        })
    });
    group.finish();
}

fn consensus(
    genesis_accounts: &[(Address, u128)],
    genesis_deposits: &[(SecretKey, u128)],
    index: usize,
    scilla: &ScillaServer,
) -> Consensus {
    let secret_key = genesis_deposits[index].0;
    let peer_id = secret_key.to_libp2p_keypair().public().to_peer_id();
    let (outbound_message_sender, a) = mpsc::unbounded_channel();
    let (local_message_sender, b) = mpsc::unbounded_channel();
    let (reset_timeout_sender, c) = mpsc::unbounded_channel();
    // Leak the receivers so they don't get dropped later.
    std::mem::forget((a, b, c));
    let message_sender = MessageSender {
        our_shard: 0,
        our_peer_id: PeerId::random(),
        outbound_channel: outbound_message_sender,
        local_channel: local_message_sender,
        request_id: RequestId::default(),
    };
    let data_dir = tempdir().unwrap();
    let db = Db::new(Some(data_dir.path()), 0, 1024, None).unwrap();
    let mut config: NodeConfig = toml::from_str(&format!(
        r#"
            consensus.rewards_per_hour = "1"
            consensus.blocks_per_hour = 1
            consensus.minimum_stake = "1"
            consensus.eth_block_gas_limit = 84000000
            consensus.gas_price = "1"
            consensus.scilla_address = "{}"
            consensus.scilla_server_socket_directory = "{}/scilla-sockets"
        "#,
        scilla.addr, scilla.temp_dir,
    ))
    .unwrap();
    config.consensus.genesis_accounts = genesis_accounts
        .iter()
        .map(|(a, v)| (*a, Amount(*v)))
        .collect();
    config.consensus.genesis_deposits = genesis_deposits
        .iter()
        .enumerate()
        .map(|(i, (k, v))| GenesisDeposit {
            public_key: k.node_public_key(),
            peer_id: k.to_libp2p_keypair().public().to_peer_id(),
            stake: Amount(*v),
            reward_address: Address::right_padding_from(&[i as u8 + 1]),
            control_address: Address::right_padding_from(&[i as u8 + 1]),
        })
        .collect();
    Consensus::new(
        secret_key,
        config,
        message_sender,
        reset_timeout_sender,
        Arc::new(db),
        Arc::new(SyncPeers::new(peer_id)),
    )
    .unwrap()
}

fn full_blocks_evm_transfers(c: &mut Criterion) {
    let signer = LocalSigner::random();
    let to = Address::random();
    let txns = (0..).map(|nonce| {
        let mut tx = TxLegacy {
            chain_id: None,
            nonce,
            gas_price: 1,
            gas_limit: 21_000,
            to: TxKind::Call(to),
            value: U256::from(1),
            input: Bytes::new(),
        };
        let sig = signer.sign_transaction_sync(&mut tx).unwrap();
        let txn = SignedTransaction::Legacy { tx, sig };
        txn.verify().unwrap()
    });

    full_transaction_benchmark(
        c,
        "full-blocks-evm-transfers",
        signer.address(),
        iter::empty(),
        txns,
        4000,
    );
}

fn full_blocks_zil_transfers(c: &mut Criterion) {
    let signer = schnorr::SecretKey::random(&mut rand::thread_rng());
    let key = signer.public_key();
    let to = Address::random();
    let txns = (1..).map(|nonce| {
        let chain_id = 700;
        let amount = 1;
        let gas_price = 1;
        let gas_limit = 50;
        let tx = TxZilliqa {
            chain_id,
            nonce,
            gas_price: ZilAmount::from_raw(gas_price),
            gas_limit: ScillaGas(gas_limit),
            to_addr: to,
            amount: ZilAmount::from_raw(amount),
            code: String::new(),
            data: String::new(),
        };
        let version = ((chain_id as u32) << 16) | 1u32;
        let proto = ProtoTransactionCoreInfo {
            version,
            toaddr: to.0.to_vec(),
            senderpubkey: Some(key.to_sec1_bytes().into()),
            amount: Some(amount.to_be_bytes().to_vec().into()),
            gasprice: Some(gas_price.to_be_bytes().to_vec().into()),
            gaslimit: gas_limit,
            oneof2: Some(Nonce::Nonce(nonce)),
            oneof8: None,
            oneof9: None,
        };
        let txn_data = proto.encode_to_vec();
        let sig = schnorr::sign(&txn_data, &signer);
        let txn = SignedTransaction::Zilliqa { tx, key, sig };
        txn.verify().unwrap()
    });

    let hashed = Sha256::digest(key.to_encoded_point(true).as_bytes());
    let address = Address::from_slice(&hashed[12..]);

    full_transaction_benchmark(
        c,
        "full-blocks-zil-transfers",
        address,
        iter::empty(),
        txns,
        2300,
    );
}

fn full_blocks_erc20_transfers(c: &mut Criterion) {
    let (abi, input) = compile_contract("benches/ERC20.sol", "ERC20FixedSupply");
    let signer = LocalSigner::random();

    let mut tx = TxLegacy {
        chain_id: None,
        nonce: 0,
        gas_price: 1,
        gas_limit: 10_000_000,
        to: TxKind::Create,
        value: U256::ZERO,
        input,
    };
    let sig = signer.sign_transaction_sync(&mut tx).unwrap();
    let setup_txn = SignedTransaction::Legacy { tx, sig };
    let setup_txn = setup_txn.verify().unwrap();

    let to = Address::random();
    let contract_address = signer.address().create(0);
    let gas_limit = 51_411;
    let transfer = abi.function("transfer").unwrap()[0].clone();
    let input: Bytes = transfer
        .abi_encode_input(&[to.into(), U256::from(1).into()])
        .unwrap()
        .into();

    let txns = (1..).map(|nonce| {
        let mut tx = TxLegacy {
            chain_id: None,
            nonce,
            gas_price: 1,
            gas_limit,
            to: TxKind::Call(contract_address),
            value: U256::ZERO,
            input: input.clone(),
        };
        let sig = signer.sign_transaction_sync(&mut tx).unwrap();
        let txn = SignedTransaction::Legacy { tx, sig };
        txn.verify().unwrap()
    });

    full_transaction_benchmark(
        c,
        "full-blocks-erc20-transfers",
        signer.address(),
        iter::once(setup_txn),
        txns,
        (84_000_000 / gas_limit) as usize,
    );
}

fn full_blocks_scilla_add(c: &mut Criterion) {
    let code = format!(
        r#"
        scilla_version 0

        contract Add
        ()

        transition Add()
        one = Uint256 1;
        {}
        end
    "#,
        iter::repeat_n("two = builtin add one one", 2000).join(";")
    );
    let call = r#"{ "_tag": "Add", "params": [] }"#.to_owned();

    scilla_contract_benchmark(c, "full-blocks-scilla-add", code, call, 4570, 43);
}

fn full_blocks_scilla_load(c: &mut Criterion) {
    let code = format!(
        r#"
        scilla_version 0

        contract Load
        ()

        field num : Uint256 = Uint256 0

        transition Load()
        {}
        end
    "#,
        iter::repeat_n("n <- num", 2000).join(";")
    );
    let call = r#"{ "_tag": "Load", "params": [] }"#.to_owned();

    scilla_contract_benchmark(c, "full-blocks-scilla-load", code, call, 8320, 24);
}

fn full_blocks_scilla_store(c: &mut Criterion) {
    let code = format!(
        r#"
        scilla_version 0

        contract Store
        ()

        field num : Uint256 = Uint256 0

        transition Store()
        one = Uint256 1;
        two = Uint256 2;
        {}
        end
    "#,
        iter::repeat_n("num := one; num := two", 1000).join(";")
    );
    let call = r#"{ "_tag": "Store", "params": [] }"#.to_owned();

    scilla_contract_benchmark(c, "full-blocks-scilla-store", code, call, 8321, 24);
}

fn full_blocks_giant_deploy(c: &mut Criterion) {
    let code = include_str!("giant.scilla");

    let signer = schnorr::SecretKey::random(&mut rand::thread_rng());
    let key = signer.public_key();
    let hashed = Sha256::digest(key.to_encoded_point(true).as_bytes());
    let address = Address::from_slice(&hashed[12..]);

    let data = r#"[
        {
            "vname": "_scilla_version",
            "type": "Uint32",
            "value": "0"
        }
    ]"#
    .to_owned();

    let chain_id = 700;
    let amount = 0;
    let gas_price = 1;
    let gas_limit = 2341;
    let to = Address::ZERO;

    let txns = (1..).map(|nonce| {
        let tx = TxZilliqa {
            chain_id,
            nonce,
            gas_price: ZilAmount::from_raw(gas_price),
            gas_limit: ScillaGas(gas_limit),
            to_addr: to,
            amount: ZilAmount::from_raw(amount),
            code: code.to_owned(),
            data: data.clone(),
        };
        let version = ((chain_id as u32) << 16) | 1u32;
        let proto = ProtoTransactionCoreInfo {
            version,
            toaddr: to.0.to_vec(),
            senderpubkey: Some(key.to_sec1_bytes().into()),
            amount: Some(amount.to_be_bytes().to_vec().into()),
            gasprice: Some(gas_price.to_be_bytes().to_vec().into()),
            gaslimit: gas_limit,
            oneof2: Some(Nonce::Nonce(nonce)),
            oneof8: Some(Code::Code(code.to_owned().into_bytes())),
            oneof9: Some(Data::Data(data.clone().into_bytes())),
        };
        let txn_data = proto.encode_to_vec();
        let sig = schnorr::sign(&txn_data, &signer);
        let txn = SignedTransaction::Zilliqa { tx, key, sig };
        txn.verify().unwrap()
    });

    full_transaction_benchmark(
        c,
        "full-blocks-giant-deploy",
        address,
        iter::empty(),
        txns,
        330,
    );
}

fn scilla_contract_benchmark(
    c: &mut Criterion,
    name: &str,
    code: String,
    call: String,
    call_gas_limit: u64,
    txns_per_block: usize,
) {
    let signer = schnorr::SecretKey::random(&mut rand::thread_rng());
    let key = signer.public_key();
    let hashed = Sha256::digest(key.to_encoded_point(true).as_bytes());
    let address = Address::from_slice(&hashed[12..]);

    let data = r#"[
        {
            "vname": "_scilla_version",
            "type": "Uint32",
            "value": "0"
        }
    ]"#
    .to_owned();

    let chain_id = 700;
    let nonce = 1;
    let amount = 0;
    let gas_price = 1;
    let gas_limit = 100000;
    let to = Address::ZERO;
    let tx = TxZilliqa {
        chain_id,
        nonce,
        gas_price: ZilAmount::from_raw(gas_price),
        gas_limit: ScillaGas(gas_limit),
        to_addr: to,
        amount: ZilAmount::from_raw(amount),
        code: code.clone(),
        data: data.clone(),
    };
    let version = ((chain_id as u32) << 16) | 1u32;
    let proto = ProtoTransactionCoreInfo {
        version,
        toaddr: to.0.to_vec(),
        senderpubkey: Some(key.to_sec1_bytes().into()),
        amount: Some(amount.to_be_bytes().to_vec().into()),
        gasprice: Some(gas_price.to_be_bytes().to_vec().into()),
        gaslimit: gas_limit,
        oneof2: Some(Nonce::Nonce(nonce)),
        oneof8: Some(Code::Code(code.into_bytes())),
        oneof9: Some(Data::Data(data.into_bytes())),
    };
    let txn_data = proto.encode_to_vec();
    let sig = schnorr::sign(&txn_data, &signer);
    let deploy_txn = SignedTransaction::Zilliqa { tx, key, sig };
    let deploy_txn = deploy_txn.verify().unwrap();
    let contract_address = zil_contract_address(address, 0);

    let txns = (2..).map(|nonce| {
        let tx = TxZilliqa {
            chain_id,
            nonce,
            gas_price: ZilAmount::from_raw(gas_price),
            gas_limit: ScillaGas(call_gas_limit),
            to_addr: contract_address,
            amount: ZilAmount::from_raw(amount),
            code: String::new(),
            data: call.clone(),
        };
        let version = ((chain_id as u32) << 16) | 1u32;
        let proto = ProtoTransactionCoreInfo {
            version,
            toaddr: contract_address.0.to_vec(),
            senderpubkey: Some(key.to_sec1_bytes().into()),
            amount: Some(amount.to_be_bytes().to_vec().into()),
            gasprice: Some(gas_price.to_be_bytes().to_vec().into()),
            gaslimit: call_gas_limit,
            oneof2: Some(Nonce::Nonce(nonce)),
            oneof8: None,
            oneof9: Some(Data::Data(call.clone().into_bytes())),
        };
        let txn_data = proto.encode_to_vec();
        let sig = schnorr::sign(&txn_data, &signer);
        let txn = SignedTransaction::Zilliqa { tx, key, sig };
        txn.verify().unwrap()
    });

    full_transaction_benchmark(
        c,
        name,
        address,
        iter::once(deploy_txn),
        txns,
        txns_per_block,
    );
}

/// Run a benchmark which produces blocks full of the provided transactions. `txns` should be infinitely iterable
/// so the benchmark can generate as many transactions as it needs.
fn full_transaction_benchmark(
    c: &mut Criterion,
    name: &str,
    genesis_address: Address,
    setup_txns: impl Iterator<Item = VerifiedTransaction>,
    txns: impl Iterator<Item = VerifiedTransaction>,
    txns_per_block: usize,
) {
    // We will create a dummy network with 2 validators - 'big' which has a large proportion of the stake and 'tiny'
    // which has a small amount of stake. The intention is that 'big' will always be the block proposer, because the
    // proposer is selected in proportion to the validators' relative stake. However, 'tiny' will still get to have a
    // vote on this proposal, despite its vote not being needed to reach a supermajority. The benchmark will execute
    // the following in each iteration:
    // 1. Get 'big' to process the previous vote and propose a block
    // 2. Get 'tiny' to vote on this block
    // 3. Get 'big' to vote on this block
    // Step 2 is important, because we want to measure the time it takes a validator to vote on a block it hasn't seen
    // before. In step 3, 'big' will skip most of the block validation logic because it knows it built the block
    // itself.
    let genesis_accounts = vec![(genesis_address, 1_000_000_000_000_000_000_000_000_000)];
    let secret_key_big = SecretKey::new().unwrap();
    let secret_key_tiny = SecretKey::new().unwrap();
    let genesis_deposits = vec![
        (secret_key_big, 1_000_000_000_000_000_000_000_000_000),
        (secret_key_tiny, 1),
    ];

    let setup_txns: Vec<_> = setup_txns.collect();
    let txns: Vec<_> = txns.take(txns_per_block).collect();

    let mut group = c.benchmark_group(name);
    group.throughput(Throughput::Elements(1));
    group.sample_size(
        env::var("ZQ_TRANSACTION_BENCHMARK_SAMPLES")
            .map(|s| s.parse().unwrap())
            .unwrap_or(10),
    );
    group.measurement_time(Duration::from_secs(
        env::var("ZQ_TRANSACTION_BENCHMARK_MEASUREMENT_TIME_S")
            .map(|s| s.parse().unwrap())
            .unwrap_or(120),
    ));
    let big_scilla = ScillaServer::default();
    let tiny_scilla = ScillaServer::default();
    group.bench_function(name, |bench| {
        bench.iter_batched(
            || {
                let mut big = consensus(&genesis_accounts, &genesis_deposits, 0, &big_scilla);
                let mut tiny = consensus(&genesis_accounts, &genesis_deposits, 1, &tiny_scilla);

                for txn in &setup_txns {
                    let result = big
                        .new_transaction(txn.clone(), false, &mut big.transaction_pool.write())
                        .unwrap();
                    assert!(result.was_added(), "transaction not added: {result:?}");
                    let result = tiny
                        .new_transaction(txn.clone(), false, &mut tiny.transaction_pool.write())
                        .unwrap();
                    assert!(result.was_added(), "transaction not added: {result:?}");
                }

                let vote = time::sync_with_fake_time(|| {
                    // Trigger a timeout to produce the vote for the genesis block.
                    let (_, message) = big.timeout().unwrap().unwrap();
                    let ExternalMessage::Vote(vote) = message else {
                        panic!()
                    };
                    let from = big.peer_id();

                    // Produce a single block containing the setup transactions. We assume they all fit in a single
                    // block.
                    // 1. Get 'big' to process the previous vote and propose a block.
                    let proposal = a_big_process_vote(&mut big, *vote, setup_txns.len());
                    // 2. Get 'tiny' to vote on this block.
                    b_tiny_process_block(&mut tiny, from, proposal.clone());
                    // 3. Get 'big' to vote on this block
                    c_big_process_block(&mut big, from, proposal)
                });

                for txn in &txns {
                    let result = big
                        .new_transaction(txn.clone(), false, &mut big.transaction_pool.write())
                        .unwrap();
                    assert!(result.was_added(), "transaction not added: {result:?}");
                    let result = tiny
                        .new_transaction(txn.clone(), false, &mut tiny.transaction_pool.write())
                        .unwrap();
                    assert!(result.was_added(), "transaction not added: {result:?}");
                }

                (big, tiny, vote)
            },
            |(mut big, mut tiny, mut vote)| {
                let from = big.peer_id();
                time::sync_with_fake_time(|| {
                    // We wrap each of these steps in a separate function call, so that they are listed separately
                    // in flamegraphs and we are able to measure the time spent in each. The function names are
                    // deliberately alphabetical, so they appear in order in the flamegraph.

                    // 1. Get 'big' to process the previous vote and propose a block.
                    let proposal = a_big_process_vote(&mut big, vote, txns_per_block);

                    // 2. Get 'tiny' to vote on this block.
                    b_tiny_process_block(&mut tiny, from, proposal.clone());

                    // 3. Get 'big' to vote on this block
                    vote = c_big_process_block(&mut big, from, proposal);
                });
            },
            BatchSize::SmallInput,
        );
    });
}

fn a_big_process_vote(big: &mut Consensus, vote: Vote, txns_per_block: usize) -> Proposal {
    let proposal = big
        .vote(PeerId::random(), black_box(vote))
        .unwrap()
        .map(|(_, t)| t.into_proposal().unwrap());
    // The first vote should immediately result in a proposal. Subsequent views require a timeout before
    // the proposal is produced. Therefore, we trigger a timeout if there was not a proposal from the vote.
    let proposal = proposal.unwrap_or_else(|| {
        time::advance(Duration::from_secs(10));
        let (_, message) = big.timeout().unwrap().unwrap();
        let ExternalMessage::Proposal(p) = message else {
            panic!()
        };
        p
    });

    assert_eq!(
        proposal.transactions.len(),
        txns_per_block,
        "proposal {} is not the expected size",
        proposal.view()
    );

    proposal
}

fn b_tiny_process_block(tiny: &mut Consensus, from: PeerId, proposal: Proposal) {
    let last_txn = proposal.transactions.last().map(|t| t.calculate_hash());
    let (_, tiny_vote) = tiny
        .proposal(from, black_box(proposal), false)
        .unwrap()
        .unwrap();
    // We assert 'tiny' actually voted but don't do anything with its vote.
    assert!(matches!(tiny_vote, ExternalMessage::Vote(_)));

    // Get the last transaction receipt and make sure it succeeded. We assume that all other transactions succeeded if
    // this one did.
    if let Some(last_txn) = last_txn {
        let receipt = tiny.get_transaction_receipt(&last_txn).unwrap().unwrap();
        assert!(receipt.success, "transaction failed: {receipt:?}");
    }
}

fn c_big_process_block(big: &mut Consensus, from: PeerId, proposal: Proposal) -> Vote {
    let (_, vote) = big
        .proposal(from, black_box(proposal), false)
        .unwrap()
        .unwrap();
    let ExternalMessage::Vote(vote) = vote else {
        panic!()
    };
    *vote
}

criterion_group!(
    name = benches;
    config = Criterion::default().with_profiler(PProfProfiler::new(100, Output::Flamegraph(None)));
    targets = process_empty, full_blocks_evm_transfers, full_blocks_zil_transfers, full_blocks_erc20_transfers, full_blocks_scilla_add, full_blocks_scilla_load, full_blocks_scilla_store, full_blocks_giant_deploy,
);
criterion_main!(benches);

```

`zilliqa/build.rs`:

```rs
use anyhow::Result;
use vergen::EmitBuilder;

fn main() -> Result<()> {
    EmitBuilder::builder()
        .git_describe(true, true, None)
        .git_sha(false)
        .fail_on_error()
        .emit()?;

    Ok(())
}

```

`zilliqa/src/api/admin.rs`:

```rs
//! An administrative API

use std::{ops::RangeInclusive, sync::Arc};

use alloy::{eips::BlockId, primitives::U64};
use anyhow::{Result, anyhow};
use itertools::Itertools;
use jsonrpsee::{RpcModule, types::Params};
use libp2p::PeerId;
use parking_lot::RwLock;
use serde::{Deserialize, Serialize};

use super::types::{admin::VotesReceivedReturnee, eth::QuorumCertificate, hex};
use crate::{
    api::{to_hex::ToHex, types::admin::VoteCount},
    cfg::EnabledApi,
    consensus::{BlockVotes, NewViewVote, Validator},
    crypto::NodePublicKey,
    message::{BitArray, BlockHeader},
    node::Node,
};

pub fn rpc_module(
    node: Arc<RwLock<Node>>,
    enabled_apis: &[EnabledApi],
) -> RpcModule<Arc<RwLock<Node>>> {
    super::declare_module!(
        node,
        enabled_apis,
        [
            ("admin_consensusInfo", consensus_info),
            ("admin_generateCheckpoint", checkpoint),
            ("admin_blockRange", admin_block_range),
            ("admin_forceView", force_view),
            ("admin_getPeers", get_peers),
            ("admin_votesReceived", votes_received),
            ("admin_clearMempool", clear_mempool),
            ("admin_getLeaders", get_leaders),
        ]
    )
}

#[derive(Clone, Debug, Serialize)]
struct ConsensusInfo {
    #[serde(serialize_with = "hex")]
    view: u64,
    high_qc: QuorumCertificate,
    milliseconds_since_last_view_change: u64,
    milliseconds_until_next_view_change: u64,
}

fn admin_block_range(_params: Params, node: &Arc<RwLock<Node>>) -> Result<RangeInclusive<u64>> {
    node.read().db.available_range()
}

fn consensus_info(_: Params, node: &Arc<RwLock<Node>>) -> Result<ConsensusInfo> {
    let node = node.read();

    let view = node.consensus.get_view()?;
    let high_qc = QuorumCertificate::from_qc(&node.consensus.high_qc);
    let (milliseconds_since_last_view_change, _, exponential_backoff_timeout) =
        node.consensus.get_consensus_timeout_params()?;
    let milliseconds_until_next_view_change =
        exponential_backoff_timeout.saturating_sub(milliseconds_since_last_view_change);

    Ok(ConsensusInfo {
        view,
        high_qc,
        milliseconds_since_last_view_change,
        milliseconds_until_next_view_change,
    })
}

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct CheckpointResponse {
    /// File name - when this file exists, the checkpoint is done.
    file_name: String,
    /// Checkpoint hash
    hash: String,
    /// Block number as hex.
    block: String,
}

fn checkpoint(params: Params, node: &Arc<RwLock<Node>>) -> Result<CheckpointResponse> {
    let mut params = params.sequence();
    let block_id: BlockId = params.next()?;
    let node = node.read();
    let block = node
        .get_block(block_id)?
        .ok_or(anyhow!("Block {block_id} does not exist"))?;

    let (file_name, hash) = node.consensus.checkpoint_at(block.number())?;
    Ok(CheckpointResponse {
        file_name,
        hash,
        block: block.number().to_hex(),
    })
}

fn force_view(params: Params, node: &Arc<RwLock<Node>>) -> Result<bool> {
    let mut params = params.sequence();
    let view: U64 = params.next()?;
    let timeout_at: String = params.next()?;
    let mut node = node.write();
    node.consensus.force_view(view.to::<u64>(), timeout_at)?;
    Ok(true)
}

#[derive(Clone, Debug, Serialize)]
struct PeerInfo {
    pub swarm_peers: Vec<PeerId>,
    pub sync_peers: Vec<PeerId>,
}

fn get_peers(_params: Params, node: &Arc<RwLock<Node>>) -> Result<PeerInfo> {
    let node = node.read();
    let (swarm_peers, sync_peers) = node.get_peer_ids()?;
    Ok(PeerInfo {
        swarm_peers,
        sync_peers,
    })
}

/// Returns information about votes and voters
fn votes_received(_params: Params, node: &Arc<RwLock<Node>>) -> Result<VotesReceivedReturnee> {
    let node = node.read();

    let new_views = node
        .consensus
        .new_views
        .iter()
        .map(|kv| (*kv.key(), kv.value().clone()))
        .collect_vec();
    let votes = node
        .consensus
        .votes
        .iter()
        .map(|kv| (*kv.key(), kv.value().clone()))
        .collect_vec();
    let buffered_votes = node
        .consensus
        .buffered_votes
        .clone()
        .into_iter()
        .collect_vec();

    let head_block = node.consensus.head_block();
    let executed_block = BlockHeader {
        number: head_block.header.number + 1,
        ..Default::default()
    };
    let committee = node
        .consensus
        .state()
        .at_root(head_block.state_root_hash().into())
        .get_stakers(executed_block)?;

    // Helper fn to match NodePublicKey with cosigned bit array
    fn filter_voters_by_cosigned_bits(bits: &BitArray, committee: &[NodePublicKey]) -> VoteCount {
        let mut voted = vec![];
        let mut not_voted = vec![];
        for (i, peer) in committee.iter().enumerate() {
            if bits[i] {
                voted.push(*peer)
            } else {
                not_voted.push(*peer)
            }
        }
        VoteCount { voted, not_voted }
    }

    let new_view_with_voters: Vec<(u64, NewViewVote, VoteCount)> = new_views
        .iter()
        .map(|(view, new_view_vote)| {
            (
                *view,
                new_view_vote.clone(),
                filter_voters_by_cosigned_bits(&new_view_vote.cosigned, &committee),
            )
        })
        .collect();

    let votes_with_voters: Vec<(crate::crypto::Hash, BlockVotes, VoteCount)> = votes
        .iter()
        .map(|(hash, block_votes)| {
            (
                *hash,
                block_votes.clone(),
                filter_voters_by_cosigned_bits(&block_votes.cosigned, &committee),
            )
        })
        .collect();

    let returnee = VotesReceivedReturnee {
        new_views: new_view_with_voters,
        votes: votes_with_voters,
        buffered_votes,
    };

    Ok(returnee)
}

fn clear_mempool(_params: Params, node: &Arc<RwLock<Node>>) -> Result<()> {
    node.read().consensus.clear_mempool();
    Ok(())
}

fn get_leaders(params: Params, node: &Arc<RwLock<Node>>) -> Result<Vec<(u64, Validator)>> {
    let mut params = params.sequence();
    let mut view = params.next::<U64>()?.to::<u64>();
    let count = params.next::<U64>()?.to::<usize>().min(100);

    let node = node.read();
    let head_block = node.consensus.head_block();
    let mut leaders = vec![];

    while leaders.len() <= count {
        leaders.push((
            view,
            node.consensus.leader_at_block(&head_block, view).unwrap(),
        ));
        view += 1;
    }
    Ok(leaders)
}

```

`zilliqa/src/api/debug.rs`:

```rs
use std::sync::Arc;

use alloy::{
    eips::BlockNumberOrTag,
    primitives::B256,
    rpc::types::trace::geth::{GethDebugTracingOptions, TraceResult},
};
use anyhow::{Result, anyhow};
use jsonrpsee::{RpcModule, types::Params};
use parking_lot::RwLock;

use crate::{cfg::EnabledApi, crypto::Hash, inspector, node::Node};

pub fn rpc_module(
    node: Arc<RwLock<Node>>,
    enabled_apis: &[EnabledApi],
) -> RpcModule<Arc<RwLock<Node>>> {
    super::declare_module!(
        node,
        enabled_apis,
        [
            ("debug_getBadBlocks", debug_get_bad_blocks),
            ("debug_getTrieFlushInterval", debug_get_trie_flush_interval),
            ("debug_storageRangeAt", debug_storage_range_at),
            ("debug_traceBlock", debug_trace_block),
            ("debug_traceBlockByHash", debug_trace_block_by_hash),
            ("debug_traceBlockByNumber", debug_trace_block_by_number),
            ("debug_traceCall", debug_trace_call),
            ("debug_traceTransaction", debug_trace_transaction),
        ]
    )
}

/// debug_getBadBlocks
fn debug_get_bad_blocks(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    Err(anyhow!(
        "API method debug_getBadBlocks is not implemented yet"
    ))
}

/// debug_getTrieFlushInterval
fn debug_get_trie_flush_interval(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    Err(anyhow!(
        "API method debug_getTrieFlushInterval is not implemented yet"
    ))
}

/// debug_storageRangeAt
fn debug_storage_range_at(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    Err(anyhow!(
        "API method debug_storageRangeAt is not implemented yet"
    ))
}

/// debug_traceBlock
fn debug_trace_block(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    Err(anyhow!(
        "API method debug_traceBlock is not implemented yet"
    ))
}

/// debug_traceBlockByHash
fn debug_trace_block_by_hash(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    Err(anyhow!(
        "API method debug_traceBlockByHash is not implemented yet"
    ))
}

/// debug_traceBlockByNumber
fn debug_trace_block_by_number(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<Vec<TraceResult>> {
    let mut params = params.sequence();
    let block_number: BlockNumberOrTag = params.next()?;
    let trace_type: Option<GethDebugTracingOptions> = params.optional_next()?;

    node.read()
        .debug_trace_block(block_number, trace_type.unwrap_or_default())
}

/// debug_traceCall
fn debug_trace_call(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    Err(anyhow!("API method debug_traceCall is not implemented yet"))
}

/// debug_traceTransaction
fn debug_trace_transaction(params: Params, node: &Arc<RwLock<Node>>) -> Result<TraceResult> {
    let mut params = params.sequence();
    let txn_hash: B256 = params.next()?;
    let txn_hash: Hash = txn_hash.into();
    let trace_opts: Option<GethDebugTracingOptions> = params.optional_next()?;

    let node = node.read();

    // Get transaction and its receipt to find the block it was included in
    let receipt = node
        .get_transaction_receipt(txn_hash)?
        .ok_or_else(|| anyhow!("transaction not mined: {txn_hash}"))?;

    let block = node
        .get_block(receipt.block_hash)?
        .ok_or_else(|| anyhow!("missing block: {}", receipt.block_hash))?;

    let parent = node
        .get_block(block.parent_hash())?
        .ok_or_else(|| anyhow!("missing parent block: {}", block.parent_hash()))?;

    let mut state = node
        .consensus
        .state()
        .at_root(parent.state_root_hash().into());

    // Find the transaction's index in the block
    let txn_index = block
        .transactions
        .iter()
        .position(|&h| h == txn_hash)
        .ok_or_else(|| anyhow!("transaction not found in specified block"))?;

    // Apply all transactions before the target transaction
    for &prev_tx_hash in &block.transactions[0..txn_index] {
        let prev_tx = node
            .get_transaction_by_hash(prev_tx_hash)?
            .ok_or_else(|| anyhow!("transaction not found: {prev_tx_hash}"))?;

        state.apply_transaction(prev_tx, block.header, inspector::noop(), false)?;
    }

    // Get the target transaction
    let _txn = node
        .get_transaction_by_hash(txn_hash)?
        .ok_or_else(|| anyhow!("transaction not found: {txn_hash}"))?;

    // Use default options if none provided
    let trace_opts = trace_opts.unwrap_or_default();

    // Debug trace the transaction
    let trace_result =
        node.debug_trace_transaction(&mut state, txn_hash, txn_index, &block, trace_opts)?;

    trace_result.ok_or_else(|| anyhow!("Failed to trace transaction"))
}

```

`zilliqa/src/api/erigon.rs`:

```rs
use std::sync::Arc;

use anyhow::Result;
use jsonrpsee::{RpcModule, types::Params};
use parking_lot::RwLock;

use super::types::eth;
use crate::{cfg::EnabledApi, node::Node};

pub fn rpc_module(
    node: Arc<RwLock<Node>>,
    enabled_apis: &[EnabledApi],
) -> RpcModule<Arc<RwLock<Node>>> {
    super::declare_module!(
        node,
        enabled_apis,
        [
            ("erigon_blockNumber", block_number),
            ("erigon_forks", forks),
            ("erigon_getBlockByTimestamp", get_block_by_timestamp),
            (
                "erigon_getBlockReceiptsByBlockHash",
                get_block_receipts_by_block_hash
            ),
            ("erigon_getHeaderByHash", get_header_by_hash),
            ("erigon_getHeaderByNumber", get_header_by_number),
            ("erigon_getLatestLogs", get_latest_logs),
            ("erigon_getLogsByHash", get_logs_by_hash),
        ]
    )
}

/// erigon_blockNumber
fn block_number(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    todo!("Endpoint not implemented yet");
}

/// erigon_forks
fn forks(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    todo!("Endpoint not implemented yet");
}

/// erigon_getBlockByTimestamp
fn get_block_by_timestamp(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    todo!("Endpoint not implemented yet");
}

/// erigon_getBlockReceiptsByBlockHash
fn get_block_receipts_by_block_hash(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    todo!("Endpoint not implemented yet");
}

/// erigon_getHeaderByHash
fn get_header_by_hash(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    todo!("Endpoint not implemented yet");
}

/// erigon_getHeaderByNumber
fn get_header_by_number(params: Params, node: &Arc<RwLock<Node>>) -> Result<Option<eth::Block>> {
    let block: u64 = params.one()?;

    // Erigon headers are a subset of the full block response. We choose to just return the full block.
    let Some(ref block) = node.read().get_block(block)? else {
        return Ok(None);
    };

    let node = node.read();
    let logs_bloom = super::eth::get_block_logs_bloom(&node, block)?;

    let miner = node.get_proposer_reward_address(block.header)?;

    let block_gas_limit = node.config.consensus.eth_block_gas_limit;
    Ok(Some(eth::Block::from_block(
        block,
        miner.unwrap_or_default(),
        block_gas_limit,
        logs_bloom,
    )))
}

/// erigon_getLatestLogs
fn get_latest_logs(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    todo!("Endpoint not implemented yet");
}

/// erigon_getLogsByHash
fn get_logs_by_hash(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    todo!("Endpoint not implemented yet");
}

```

`zilliqa/src/api/eth.rs`:

```rs
//! The Ethereum API, as documented at <https://ethereum.org/en/developers/docs/apis/json-rpc>.

use std::sync::Arc;

use alloy::{
    consensus::{TxEip1559, TxEip2930, TxLegacy, transaction::RlpEcdsaDecodableTx},
    eips::{BlockId, BlockNumberOrTag, RpcBlockHash},
    primitives::{Address, B256, U64, U256},
    rpc::types::{
        FilteredParams,
        pubsub::{self, SubscriptionKind},
    },
};
use anyhow::{Result, anyhow};
use http::Extensions;
use itertools::Either;
use jsonrpsee::{
    PendingSubscriptionSink, RpcModule, SubscriptionMessage,
    core::StringError,
    types::{
        Params,
        error::{ErrorObject, ErrorObjectOwned},
        params::ParamsSequence,
    },
};
use parking_lot::{RwLock, RwLockReadGuard};
use serde_json::json;
use tracing::*;

use super::{
    to_hex::ToHex,
    types::{
        eth::{self, CallParams, ErrorCode, HashOrTransaction, SyncingResult, TransactionReceipt},
        filters::{BlockFilter, FilterKind, LogFilter, PendingTxFilter},
    },
};
use crate::{
    api::zilliqa::ZilAddress,
    cfg::EnabledApi,
    crypto::Hash,
    error::ensure_success,
    exec::zil_contract_address,
    message::Block,
    node::Node,
    pool::TxAddResult,
    state::{Account, Code},
    time::SystemTime,
    transaction::{EvmGas, Log, SignedTransaction},
};

pub fn rpc_module(
    node: Arc<RwLock<Node>>,
    enabled_apis: &[EnabledApi],
) -> RpcModule<Arc<RwLock<Node>>> {
    let mut module = super::declare_module!(
        node,
        enabled_apis,
        [
            ("eth_accounts", accounts),
            ("eth_blobBaseFee", blob_base_fee),
            ("eth_blockNumber", block_number),
            ("eth_call", call),
            ("eth_callMany", call_many),
            ("eth_chainId", chain_id),
            ("eth_estimateGas", estimate_gas),
            ("eth_feeHistory", fee_history),
            ("eth_gasPrice", get_gas_price),
            ("eth_getAccount", get_account),
            ("eth_getBalance", get_balance),
            ("eth_getBlockByHash", get_block_by_hash),
            ("eth_getBlockByNumber", get_block_by_number),
            ("eth_getBlockReceipts", get_block_receipts),
            (
                "eth_getBlockTransactionCountByHash",
                get_block_transaction_count_by_hash
            ),
            (
                "eth_getBlockTransactionCountByNumber",
                get_block_transaction_count_by_number
            ),
            ("eth_getCode", get_code),
            ("eth_getFilterChanges", get_filter_changes),
            ("eth_getFilterLogs", get_filter_logs),
            ("eth_getLogs", get_logs),
            ("eth_getProof", get_proof),
            ("eth_getStorageAt", get_storage_at),
            (
                "eth_getTransactionByBlockHashAndIndex",
                get_transaction_by_block_hash_and_index
            ),
            (
                "eth_getTransactionByBlockNumberAndIndex",
                get_transaction_by_block_number_and_index
            ),
            ("eth_getTransactionByHash", get_transaction_by_hash),
            ("eth_getTransactionCount", get_transaction_count),
            ("eth_getTransactionReceipt", get_transaction_receipt),
            ("eth_getUncleByBlockHashAndIndex", get_uncle),
            ("eth_getUncleByBlockNumberAndIndex", get_uncle),
            ("eth_getUncleCountByBlockHash", get_uncle_count),
            ("eth_getUncleCountByBlockNumber", get_uncle_count),
            ("eth_hashrate", hashrate),
            ("eth_maxPriorityFeePerGas", max_priority_fee_per_gas),
            ("eth_mining", mining),
            ("eth_newBlockFilter", new_block_filter),
            ("eth_newFilter", new_filter),
            (
                "eth_newPendingTransactionFilter",
                new_pending_transaction_filter
            ),
            ("eth_protocolVersion", protocol_version),
            ("eth_sendRawTransaction", send_raw_transaction),
            ("eth_signTransaction", sign_transaction),
            ("eth_simulateV1", simulate_v1),
            ("eth_submitWork", submit_work),
            ("eth_syncing", syncing),
            ("eth_uninstallFilter", uninstall_filter),
        ],
    );

    module
        .register_subscription(
            "eth_subscribe",
            "eth_subscription",
            "eth_unsubscribe",
            subscribe,
        )
        .unwrap();

    module
}

// See https://eips.ethereum.org/EIPS/eip-1898
fn build_errored_response_for_missing_block(
    request: BlockId,
    result: Option<Block>,
) -> Result<Block> {
    // Block has been found
    if let Some(block) = result {
        return Ok(block);
    }

    const INVALID_INPUT: i32 = -32000;
    let resource_not_found = ErrorObjectOwned::owned(
        INVALID_INPUT,
        "Invalid input".to_string(),
        Option::<String>::None,
    );

    let BlockId::Hash(RpcBlockHash {
        require_canonical, ..
    }) = request
    else {
        return Err(resource_not_found.into());
    };

    let require_canonical = require_canonical.unwrap_or_default();

    match require_canonical {
        true => {
            const INVALID_INPUT: i32 = -32000;
            let response = ErrorObjectOwned::owned(
                INVALID_INPUT,
                "Invalid input".to_string(),
                Option::<String>::None,
            );
            Err(response.into())
        }
        false => Err(resource_not_found.into()),
    }
}

fn expect_end_of_params(seq: &mut ParamsSequence, min: u32, max: u32) -> Result<()> {
    // Styled after the geth error message.
    let msg = if min != max {
        format!("too many arguments, want at most {max}")
    } else {
        format!("too many arguments, want {max}")
    };
    match seq.next::<serde_json::Value>() {
        Ok(_) => Err(ErrorObjectOwned::owned(
            jsonrpsee::types::error::INVALID_PARAMS_CODE,
            msg,
            Option::<String>::None,
        )
        .into()),
        _ => Ok(()),
    }
}

fn accounts(params: Params, _: &Arc<RwLock<Node>>) -> Result<[(); 0]> {
    expect_end_of_params(&mut params.sequence(), 0, 0)?;
    Ok([])
}

fn block_number(params: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    expect_end_of_params(&mut params.sequence(), 0, 0)?;
    let node = node.read();
    Ok(node.consensus.get_highest_canonical_block_number().to_hex())
}

fn call_many(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    // TODO: disable_eip3607 for this call.
    Err(anyhow!("API method eth_callMany is not implemented yet"))
}

fn call(params: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    let mut params = params.sequence();
    let call_params: CallParams = params.next()?;
    let block_id: BlockId = params.optional_next()?.unwrap_or_default();
    expect_end_of_params(&mut params, 1, 2)?;

    let node = node.read();
    let block = node.get_block(block_id)?;
    let block = build_errored_response_for_missing_block(block_id, block)?;

    let result = node.call_contract(
        &block,
        call_params.from,
        call_params.to,
        call_params
            .data
            .try_into_unique_input()?
            .unwrap_or_default()
            .to_vec(),
        call_params.value.to(),
    )?;

    match ensure_success(result) {
        Ok(output) => Ok(output.to_hex()),
        Err(err) => Err(ErrorObjectOwned::from(err).into()),
    }
}

fn chain_id(params: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    expect_end_of_params(&mut params.sequence(), 0, 0)?;
    Ok(node.read().config.eth_chain_id.to_hex())
}

fn estimate_gas(params: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    let mut params = params.sequence();
    let call_params: CallParams = params.next()?;
    let block_number: BlockNumberOrTag = params.optional_next()?.unwrap_or_default();
    expect_end_of_params(&mut params, 1, 2)?;

    let return_value = node.read().estimate_gas(
        block_number,
        call_params.from,
        call_params.to,
        call_params
            .data
            .try_into_unique_input()?
            .unwrap_or_default()
            .to_vec(),
        call_params.gas.map(|g| EvmGas(g.to())),
        call_params.gas_price.map(|g| g.to()),
        call_params.value.to(),
    )?;

    Ok(return_value.to_hex())
}

fn get_balance(params: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    let mut params = params.sequence();
    let address: ZilAddress = params.next()?;
    let address: Address = address.into();

    let block_id: BlockId = params.next()?;
    expect_end_of_params(&mut params, 2, 2)?;

    let node = node.read();
    let block = node.get_block(block_id)?;

    let block = build_errored_response_for_missing_block(block_id, block)?;

    Ok(node
        .get_state(&block)?
        .get_account(address)?
        .balance
        .to_hex())
}

pub fn get_block_transaction_receipts_inner(
    node: &RwLockReadGuard<Node>,
    block_id: impl Into<BlockId>,
) -> Result<Vec<eth::TransactionReceipt>> {
    let Some(block) = node.get_block(block_id)? else {
        return Err(anyhow!("Block not found"));
    };

    let mut log_index = 0;
    let mut receipts = Vec::new();

    let receipts_retrieved = node.get_transaction_receipts_in_block(block.header.hash)?;

    for (transaction_index, receipt_retrieved) in receipts_retrieved.iter().enumerate() {
        // This could maybe be a bit faster if we had a db function that queried transactions by
        // block hash, joined on receipts, but this would be quite a bit of new code.
        let Some(signed_transaction) = node.get_transaction_by_hash(receipt_retrieved.tx_hash)?
        else {
            warn!(
                "Failed to get TX by hash when getting TX receipt! {}",
                receipt_retrieved.tx_hash
            );
            continue;
        };

        // Required workaround for incorrectly converted nonces for zq1 scilla transactions
        let contract_address = match &signed_transaction.tx {
            SignedTransaction::Zilliqa { tx, .. } => {
                if tx.to_addr.is_zero() && receipt_retrieved.success {
                    Some(zil_contract_address(
                        signed_transaction.signer,
                        signed_transaction
                            .tx
                            .nonce()
                            .ok_or_else(|| anyhow!("Unable to extract nonce!"))?,
                    ))
                } else {
                    receipt_retrieved.contract_address
                }
            }
            _ => receipt_retrieved.contract_address,
        };

        let mut logs_bloom = [0; 256];

        let mut logs = Vec::new();
        for log in receipt_retrieved.logs.iter() {
            let log = match log {
                Log::Evm(log) => log.clone(),
                Log::Scilla(log) => log.clone().into_evm(),
            };
            let log = eth::Log::new(
                log,
                log_index,
                transaction_index,
                receipt_retrieved.tx_hash,
                block.number(),
                block.hash(),
            );
            log_index += 1;
            log.bloom(&mut logs_bloom);
            logs.push(log);
        }

        let from = signed_transaction.signer;
        let v = signed_transaction.tx.sig_v();
        let r = signed_transaction.tx.sig_r();
        let s = signed_transaction.tx.sig_s();
        let transaction = signed_transaction.tx.into_transaction();

        let receipt = eth::TransactionReceipt {
            transaction_hash: (receipt_retrieved.tx_hash).into(),
            transaction_index: transaction_index as u64,
            block_hash: block.hash().into(),
            block_number: block.number(),
            from,
            to: transaction.to_addr(),
            cumulative_gas_used: receipt_retrieved.cumulative_gas_used,
            effective_gas_price: transaction.max_fee_per_gas(),
            gas_used: receipt_retrieved.gas_used,
            contract_address,
            logs,
            logs_bloom,
            ty: 0,
            status: receipt_retrieved.success,
            v,
            r,
            s,
        };

        receipts.push(receipt);
    }

    Ok(receipts)
}

// This has to iterate through a whole block, so get_block_transaction_receipts_inner is more efficient for multiple receipts
pub fn get_transaction_receipt_inner_slow(
    node: &RwLockReadGuard<Node>,
    block_id: impl Into<BlockId>,
    txn_hash: Hash,
) -> Result<Option<eth::TransactionReceipt>> {
    let receipts = get_block_transaction_receipts_inner(node, block_id)?;
    Ok(receipts
        .into_iter()
        .find(|r| r.transaction_hash == txn_hash.as_bytes()))
}

fn get_block_receipts(params: Params, node: &Arc<RwLock<Node>>) -> Result<Vec<TransactionReceipt>> {
    let block_id: BlockId = params.one()?;
    let node = node.read();

    get_block_transaction_receipts_inner(&node, block_id)
}

fn get_code(params: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    let mut params = params.sequence();
    let address: Address = params.next()?;
    let block_id: BlockId = params.next()?;
    expect_end_of_params(&mut params, 2, 2)?;

    let node = node.read();
    let block = node.get_block(block_id)?;

    let block = build_errored_response_for_missing_block(block_id, block)?;

    // For compatibility with Zilliqa 1, eth_getCode also returns Scilla code if any is present.
    let code = node.get_state(&block)?.get_account(address)?.code;

    // do it this way so the compiler will tell us when another option inevitably
    // turns up and we have to deal with it ..
    let return_code = if code.is_eoa() {
        vec![].to_hex()
    } else {
        match code {
            Code::Evm(val) => val.to_hex(),
            Code::Scilla { code, .. } => code.to_hex(),
        }
    };

    Ok(return_code)
}

fn get_storage_at(params: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    let mut params = params.sequence();
    let address: Address = params.next()?;
    let position: U256 = params.next()?;
    let position = B256::new(position.to_be_bytes());
    let block_id: BlockId = params.next()?;
    expect_end_of_params(&mut params, 3, 3)?;

    let node = node.read();
    let block = node.get_block(block_id)?;
    let block = build_errored_response_for_missing_block(block_id, block)?;

    let value = node
        .get_state(&block)?
        .get_account_storage(address, position)?;

    Ok(value.to_hex())
}

fn get_transaction_count(params: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    let mut params = params.sequence();
    let address: Address = params.next()?;
    let block_id: BlockId = params.next()?;
    expect_end_of_params(&mut params, 3, 3)?;

    let node = node.read();

    let block = node.get_block(block_id)?;
    let block = build_errored_response_for_missing_block(block_id, block)?;

    let nonce = node.get_state(&block)?.get_account(address)?.nonce;

    if matches!(block_id, BlockId::Number(BlockNumberOrTag::Pending)) {
        Ok(node.consensus.pending_transaction_count(address).to_hex())
    } else {
        Ok(nonce.to_hex())
    }
}

fn get_gas_price(params: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    expect_end_of_params(&mut params.sequence(), 0, 0)?;
    Ok(node.read().get_gas_price().to_hex())
}

fn get_block_by_number(params: Params, node: &Arc<RwLock<Node>>) -> Result<Option<eth::Block>> {
    let mut params = params.sequence();
    let block_number: BlockNumberOrTag = params.next()?;
    let full: bool = params.next()?;
    expect_end_of_params(&mut params, 2, 2)?;

    let node = node.read();
    let block = node.get_block(block_number)?;
    let block = block.map(|b| convert_block(&node, &b, full)).transpose()?;

    Ok(block)
}

fn get_block_by_hash(params: Params, node: &Arc<RwLock<Node>>) -> Result<Option<eth::Block>> {
    let mut params = params.sequence();
    let hash: B256 = params.next()?;
    let full: bool = params.next()?;
    expect_end_of_params(&mut params, 2, 2)?;

    let node = node.read();
    let block = node
        .get_block(hash)?
        .map(|b| convert_block(&node, &b, full))
        .transpose()?;

    Ok(block)
}

pub fn get_block_logs_bloom(node: &RwLockReadGuard<Node>, block: &Block) -> Result<[u8; 256]> {
    let mut logs_bloom = [0; 256];
    let receipts = get_block_transaction_receipts_inner(node, block.header.hash)?;
    for txn_receipt in receipts {
        // Ideally we'd implement a full blown bloom filter type but this'll do for now
        txn_receipt.logs.iter().for_each(|log| {
            log.bloom(&mut logs_bloom);
        });
    }
    Ok(logs_bloom)
}

fn convert_block(node: &RwLockReadGuard<Node>, block: &Block, full: bool) -> Result<eth::Block> {
    let logs_bloom = get_block_logs_bloom(node, block)?;
    if !full {
        let miner = node.get_proposer_reward_address(block.header)?;
        let block_gas_limit = block.gas_limit();
        Ok(eth::Block::from_block(
            block,
            miner.unwrap_or_default(),
            block_gas_limit,
            logs_bloom,
        ))
    } else {
        let transactions = block
            .transactions
            .iter()
            .map(|h| {
                get_transaction_inner(*h, node)?
                    .ok_or_else(|| anyhow!("missing transaction: {}", h))
            })
            .map(|t| Ok(HashOrTransaction::Transaction(t?)))
            .collect::<Result<_>>()?;
        let miner = node.get_proposer_reward_address(block.header)?;
        let block_gas_limit = block.gas_limit();
        let block = eth::Block::from_block(
            block,
            miner.unwrap_or_default(),
            block_gas_limit,
            logs_bloom,
        );
        Ok(eth::Block {
            transactions,
            ..block
        })
    }
}

fn get_block_transaction_count_by_hash(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<Option<String>> {
    let mut params = params.sequence();
    let hash: B256 = params.next()?;
    expect_end_of_params(&mut params, 1, 1)?;

    let node = node.read();
    let block = node.get_block(hash)?;

    Ok(block.map(|b| b.transactions.len().to_hex()))
}

fn get_block_transaction_count_by_number(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<Option<String>> {
    let mut params = params.sequence();
    // The ethereum RPC spec says this is optional, but it is mandatory in geth and erigon.
    let block_number: BlockNumberOrTag = params.next()?;
    expect_end_of_params(&mut params, 1, 1)?;

    let node = node.read();
    let block = node.get_block(block_number)?;

    Ok(Some(
        block.map_or(0, |block| block.transactions.len()).to_hex(),
    ))
}

fn get_logs(params: Params, node: &Arc<RwLock<Node>>) -> Result<Vec<eth::Log>> {
    let mut seq = params.sequence();
    let params: alloy::rpc::types::Filter = seq.next()?;
    expect_end_of_params(&mut seq, 1, 1)?;
    let node = node.read();
    get_logs_inner(&params, &node)
}

fn get_logs_inner(
    params: &alloy::rpc::types::Filter,
    node: &RwLockReadGuard<Node>,
) -> Result<Vec<eth::Log>> {
    let filter_params = FilteredParams::new(Some(params.clone()));

    // Find the range of blocks we care about. This is an iterator of blocks.
    let blocks = match params.block_option {
        alloy::rpc::types::FilterBlockOption::AtBlockHash(block_hash) => {
            Either::Left(std::iter::once(Ok(node
                .get_block(block_hash)?
                .ok_or_else(|| anyhow!("block not found"))?)))
        }
        alloy::rpc::types::FilterBlockOption::Range {
            from_block,
            to_block,
        } => {
            let Some(from) = node
                .resolve_block_number(from_block.unwrap_or(BlockNumberOrTag::Latest))?
                .as_ref()
                .map(Block::number)
            else {
                return Ok(vec![]);
            };

            let to = match node
                .resolve_block_number(to_block.unwrap_or(BlockNumberOrTag::Latest))?
                .as_ref()
            {
                Some(block) => block.number(),
                None => node
                    .resolve_block_number(BlockNumberOrTag::Latest)?
                    .unwrap()
                    .number(),
            };

            if from > to {
                return Err(anyhow!("`from` is greater than `to` ({from} > {to})"));
            }

            Either::Right((from..=to).map(|number| {
                node.get_block(number)?
                    .ok_or_else(|| anyhow!("missing block: {number}"))
            }))
        }
    };

    let mut logs = vec![];

    for block in blocks {
        let block = block?;

        for (txn_index, txn_hash) in block.transactions.iter().enumerate() {
            let receipt = node
                .get_transaction_receipt(*txn_hash)?
                .ok_or(anyhow!("missing receipt"))?;

            for (log_index, log) in receipt.logs.into_iter().enumerate() {
                let log = match log {
                    Log::Evm(l) => l,
                    Log::Scilla(l) => l.into_evm(),
                };

                if !filter_params.filter_address(&log.address) {
                    continue;
                }

                if !filter_params.filter_topics(&log.topics) {
                    continue;
                }

                logs.push(eth::Log::new(
                    log,
                    log_index,
                    txn_index,
                    *txn_hash,
                    block.number(),
                    block.hash(),
                ));
            }
        }
    }

    Ok(logs)
}

fn get_transaction_by_block_hash_and_index(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<Option<eth::Transaction>> {
    let mut params = params.sequence();
    let block_hash: B256 = params.next()?;
    let index: U64 = params.next()?;
    expect_end_of_params(&mut params, 2, 2)?;
    let node = node.read();

    let Some(block) = node.get_block(block_hash)? else {
        return Ok(None);
    };
    let Some(txn_hash) = block.transactions.get(index.to::<usize>()) else {
        return Ok(None);
    };

    get_transaction_inner(*txn_hash, &node)
}

fn get_transaction_by_block_number_and_index(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<Option<eth::Transaction>> {
    let mut params = params.sequence();
    let block_number: BlockNumberOrTag = params.next()?;
    let index: U64 = params.next()?;
    expect_end_of_params(&mut params, 2, 2)?;

    let node = node.read();

    let Some(block) = node.get_block(block_number)? else {
        return Ok(None);
    };
    let Some(txn_hash) = block.transactions.get(index.to::<usize>()) else {
        return Ok(None);
    };

    get_transaction_inner(*txn_hash, &node)
}

fn get_transaction_by_hash(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<Option<eth::Transaction>> {
    let hash: B256 = params.one()?;
    let hash: Hash = Hash(hash.0);
    let node = node.read();

    get_transaction_inner(hash, &node)
}

pub(super) fn get_transaction_inner(
    hash: Hash,
    node: &RwLockReadGuard<Node>,
) -> Result<Option<eth::Transaction>> {
    let Some(tx) = node.get_transaction_by_hash(hash)? else {
        return Ok(None);
    };

    // The block can either be null or some based on whether the tx exists
    let block = if let Some(receipt) = node.get_transaction_receipt(hash)? {
        node.get_block(receipt.block_hash)?
    } else {
        // Even if it has not been mined, the tx may still be in the mempool and should return
        // a correct tx, with pending/null fields
        None
    };

    Ok(Some(eth::Transaction::new(tx, block)))
}

fn get_transaction_receipt(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<Option<eth::TransactionReceipt>> {
    let hash: B256 = params.one()?;
    let hash: Hash = hash.into();
    let node = node.read();
    let block_hash = match node.get_transaction_receipt(hash)? {
        Some(receipt) => receipt.block_hash,
        None => return Ok(None),
    };
    get_transaction_receipt_inner_slow(&node, block_hash, hash)
}

fn send_raw_transaction(params: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    let transaction: String = params.one()?;
    let transaction = transaction
        .strip_prefix("0x")
        .ok_or_else(|| anyhow!("no 0x prefix"))?;
    let transaction = hex::decode(transaction)?;
    let transaction = parse_transaction(&transaction)?;

    let transaction = transaction.verify()?;

    let (hash, result) = node.read().create_transaction(transaction)?;
    match result {
        TxAddResult::AddedToMempool
        | TxAddResult::Duplicate(_)
        | TxAddResult::SameNonceButLowerGasPrice => Ok(()),
        TxAddResult::CannotVerifySignature => Err(ErrorObject::owned::<String>(
            ErrorCode::TransactionRejected as i32,
            "Cannot verify signature".to_string(),
            None,
        )),
        TxAddResult::ValidationFailed(reason) => Err(ErrorObject::owned::<String>(
            ErrorCode::InvalidParams as i32,
            reason.to_msg_string(),
            None,
        )),
        TxAddResult::NonceTooLow(got, expected) => Err(ErrorObject::owned::<String>(
            ErrorCode::InvalidParams as i32,
            format!("Nonce ({got}) lower than current ({expected})"),
            None,
        )),
    }?;
    let transaction_hash = B256::from(hash);

    Ok(transaction_hash.to_hex())
}

fn parse_transaction(bytes: &[u8]) -> Result<SignedTransaction> {
    // https://eips.ethereum.org/EIPS/eip-2718#backwards-compatibility
    // "Clients can differentiate between the legacy transactions and typed transactions by looking at the first byte.
    // If it starts with a value in the range [0, 0x7f] then it is a new transaction type, if it starts with a value in
    // the range [0xc0, 0xfe] then it is a legacy transaction type."
    match bytes[0] {
        0xc0..=0xfe => parse_legacy_transaction(bytes),
        0x01 => parse_eip2930_transaction(&bytes[1..]),
        0x02 => parse_eip1559_transaction(&bytes[1..]),
        _ => Err(anyhow!(
            "invalid transaction with starting byte {}",
            bytes[0]
        )),
    }
}

fn parse_legacy_transaction(mut buf: &[u8]) -> Result<SignedTransaction> {
    let (tx, sig) = TxLegacy::rlp_decode_with_signature(&mut buf)?;
    Ok(SignedTransaction::Legacy { tx, sig })
}

fn parse_eip2930_transaction(mut buf: &[u8]) -> Result<SignedTransaction> {
    let (tx, sig) = TxEip2930::rlp_decode_with_signature(&mut buf)?;
    Ok(SignedTransaction::Eip2930 { tx, sig })
}

fn parse_eip1559_transaction(mut buf: &[u8]) -> Result<SignedTransaction> {
    let (tx, sig) = TxEip1559::rlp_decode_with_signature(&mut buf)?;
    Ok(SignedTransaction::Eip1559 { tx, sig })
}

fn get_uncle_count(_: Params, _: &Arc<RwLock<Node>>) -> Result<String> {
    Ok("0x0".to_string())
}

fn get_uncle(_: Params, _: &Arc<RwLock<Node>>) -> Result<Option<String>> {
    Ok(None)
}

fn mining(_: Params, _: &Arc<RwLock<Node>>) -> Result<bool> {
    Ok(false)
}

fn protocol_version(_: Params, _: &Arc<RwLock<Node>>) -> Result<String> {
    Ok("0x41".to_string())
}

fn syncing(params: Params, node: &Arc<RwLock<Node>>) -> Result<SyncingResult> {
    expect_end_of_params(&mut params.sequence(), 0, 0)?;
    if let Some(result) = node.read().consensus.get_sync_data()? {
        Ok(SyncingResult::Struct(result))
    } else {
        Ok(SyncingResult::Bool(false))
    }
}

#[allow(clippy::redundant_allocation, clippy::await_holding_lock)]
async fn subscribe(
    params: Params<'_>,
    pending: PendingSubscriptionSink,
    node: Arc<Arc<RwLock<Node>>>,
    _: Extensions,
) -> Result<(), StringError> {
    let mut params = params.sequence();
    let kind: SubscriptionKind = params.next()?;
    let params: Option<pubsub::Params> = params.optional_next()?;
    let params = params.unwrap_or_default();

    let sink = pending.accept().await?;

    let node_lock = node.read();

    match kind {
        SubscriptionKind::NewHeads => {
            let mut new_blocks = node_lock.subscribe_to_new_blocks();
            std::mem::drop(node_lock);

            while let Ok(header) = new_blocks.recv().await {
                let node_lock = node.read();
                let miner = node_lock.get_proposer_reward_address(header)?;
                let block_gas_limit = node_lock.config.consensus.eth_block_gas_limit;
                let block = node_lock
                    .get_block(header.hash)?
                    .ok_or_else(|| anyhow!("missing block"))?;
                let logs_bloom = get_block_logs_bloom(&node_lock, &block)?;
                std::mem::drop(node_lock);
                let header = eth::Header::from_header(
                    header,
                    miner.unwrap_or_default(),
                    block_gas_limit,
                    logs_bloom,
                );
                let _ = sink.send(SubscriptionMessage::from_json(&header)?).await;
            }
        }
        SubscriptionKind::Logs => {
            let filter = match params {
                pubsub::Params::None => None,
                pubsub::Params::Logs(f) => Some(*f),
                pubsub::Params::Bool(_) => {
                    return Err("invalid params for logs".into());
                }
            };
            let filter = FilteredParams::new(filter);

            let mut receipts = node_lock.subscribe_to_receipts();
            std::mem::drop(node_lock);

            'outer: while let Ok((receipt, transaction_index)) = receipts.recv().await {
                let node_lock = node.read();
                if !filter.filter_block_hash(receipt.block_hash.into()) {
                    continue;
                }

                // We track log index plus one because we have to increment before we use the log index, and log indexes are 0-based.
                let mut log_index_plus_one: i64 =
                    get_block_transaction_receipts_inner(&node_lock, receipt.block_hash)?
                        .iter()
                        .take_while(|x| x.transaction_index < receipt.index)
                        .map(|x| x.logs.len())
                        .sum::<usize>() as i64;

                let mut logs = Vec::new();
                for log in receipt.logs.into_iter() {
                    log_index_plus_one += 1;
                    // Only consider EVM logs
                    let Log::Evm(log) = log else {
                        continue;
                    };
                    if !filter.filter_address(&log.address) {
                        continue;
                    }
                    if !filter.filter_topics(&log.topics) {
                        continue;
                    }

                    // We defer this check to later to avoid querying the block if the log was already filtered out by
                    // something else.
                    let block = node_lock
                        .get_block(receipt.block_hash)?
                        .ok_or_else(|| anyhow!("missing block"))?;
                    if !filter.filter_block_range(block.number()) {
                        continue 'outer;
                    }

                    logs.push(alloy::rpc::types::Log {
                        inner: alloy::primitives::Log {
                            address: log.address,
                            data: alloy::primitives::LogData::new_unchecked(
                                log.topics,
                                log.data.into(),
                            ),
                        },
                        block_hash: Some(block.hash().into()),
                        block_number: Some(block.number()),
                        block_timestamp: Some(
                            block
                                .timestamp()
                                .duration_since(SystemTime::UNIX_EPOCH)
                                .unwrap_or_default()
                                .as_secs(),
                        ),
                        transaction_hash: Some(receipt.tx_hash.into()),
                        transaction_index: Some(transaction_index as u64),
                        log_index: Some((log_index_plus_one - 1) as u64),
                        removed: false,
                    });
                }
                std::mem::drop(node_lock);
                for log in logs {
                    let _ = sink.send(SubscriptionMessage::from_json(&log)?).await;
                }
            }
        }
        SubscriptionKind::NewPendingTransactions => {
            let full = match params {
                pubsub::Params::None => false,
                pubsub::Params::Bool(b) => b,
                pubsub::Params::Logs(_) => {
                    return Err("invalid params for newPendingTransactions".into());
                }
            };

            if full {
                let mut txns = node_lock.subscribe_to_new_transactions();
                std::mem::drop(node_lock);

                while let Ok(txn) = txns.recv().await {
                    let txn = eth::Transaction::new(txn, None);
                    let _ = sink.send(SubscriptionMessage::from_json(&txn)?).await;
                }
            } else {
                let mut txns = node_lock.subscribe_to_new_transaction_hashes();
                std::mem::drop(node_lock);

                while let Ok(txn) = txns.recv().await {
                    let _ = sink
                        .send(SubscriptionMessage::from_json(&B256::from(txn))?)
                        .await;
                }
            }
        }
        _ => {
            return Err("invalid subscription kind".into());
        }
    }

    Ok(())
}

/// eth_blobBaseFee
/// Returns the expected base fee for blobs in the next block
fn blob_base_fee(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    Err(anyhow!("API method eth_blobBaseFee is not implemented yet"))
}

/// eth_feeHistory
/// Returns the collection of historical gas information
fn fee_history(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    Err(anyhow!("API method eth_feeHistory is not implemented yet"))
}

/// eth_getAccount
/// Retrieve account details by specifying an address and a block number/tag.
fn get_account(params: Params, node: &Arc<RwLock<Node>>) -> Result<Account> {
    let mut params = params.sequence();
    let address: ZilAddress = params.next()?;
    let address: Address = address.into();
    let block_id: BlockId = params.next()?;
    expect_end_of_params(&mut params, 2, 2)?;

    let node = node.read();
    let block = node.get_block(block_id)?;
    let block = build_errored_response_for_missing_block(block_id, block)?;

    node.get_state(&block)?.get_account(address)
}

/// eth_getFilterChanges
/// Polling method for a filter, which returns an array of events that have occurred since the last poll.
fn get_filter_changes(params: Params, node: &Arc<RwLock<Node>>) -> Result<serde_json::Value> {
    let filter_id: u128 = params.one()?;

    let node = node.read();

    let mut filter = node
        .filters
        .get(filter_id)
        .ok_or(anyhow!("filter not found"))?;

    match &mut filter.kind {
        FilterKind::Block(block_filter) => {
            let headers = block_filter.poll()?;

            let results: Vec<_> = headers
                .into_iter()
                .map(|header| B256::from(header.hash).to_hex())
                .collect();

            Ok(json!(results))
        }

        FilterKind::PendingTx(pending_tx_filter) => {
            let pending_txns = pending_tx_filter.poll()?;
            let result: Vec<_> = pending_txns
                .into_iter()
                .map(|txn| B256::from(txn.hash).to_hex())
                .collect();
            Ok(json!(result))
        }

        FilterKind::Log(log_filter) => {
            // If necessary, adjust the filter so it ignores already returned blocks
            let last_block = log_filter.last_block_number; // exclusive
            let criteria_last_block = log_filter.criteria.get_from_block(); // inclusive
            let adjusted_criteria = *log_filter.criteria.clone();
            let adjusted_criteria = match (last_block, criteria_last_block) {
                (None, None) => adjusted_criteria,
                (None, Some(y)) => adjusted_criteria.from_block(y),
                (Some(x), None) => adjusted_criteria.from_block(x + 1),
                (Some(x), Some(y)) => adjusted_criteria.from_block(std::cmp::max(x + 1, y)),
            };

            // Get the logs
            let logs = get_logs_inner(&adjusted_criteria, &node)?;

            // Set the last recorded block in the filter to the most recent block in the returned logs
            let last_block = logs.iter().fold(None, |acc, x| {
                Some(std::cmp::max(x.block_number, acc.unwrap_or(0)))
            });
            log_filter.last_block_number = last_block;

            Ok(json!(logs))
        }
    }
}

/// eth_getFilterLogs
/// Returns an array of all logs matching filter with given id.
fn get_filter_logs(params: Params, node: &Arc<RwLock<Node>>) -> Result<serde_json::Value> {
    let filter_id: u128 = params.one()?;
    let node = node.read();

    if let Some(filter) = node.filters.get(filter_id) {
        match &filter.kind {
            FilterKind::Block(_) => Err(anyhow!("pending tx filter not supported")),
            FilterKind::PendingTx(_) => Err(anyhow!("pending tx filter not supported")),
            FilterKind::Log(log_filter) => {
                let result = get_logs_inner(&log_filter.criteria, &node)?;
                Ok(json!(result))
            }
        }
    } else {
        Err(anyhow!("filter not found"))
    }
}

/// eth_getProof
/// Returns the account and storage values of the specified account including the Merkle-proof.
fn get_proof(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    Err(anyhow!("API method eth_getProof is not implemented yet"))
}

/// eth_hashrate
/// Returns the number of hashes per second that the node is mining with.
fn hashrate(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    Err(anyhow!("API method eth_hashrate is not implemented yet"))
}

/// eth_maxPriorityFeePerGas
/// Get the priority fee needed to be included in a block.
fn max_priority_fee_per_gas(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    Err(anyhow!(
        "API method eth_maxPriorityFeePerGas is not implemented yet"
    ))
}

/// eth_newBlockFilter
/// Creates a filter in the node, to notify when a new block arrives. To check if the state has changed, call eth_getFilterChanges
fn new_block_filter(params: Params, node: &Arc<RwLock<Node>>) -> Result<u128> {
    expect_end_of_params(&mut params.sequence(), 0, 0)?;

    let node = node.read();

    let filter = BlockFilter {
        block_receiver: node.subscribe_to_new_blocks(),
    };
    let id = node.filters.add(FilterKind::Block(filter));
    Ok(id)
}

/// eth_newFilter
/// Creates a filter object, based on filter options, to notify when the state changes (logs). To check if the state has changed, call eth_getFilterChanges.
fn new_filter(params: Params, node: &Arc<RwLock<Node>>) -> Result<u128> {
    let criteria: alloy::rpc::types::Filter = params.one()?;
    let node = node.read();

    let id = node.filters.add(FilterKind::Log(LogFilter {
        criteria: Box::new(criteria),
        last_block_number: None,
    }));
    Ok(id)
}

/// eth_newPendingTransactionFilter
/// Creates a filter in the node to notify when new pending transactions arrive. To check if the state has changed, call eth_getFilterChanges.
fn new_pending_transaction_filter(params: Params, node: &Arc<RwLock<Node>>) -> Result<u128> {
    expect_end_of_params(&mut params.sequence(), 0, 0)?;
    let node = node.read();

    let filter = PendingTxFilter {
        pending_txn_receiver: node.subscribe_to_new_transactions(),
    };
    let id = node.filters.add(FilterKind::PendingTx(filter));
    Ok(id)
}

/// eth_signTransaction
/// Signs a transaction that can be submitted to the network later using eth_sendRawTransaction
fn sign_transaction(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    Err(anyhow!(
        "API method eth_signTransaction is not implemented yet"
    ))
}

/// eth_simulateV1
/// Simulates a series of transactions at a specific block height with optional state overrides. This method allows you to test transactions with custom block and state parameters without actually submitting them to the network.
fn simulate_v1(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    // TODO: disable_eip3607 for this call.
    Err(anyhow!("API method eth_simulateV1 is not implemented yet"))
}

/// eth_submitWork
/// Used for submitting a proof-of-work solution.
fn submit_work(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    Err(anyhow!("API method eth_submitWork is not implemented yet"))
}

/// eth_uninstallFilter
/// It uninstalls a filter with the given filter id.
fn uninstall_filter(params: Params, node: &Arc<RwLock<Node>>) -> Result<bool> {
    let filter_id: u128 = params.one()?;

    let node = node.read();

    Ok(node.filters.remove(filter_id))
}

```

`zilliqa/src/api/mod.rs`:

```rs
pub mod admin;
mod debug;
mod erigon;
pub mod eth;
mod net;
pub mod ots;
pub mod subscription_id_provider;
pub mod to_hex;
mod trace;
mod txpool;
pub mod types;
mod web3;
pub mod zilliqa;

pub fn rpc_module(
    node: Arc<RwLock<Node>>,
    enabled_apis: &[EnabledApi],
) -> RpcModule<Arc<RwLock<Node>>> {
    let mut module = RpcModule::new(node.clone());

    module
        .merge(admin::rpc_module(node.clone(), enabled_apis))
        .unwrap();
    module
        .merge(debug::rpc_module(node.clone(), enabled_apis))
        .unwrap();
    module
        .merge(erigon::rpc_module(node.clone(), enabled_apis))
        .unwrap();
    module
        .merge(eth::rpc_module(node.clone(), enabled_apis))
        .unwrap();
    module
        .merge(net::rpc_module(node.clone(), enabled_apis))
        .unwrap();
    module
        .merge(ots::rpc_module(node.clone(), enabled_apis))
        .unwrap();
    module
        .merge(trace::rpc_module(node.clone(), enabled_apis))
        .unwrap();
    module
        .merge(txpool::rpc_module(node.clone(), enabled_apis))
        .unwrap();
    module
        .merge(web3::rpc_module(node.clone(), enabled_apis))
        .unwrap();
    module
        .merge(zilliqa::rpc_module(node.clone(), enabled_apis))
        .unwrap();

    module
}

pub fn all_enabled() -> Vec<crate::cfg::EnabledApi> {
    [
        "admin", "debug", "erigon", "eth", "net", "ots", "trace", "txpool", "web3", "zilliqa",
    ]
    .into_iter()
    .map(|ns| crate::cfg::EnabledApi::EnableAll(ns.to_owned()))
    .collect()
}

/// Returns an `RpcModule<Arc<RwLock<Node>>>`. Call with the following syntax:
/// ```ignore
/// declare_module!(
///     node,
///     [
///         ("method1", method_one),
///         ("method2", method_two),
///     ],
/// )
/// ```
///
/// where `node` is an `Arc<RwLock<Node>>` and each implementation method has the signature
/// `Fn(jsonrpsee::types::Params, &Arc<RwLock<Node>>) -> Result<T>`.
///
/// Will panic if any of the method names collide.
macro_rules! declare_module {
    (
        $node:expr,
        $enabled_apis:expr,
        [ $(($name:expr, $method:expr)),* $(,)? ] $(,)?
    ) => {{
        let mut module: jsonrpsee::RpcModule<std::sync::Arc<parking_lot::RwLock<crate::node::Node>>> = jsonrpsee::RpcModule::new($node.clone());
        let meter = opentelemetry::global::meter("zilliqa");

        $(
            let enabled = $enabled_apis.iter().any(|n| n.enabled($name));
            let rpc_server_duration = meter
                .f64_histogram(opentelemetry_semantic_conventions::metric::RPC_SERVER_DURATION)
                .with_boundaries(vec![0.005, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1.0, 2.5, 5.0, 7.5, 10.0])
                .with_unit("s")
                .build();
            module
                .register_method($name, move |params, context, _| {
                    tracing::debug!("{}: params: {:?}", $name, params);
                    if !enabled {
                        return Err(jsonrpsee::types::ErrorObject::owned(
                            jsonrpsee::types::error::ErrorCode::InvalidRequest.code(),
                            format!("{} is disabled", $name),
                            None as Option<String>,
                        ));
                    }

                    let mut attributes = vec![
                        opentelemetry::KeyValue::new(opentelemetry_semantic_conventions::attribute::RPC_SYSTEM, "jsonrpc"),
                        opentelemetry::KeyValue::new(opentelemetry_semantic_conventions::attribute::RPC_SERVICE, "zilliqa.eth"),
                        opentelemetry::KeyValue::new(opentelemetry_semantic_conventions::attribute::RPC_METHOD, $name),
                        opentelemetry::KeyValue::new(opentelemetry_semantic_conventions::attribute::NETWORK_TRANSPORT, "tcp"),
                        opentelemetry::KeyValue::new(opentelemetry_semantic_conventions::attribute::RPC_JSONRPC_VERSION, "2.0"),
                    ];

                    let start = std::time::SystemTime::now();

                    #[allow(clippy::redundant_closure_call)]
                    let result = std::panic::catch_unwind(std::panic::AssertUnwindSafe(|| $method(params, context))).unwrap_or_else(|cause| {
                        Err(anyhow::anyhow!("Unhandled panic in RPC handler {} : {:?}", $name, cause))
                    });

                    let result = result.map_err(|e| {
                        // If the error is already an `ErrorObjectOwned`, we can just return that. Otherwise, wrap it
                        // with an `InternalError` code.
                        match e.downcast::<jsonrpsee::types::ErrorObjectOwned>() {
                            Ok(e) => e,
                            Err(e) => {
                                if !e.to_string().starts_with("Txn Hash not Present") {
                                     tracing::error!(?e);
                                }
                                jsonrpsee::types::ErrorObject::owned(
                                jsonrpsee::types::error::ErrorCode::InternalError.code(),
                                e.to_string(),
                                None as Option<String>,
                            )}
                        }
                    });
                    if let Err(err) = &result {
                        attributes.push(opentelemetry::KeyValue::new(opentelemetry_semantic_conventions::attribute::RPC_JSONRPC_ERROR_CODE, err.code() as i64));
                    }
                    rpc_server_duration.record(
                        start.elapsed().map_or(0.0, |d| d.as_secs_f64()),
                        &attributes,
                    );
                    result
                })
                .unwrap();
        )*

        module
    }}
}

use std::sync::Arc;

use declare_module;
use jsonrpsee::RpcModule;
use parking_lot::RwLock;

use crate::{cfg::EnabledApi, node::Node};

```

`zilliqa/src/api/net.rs`:

```rs
use std::sync::Arc;

use anyhow::Result;
use jsonrpsee::{RpcModule, types::Params};
use parking_lot::RwLock;

use crate::{cfg::EnabledApi, node::Node};

pub fn rpc_module(
    node: Arc<RwLock<Node>>,
    enabled_apis: &[EnabledApi],
) -> RpcModule<Arc<RwLock<Node>>> {
    super::declare_module!(
        node,
        enabled_apis,
        [
            ("net_listening", net_listening),
            ("net_peerCount", net_peer_count),
            ("net_version", version),
        ]
    )
}

/// net_listening
fn net_listening(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<bool> {
    Ok(true)
}

/// net_peerCount
fn net_peer_count(_: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    let peer_count = node.read().get_peer_num();
    Ok(format!("0x{:x}", peer_count))
}

/// net_version
fn version(_: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    Ok(node.read().config.eth_chain_id.to_string())
}

```

`zilliqa/src/api/ots.rs`:

```rs
use std::{borrow::Cow, sync::Arc};

use alloy::{
    eips::BlockId,
    primitives::{Address, B256},
};
use anyhow::{Result, anyhow};
use ethabi::Token;
use jsonrpsee::{RpcModule, types::Params};
use parking_lot::RwLock;
use serde_json::{Value, json};

use super::{
    eth::{
        get_block_transaction_receipts_inner, get_transaction_inner,
        get_transaction_receipt_inner_slow,
    },
    types::ots::{self, Operation, TraceEntry},
};
use crate::{
    api::to_hex::ToHex,
    cfg::EnabledApi,
    crypto::Hash,
    inspector::{self, CreatorInspector, OtterscanOperationInspector, OtterscanTraceInspector},
    node::Node,
    time::SystemTime,
};

pub fn rpc_module(
    node: Arc<RwLock<Node>>,
    enabled_apis: &[EnabledApi],
) -> RpcModule<Arc<RwLock<Node>>> {
    super::declare_module!(
        node,
        enabled_apis,
        [
            ("ots_getApiLevel", get_otterscan_api_level),
            ("ots_getBlockDetails", get_block_details),
            ("ots_getBlockDetailsByHash", get_block_details_by_hash),
            ("ots_getBlockTransactions", get_block_transactions),
            ("ots_getContractCreator", get_contract_creator),
            ("ots_getInternalOperations", get_internal_operations),
            (
                "ots_getTransactionBySenderAndNonce",
                get_transaction_by_sender_and_nonce
            ),
            ("ots_getTransactionError", get_transaction_error),
            ("ots_hasCode", has_code),
            ("ots_searchTransactionsAfter", search_transactions_after),
            ("ots_searchTransactionsBefore", search_transactions_before),
            ("ots_traceTransaction", trace_transaction),
        ],
    )
}

pub fn get_otterscan_api_level(_: Params, _: &Arc<RwLock<Node>>) -> Result<u64> {
    // https://github.com/otterscan/otterscan/blob/0a819f3557fe19c0f47327858261881ec5f56d6c/src/params.ts#L1
    Ok(8)
}

fn get_block_details(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<Option<ots::BlockDetails>> {
    let block_number: u64 = params.one()?;

    let Some(ref block) = node.read().get_block(block_number)? else {
        return Ok(None);
    };
    let miner = node.read().get_proposer_reward_address(block.header)?;

    let block_gas_limit = node.read().config.consensus.eth_block_gas_limit;
    Ok(Some(ots::BlockDetails::from_block(
        block,
        miner.unwrap_or_default(),
        block_gas_limit,
    )))
}

fn get_block_details_by_hash(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<Option<ots::BlockDetails>> {
    let block_hash: B256 = params.one()?;

    let Some(ref block) = node.read().get_block(block_hash)? else {
        return Ok(None);
    };
    let miner = node.read().get_proposer_reward_address(block.header)?;
    let block_gas_limit = node.read().config.consensus.eth_block_gas_limit;
    Ok(Some(ots::BlockDetails::from_block(
        block,
        miner.unwrap_or_default(),
        block_gas_limit,
    )))
}

fn get_block_transactions(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<Option<ots::BlockTransactions>> {
    let mut params = params.sequence();
    let block_number: u64 = params.next()?;
    let page_number: usize = params.next()?;
    let page_size: usize = params.next()?;

    let node = node.read();

    let Some(block) = node.get_block(block_number)? else {
        return Ok(None);
    };
    let miner = node.get_proposer_reward_address(block.header)?;

    let start = usize::min(page_number * page_size, block.transactions.len());
    let end = usize::min((page_number + 1) * page_size, block.transactions.len());

    let receipts = get_block_transaction_receipts_inner(&node, block_number)?;
    let transactions = block.transactions[start..end]
        .iter()
        .map(|hash| get_transaction_inner(*hash, &node))
        .collect::<Result<Vec<_>>>()?
        .into_iter()
        .flatten()
        .collect::<Vec<_>>();

    let block_gas_limit = node.config.consensus.eth_block_gas_limit;
    let full_block = ots::BlockWithTransactions {
        transactions,
        block: ots::Block::from_block(&block, miner.unwrap_or_default(), block_gas_limit),
    };

    Ok(Some(ots::BlockTransactions {
        full_block,
        receipts,
    }))
}

fn get_contract_creator(params: Params, node: &Arc<RwLock<Node>>) -> Result<Option<Value>> {
    let address: Address = params.one()?;

    let touched = node.read().get_touched_transactions(address)?;

    // Perform a linear search over each transaction which touched this address. Replay each one to try and find the
    // transaction which created it.
    for txn_hash in touched {
        // Replay the creation transaction to work out the creator. This is important for contracts which are created
        // by other contracts, for which the creator is not the same as `txn.from_addr`.
        let mut inspector = CreatorInspector::new(address);
        node.read().replay_transaction(txn_hash, &mut inspector)?;

        if let Some(creator) = inspector.creator() {
            return Ok(Some(json!({
                "hash": B256::from(txn_hash).to_hex(),
                "creator": creator.to_hex(),
            })));
        }
    }

    Ok(None)
}

fn get_internal_operations(params: Params, node: &Arc<RwLock<Node>>) -> Result<Vec<Operation>> {
    let txn_hash: B256 = params.one()?;
    let txn_hash = Hash(txn_hash.0);

    let mut inspector = OtterscanOperationInspector::default();
    node.read().replay_transaction(txn_hash, &mut inspector)?;

    Ok(inspector.entries())
}

fn get_transaction_by_sender_and_nonce(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<Option<String>> {
    let mut params = params.sequence();
    let sender: Address = params.next()?;
    let nonce: u64 = params.next()?;

    let node = node.read();
    let touched = node.get_touched_transactions(sender)?;

    // Iterate over each transaction which touched the sender. This will include transactions which weren't sent by the
    // sender which we need to filter out.
    for txn_hash in touched {
        let txn = node
            .get_transaction_by_hash(txn_hash)?
            .ok_or_else(|| anyhow!("missing transaction: {txn_hash}"))?;
        if txn.signer == sender && txn.tx.nonce().map(|n| n == nonce).unwrap_or(false) {
            return Ok(Some(B256::from(txn_hash).to_hex()));
        }
    }

    Ok(None)
}

fn get_transaction_error(params: Params, node: &Arc<RwLock<Node>>) -> Result<Cow<'static, str>> {
    let txn_hash: B256 = params.one()?;
    let txn_hash = Hash(txn_hash.0);

    let result = node
        .read()
        .replay_transaction(txn_hash, inspector::noop())?;

    if !result.exceptions().is_empty() {
        // If the transaction resulted in Scilla exceptions, concatenate them into a single string and ABI encode it.
        let error: String = itertools::intersperse_with(
            result.exceptions().iter().map(|e| e.message.as_str()),
            || ", ",
        )
        .collect();
        let error = ethabi::encode(&[Token::String(error)]);
        // Prefix the error with the function selector for 'Error'. This is how raw reverts are encoded in Solidity.
        let mut encoded = vec![0x08, 0xc3, 0x79, 0xa0];
        encoded.extend_from_slice(&error);
        Ok(encoded.to_hex().into())
    } else {
        match result.output() {
            Some(output) => Ok(output.to_hex().into()),
            _ => Ok("0x".into()),
        }
    }
}

fn has_code(params: Params, node: &Arc<RwLock<Node>>) -> Result<bool> {
    let mut params = params.sequence();
    let address: Address = params.next()?;
    let block_id: BlockId = params.optional_next()?.unwrap_or_default();

    let node = node.read();
    let block = node
        .get_block(block_id)?
        .ok_or_else(|| anyhow!("Unable to get the latest block!"))?;
    let empty = node.get_state(&block)?.get_account(address)?.code.is_eoa();

    Ok(!empty)
}

fn search_transactions_inner(
    node: &Arc<RwLock<Node>>,
    address: Address,
    block_number: u64,
    page_size: usize,
    reverse: bool,
) -> Result<ots::Transactions> {
    let mut touched = node.read().get_touched_transactions(address)?;

    // If searching in reverse, we should start with the most recent transaction and work backwards.
    if reverse {
        touched.reverse();
    }

    let mut transactions = Vec::with_capacity(page_size);
    let mut receipts = Vec::with_capacity(page_size);

    // Keep track of the current block number. Once we reach `page_size` transactions, we still need to continue adding
    // transactions from the current block.
    let mut current_block = u64::MAX;
    // This will be set to false if we break out of the loop, indicating to the caller there are further pages.
    let mut finished = true;

    for hash in touched {
        let txn = get_transaction_inner(hash, &node.read()).unwrap().unwrap();

        let txn_block_number = match txn.block_number {
            Some(txn_block_number) => txn_block_number,
            None => continue,
        };

        let cmp = if !reverse {
            PartialOrd::le
        } else {
            PartialOrd::ge
        };
        if cmp(&txn_block_number, &block_number) {
            continue;
        }

        // Don't break until we have at least `page_size` transactions AND we've added everything from the last searched block.
        if transactions.len() >= page_size && txn_block_number != current_block {
            finished = false;
            break;
        }

        let timestamp = node
            .read()
            .get_block(txn.block_hash.unwrap_or_default())?
            .unwrap()
            .timestamp();

        transactions.push(txn);

        let node = node.read();
        let receipt = ots::TransactionReceiptWithTimestamp {
            receipt: get_transaction_receipt_inner_slow(&node, txn_block_number, hash)
                .unwrap()
                .unwrap(),
            timestamp: timestamp
                .duration_since(SystemTime::UNIX_EPOCH)
                .unwrap()
                .as_secs(),
        };
        receipts.push(receipt);

        current_block = txn_block_number;
    }

    // The results should always be returned in descending order (latest to earliest). If we were searching forwards
    // in time, we should reverse the results to ensure they are in descending order.
    if !reverse {
        transactions.reverse();
        receipts.reverse();
    }

    // `first_page` should be set if this was the latest page in time and `last_page` should be set if this was the
    // earliest page in time.
    let (first_page, last_page) = if reverse {
        (block_number == u64::MAX, finished)
    } else {
        (finished, block_number == 0)
    };

    Ok(ots::Transactions {
        transactions,
        receipts,
        first_page,
        last_page,
    })
}

fn search_transactions_after(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<ots::Transactions> {
    let mut params = params.sequence();
    let address: Address = params.next()?;
    let block_number: u64 = params.next()?;
    let page_size: usize = params.next()?;

    search_transactions_inner(node, address, block_number, page_size, false)
}

fn search_transactions_before(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<ots::Transactions> {
    let mut params = params.sequence();
    let address: Address = params.next()?;
    let mut block_number: u64 = params.next()?;
    let page_size: usize = params.next()?;

    // A `block_number` of `0` tells us to search from the most recent block.
    if block_number == 0 {
        block_number = u64::MAX;
    }

    search_transactions_inner(node, address, block_number, page_size, true)
}

fn trace_transaction(params: Params, node: &Arc<RwLock<Node>>) -> Result<Vec<TraceEntry>> {
    let txn_hash: B256 = params.one()?;
    let txn_hash = Hash(txn_hash.0);

    let mut inspector = OtterscanTraceInspector::default();
    node.read().replay_transaction(txn_hash, &mut inspector)?;

    Ok(inspector.entries())
}

```

`zilliqa/src/api/subscription_id_provider.rs`:

```rs
use jsonrpsee::{server::IdProvider, types::SubscriptionId};

use super::to_hex::ToHex;

#[derive(Debug)]
pub struct EthIdProvider;

impl IdProvider for EthIdProvider {
    fn next_id(&self) -> SubscriptionId<'static> {
        rand::random::<u64>().to_hex().into()
    }
}

```

`zilliqa/src/api/to_hex.rs`:

```rs
use alloy::primitives::{Address, B128, B256, B512, U128, U256, U512};

use crate::{
    message::BitArray,
    transaction::{EvmGas, ScillaGas},
};

/// A version of [hex::ToHex] which is also implemented for integer types. This version also prefixes the produced
/// string with `"0x"` and omits leading zeroes for quantities (types with fixed lengths).
pub trait ToHex {
    fn to_hex_inner(&self, prefix: bool) -> String;

    fn to_hex(&self) -> String {
        self.to_hex_inner(true)
    }

    fn to_hex_no_prefix(&self) -> String {
        self.to_hex_inner(false)
    }
}

/// Generates an implementation of [ToHex] for types which implement `AsRef<[u8]>`.
macro_rules! as_ref_impl {
    ($T:ty) => {
        impl ToHex for $T {
            fn to_hex_inner(&self, prefix: bool) -> String {
                if prefix {
                    format!("0x{}", hex::encode(self))
                } else {
                    hex::encode(self)
                }
            }
        }
    };
}

/// Generates an implementation of [ToHex] for types which implement [std::fmt::LowerHex].
macro_rules! int_impl {
    ($T:ty) => {
        impl ToHex for $T {
            fn to_hex_inner(&self, prefix: bool) -> String {
                if prefix {
                    format!("{:#x}", self)
                } else {
                    format!("{:x}", self)
                }
            }
        }
    };
}

/// Generates an implementation of [ToHex] via a type's [serde::Serialize] implementation.
macro_rules! serde_impl {
    ($T:ty) => {
        impl ToHex for $T {
            fn to_hex_inner(&self, prefix: bool) -> String {
                let serde_json::Value::String(mut hex) = serde_json::to_value(self).unwrap() else {
                    panic!("did not deserialize to a string");
                };
                if !prefix {
                    hex = (&hex[2..]).to_owned();
                }
                hex
            }
        }
    };
}

impl<T: ToHex + ?Sized> ToHex for &T {
    fn to_hex_inner(&self, prefix: bool) -> String {
        (*self).to_hex_inner(prefix)
    }
}

impl<const N: usize> ToHex for [u8; N] {
    fn to_hex_inner(&self, prefix: bool) -> String {
        self.as_ref().to_hex_inner(prefix)
    }
}

impl ToHex for EvmGas {
    fn to_hex_inner(&self, prefix: bool) -> String {
        self.0.to_hex_inner(prefix)
    }
}

impl ToHex for ScillaGas {
    fn to_hex_inner(&self, prefix: bool) -> String {
        self.0.to_hex_inner(prefix)
    }
}

impl ToHex for BitArray {
    fn to_hex_inner(&self, prefix: bool) -> String {
        self.as_raw_slice().to_hex_inner(prefix)
    }
}

as_ref_impl!(str);
as_ref_impl!(String);
as_ref_impl!([u8]);
as_ref_impl!(Vec<u8>);
as_ref_impl!(B128);
as_ref_impl!(Address);
as_ref_impl!(B256);
as_ref_impl!(B512);

int_impl!(i8);
int_impl!(i16);
int_impl!(i32);
int_impl!(i64);
int_impl!(i128);
int_impl!(u8);
int_impl!(u16);
int_impl!(u32);
int_impl!(u64);
int_impl!(u128);
int_impl!(isize);
int_impl!(usize);
serde_impl!(U128);
serde_impl!(U256);
serde_impl!(U512);

#[cfg(test)]
mod tests {
    use std::assert_eq;

    use alloy::primitives::U128;

    use super::ToHex;

    #[test]
    fn test_as_ref_to_hex() {
        let cases = [
            (vec![], "0x"),
            (vec![0u8, 0, 0, 0], "0x00000000"),
            (vec![0, 0, 0, 1], "0x00000001"),
            (vec![1, 2, 3, 4], "0x01020304"),
        ];

        for (val, expected) in cases {
            let actual = val.to_hex();
            assert_eq!(expected, actual);
        }
    }

    #[test]
    fn test_int_to_hex() {
        let cases = [(0, "0x0"), (1, "0x1")];

        for (val, expected) in cases {
            let actual = val.to_hex();
            assert_eq!(expected, actual);
        }
    }

    #[test]
    fn test_big_int_to_hex() {
        let cases = [
            (U128::ZERO, "0x0"),
            (U128::try_from(256u64).unwrap(), "0x100"),
            (U128::MAX, "0xffffffffffffffffffffffffffffffff"),
        ];

        for (val, expected) in cases {
            let actual = val.to_hex();
            assert_eq!(expected, actual);
        }
    }
}

```

`zilliqa/src/api/trace.rs`:

```rs
use std::sync::Arc;

use alloy::{
    eips::BlockNumberOrTag,
    primitives::{Address, B256},
    rpc::types::trace::parity::{TraceResults, TraceType},
};
use anyhow::{Result, anyhow};
use jsonrpsee::{RpcModule, types::Params};
use parking_lot::RwLock;
use revm_inspectors::tracing::{TracingInspector, TracingInspectorConfig};
use serde::Deserialize;

use crate::{cfg::EnabledApi, crypto::Hash, exec::TransactionApplyResult, node::Node};

pub fn rpc_module(
    node: Arc<RwLock<Node>>,
    enabled_apis: &[EnabledApi],
) -> RpcModule<Arc<RwLock<Node>>> {
    super::declare_module!(
        node,
        enabled_apis,
        [
            ("trace_block", trace_block),
            ("trace_call", trace_call),
            ("trace_callMany", trace_call_many),
            ("trace_filter", trace_filter),
            ("trace_rawTransaction", trace_raw_transaction),
            (
                "trace_replayBlockTransactions",
                trace_replay_block_transactions
            ),
            ("trace_replayTransaction", trace_replay_transaction),
            ("trace_transaction", trace_transaction),
        ]
    )
}

/// trace_block
fn trace_block(params: Params, node: &Arc<RwLock<Node>>) -> Result<Vec<TraceResults>> {
    let mut params = params.sequence();
    let block_number: BlockNumberOrTag = params.next()?;

    // Default trace types for block tracing
    let trace_types = [TraceType::Trace, TraceType::StateDiff]
        .into_iter()
        .collect();

    let node = node.read();

    // Get the block
    let block = node
        .get_block(block_number)?
        .ok_or_else(|| anyhow!("missing block: {block_number}"))?;

    // Get the parent block
    let parent = node
        .get_block(block.parent_hash())?
        .ok_or_else(|| anyhow!("missing parent block: {}", block.parent_hash()))?;

    // Start from parent block's state
    let mut state = node
        .consensus
        .state()
        .at_root(parent.state_root_hash().into());

    let mut traces = Vec::new();

    // Process each transaction
    for &txn_hash in block.transactions.iter() {
        let txn = node
            .get_transaction_by_hash(txn_hash)?
            .ok_or_else(|| anyhow!("transaction not found: {txn_hash}"))?;

        // Create inspector for tracing
        let config = TracingInspectorConfig::from_parity_config(&trace_types);
        let mut inspector = TracingInspector::new(config);
        let pre_state = state.try_clone()?;

        // Apply the transaction
        let result = state.apply_transaction(txn, block.header, &mut inspector, true)?;

        // Build trace results
        if let TransactionApplyResult::Evm(result, ..) = result {
            let builder = inspector.into_parity_builder();
            let trace = builder.into_trace_results_with_state(&result, &trace_types, &pre_state)?;
            traces.push(trace);
        }
    }

    Ok(traces)
}

/// trace_call
fn trace_call(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    // TODO: disable_eip3607 for this call.
    Err(anyhow!("API method trace_call is not implemented yet"))
}

/// trace_callMany
fn trace_call_many(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    // TODO: disable_eip3607 for this call.
    Err(anyhow!("API method trace_callMany is not implemented yet"))
}

/// trace_filter
fn trace_filter(params: Params, node: &Arc<RwLock<Node>>) -> Result<Vec<TraceResults>> {
    #[derive(Debug, Deserialize)]
    struct TraceFilter {
        from_block: Option<BlockNumberOrTag>,
        to_block: Option<BlockNumberOrTag>,
        from_address: Option<Vec<Address>>,
        to_address: Option<Vec<Address>>,
        after: Option<u64>, // Offset
        count: Option<u64>, // Number of traces to return
    }

    let mut params = params.sequence();
    let filter: TraceFilter = params.next()?;

    let node = node.read();

    // Default to latest block if not specified
    let from_block = filter.from_block.unwrap_or(BlockNumberOrTag::Earliest);
    let to_block = filter.to_block.unwrap_or(BlockNumberOrTag::Latest);

    // Resolve block numbers
    let start_block = node
        .resolve_block_number(from_block)?
        .ok_or_else(|| anyhow!("invalid from_block"))?;
    let end_block = node
        .resolve_block_number(to_block)?
        .ok_or_else(|| anyhow!("invalid to_block"))?;

    // Validate block range
    if start_block.number() > end_block.number() {
        return Err(anyhow!("invalid block range"));
    }

    // Default trace types for filtering
    let trace_types = [TraceType::Trace, TraceType::StateDiff]
        .into_iter()
        .collect();

    // Paging information
    let mut txns_skipped_count = 0;
    let mut txns_returned_count = 0;

    let mut all_traces = Vec::new();

    // Process each block in range
    'block_loop: for block_num in start_block.number()..=end_block.number() {
        let Some(block) = node.get_block(BlockNumberOrTag::Number(block_num))? else {
            continue;
        };

        // Skip empty blocks
        if block.transactions.is_empty() {
            continue;
        }

        let parent = node
            .get_block(block.parent_hash())?
            .ok_or_else(|| anyhow!("missing parent block: {}", block.parent_hash()))?;

        let mut state = node
            .consensus
            .state()
            .at_root(parent.state_root_hash().into());

        // Process each transaction in the block
        for txn_hash in &block.transactions {
            let txn = match node.get_transaction_by_hash(*txn_hash)? {
                Some(tx) => tx,
                None => continue,
            };

            // Apply address filters
            let tx_from = txn.signer;
            let tx_to = txn.tx.clone().into_transaction().to_addr();

            if let Some(ref from_addrs) = filter.from_address {
                if !from_addrs.contains(&tx_from) {
                    continue;
                }
            }

            if let Some(ref to_addrs) = filter.to_address {
                if let Some(to_addr) = tx_to {
                    if !to_addrs.contains(&to_addr) {
                        continue;
                    }
                } else {
                    // Skip if filtering by to_address and this is a contract creation
                    continue;
                }
            }

            if filter.after.is_some() && txns_skipped_count < filter.after.unwrap() {
                txns_skipped_count += 1;
                continue;
            }
            if filter.count.is_some() && txns_returned_count >= filter.count.unwrap() {
                break 'block_loop;
            }
            txns_returned_count += 1;

            // Create inspector and trace the transaction
            let config = TracingInspectorConfig::from_parity_config(&trace_types);
            let mut inspector = TracingInspector::new(config);
            let pre_state = state.try_clone()?;

            let result = state.apply_transaction(txn, block.header, &mut inspector, true)?;

            // Only include EVM transaction traces
            if let TransactionApplyResult::Evm(result, ..) = result {
                let builder = inspector.into_parity_builder();
                let trace =
                    builder.into_trace_results_with_state(&result, &trace_types, &pre_state)?;
                all_traces.push(trace);
            }
        }
    }

    Ok(all_traces)
}

/// trace_rawTransaction
fn trace_raw_transaction(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    Err(anyhow!(
        "API method trace_rawTransaction is not implemented yet"
    ))
}

/// trace_replayBlockTransactions
fn trace_replay_block_transactions(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<()> {
    Err(anyhow!(
        "API method trace_replayBlockTransactions is not implemented yet"
    ))
}

/// trace_replayTransaction
fn trace_replay_transaction(params: Params, node: &Arc<RwLock<Node>>) -> Result<TraceResults> {
    let mut params = params.sequence();
    let txn_hash: B256 = params.next()?;
    let txn_hash: Hash = txn_hash.into();
    let trace_types = params.next()?;

    let trace = node.read().trace_evm_transaction(txn_hash, &trace_types)?;

    Ok(trace)
}

/// trace_transaction
fn trace_transaction(params: Params, node: &Arc<RwLock<Node>>) -> Result<TraceResults> {
    let mut params = params.sequence();
    let txn_hash: B256 = params.next()?;
    let txn_hash: Hash = txn_hash.into();

    // Default parity trace types for transaction tracing
    let trace_types = [TraceType::Trace, TraceType::VmTrace, TraceType::StateDiff]
        .into_iter()
        .collect();

    let trace = node.read().trace_evm_transaction(txn_hash, &trace_types)?;

    Ok(trace)
}

```

`zilliqa/src/api/txpool.rs`:

```rs
use std::{collections::HashMap, sync::Arc};

use alloy::primitives::Address;
use anyhow::Result;
use jsonrpsee::{RpcModule, types::Params};
use parking_lot::RwLock;

use super::types;
use crate::{api::types::eth::Transaction, cfg::EnabledApi, node::Node};

pub fn rpc_module(
    node: Arc<RwLock<Node>>,
    enabled_apis: &[EnabledApi],
) -> RpcModule<Arc<RwLock<Node>>> {
    super::declare_module!(
        node,
        enabled_apis,
        [
            ("txpool_content", txpool_content),
            ("txpool_contentFrom", txpool_content_from),
            ("txpool_inspect", txpool_inspect),
            ("txpool_status", txpool_status),
        ]
    )
}

/// txpool_content
fn txpool_content(
    _params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<Option<types::txpool::TxPoolContent>> {
    let mut node = node.write();
    let content = node.txpool_content();

    let pending = content
        .pending
        .into_iter()
        .map(|(k, v)| {
            (
                k,
                v.iter()
                    .filter(|x| x.tx.nonce().is_some())
                    .map(|x| (x.tx.nonce().unwrap(), Transaction::new(x.clone(), None)))
                    .collect(),
            )
        })
        .collect();

    let queued = content
        .queued
        .into_iter()
        .map(|(k, v)| {
            (
                k,
                v.iter()
                    .filter(|x| x.tx.nonce().is_some())
                    .map(|x| (x.tx.nonce().unwrap(), Transaction::new(x.clone(), None)))
                    .collect(),
            )
        })
        .collect();

    let result = types::txpool::TxPoolContent { pending, queued };

    Ok(Some(result))
}

/// txpool_contentFrom
fn txpool_content_from(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<types::txpool::TxPoolContent> {
    let address: super::zilliqa::ZilAddress = params.one()?;
    let address: Address = address.into();
    let mut node = node.write();
    let content = node.txpool_content_from(&address);

    let mut result = types::txpool::TxPoolContent {
        pending: HashMap::new(),
        queued: HashMap::new(),
    };

    for item in content.pending {
        if item.signer == address {
            let txns = result.pending.entry(item.signer).or_default();
            txns.insert(
                item.tx.nonce().unwrap(),
                Transaction::new(item.clone(), None),
            );
        }
    }

    for item in content.queued {
        if item.signer == address {
            let txns = result.queued.entry(item.signer).or_default();
            txns.insert(
                item.tx.nonce().unwrap(),
                Transaction::new(item.clone(), None),
            );
        }
    }

    Ok(result)
}

/// txpool_inspect
fn txpool_inspect(
    _params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<types::txpool::TxPoolInspect> {
    let mut node = node.write();
    let content = node.txpool_content();

    let mut result = types::txpool::TxPoolInspect {
        pending: HashMap::new(),
        queued: HashMap::new(),
    };

    for item in content.pending.values().flatten() {
        let txns = result.pending.entry(item.signer).or_default();
        let txn = Transaction::new(item.clone(), None);
        let summary = format!(
            "{}: {} wei + {} × {} wei",
            txn.to.unwrap_or_default(),
            txn.value,
            txn.gas,
            txn.gas_price
        );
        txns.insert(item.tx.nonce().unwrap(), summary);
    }

    for item in content.queued.values().flatten() {
        let txns = result.queued.entry(item.signer).or_default();
        let txn = Transaction::new(item.clone(), None);
        let summary = format!(
            "{}: {} wei + {} × {} wei",
            txn.to.unwrap_or_default(),
            txn.value,
            txn.gas,
            txn.gas_price
        );
        txns.insert(item.tx.nonce().unwrap(), summary);
    }

    Ok(result)
}

/// txpool_status
fn txpool_status(_params: Params, node: &Arc<RwLock<Node>>) -> Result<types::txpool::TxPoolStatus> {
    let mut node = node.write();
    let content = node.txpool_status();

    Ok(types::txpool::TxPoolStatus {
        pending: content.pending,
        queued: content.queued,
    })
}

```

`zilliqa/src/api/types/admin.rs`:

```rs
use libp2p::PeerId;
use serde::Serialize;

use crate::crypto::NodePublicKey;

#[derive(Clone, Debug, Serialize)]
pub struct VotesReceivedReturnee {
    pub votes: Vec<(crate::crypto::Hash, crate::consensus::BlockVotes, VoteCount)>,
    pub buffered_votes: Vec<(crate::crypto::Hash, Vec<(PeerId, crate::message::Vote)>)>,
    pub new_views: Vec<(u64, crate::consensus::NewViewVote, VoteCount)>,
}

#[derive(Clone, Debug, Serialize)]
pub struct VoteCount {
    pub voted: Vec<NodePublicKey>,
    pub not_voted: Vec<NodePublicKey>,
}

```

`zilliqa/src/api/types/eth.rs`:

```rs
use std::collections::HashMap;

use alloy::{
    consensus::TxEip1559,
    primitives::{Address, B256, U64, U128, U256},
    rpc::types::TransactionInput,
};
use serde::{Deserialize, Serialize};
use sha3::{Digest, Keccak256};

use super::{bool_as_int, hex, option_hex, vec_hex};
use crate::{
    api::types::ser_display,
    crypto::Hash,
    message::{self, BitArray},
    time::SystemTime,
    transaction::{self, EvmGas, EvmLog},
};

#[derive(Clone, Serialize)]
#[serde(untagged)]
#[allow(clippy::large_enum_variant)]
pub enum HashOrTransaction {
    Hash(B256),
    Transaction(Transaction),
}

#[derive(Clone, Debug, Serialize)]
pub struct QuorumCertificate {
    #[serde(serialize_with = "hex")]
    pub signature: Vec<u8>,
    #[serde(serialize_with = "hex")]
    pub cosigned: BitArray,
    #[serde(serialize_with = "hex")]
    pub view: u64,
    #[serde(serialize_with = "hex")]
    pub block_hash: B256,
}

impl QuorumCertificate {
    pub fn from_qc(qc: &message::QuorumCertificate) -> Self {
        Self {
            signature: qc.signature.to_bytes(),
            cosigned: qc.cosigned,
            view: qc.view,
            block_hash: qc.block_hash.into(),
        }
    }
}

#[derive(Clone)]
pub enum ErrorCode {
    ParseError = -32700,
    InvalidRequest = -32600,
    MethodNotFound = -32601,
    InvalidParams = -32602,
    InternalError = -32603,
    // missing or invalid parameters, apparently.
    InvalidInput = -32000,
    ResourceNotFound = -32001,
    ResourceUnavailable = -32002,
    // Transaction creation failed.
    TransactionRejected = -32003,
    MethodNotSupported = -32004,
    LimitExceeded = -32005,
    JSONRPCVersionNotSupported = -32006,
}

#[derive(Clone, Serialize)]
pub struct AggregateQc {
    #[serde(serialize_with = "hex")]
    pub signature: Vec<u8>,
    #[serde(serialize_with = "ser_display")]
    pub cosigned: BitArray,
    #[serde(serialize_with = "hex")]
    pub view: u64,
    pub quorum_certificates: Vec<QuorumCertificate>,
}

impl AggregateQc {
    pub fn from_agg(agg_qc: &Option<message::AggregateQc>) -> Option<Self> {
        agg_qc.as_ref().map(|agg_qc| Self {
            signature: agg_qc.signature.to_bytes(),
            cosigned: agg_qc.cosigned,
            view: agg_qc.view,
            quorum_certificates: agg_qc.qcs.iter().map(QuorumCertificate::from_qc).collect(),
        })
    }
}

/// A block object, returned by the Ethereum API.
#[derive(Clone, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct Block {
    #[serde(flatten)]
    pub header: Header,
    #[serde(serialize_with = "hex")]
    pub size: u64,
    pub transactions: Vec<HashOrTransaction>,
    pub uncles: Vec<B256>,
    pub quorum_certificate: QuorumCertificate,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub aggregate_quorum_certificate: Option<AggregateQc>,
}

impl Block {
    pub fn from_block(
        block: &message::Block,
        miner: Address,
        block_gas_limit: EvmGas,
        logs_bloom: [u8; 256],
    ) -> Self {
        Block {
            header: Header::from_header(block.header, miner, block_gas_limit, logs_bloom),
            size: block.size() as u64,
            transactions: block
                .transactions
                .iter()
                .map(|h| HashOrTransaction::Hash((*h).into()))
                .collect(),
            uncles: vec![], // Uncles do not exist in ZQ2
            quorum_certificate: QuorumCertificate::from_qc(&block.header.qc),
            aggregate_quorum_certificate: AggregateQc::from_agg(&block.agg),
        }
    }
}

#[derive(Clone, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct Header {
    #[serde(serialize_with = "hex")]
    pub number: u64,
    #[serde(serialize_with = "hex")]
    pub view: u64,
    #[serde(serialize_with = "hex")]
    pub hash: B256,
    #[serde(serialize_with = "hex")]
    pub parent_hash: B256,
    #[serde(serialize_with = "hex")]
    pub nonce: [u8; 8],
    #[serde(serialize_with = "hex")]
    pub sha_3_uncles: B256, // Uncles do not exist in ZQ2
    #[serde(serialize_with = "hex")]
    pub transactions_root: B256,
    #[serde(serialize_with = "hex")]
    pub state_root: B256,
    #[serde(serialize_with = "hex")]
    pub receipts_root: B256,
    #[serde(serialize_with = "hex")]
    pub miner: Address,
    #[serde(serialize_with = "hex")]
    pub difficulty: u64, // Difficulty does not exist in ZQ2
    #[serde(serialize_with = "hex")]
    pub total_difficulty: u64, // Difficulty does not exist in ZQ2
    #[serde(serialize_with = "hex")]
    pub extra_data: Vec<u8>,
    #[serde(serialize_with = "hex")]
    pub gas_limit: EvmGas,
    #[serde(serialize_with = "hex")]
    pub gas_used: EvmGas,
    #[serde(serialize_with = "hex")]
    pub timestamp: u64,
    #[serde(serialize_with = "hex")]
    pub mix_hash: B256,
    #[serde(serialize_with = "hex")]
    pub logs_bloom: [u8; 256],
}

impl Header {
    pub fn from_header(
        header: message::BlockHeader,
        miner: Address,
        block_gas_limit: EvmGas,
        logs_bloom: [u8; 256],
    ) -> Self {
        // TODO(#79): Lots of these fields are empty/zero and shouldn't be.
        Header {
            number: header.number,
            view: header.view,
            hash: header.hash.into(),
            parent_hash: header.qc.block_hash.into(),
            mix_hash: B256::ZERO,
            nonce: [0; 8],
            sha_3_uncles: "0x1dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d49347"
                .parse::<B256>()
                .unwrap(), // Uncles do not exist in ZQ2
            transactions_root: header.transactions_root_hash.into(),
            state_root: header.state_root_hash.into(),
            receipts_root: header.receipts_root_hash.into(),
            miner,
            difficulty: 0,       // Difficulty does not exist in ZQ2
            total_difficulty: 0, // Difficulty does not exist in ZQ2
            extra_data: vec![],
            gas_limit: block_gas_limit,
            gas_used: header.gas_used,
            timestamp: header
                .timestamp
                .duration_since(SystemTime::UNIX_EPOCH)
                .unwrap_or_default()
                .as_secs(),
            logs_bloom,
        }
    }
}

/// A transaction object, returned by the Ethereum API.
#[derive(Clone, Serialize, Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct Transaction {
    #[serde(serialize_with = "option_hex")]
    pub block_hash: Option<B256>,
    #[serde(serialize_with = "option_hex")]
    pub block_number: Option<u64>,
    #[serde(serialize_with = "hex")]
    pub from: Address,
    #[serde(serialize_with = "hex")]
    pub gas: EvmGas,
    #[serde(serialize_with = "hex")]
    pub gas_price: u128,
    #[serde(skip_serializing_if = "Option::is_none", serialize_with = "option_hex")]
    pub max_fee_per_gas: Option<u128>,
    #[serde(skip_serializing_if = "Option::is_none", serialize_with = "option_hex")]
    pub max_priority_fee_per_gas: Option<u128>,
    #[serde(serialize_with = "hex")]
    pub hash: B256,
    #[serde(serialize_with = "hex")]
    pub input: Vec<u8>,
    #[serde(serialize_with = "hex")]
    pub nonce: u64,
    #[serde(serialize_with = "option_hex")]
    pub to: Option<Address>,
    #[serde(serialize_with = "option_hex")]
    pub transaction_index: Option<u64>,
    #[serde(serialize_with = "hex")]
    pub value: u128,
    #[serde(serialize_with = "hex")]
    pub v: u64,
    #[serde(serialize_with = "hex")]
    pub r: U256,
    #[serde(serialize_with = "hex")]
    pub s: U256,
    #[serde(skip_serializing_if = "Option::is_none", serialize_with = "option_hex")]
    pub chain_id: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub access_list: Option<Vec<(Address, Vec<B256>)>>,
    #[serde(rename = "type", serialize_with = "hex")]
    pub transaction_type: u64,
}

impl Transaction {
    pub fn new(tx: transaction::VerifiedTransaction, block: Option<message::Block>) -> Self {
        let hash = tx.hash;
        let from = tx.signer;
        let v = tx.tx.sig_v();
        let r = tx.tx.sig_r();
        let s = tx.tx.sig_s();
        let transaction = tx.tx.into_transaction();
        let (gas_price, max_fee_per_gas, max_priority_fee_per_gas) = match transaction {
            transaction::Transaction::Legacy(_)
            | transaction::Transaction::Eip2930(_)
            | transaction::Transaction::Zilliqa(_)
            | transaction::Transaction::Intershard(_) => {
                (transaction.max_fee_per_gas(), None, None)
            }
            transaction::Transaction::Eip1559(TxEip1559 {
                max_fee_per_gas,
                max_priority_fee_per_gas,
                ..
            }) => (
                // The `gasPrice` for EIP-1559 transactions should be set to the effective gas price of this transaction,
                // which depends on the block's base fee. We don't yet have a base fee so we just set it to the max fee
                // per gas.
                max_fee_per_gas,
                Some(max_fee_per_gas),
                Some(max_priority_fee_per_gas),
            ),
        };
        Transaction {
            block_hash: block.as_ref().map(|b| b.hash().0.into()),
            block_number: block.as_ref().map(|b| b.number()),
            from,
            gas: transaction.gas_limit(),
            gas_price,
            max_fee_per_gas,
            max_priority_fee_per_gas,
            hash: hash.into(),
            input: transaction.payload().to_vec(),
            nonce: transaction.nonce().unwrap_or(u64::MAX),
            to: transaction.to_addr(),
            transaction_index: block
                .map(|b| b.transactions.iter().position(|t| *t == hash).unwrap() as u64),
            value: transaction.amount(),
            v,
            r,
            s,
            chain_id: transaction.chain_id(),
            access_list: transaction.access_list().map(|a| a.to_vec()),
            transaction_type: match transaction {
                transaction::Transaction::Legacy(_) => 0,
                transaction::Transaction::Eip2930(_) => 1,
                transaction::Transaction::Eip1559(_) => 2,
                // Set Zilliqa transaction types to a unique number. This is "ZIL" encoded in ASCII.
                transaction::Transaction::Zilliqa(_) => 90_73_76,
                // Set intershard transactions as unique, too. This is ZIL + 1.
                transaction::Transaction::Intershard(_) => 90_73_77,
            },
        }
    }
}

/// A transaction receipt object, returned by the Ethereum API.
#[derive(Debug, Clone, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct TransactionReceipt {
    #[serde(serialize_with = "hex")]
    pub transaction_hash: B256,
    #[serde(serialize_with = "hex")]
    pub transaction_index: u64,
    #[serde(serialize_with = "hex")]
    pub block_hash: B256,
    #[serde(serialize_with = "hex")]
    pub block_number: u64,
    #[serde(serialize_with = "hex")]
    pub from: Address,
    #[serde(serialize_with = "option_hex")]
    pub to: Option<Address>,
    #[serde(serialize_with = "hex")]
    pub cumulative_gas_used: EvmGas,
    #[serde(serialize_with = "hex")]
    pub effective_gas_price: u128,
    #[serde(serialize_with = "hex")]
    pub gas_used: EvmGas,
    #[serde(serialize_with = "option_hex")]
    pub contract_address: Option<Address>,
    pub logs: Vec<Log>,
    #[serde(serialize_with = "hex")]
    pub logs_bloom: [u8; 256],
    #[serde(rename = "type", serialize_with = "hex")]
    pub ty: u64,
    #[serde(serialize_with = "bool_as_int")]
    pub status: bool,
    #[serde(serialize_with = "hex")]
    pub v: u64,
    #[serde(serialize_with = "hex")]
    pub r: U256,
    #[serde(serialize_with = "hex")]
    pub s: U256,
}

/// A transaction receipt object, returned by the Ethereum API.
#[derive(Clone, Debug, Deserialize, Eq, Hash, PartialEq, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct Log {
    pub removed: bool,
    #[serde(serialize_with = "hex")]
    pub log_index: u64,
    #[serde(serialize_with = "hex")]
    pub transaction_index: u64,
    #[serde(serialize_with = "hex")]
    pub transaction_hash: B256,
    #[serde(serialize_with = "hex")]
    pub block_hash: B256,
    #[serde(serialize_with = "hex")]
    pub block_number: u64,
    #[serde(serialize_with = "hex")]
    pub address: Address,
    #[serde(serialize_with = "hex")]
    pub data: Vec<u8>,
    #[serde(serialize_with = "vec_hex")]
    pub topics: Vec<B256>,
}

impl Log {
    pub fn new(
        log: EvmLog,
        log_index: usize,
        transaction_index: usize,
        transaction_hash: Hash,
        block_number: u64,
        block_hash: Hash,
    ) -> Log {
        Log {
            removed: false,
            log_index: log_index as u64,
            transaction_index: transaction_index as u64,
            transaction_hash: transaction_hash.into(),
            block_hash: block_hash.into(),
            block_number,
            address: log.address,
            data: log.data,
            topics: log.topics,
        }
    }

    pub fn bloom(&self, bloom: &mut [u8; 256]) {
        m3_2048(bloom, self.address.as_slice());
        for topic in &self.topics {
            m3_2048(bloom, topic.as_slice());
        }
    }
}

// Adapted from https://github.com/paradigmxyz/reth/blob/c991a31e0d7bc8415e081d8549311122e7531c77/crates/primitives/src/bloom.rs#L194.
fn m3_2048(bloom: &mut [u8; 256], data: &[u8]) {
    let hash = Keccak256::digest(data);

    for i in [0usize, 2, 4] {
        // Calculate `m` by taking the bottom 11 bits of each pair from the hash. (2 ^ 11) - 1 = 2047.
        let m = (hash[i + 1] as usize + ((hash[i] as usize) << 8)) & 2047;
        // The bit at index `2047 - m` (big-endian) in `bloom` should be set to 1.
        let byte = m / 8;
        let bit = m % 8;
        bloom[255 - byte] |= 1 << bit;
    }
}

/// A type for representing null, a single item or an array of items.
#[derive(Clone, Debug, Deserialize, Serialize)]
#[serde(untagged)]
pub enum OneOrMany<T> {
    Null,
    One(T),
    Many(Vec<T>),
}

impl<T: PartialEq> OneOrMany<T> {
    pub fn contains(&self, x: &T) -> bool {
        match self {
            OneOrMany::Null => false,
            OneOrMany::One(item) => item == x,
            OneOrMany::Many(items) => items.contains(x),
        }
    }

    pub fn is_empty(&self) -> bool {
        match self {
            OneOrMany::Null => true,
            OneOrMany::One(_) => false,
            OneOrMany::Many(items) => items.is_empty(),
        }
    }
}

/// Parameters passed to `eth_call` and `eth_estimateGas`.
#[derive(Deserialize, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct CallParams {
    #[serde(default)]
    pub from: Address,
    pub to: Option<Address>,
    pub gas: Option<U64>,
    pub gas_price: Option<U128>,
    #[serde(default)]
    pub value: U128,
    #[serde(default, flatten)]
    pub data: TransactionInput,
}

#[derive(Clone, Serialize)]
pub struct TxPoolContent {
    pub pending: HashMap<Address, HashMap<u64, Transaction>>,
    pub queued: HashMap<Address, HashMap<u64, Transaction>>,
}

#[derive(Clone, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct SyncingMeta {
    pub current_phase: String,
    #[serde(serialize_with = "hex")]
    pub peer_count: usize,
    #[serde(serialize_with = "hex")]
    pub header_downloads: usize,
    #[serde(serialize_with = "hex")]
    pub block_downloads: usize,
    #[serde(serialize_with = "hex")]
    pub buffered_blocks: usize,
    #[serde(serialize_with = "hex")]
    pub empty_count: usize,
    #[serde(serialize_with = "hex")]
    pub retry_count: usize,
    #[serde(serialize_with = "hex")]
    pub error_count: usize,
    #[serde(serialize_with = "hex")]
    pub active_sync_count: usize,
}

#[derive(Clone, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct SyncingStruct {
    #[serde(serialize_with = "hex")]
    pub starting_block: u64,
    #[serde(serialize_with = "hex")]
    pub current_block: u64,
    #[serde(serialize_with = "hex")]
    pub highest_block: u64,
    pub stats: SyncingMeta,
}

#[derive(Clone, Serialize)]
#[serde(untagged)]
pub enum SyncingResult {
    Bool(bool),
    Struct(SyncingStruct),
}

#[cfg(test)]
mod tests {
    use alloy::primitives::B256;

    use super::Log;

    #[test]
    fn test_logs_bloom() {
        // Random example from Ethereum mainnet: https://etherscan.io/tx/0x0d70ebb14d21e085b5e9f68a157f58592147e2606f2b75aa996eb2e1648eab7e.
        let log = Log {
            removed: false,
            log_index: 0,
            transaction_index: 0,
            transaction_hash: B256::ZERO,
            block_hash: B256::ZERO,
            block_number: 0,
            address: "0xdac17f958d2ee523a2206206994597c13d831ec7"
                .parse()
                .unwrap(),
            data: vec![],
            topics: vec![
                "0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef"
                    .parse()
                    .unwrap(),
                "0x0000000000000000000000006113dbc74fa1bb8b39ba8d529cc3e212730ef796"
                    .parse()
                    .unwrap(),
                "0x000000000000000000000000c84eb339b9679c9febb073cb2657fa4bbdc48a9f"
                    .parse()
                    .unwrap(),
            ],
        };

        let expected = hex::decode("00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010002000010020000000000000000000000000000000000000000000008000000000000000000000000000000000000000000000000000040000000000000000000000000000000000100000010000000001000000000000000000000000000000000000000000000000000000000100000000000000000000000000080000000000000000000000000000000000000000000000002000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000").unwrap();
        let mut actual = [0; 256];
        log.bloom(&mut actual);
        assert_eq!(actual.as_slice(), expected.as_slice());
    }
}

```

`zilliqa/src/api/types/filters.rs`:

```rs
use std::{collections::HashMap, time::Duration};

use anyhow::anyhow;
use parking_lot::{MappedMutexGuard, Mutex, MutexGuard};

use crate::{message::BlockHeader, time::SystemTime, transaction::VerifiedTransaction};

#[derive(Debug)]
pub struct Filter {
    pub last_poll: SystemTime,
    pub kind: FilterKind,
}

#[derive(Debug)]
pub enum FilterKind {
    Block(BlockFilter),
    PendingTx(PendingTxFilter),
    Log(LogFilter),
}

#[derive(Debug)]
pub struct BlockFilter {
    pub block_receiver: tokio::sync::broadcast::Receiver<BlockHeader>,
}

impl BlockFilter {
    pub fn poll(&mut self) -> anyhow::Result<Vec<BlockHeader>> {
        let mut headers = Vec::new();

        // Try to receive all currently available messages
        loop {
            match self.block_receiver.try_recv() {
                Ok(header) => {
                    // Successfully got a header, add it to our vec
                    headers.push(header);
                }
                Err(tokio::sync::broadcast::error::TryRecvError::Empty) => {
                    // No more messages available, we're done
                    break;
                }
                Err(tokio::sync::broadcast::error::TryRecvError::Lagged(skipped)) => {
                    // We've lagged behind, some messages were missed
                    return Err(anyhow!(
                        "Filter was not polled in time, {} blocks missed",
                        skipped
                    ));
                }
                Err(tokio::sync::broadcast::error::TryRecvError::Closed) => {
                    // Channel is closed
                    return Err(anyhow!("Filter has been deleted"));
                }
            }
        }

        Ok(headers)
    }
}

#[derive(Debug)]
pub struct PendingTxFilter {
    pub pending_txn_receiver: tokio::sync::broadcast::Receiver<VerifiedTransaction>,
}

impl PendingTxFilter {
    pub fn poll(&mut self) -> anyhow::Result<Vec<VerifiedTransaction>> {
        let mut txns = Vec::new();

        // Try to receive all currently available messages
        loop {
            match self.pending_txn_receiver.try_recv() {
                Ok(txn) => {
                    // Successfully got a header, add it to our vec
                    txns.push(txn);
                }
                Err(tokio::sync::broadcast::error::TryRecvError::Empty) => {
                    // No more messages available, we're done
                    break;
                }
                Err(tokio::sync::broadcast::error::TryRecvError::Lagged(skipped)) => {
                    // We've lagged behind, some messages were missed
                    return Err(anyhow!(
                        "Filter was not polled in time, {} transactions missed",
                        skipped
                    ));
                }
                Err(tokio::sync::broadcast::error::TryRecvError::Closed) => {
                    // Channel is closed
                    return Err(anyhow!("Filter has been deleted"));
                }
            }
        }

        Ok(txns)
    }
}

#[derive(Debug)]
pub struct LogFilter {
    pub criteria: Box<alloy::rpc::types::Filter>,
    pub last_block_number: Option<u64>,
}

impl Filter {
    pub fn new(kind: FilterKind) -> Self {
        Self {
            last_poll: SystemTime::now(),
            kind,
        }
    }

    pub fn touch(&mut self) {
        self.last_poll = SystemTime::now();
    }
}

#[derive(Debug, Default)]
pub struct Filters {
    filters: Mutex<HashMap<u128, Filter>>,
}

impl Filters {
    pub fn new() -> Self {
        Self {
            filters: Mutex::new(HashMap::new()),
        }
    }

    pub fn add(&self, kind: FilterKind) -> u128 {
        let mut filters = self.filters.lock();

        // Clean expired filters
        filters.retain(|_, filter| {
            SystemTime::now()
                .duration_since(filter.last_poll)
                .unwrap_or_default()
                > Duration::from_secs(5 * 60)
        });

        let id = rand::random::<u128>();
        filters.insert(id, Filter::new(kind));
        id
    }

    pub fn remove(&self, id: u128) -> bool {
        self.filters.lock().remove(&id).is_some()
    }

    pub fn get(&self, id: u128) -> Option<MappedMutexGuard<'_, Filter>> {
        let filters = self.filters.lock();
        if !filters.contains_key(&id) {
            return None;
        }
        let mut filter = MutexGuard::map(filters, |fs| fs.get_mut(&id).unwrap());
        filter.touch();
        Some(filter)
    }
}

```

`zilliqa/src/api/types/mod.rs`:

```rs
use std::fmt::Display;

use alloy::{eips::BlockId, primitives::B256};
use serde::{Serializer, ser::SerializeSeq};

use super::to_hex::ToHex;
use crate::crypto;

pub mod admin;
pub mod eth;
pub mod filters;
pub mod ots;
pub mod txpool;
pub mod zil;
pub fn hex<S: Serializer, T: ToHex>(data: T, serializer: S) -> Result<S::Ok, S::Error> {
    serializer.serialize_str(&data.to_hex())
}

pub fn option_hex<S: Serializer, T: ToHex>(
    data: &Option<T>,
    serializer: S,
) -> Result<S::Ok, S::Error> {
    if let Some(data) = data {
        serializer.serialize_some(&data.to_hex())
    } else {
        serializer.serialize_none()
    }
}

pub fn vec_hex<S: Serializer, T: ToHex>(data: &[T], serializer: S) -> Result<S::Ok, S::Error> {
    let mut serializer = serializer.serialize_seq(Some(data.len()))?;

    data.iter()
        .try_for_each(|item| serializer.serialize_element(&item.to_hex()))?;

    serializer.end()
}

pub fn bool_as_int<S: Serializer>(b: &bool, serializer: S) -> Result<S::Ok, S::Error> {
    serializer.serialize_str(if *b { "0x1" } else { "0x0" })
}

pub fn hex_no_prefix<S: Serializer, T: ToHex>(data: T, serializer: S) -> Result<S::Ok, S::Error> {
    serializer.serialize_str(&data.to_hex_no_prefix())
}

pub fn option_hex_no_prefix<S: Serializer, T: ToHex>(
    data: &Option<T>,
    serializer: S,
) -> Result<S::Ok, S::Error> {
    if let Some(data) = data {
        serializer.serialize_some(&data.to_hex_no_prefix())
    } else {
        serializer.serialize_none()
    }
}

fn ser_display<T, S>(value: &T, serializer: S) -> Result<S::Ok, S::Error>
where
    T: Display,
    S: Serializer,
{
    serializer.collect_str(value)
}

impl From<crypto::Hash> for BlockId {
    fn from(hash: crypto::Hash) -> Self {
        BlockId::from(B256::from(hash))
    }
}

```

`zilliqa/src/api/types/ots.rs`:

```rs
use alloy::primitives::{Address, B256};
use serde::Serialize;

use super::{eth, hex, option_hex};
use crate::{message, time::SystemTime, transaction::EvmGas};

#[derive(Clone, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct Block {
    #[serde(serialize_with = "hex")]
    number: u64,
    #[serde(serialize_with = "hex")]
    hash: B256,
    #[serde(serialize_with = "hex")]
    parent_hash: B256,
    #[serde(serialize_with = "hex")]
    nonce: u64,
    #[serde(serialize_with = "hex")]
    sha_3_uncles: B256,
    #[serde(serialize_with = "hex")]
    transactions_root: B256,
    #[serde(serialize_with = "hex")]
    state_root: B256,
    #[serde(serialize_with = "hex")]
    receipts_root: B256,
    #[serde(serialize_with = "hex")]
    miner: Address,
    #[serde(serialize_with = "hex")]
    difficulty: u64,
    #[serde(serialize_with = "hex")]
    total_difficulty: u64,
    #[serde(serialize_with = "hex")]
    extra_data: Vec<u8>,
    #[serde(serialize_with = "hex")]
    size: u64,
    #[serde(serialize_with = "hex")]
    gas_limit: EvmGas,
    #[serde(serialize_with = "hex")]
    gas_used: EvmGas,
    #[serde(serialize_with = "hex")]
    timestamp: u64,
    transaction_count: usize,
    uncles: Vec<B256>,
    #[serde(serialize_with = "hex")]
    base_fee_per_gas: u64,
}

#[derive(Clone, Serialize)]
pub struct BlockWithTransactions {
    #[serde(flatten)]
    pub block: Block,
    pub transactions: Vec<eth::Transaction>,
}

/// A block details object, returned by the Otterscan API.
#[derive(Clone, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct BlockDetails {
    block: Block,
    issuance: BlockIssuance,
    #[serde(serialize_with = "hex")]
    total_fees: u64,
}

impl BlockDetails {
    pub fn from_block(block: &message::Block, miner: Address, block_gas_limit: EvmGas) -> Self {
        BlockDetails {
            block: Block::from_block(block, miner, block_gas_limit),
            issuance: BlockIssuance {
                block_reward: 0,
                uncle_reward: 0,
                issuance: 0,
            },
            total_fees: 0,
        }
    }
}

#[derive(Clone, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct BlockIssuance {
    #[serde(serialize_with = "hex")]
    block_reward: u64,
    #[serde(serialize_with = "hex")]
    uncle_reward: u64,
    #[serde(serialize_with = "hex")]
    issuance: u64,
}

impl Block {
    pub fn from_block(block: &message::Block, miner: Address, block_gas_limit: EvmGas) -> Self {
        // TODO(#79): Lots of these fields are empty/zero and shouldn't be.
        Block {
            number: block.number(),
            hash: block.hash().into(),
            parent_hash: block.parent_hash().into(),
            nonce: 0,
            sha_3_uncles: B256::ZERO,
            transactions_root: B256::ZERO,
            state_root: block.state_root_hash().into(),
            receipts_root: B256::ZERO,
            miner,
            difficulty: 0,
            total_difficulty: 0,
            extra_data: vec![],
            size: 0,
            gas_limit: block_gas_limit,
            gas_used: block.gas_used(),
            timestamp: block
                .timestamp()
                .duration_since(SystemTime::UNIX_EPOCH)
                .unwrap_or_default()
                .as_secs(),
            transaction_count: block.transactions.len(),
            uncles: vec![],
            base_fee_per_gas: 0,
        }
    }
}

#[derive(Clone, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct BlockTransactions {
    #[serde(rename = "fullblock")]
    pub full_block: BlockWithTransactions,
    pub receipts: Vec<eth::TransactionReceipt>,
}

#[derive(Clone, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct Transactions {
    #[serde(rename = "txs")]
    pub transactions: Vec<eth::Transaction>,
    pub receipts: Vec<TransactionReceiptWithTimestamp>,
    pub first_page: bool,
    pub last_page: bool,
}

#[derive(Clone, Serialize)]
pub struct TransactionReceiptWithTimestamp {
    #[serde(flatten)]
    pub receipt: eth::TransactionReceipt,
    #[serde(serialize_with = "hex")]
    pub timestamp: u64,
}

#[derive(Debug, Clone, Serialize)]
pub struct TraceEntry {
    #[serde(rename = "type")]
    pub ty: TraceEntryType,
    pub depth: u64,
    #[serde(serialize_with = "hex")]
    pub from: Address,
    #[serde(serialize_with = "hex")]
    pub to: Address,
    #[serde(serialize_with = "option_hex")]
    pub value: Option<u128>,
    #[serde(serialize_with = "hex")]
    pub input: Vec<u8>,
}

#[derive(Debug, Clone, Serialize)]
#[serde(rename_all = "UPPERCASE")]
pub enum TraceEntryType {
    Call,
    StaticCall,
    DelegateCall,
    CallCode,
    Create,
    Create2,
    SelfDestruct,
    ExtCall,
    ExtStaticCall,
    ExtDelegateCall,
}

#[derive(Debug, Clone, Serialize)]
pub struct Operation {
    #[serde(rename = "type")]
    pub ty: OperationType,
    #[serde(serialize_with = "hex")]
    pub from: Address,
    #[serde(serialize_with = "hex")]
    pub to: Address,
    #[serde(serialize_with = "hex")]
    pub value: u128,
}

#[derive(Debug, Clone)]
pub enum OperationType {
    Transfer,
    SelfDestruct,
    Create,
    Create2,
}

impl Serialize for OperationType {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        let ty: u8 = match self {
            OperationType::Transfer => 0,
            OperationType::SelfDestruct => 1,
            OperationType::Create => 2,
            OperationType::Create2 => 3,
        };
        ty.serialize(serializer)
    }
}

```

`zilliqa/src/api/types/txpool.rs`:

```rs
use std::collections::HashMap;

use alloy::primitives::Address;
use serde::Serialize;

use super::eth::Transaction;

#[derive(Clone, Serialize)]
pub struct TxPoolContent {
    #[serde(skip_serializing_if = "HashMap::is_empty")]
    pub pending: HashMap<Address, HashMap<u64, Transaction>>,
    #[serde(skip_serializing_if = "HashMap::is_empty")]
    pub queued: HashMap<Address, HashMap<u64, Transaction>>,
}

#[derive(Clone, Serialize)]
pub struct TxPoolInspect {
    #[serde(skip_serializing_if = "HashMap::is_empty")]
    pub pending: HashMap<Address, HashMap<u64, String>>,
    #[serde(skip_serializing_if = "HashMap::is_empty")]
    pub queued: HashMap<Address, HashMap<u64, String>>,
}

#[derive(Clone, Serialize)]
pub struct TxPoolStatus {
    pub pending: u64,
    pub queued: u64,
}

```

`zilliqa/src/api/types/zil.rs`:

```rs
use std::collections::BTreeMap;

use alloy::{
    consensus::SignableTransaction,
    primitives::{Address, B256, B512},
};
use anyhow::Result;
use k256::elliptic_curve::sec1::ToEncodedPoint;
use serde::{Deserialize, Serialize};
use serde_repr::{Deserialize_repr, Serialize_repr};

use super::{hex, hex_no_prefix, option_hex_no_prefix};
use crate::{
    api::{
        to_hex::ToHex,
        zilliqa::{TRANSACTIONS_PER_PAGE, TX_BLOCKS_PER_DS_BLOCK},
    },
    exec::ScillaException,
    message::Block,
    schnorr,
    scilla::ParamValue,
    serde_util::num_as_str,
    time::SystemTime,
    transaction::{
        EvmGas, ScillaGas, SignedTransaction, TransactionReceipt, VerifiedTransaction, ZilAmount,
    },
};

#[derive(Clone, Serialize)]
pub struct TxBlock {
    pub header: TxBlockHeader,
    pub body: TxBlockBody,
}

impl TxBlock {
    pub fn new(block: &Block, txn_fees: EvmGas) -> Self {
        let mut scalar = [0; 32];
        scalar[31] = 1;
        TxBlock {
            header: TxBlockHeader {
                version: 1,                                    // To match ZQ1
                gas_limit: ScillaGas::from(block.gas_limit()), // In Scilla
                gas_used: ScillaGas::from(block.gas_used()),   // In Scilla
                rewards: 0,
                txn_fees,
                prev_block_hash: block.parent_hash().into(),
                block_num: block.number(),
                timestamp: block
                    .timestamp()
                    .duration_since(SystemTime::UNIX_EPOCH)
                    .unwrap_or_default()
                    .as_micros(),
                mb_info_hash: B256::ZERO, // Obsolete in ZQ2
                state_root_hash: block.state_root_hash().into(),
                state_delta_hash: B256::ZERO, // Obsolete in ZQ2
                num_txns: block.transactions.len() as u64,
                num_pages: if block.transactions.is_empty() {
                    0
                } else {
                    (block.transactions.len() / TRANSACTIONS_PER_PAGE) + 1
                },
                num_micro_blocks: 0, // Microblocks obsolete in ZQ2
                ds_block_num: (block.number() / TX_BLOCKS_PER_DS_BLOCK) + 1,
            },
            body: TxBlockBody {
                header_sign: B512::ZERO, // Obsolete in ZQ2
                block_hash: block.hash().into(),
                micro_block_infos: vec![],
            },
        }
    }
}

#[derive(Clone, Serialize)]
#[serde(rename_all = "PascalCase")]
pub struct TxBlockHeader {
    pub version: u8,
    #[serde(with = "num_as_str")]
    pub gas_limit: ScillaGas,
    #[serde(with = "num_as_str")]
    pub gas_used: ScillaGas,
    #[serde(with = "num_as_str")]
    pub rewards: u128,
    #[serde(with = "num_as_str")]
    pub txn_fees: EvmGas,
    #[serde(serialize_with = "hex_no_prefix")]
    pub prev_block_hash: B256,
    #[serde(with = "num_as_str")]
    pub block_num: u64,
    #[serde(with = "num_as_str")]
    pub timestamp: u128,
    #[serde(serialize_with = "hex_no_prefix")]
    pub mb_info_hash: B256,
    #[serde(serialize_with = "hex_no_prefix")]
    pub state_root_hash: B256,
    #[serde(serialize_with = "hex_no_prefix")]
    pub state_delta_hash: B256,
    pub num_txns: u64,
    pub num_pages: usize,
    pub num_micro_blocks: u8,
    #[serde(rename = "DSBlockNum", with = "num_as_str")]
    pub ds_block_num: u64,
}

#[derive(Clone, Serialize)]
pub struct TxBlockVerbose {
    pub header: TxBlockVerboseHeader,
    pub body: TxBlockVerboseBody,
}

impl TxBlockVerbose {
    pub fn new(block: &Block, txn_fees: EvmGas, proposer: Address) -> Self {
        let mut scalar = [0; 32];
        scalar[31] = 1;
        TxBlockVerbose {
            header: TxBlockVerboseHeader {
                non_verbose_header: TxBlockHeader {
                    version: 1,                                    // To match ZQ1
                    gas_limit: ScillaGas::from(block.gas_limit()), // In Scilla
                    gas_used: ScillaGas::from(block.gas_used()),   // In Scilla
                    rewards: 0,
                    txn_fees,
                    prev_block_hash: block.parent_hash().into(),
                    block_num: block.number(),
                    timestamp: block
                        .timestamp()
                        .duration_since(SystemTime::UNIX_EPOCH)
                        .unwrap_or_default()
                        .as_micros(),
                    mb_info_hash: B256::ZERO, // Obsolete in ZQ2
                    state_root_hash: block.state_root_hash().into(),
                    state_delta_hash: B256::ZERO, // Obsolete in ZQ2
                    num_txns: block.transactions.len() as u64,
                    num_pages: if block.transactions.is_empty() {
                        0
                    } else {
                        (block.transactions.len() / TRANSACTIONS_PER_PAGE) + 1
                    },
                    num_micro_blocks: 0, // Microblocks obsolete in ZQ2
                    ds_block_num: (block.number() / TX_BLOCKS_PER_DS_BLOCK) + 1,
                },
                miner_pub_key: proposer,
                committee_hash: Some(B256::ZERO),
            },
            body: TxBlockVerboseBody {
                header_sign: B512::ZERO, // Obsolete in ZQ2
                block_hash: block.hash().into(),
                micro_block_infos: vec![],
                cosig_bitmap_1: vec![true; 8],
                cosig_bitmap_2: vec![true; 8],
                cosig_1: Some(schnorr::Signature::from_scalars(scalar, scalar).unwrap()),
            },
        }
    }
}

#[derive(Clone, Serialize)]
#[serde(rename_all = "PascalCase")]
pub struct TxBlockVerboseHeader {
    #[serde(flatten)]
    pub non_verbose_header: TxBlockHeader,
    #[serde(serialize_with = "hex")]
    pub miner_pub_key: Address,
    #[serde(
        serialize_with = "option_hex_no_prefix",
        skip_serializing_if = "Option::is_none"
    )]
    pub committee_hash: Option<B256>,
}

#[derive(Clone, Serialize)]
#[serde(rename_all = "PascalCase")]
pub struct TxBlockVerboseBody {
    #[serde(serialize_with = "hex_no_prefix")]
    pub header_sign: B512,
    #[serde(serialize_with = "hex_no_prefix")]
    pub block_hash: B256,
    pub micro_block_infos: Vec<MicroBlockInfo>,
    #[serde(rename = "B1")]
    pub cosig_bitmap_1: Vec<bool>,
    #[serde(rename = "B2")]
    pub cosig_bitmap_2: Vec<bool>,
    #[serde(rename = "CS1")]
    pub cosig_1: Option<schnorr::Signature>,
}

#[derive(Clone, Serialize, Deserialize, Debug)]
#[serde(rename_all = "camelCase")]
pub struct GetTxResponse {
    #[serde(rename = "ID", serialize_with = "hex_no_prefix")]
    pub id: B256,
    #[serde(with = "num_as_str")]
    pub version: u32,
    #[serde(with = "num_as_str")]
    pub nonce: u64,
    #[serde(serialize_with = "hex_no_prefix")]
    pub to_addr: Address,
    pub sender_pub_key: String,
    #[serde(with = "num_as_str")]
    pub amount: ZilAmount,
    pub signature: String,
    pub receipt: GetTxResponseReceipt,
    #[serde(with = "num_as_str")]
    pub gas_price: ZilAmount,
    #[serde(with = "num_as_str")]
    pub gas_limit: ScillaGas,
    pub code: Option<String>,
    pub data: Option<String>,
}

#[derive(Clone, Serialize, Debug)]
#[serde(rename_all = "PascalCase")]
pub struct CreateTransactionResponse {
    #[serde(skip_serializing_if = "Option::is_none")]
    pub contract_address: Option<Address>,
    pub info: String,
    #[serde(rename = "TranID")]
    pub tran_id: B256,
}

#[derive(Clone, Serialize, Deserialize, Debug)]
pub struct Transition {
    pub addr: Address,
    pub depth: u64,
    pub msg: TransitionMessage,
}

#[derive(Clone, Serialize, Deserialize, Debug)]
pub struct TransitionMessage {
    #[serde(rename = "_amount", with = "num_as_str")]
    pub amount: ZilAmount,
    #[serde(rename = "_recipient")]
    pub recipient: Address,
    #[serde(rename = "_tag")]
    pub tag: String,
    pub params: serde_json::Value,
}

#[derive(Clone, Serialize, Deserialize, Debug)]
pub struct EventLog {
    pub address: Address,
    #[serde(rename = "_eventname")]
    pub event_name: String,
    pub params: Vec<ParamValue>,
}

#[derive(Clone, Serialize, Deserialize, Debug)]
pub struct GetTxResponseReceipt {
    pub accepted: bool,
    #[serde(with = "num_as_str")]
    pub cumulative_gas: ScillaGas,
    #[serde(with = "num_as_str")]
    pub epoch_num: u64,
    pub transitions: Vec<Transition>,
    pub event_logs: Vec<EventLog>,
    pub errors: BTreeMap<u64, Vec<u64>>,
    pub exceptions: Vec<ScillaException>,
    pub success: bool,
}

impl GetTxResponse {
    pub fn new(
        tx: VerifiedTransaction,
        receipt: TransactionReceipt,
        block_number: u64,
    ) -> Result<GetTxResponse> {
        let amount = tx.tx.zil_amount();
        let gas_price = tx.tx.gas_price_per_scilla_gas();
        let gas_limit = tx.tx.gas_limit_scilla();
        // Some of these are returned as all caps in ZQ1, but that should be fine
        let (nonce, version, to_addr, sender_pub_key, signature, code, data) = match tx.tx {
            SignedTransaction::Zilliqa { tx, sig, key } => (
                tx.nonce,
                ((tx.chain_id as u32) << 16) | 1,
                tx.to_addr,
                key.to_encoded_point(true).as_bytes().to_hex(),
                <[u8; 64]>::from(sig.to_bytes()).to_hex(),
                (!tx.code.is_empty()).then_some(tx.code),
                (!tx.data.is_empty()).then_some(tx.data),
            ),
            SignedTransaction::Legacy { tx, sig } => (
                tx.nonce,
                ((tx.chain_id.unwrap_or_default() as u32) << 16) | 2,
                tx.to.to().copied().unwrap_or_default(),
                sig.recover_from_prehash(&tx.signature_hash())?
                    .to_sec1_bytes()
                    .to_hex(),
                sig.as_bytes().to_hex(),
                tx.to.is_create().then(|| hex::encode(&tx.input)),
                tx.to.is_call().then(|| hex::encode(&tx.input)),
            ),
            SignedTransaction::Eip2930 { tx, sig } => (
                tx.nonce,
                ((tx.chain_id as u32) << 16) | 3,
                tx.to.to().copied().unwrap_or_default(),
                sig.recover_from_prehash(&tx.signature_hash())?
                    .to_sec1_bytes()
                    .to_hex(),
                sig.as_bytes().to_hex(),
                tx.to.is_create().then(|| hex::encode(&tx.input)),
                tx.to.is_call().then(|| hex::encode(&tx.input)),
            ),
            SignedTransaction::Eip1559 { tx, sig } => (
                tx.nonce,
                ((tx.chain_id as u32) << 16) | 4,
                tx.to.to().copied().unwrap_or_default(),
                sig.recover_from_prehash(&tx.signature_hash())?
                    .to_sec1_bytes()
                    .to_hex(),
                sig.as_bytes().to_hex(),
                tx.to.is_create().then(|| hex::encode(&tx.input)),
                tx.to.is_call().then(|| hex::encode(&tx.input)),
            ),
            SignedTransaction::Intershard { tx, .. } => (
                0,
                ((tx.chain_id as u32) << 16) | 20,
                tx.to_addr.unwrap_or_default(),
                String::new(),
                String::new(),
                tx.to_addr.is_none().then(|| hex::encode(&tx.payload)),
                tx.to_addr.is_some().then(|| hex::encode(&tx.payload)),
            ),
        };

        Ok(GetTxResponse {
            id: tx.hash.into(),
            version,
            nonce,
            to_addr,
            sender_pub_key,
            amount,
            signature,
            receipt: GetTxResponseReceipt {
                cumulative_gas: receipt.cumulative_gas_used.into(),
                epoch_num: block_number,
                transitions: receipt
                    .transitions
                    .into_iter()
                    .map(|t| {
                        Ok(Transition {
                            addr: t.from,
                            // The depth of transitions from this API start counting from the first contract call, rather
                            // than from the initial EOA. The initial call is not included as a transition, so this should
                            // never underflow.
                            depth: t.depth - 1,
                            msg: TransitionMessage {
                                amount: t.amount,
                                recipient: t.to,
                                tag: t.tag,
                                params: serde_json::from_str(&t.params)?,
                            },
                        })
                    })
                    .collect::<Result<_>>()?,
                event_logs: receipt
                    .logs
                    .into_iter()
                    .filter_map(|log| log.into_scilla())
                    .map(|log| EventLog {
                        address: log.address,
                        event_name: log.event_name,
                        params: log.params,
                    })
                    .collect(),
                success: receipt.success,
                accepted: receipt.accepted.unwrap_or(false),
                errors: receipt
                    .errors
                    .into_iter()
                    .map(|(k, v)| (k, v.into_iter().map(|err| err as u64).collect()))
                    .collect(),
                exceptions: receipt.exceptions,
            },
            gas_price,
            gas_limit,
            code,
            data,
        })
    }
}

#[derive(Clone, Serialize)]
#[serde(rename_all = "PascalCase")]
pub struct TxBlockBody {
    #[serde(serialize_with = "hex_no_prefix")]
    pub header_sign: B512,
    #[serde(serialize_with = "hex_no_prefix")]
    pub block_hash: B256,
    pub micro_block_infos: Vec<MicroBlockInfo>,
}

#[derive(Clone, Serialize)]
#[serde(rename_all = "PascalCase")]
pub struct MicroBlockInfo {
    micro_block_hash: B256,
    micro_block_shard_id: u8,
    micro_block_txn_root_hash: B256,
}

#[derive(Clone, Serialize)]
#[serde(rename_all = "PascalCase")]
pub struct BlockchainInfo {
    #[serde(rename = "NumPeers")]
    pub num_peers: u16,
    #[serde(with = "num_as_str", rename = "NumTxBlocks")]
    pub num_tx_blocks: u64,
    #[serde(with = "num_as_str", rename = "NumDSBlocks")]
    pub num_ds_blocks: u64,
    #[serde(with = "num_as_str", rename = "NumTransactions")]
    pub num_transactions: u64,
    #[serde(rename = "TransactionRate")]
    pub transaction_rate: f64,
    #[serde(rename = "TxBlockRate")]
    pub tx_block_rate: f64,
    #[serde(rename = "DSBlockRate")]
    pub ds_block_rate: f64,
    #[serde(with = "num_as_str", rename = "CurrentMiniEpoch")]
    pub current_mini_epoch: u64,
    #[serde(with = "num_as_str", rename = "CurrentDSEpoch")]
    pub current_ds_epoch: u64,
    #[serde(with = "num_as_str", rename = "NumTxnsDSEpoch")]
    pub num_txns_ds_epoch: u64,
    #[serde(with = "num_as_str", rename = "NumTxnsTxEpoch")]
    pub num_txns_tx_epoch: u64,
    #[serde(rename = "ShardingStructure")]
    pub sharding_structure: ShardingStructure,
}

#[derive(Clone, Serialize, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub struct ShardingStructure {
    #[serde(rename = "NumPeers")]
    pub num_peers: Vec<u64>,
}

#[derive(Clone, Serialize)]
pub struct SmartContract {
    #[serde(serialize_with = "hex_no_prefix")]
    pub address: Address,
}

#[derive(Clone, Debug)]
pub enum RPCErrorCode {
    // Standard JSON-RPC 2.0 errors
    // RPC_INVALID_REQUEST is internally mapped to HTTP_BAD_REQUEST (400).
    // It should not be used for application-layer errors.
    RpcInvalidRequest = -32600,
    // RPC_METHOD_NOT_FOUND is internally mapped to HTTP_NOT_FOUND (404).
    // It should not be used for application-layer errors.
    RpcMethodNotFound = -32601,
    RpcInvalidParams = -32602,
    // RPC_INTERNAL_ERROR should only be used for genuine errors in bitcoind
    // (for example datadir corruption).
    RpcInternalError = -32603,
    RpcParseError = -32700,

    // General application defined errors
    RpcMiscError = -1,             // std::exception thrown in command handling
    RpcTypeError = -3,             // Unexpected type was passed as parameter
    RpcInvalidAddressOrKey = -5,   // Invalid address or key
    RpcInvalidParameter = -8,      // Invalid, missing or duplicate parameter
    RpcDatabaseError = -20,        // Database error
    RpcDeserializationError = -22, // Error parsing or validating structure in raw format
    RpcVerifyError = -25,          // General error during transaction or block submission
    RpcVerifyRejected = -26,       // Transaction or block was rejected by network rules
    RpcInWarmup = -28,             // Client still warming up
    RpcMethodDeprecated = -32,     // RPC method is deprecated
}

#[derive(Serialize, Deserialize, Clone)]
pub struct DSBlock {
    pub header: DSBlockHeader,
    pub signature: String,
}

impl From<DSBlockVerbose> for DSBlock {
    fn from(verbose_block: DSBlockVerbose) -> Self {
        DSBlock {
            header: DSBlockHeader::from(verbose_block.header),
            signature: verbose_block.signature,
        }
    }
}

#[derive(Serialize, Deserialize, Clone)]
pub struct DSBlockHeader {
    #[serde(rename = "BlockNum")]
    pub block_num: String,
    #[serde(rename = "Difficulty")]
    pub difficulty: u64,
    #[serde(rename = "DifficultyDS")]
    pub difficulty_ds: u64,
    #[serde(rename = "GasPrice")]
    pub gas_price: String,
    #[serde(rename = "PoWWinners")]
    pub pow_winners: Vec<String>,
    #[serde(rename = "PrevHash")]
    pub prev_hash: String,
    #[serde(rename = "Timestamp")]
    pub timestamp: String,
}

#[derive(Serialize, Deserialize, Clone)]
pub struct DSBlockVerbose {
    // Sample fields based on given/expected data structure
    #[serde(rename = "B1")]
    pub b1: Vec<bool>,
    #[serde(rename = "B2")]
    pub b2: Vec<bool>,
    #[serde(rename = "CS1")]
    pub cs1: String,
    #[serde(rename = "PrevDSHash")]
    pub prev_dshash: String,
    pub header: DSBlockHeaderVerbose,
    pub signature: String,
}

impl From<DSBlockHeaderVerbose> for DSBlockHeader {
    fn from(header: DSBlockHeaderVerbose) -> Self {
        DSBlockHeader {
            block_num: header.block_num,
            difficulty: header.difficulty,
            difficulty_ds: header.difficulty_ds,
            gas_price: header.gas_price,
            pow_winners: header.po_wwinners,
            prev_hash: header.prev_hash,
            timestamp: header.timestamp,
        }
    }
}

#[derive(Serialize, Deserialize, Clone)]
pub struct DSBlockHeaderVerbose {
    #[serde(rename = "BlockNum")]
    pub block_num: String,
    #[serde(rename = "CommitteeHash")]
    pub committee_hash: String,
    #[serde(rename = "Difficulty")]
    pub difficulty: u64,
    #[serde(rename = "DifficultyDS")]
    pub difficulty_ds: u64,
    #[serde(rename = "EpochNum")]
    pub epoch_num: String,
    #[serde(rename = "GasPrice")]
    pub gas_price: String,
    #[serde(rename = "MembersEjected")]
    pub members_ejected: Vec<String>,
    #[serde(rename = "PoWWinners")]
    pub po_wwinners: Vec<String>,
    #[serde(rename = "PoWWinnersIP")]
    pub po_wwinners_ip: Vec<PoWWinnerIP>,
    #[serde(rename = "PrevHash")]
    pub prev_hash: String,
    #[serde(rename = "ReservedField")]
    pub reserved_field: String,
    #[serde(rename = "SWInfo")]
    pub swinfo: SWInfo,
    #[serde(rename = "ShardingHash")]
    pub sharding_hash: String,
    #[serde(rename = "Timestamp")]
    pub timestamp: String,
    #[serde(rename = "Version")]
    pub version: u32,
}

#[derive(Serialize, Deserialize, Clone)]
pub struct PoWWinnerIP {
    #[serde(rename = "IP")]
    pub ip: String,
    pub port: u32,
}

#[derive(Serialize, Deserialize, Clone)]
pub struct SWInfo {
    #[serde(rename = "Scilla")]
    pub scilla: Vec<u64>,
    #[serde(rename = "Zilliqa")]
    pub zilliqa: Vec<u64>,
}

#[derive(Serialize, Deserialize, Clone)]
pub struct GetCurrentDSCommResult {
    #[serde(rename = "CurrentDSEpoch")]
    pub current_dsepoch: String,
    #[serde(rename = "CurrentTxEpoch")]
    pub current_tx_epoch: String,
    #[serde(rename = "NumOfDSGuard")]
    pub num_of_dsguard: u32,
    pub dscomm: Vec<String>,
}

#[derive(Serialize, Deserialize, Clone)]
pub struct DSBlockRateResult {
    pub rate: f64,
}

#[derive(Serialize, Deserialize, Clone)]
pub struct DSBlockListingResult {
    pub data: Vec<DSBlockListing>,
    #[serde(rename = "maxPages")]
    pub max_pages: u32,
}

#[derive(Serialize, Deserialize, Clone)]
pub struct DSBlockListing {
    #[serde(rename = "BlockNum")]
    pub block_num: u64,
    #[serde(rename = "Hash")]
    pub hash: String,
}

#[derive(Serialize, Deserialize, Clone)]
pub struct TXBlockRateResult {
    pub rate: f64,
}

#[derive(Serialize, Deserialize, Clone)]
pub struct TxBlockListing {
    #[serde(rename = "BlockNum")]
    pub block_num: u64,
    #[serde(rename = "Hash")]
    pub hash: String,
}

#[derive(Serialize, Deserialize, Clone)]
pub struct TxBlockListingResult {
    pub data: Vec<TxBlockListing>,
    #[serde(rename = "maxPages")]
    pub max_pages: u64,
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct TxnsForTxBlockExResponse {
    #[serde(rename = "CurrPage")]
    pub curr_page: u64,
    #[serde(rename = "NumPages")]
    pub num_pages: u64,
    #[serde(rename = "Transactions")]
    pub transactions: Vec<String>,
}

#[derive(Serialize, Deserialize, Clone)]
pub struct TxnBodiesForTxBlockExResponse {
    #[serde(rename = "CurrPage")]
    pub curr_page: u64,
    #[serde(rename = "NumPages")]
    pub num_pages: u64,
    #[serde(rename = "Transactions")]
    pub transactions: Vec<TransactionBody>,
}

#[derive(Serialize, Deserialize, Clone)]
pub struct TransactionBody {
    #[serde(rename = "ID")]
    pub id: String,
    pub amount: String,
    #[serde(rename = "gasLimit")]
    pub gas_limit: String,
    #[serde(rename = "gasPrice")]
    pub gas_price: String,
    pub nonce: String,
    pub receipt: TransactionReceiptResponse,
    #[serde(rename = "senderPubKey")]
    pub sender_pub_key: String,
    pub signature: String,
    #[serde(rename = "toAddr")]
    pub to_addr: String,
    pub version: String,
}

#[derive(Serialize, Deserialize, Clone)]
pub struct TransactionReceiptResponse {
    pub cumulative_gas: String,
    pub epoch_num: String,
    pub success: bool,
}

// From https://github.com/Zilliqa/Zilliqa/blob/master/src/common/TxnStatus.h#L23
#[derive(Serialize_repr, Debug, Deserialize_repr, Clone)]
#[repr(u8)] // Because otherwise it's weird that 255 is a special case
pub enum TxnStatusCode {
    Dispatched = 1,
    Confirmed = 3,
    PresentNonceHigh = 4,
    Error = 255, // MiscError
}

#[derive(Serialize, Debug, Deserialize, Clone)]
pub struct TransactionStatusResponse {
    #[serde(rename = "ID")]
    pub id: String,
    #[serde(rename = "_id")]
    pub _id: serde_json::Value,
    pub amount: String,
    pub data: String,
    #[serde(rename = "epochInserted")]
    pub epoch_inserted: String,
    #[serde(rename = "epochUpdated")]
    pub epoch_updated: String,
    #[serde(rename = "gasLimit")]
    pub gas_limit: String,
    #[serde(rename = "gasPrice")]
    pub gas_price: String,
    #[serde(rename = "lastModified")]
    pub last_modified: String,
    #[serde(rename = "modificationState")]
    pub modification_state: u64,
    pub status: TxnStatusCode,
    pub nonce: String,
    #[serde(rename = "senderAddr")]
    pub sender_addr: String,
    pub signature: String,
    pub success: bool,
    #[serde(rename = "toAddr")]
    pub to_addr: String,
    pub version: String,
}

#[derive(Clone, Copy)]
pub enum TransactionState {
    Queued,
    Pending,
    Finalized,
    Error,
}

impl TransactionStatusResponse {
    pub fn new(
        tx: VerifiedTransaction,
        success: bool,
        block: Option<Block>,
        state: TransactionState,
    ) -> Result<Self> {
        let amount = tx.tx.zil_amount();
        let gas_price = tx.tx.gas_price_per_scilla_gas();
        let gas_limit = tx.tx.gas_limit_scilla();
        let (nonce, version, to_addr, sender_pub_key, signature, _code, data) = match tx.tx {
            SignedTransaction::Zilliqa { tx, sig, key } => (
                tx.nonce,
                ((tx.chain_id as u32) << 16) | 1,
                tx.to_addr,
                key.to_encoded_point(true).as_bytes().to_hex(),
                <[u8; 64]>::from(sig.to_bytes()).to_hex(),
                (!tx.code.is_empty()).then_some(tx.code),
                (!tx.data.is_empty()).then_some(tx.data),
            ),
            SignedTransaction::Legacy { tx, sig } => (
                tx.nonce,
                ((tx.chain_id.unwrap_or_default() as u32) << 16) | 2,
                tx.to.to().copied().unwrap_or_default(),
                sig.recover_from_prehash(&tx.signature_hash())?
                    .to_sec1_bytes()
                    .to_hex(),
                sig.as_bytes().to_hex(),
                tx.to.is_create().then(|| hex::encode(&tx.input)),
                tx.to.is_call().then(|| hex::encode(&tx.input)),
            ),
            SignedTransaction::Eip2930 { tx, sig } => (
                tx.nonce,
                ((tx.chain_id as u32) << 16) | 3,
                tx.to.to().copied().unwrap_or_default(),
                sig.recover_from_prehash(&tx.signature_hash())?
                    .to_sec1_bytes()
                    .to_hex(),
                sig.as_bytes().to_hex(),
                tx.to.is_create().then(|| hex::encode(&tx.input)),
                tx.to.is_call().then(|| hex::encode(&tx.input)),
            ),
            SignedTransaction::Eip1559 { tx, sig } => (
                tx.nonce,
                ((tx.chain_id as u32) << 16) | 4,
                tx.to.to().copied().unwrap_or_default(),
                sig.recover_from_prehash(&tx.signature_hash())?
                    .to_sec1_bytes()
                    .to_hex(),
                sig.as_bytes().to_hex(),
                tx.to.is_create().then(|| hex::encode(&tx.input)),
                tx.to.is_call().then(|| hex::encode(&tx.input)),
            ),
            SignedTransaction::Intershard { tx, .. } => (
                0,
                ((tx.chain_id as u32) << 16) | 20,
                tx.to_addr.unwrap_or_default(),
                String::new(),
                String::new(),
                tx.to_addr.is_none().then(|| hex::encode(&tx.payload)),
                tx.to_addr.is_some().then(|| hex::encode(&tx.payload)),
            ),
        };
        let (status_code, modification_state) = match state {
            TransactionState::Error => (TxnStatusCode::Error, 2),
            TransactionState::Finalized => (TxnStatusCode::Confirmed, 2),
            TransactionState::Pending => (TxnStatusCode::Dispatched, 1),
            TransactionState::Queued => (TxnStatusCode::PresentNonceHigh, 1),
        };
        let epoch_inserted = if let Some(block) = &block {
            block.number().to_string()
        } else {
            "".to_string()
        };
        let epoch_updated = if let Some(block) = &block {
            block.number().to_string()
        } else {
            "".to_string()
        };
        let last_modified = if let Some(block) = &block {
            block
                .timestamp()
                .duration_since(SystemTime::UNIX_EPOCH)?
                .as_micros()
                .to_string()
        } else {
            SystemTime::now()
                .duration_since(SystemTime::UNIX_EPOCH)?
                .as_micros()
                .to_string()
        };
        Ok(Self {
            id: tx.hash.to_string(),
            _id: serde_json::Value::Null,
            amount: amount.to_string(),
            data: data.unwrap_or_default(),
            epoch_inserted,
            epoch_updated,
            gas_limit: gas_limit.to_string(),
            gas_price: gas_price.to_string(),
            last_modified,
            modification_state,
            status: status_code,
            nonce: nonce.to_string(),
            sender_addr: sender_pub_key,
            signature,
            success,
            to_addr: to_addr.to_hex(),
            version: version.to_string(),
        })
    }
}

#[derive(Serialize, Deserialize, Clone)]
pub struct RecentTransactionsResponse {
    #[serde(rename = "TxnHashes")]
    pub txn_hashes: Vec<String>,
    pub number: u64,
}

#[derive(Serialize, Deserialize, Clone)]
pub struct MinerInfo {
    pub dscommittee: Vec<String>,
    pub shards: Vec<ShardInfo>,
}

#[derive(Serialize, Deserialize, Clone)]
pub struct ShardInfo {
    pub nodes: Vec<String>,
    pub size: u64,
}

#[derive(Serialize, Deserialize, Clone)]
pub struct StateProofResponse {
    #[serde(rename = "accountProof")]
    pub account_proof: Vec<String>,
    #[serde(rename = "stateProof")]
    pub state_proof: Vec<String>,
}

```

`zilliqa/src/api/web3.rs`:

```rs
use std::sync::Arc;

use anyhow::{Result, anyhow};
use jsonrpsee::{RpcModule, types::Params};
use parking_lot::RwLock;
use sha3::{Digest, Keccak256};

use super::to_hex::ToHex;
use crate::{cfg::EnabledApi, node::Node};

pub fn rpc_module(
    node: Arc<RwLock<Node>>,
    enabled_apis: &[EnabledApi],
) -> RpcModule<Arc<RwLock<Node>>> {
    super::declare_module!(
        node,
        enabled_apis,
        [("web3_clientVersion", client_version), ("web3_sha3", sha3)],
    )
}

fn client_version(_: Params, _: &Arc<RwLock<Node>>) -> Result<&'static str> {
    // Format: "<name>/<version>"
    Ok(concat!("zilliqa2/", env!("VERGEN_GIT_DESCRIBE")))
}

fn sha3(params: Params, _: &Arc<RwLock<Node>>) -> Result<String> {
    let data: String = params.one()?;
    let data = data
        .strip_prefix("0x")
        .ok_or_else(|| anyhow!("no 0x prefix"))?;
    let data = hex::decode(data)?;

    let hashed = Keccak256::digest(data);

    Ok(hashed.to_hex())
}

```

`zilliqa/src/api/zilliqa.rs`:

```rs
//! The Zilliqa API, as documented at <https://dev.zilliqa.com/api/introduction/api-introduction>.

use std::{fmt::Display, str::FromStr, sync::Arc};

use alloy::{
    consensus::SignableTransaction,
    eips::{BlockId, BlockNumberOrTag},
    primitives::{Address, B256},
};
use anyhow::{Result, anyhow};
use jsonrpsee::{
    RpcModule,
    types::{ErrorObject, Params},
};
use k256::elliptic_curve::sec1::ToEncodedPoint;
use parking_lot::RwLock;
use serde::{Deserialize, Deserializer};
use serde_json::{Value, json};
use sha2::{Digest, Sha256};
use sha3::digest::generic_array::{
    GenericArray,
    sequence::Split,
    typenum::{U12, U20},
};

use super::{
    to_hex::ToHex,
    types::zil::{
        self, BlockchainInfo, DSBlock, DSBlockHeaderVerbose, DSBlockListing, DSBlockListingResult,
        DSBlockRateResult, DSBlockVerbose, GetCurrentDSCommResult, MinerInfo,
        RecentTransactionsResponse, SWInfo, ShardingStructure, SmartContract, StateProofResponse,
        TXBlockRateResult, TransactionBody, TransactionReceiptResponse, TransactionState,
        TransactionStatusResponse, TxBlockListing, TxBlockListingResult,
        TxnBodiesForTxBlockExResponse, TxnsForTxBlockExResponse,
    },
};
use crate::{
    api::types::zil::{CreateTransactionResponse, GetTxResponse, RPCErrorCode},
    cfg::EnabledApi,
    crypto::Hash,
    exec::zil_contract_address,
    message::Block,
    node::Node,
    pool::{PendingOrQueued, TxAddResult},
    schnorr,
    scilla::{ParamValue, split_storage_key, storage_key},
    state::Code,
    time::SystemTime,
    transaction::{
        EVM_GAS_PER_SCILLA_GAS, EvmGas, ScillaGas, SignedTransaction, TxZilliqa, ValidationOutcome,
        ZilAmount,
    },
};

pub fn rpc_module(
    node: Arc<RwLock<Node>>,
    enabled_apis: &[EnabledApi],
) -> RpcModule<Arc<RwLock<Node>>> {
    super::declare_module!(
        node,
        enabled_apis,
        [
            ("CreateTransaction", create_transaction),
            (
                "GetContractAddressFromTransactionID",
                get_contract_address_from_transaction_id
            ),
            ("GetBlockchainInfo", get_blockchain_info),
            ("GetNumTxBlocks", get_num_tx_blocks),
            ("GetSmartContractState", get_smart_contract_state),
            ("GetSmartContractCode", get_smart_contract_code),
            ("GetSmartContractInit", get_smart_contract_init),
            ("GetTransaction", get_transaction),
            ("GetBalance", get_balance),
            ("GetCurrentMiniEpoch", get_current_mini_epoch),
            ("GetLatestTxBlock", get_latest_tx_block),
            ("GetMinimumGasPrice", get_minimum_gas_price),
            ("GetNetworkId", get_network_id),
            ("GetVersion", get_version),
            ("GetTransactionsForTxBlock", get_transactions_for_tx_block),
            ("GetTxBlock", get_tx_block),
            ("GetTxBlockVerbose", get_tx_block_verbose),
            ("GetSmartContracts", get_smart_contracts),
            ("GetDSBlock", get_ds_block),
            ("GetDSBlockVerbose", get_ds_block_verbose),
            ("GetLatestDSBlock", get_latest_ds_block),
            ("GetCurrentDSComm", get_current_ds_comm),
            ("GetCurrentDSEpoch", get_current_ds_epoch),
            ("DSBlockListing", ds_block_listing),
            ("GetDSBlockRate", get_ds_block_rate),
            ("GetTxBlockRate", get_tx_block_rate),
            ("TxBlockListing", tx_block_listing),
            ("GetNumPeers", get_num_peers),
            ("GetTransactionRate", get_tx_rate),
            (
                "GetTransactionsForTxBlockEx",
                get_transactions_for_tx_block_ex
            ),
            ("GetTxnBodiesForTxBlock", get_txn_bodies_for_tx_block),
            ("GetTxnBodiesForTxBlockEx", get_txn_bodies_for_tx_block_ex),
            ("GetNumDSBlocks", get_num_ds_blocks),
            ("GetRecentTransactions", get_recent_transactions),
            ("GetNumTransactions", get_num_transactions),
            ("GetNumTxnsTXEpoch", get_num_txns_tx_epoch),
            ("GetNumTxnsDSEpoch", get_num_txns_ds_epoch),
            ("GetTotalCoinSupply", get_total_coin_supply),
            ("GetTotalCoinSupplyAsInt", get_total_coin_supply_as_int),
            ("GetMinerInfo", get_miner_info),
            ("GetNodeType", get_node_type),
            ("GetPrevDifficulty", get_prev_difficulty),
            ("GetPrevDSDifficulty", get_prev_ds_difficulty),
            ("GetShardingStructure", get_sharding_structure),
            ("GetSmartContractSubState", get_smart_contract_sub_state),
            (
                "GetSoftConfirmedTransaction",
                get_soft_confirmed_transaction
            ),
            ("GetStateProof", get_state_proof),
            ("GetTransactionStatus", get_transaction_status),
        ],
    )
}

/// Take an Address and produce a checksummed hex representation of it.
/// No initial 0x will be added.
/// Public because some of the tests require it.
pub fn to_zil_checksum_string(address: &Address) -> String {
    const UPPER_CHARS: [char; 6] = ['A', 'B', 'C', 'D', 'E', 'F'];
    const LOWER_CHARS: [char; 16] = [
        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f',
    ];
    let bytes = address.into_array();
    let mut hasher = Sha256::new();
    hasher.update(bytes);
    let digest = hasher.finalize();
    let mut result = String::new();
    // You could do this with iterators, but it's horrid.
    for (idx, byte) in bytes.iter().enumerate() {
        for nibble in 0..2 {
            let shift = (1 - nibble) << 2;
            let val = (byte >> shift) & 0xf;
            // Should this be uppercase?
            let bit_num = 6 * ((idx << 1) + nibble);
            let bit = digest[bit_num >> 3] & (1 << (7 - (bit_num & 7)));
            if bit != 0 && val > 9 {
                result.push(UPPER_CHARS[usize::from(val - 10)])
            } else {
                result.push(LOWER_CHARS[usize::from(val)])
            }
        }
    }
    result
}

#[derive(Deserialize)]
#[serde(transparent)]
pub struct ZilAddress {
    #[serde(deserialize_with = "deserialize_zil_address")]
    inner: Address,
}

impl From<ZilAddress> for Address {
    fn from(value: ZilAddress) -> Self {
        value.inner
    }
}

fn deserialize_zil_address<'de, D>(deserializer: D) -> Result<Address, D::Error>
where
    D: Deserializer<'de>,
{
    use serde::de::Error as E;

    let s = String::deserialize(deserializer)?;

    bech32::decode(&s).map_or_else(
        |_| s.parse().map_err(E::custom),
        |(hrp, data)| {
            if hrp.as_str() == "zil" {
                (&data[..]).try_into().map_err(E::custom)
            } else {
                Err(E::custom("Invalid HRP, expected 'zil'"))
            }
        },
    )
}

#[derive(Deserialize)]
#[serde(rename_all = "camelCase")]
struct TransactionParams {
    version: u32,
    nonce: u64,
    to_addr: String,
    #[serde(deserialize_with = "from_str")]
    amount: ZilAmount,
    pub_key: String,
    #[serde(deserialize_with = "from_str")]
    gas_price: ZilAmount,
    #[serde(deserialize_with = "from_str")]
    gas_limit: ScillaGas,
    #[serde(default)]
    code: Option<String>,
    #[serde(default)]
    data: Option<String>,
    signature: String,
}

fn from_str<'de, T, D>(deserializer: D) -> Result<T, D::Error>
where
    D: Deserializer<'de>,
    T: FromStr,
    T::Err: Display,
{
    let s = String::deserialize(deserializer)?;
    s.parse().map_err(serde::de::Error::custom)
}
/// Helper function to extract signer address from a public key
fn extract_signer_address(key: &schnorr::PublicKey) -> Address {
    let hashed = Sha256::digest(key.to_encoded_point(true).as_bytes());
    let (_, bytes): (GenericArray<u8, U12>, GenericArray<u8, U20>) = hashed.split();
    Address::new(bytes.into())
}

// CreateTransaction
fn create_transaction(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<CreateTransactionResponse> {
    let transaction: TransactionParams = params.one()?;

    let node = node.read();

    let version = transaction.version & 0xffff;
    let chain_id = transaction.version >> 16;

    if (chain_id as u64) != (node.chain_id.zil()) {
        Err(ErrorObject::owned::<String>(
            RPCErrorCode::RpcVerifyRejected as i32,
            format!(
                "unexpected chain ID, expected: {}, got: {chain_id}",
                node.chain_id.zil()
            ),
            None,
        ))?;
    }

    if version != 1 {
        Err(ErrorObject::owned::<String>(
            RPCErrorCode::RpcVerifyRejected as i32,
            format!("unexpected version, expected: 1, got: {version}"),
            None,
        ))?;
    }

    let pre_key = hex::decode(transaction.pub_key).map_err(|_|
                // This is apparently what ZQ1 does.
                ErrorObject::owned::<String>(RPCErrorCode::RpcVerifyRejected as i32,
                                   "Cannot parse public key".to_string(),
                                   None))?;

    let key = schnorr::PublicKey::from_sec1_bytes(&pre_key).map_err(|_|
                 // This is apparently what ZQ1 does.
                 ErrorObject::owned::<String>(RPCErrorCode::RpcVerifyRejected as i32,
                                              "Invalid public key".to_string(),
                                              None))?;

    // Addresses without an 0x prefix are legal.
    let corrected_addr = if transaction.to_addr.starts_with("0x") {
        transaction.to_addr
    } else {
        format!("0x{0}", transaction.to_addr)
    };
    let to_addr = Address::parse_checksummed(&corrected_addr, None).or_else(|_| {
        // Not eth checksummed. How about Zilliqa?
        let addr = Address::from_str(&corrected_addr)?;
        let summed = format!("0x{0}", to_zil_checksum_string(&addr));
        if summed == corrected_addr {
            Ok(addr)
        } else {
            // Copied from ZQ1
            Err(anyhow!("To Addr checksum wrong"))
        }
    })?;

    let sig = schnorr::Signature::from_str(&transaction.signature).map_err(|err| {
        ErrorObject::owned::<String>(
            RPCErrorCode::RpcVerifyRejected as i32,
            format!("Cannot extract signature - {}", err),
            None,
        )
    })?;

    // If we don't trap this here, it will later cause the -1 in
    // transaction::get_nonce() to pan1ic.
    if transaction.nonce == 0 {
        Err(ErrorObject::owned::<String>(
            RPCErrorCode::RpcInvalidParameter as i32,
            "Invalid nonce (0)".to_string(),
            None,
        ))?;
    }

    let tx = TxZilliqa {
        chain_id: chain_id as u16,
        nonce: transaction.nonce,
        gas_price: transaction.gas_price,
        gas_limit: transaction.gas_limit,
        to_addr,
        amount: transaction.amount,
        code: transaction.code.unwrap_or_default(),
        data: transaction.data.unwrap_or_default(),
    };
    let signed_transaction = SignedTransaction::Zilliqa {
        tx: tx.clone(),
        key,
        sig,
    };

    let Ok(transaction) = signed_transaction.verify() else {
        Err(ErrorObject::owned::<String>(
            RPCErrorCode::RpcVerifyRejected as i32,
            "signature",
            None,
        ))?
    };
    let (transaction_hash, result) = node.create_transaction(transaction)?;
    let info = match result {
        TxAddResult::AddedToMempool => Ok("Txn processed".to_string()),
        TxAddResult::Duplicate(_) => Ok("Txn already present".to_string()),
        TxAddResult::SameNonceButLowerGasPrice => {
            // Ideally it would be nice to return an error here, but we would break compatibility if we did.
            Ok("Another transaction exists with the same nonce but a higher gas price".to_string())
        }
        TxAddResult::CannotVerifySignature => Err(ErrorObject::owned::<String>(
            RPCErrorCode::RpcVerifyRejected as i32,
            "Cannot verify signature".to_string(),
            None,
        )),
        TxAddResult::ValidationFailed(reason) => {
            let code = match &reason {
                ValidationOutcome::InsufficientGasZil(_, _)
                | ValidationOutcome::InsufficientGasEvm(_, _)
                | ValidationOutcome::NonceTooLow(_, _)
                | ValidationOutcome::InsufficientFunds(_, _)
                | ValidationOutcome::BlockGasLimitExceeded(_, _) => {
                    RPCErrorCode::RpcInvalidParameter
                }
                _ => RPCErrorCode::RpcVerifyRejected,
            };
            Err(ErrorObject::owned::<String>(
                code as i32,
                reason.to_msg_string(),
                None,
            ))
        }
        TxAddResult::NonceTooLow(got, expected) => {
            Ok(format!("Nonce ({got}) lower than current ({expected})"))
        }
    }?;
    let contract_address = if !tx.code.is_empty() {
        let signer = extract_signer_address(&key);
        Some(zil_contract_address(signer, tx.nonce - 1))
    } else {
        None
    };

    let response = CreateTransactionResponse {
        contract_address,
        info,
        tran_id: transaction_hash.0.into(),
    };

    Ok(response)
}

// GetContractAddressFromTransactionID
fn get_contract_address_from_transaction_id(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<String> {
    let hash: B256 = params.one()?;
    let hash: Hash = Hash(hash.0);
    let (receipt, signed_transaction) = {
        let node = node.read();
        let receipt = node
            .get_transaction_receipt(hash)?
            .ok_or_else(|| anyhow!("Txn Hash not Present"))?;
        let signed_transaction = node
            .get_transaction_by_hash(hash)?
            .ok_or_else(|| anyhow!("Txn Hash not Present"))?;
        (receipt, signed_transaction)
    };

    let contract_address = receipt
        .contract_address
        .ok_or_else(|| anyhow!("ID is not a contract txn"))?;

    let contract_address = match signed_transaction.tx {
        SignedTransaction::Zilliqa { tx, .. } => {
            tx.get_contract_address(&signed_transaction.signer)?
        }
        _ => contract_address,
    };

    Ok(contract_address.to_hex_no_prefix())
}

// GetTransaction
fn get_transaction(params: Params, node: &Arc<RwLock<Node>>) -> Result<GetTxResponse> {
    let jsonrpc_error_data: Option<String> = None;
    let hash: B256 = params.one()?;
    let hash: Hash = Hash(hash.0);

    let node = node.read();

    let tx = node.get_transaction_by_hash(hash)?.ok_or_else(|| {
        ErrorObject::owned(
            RPCErrorCode::RpcDatabaseError as i32,
            "Txn Hash not Present".to_string(),
            jsonrpc_error_data.clone(),
        )
    })?;
    let receipt = node.get_transaction_receipt(hash)?.ok_or_else(|| {
        jsonrpsee::types::ErrorObject::owned(
            RPCErrorCode::RpcDatabaseError as i32,
            "Txn Hash not Present".to_string(),
            jsonrpc_error_data.clone(),
        )
    })?;
    let block = node
        .get_block(receipt.block_hash)?
        .ok_or_else(|| anyhow!("block does not exist"))?;
    if block.number() > node.get_finalized_height()? {
        return Err(ErrorObject::owned(
            RPCErrorCode::RpcDatabaseError as i32,
            "Block not finalized".to_string(),
            jsonrpc_error_data,
        )
        .into());
    }

    GetTxResponse::new(tx, receipt, block.number())
}

// GetBalance
fn get_balance(params: Params, node: &Arc<RwLock<Node>>) -> Result<Value> {
    let address: ZilAddress = params.one()?;
    let address: Address = address.into();

    let node = node.read();
    let block = node
        .get_block(BlockId::finalized())?
        .ok_or_else(|| anyhow!("Unable to get finalized block!"))?;

    let state = node.get_state(&block)?;

    if !state.has_account(address)? {
        return Err(ErrorObject::owned(
            RPCErrorCode::RpcInvalidAddressOrKey as i32,
            "Account is not created",
            None::<()>,
        )
        .into());
    }

    let account = state.get_account(address)?;

    // We need to scale the balance from units of (10^-18) ZIL to (10^-12) ZIL. The value is truncated in this process.
    let balance = account.balance / 10u128.pow(6);

    Ok(json!({"balance": balance.to_string(), "nonce": account.nonce}))
}

// GetCurrentMiniEpoch
fn get_current_mini_epoch(_: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    Ok(node.read().get_finalized_block_number()?.to_string())
}

// GetLatestTxBlock
fn get_latest_tx_block(_: Params, node: &Arc<RwLock<Node>>) -> Result<zil::TxBlock> {
    let node = node.read();
    let block = node
        .get_block(BlockId::finalized())?
        .ok_or_else(|| anyhow!("no finalized blocks"))?;

    let txn_fees = get_txn_fees_for_block(&node, block.hash())?;
    let tx_block: zil::TxBlock = zil::TxBlock::new(&block, txn_fees);
    Ok(tx_block)
}

// GetMinimumGasPrice
fn get_minimum_gas_price(_: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    let price = node.read().get_gas_price();
    // `price` is the cost per unit of [EvmGas]. This API should return the cost per unit of [ScillaGas].
    let price = price * (EVM_GAS_PER_SCILLA_GAS as u128);

    Ok(ZilAmount::from_amount(price).to_string())
}

// GetNetworkId
fn get_network_id(_: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    let network_id = node.read().chain_id.zil();
    Ok(network_id.to_string())
}

// GetVersion
fn get_version(_: Params, _: &Arc<RwLock<Node>>) -> Result<Value> {
    let commit = env!("VERGEN_GIT_SHA");
    let version = env!("VERGEN_GIT_DESCRIBE");
    Ok(json!({
        "Commit": commit,
        "Version": version,
    }))
}

// GetBlockchainInfo
fn get_blockchain_info(_: Params, node: &Arc<RwLock<Node>>) -> Result<BlockchainInfo> {
    let transaction_rate = get_tx_rate(Params::new(None), node)?;
    let tx_block_rate = calculate_tx_block_rate(node)?;
    let sharding_structure = get_sharding_structure(Params::new(None), node)?;

    let node = node.read();

    let num_peers = node.get_peer_num();
    let num_tx_blocks = node.get_finalized_block_number()?;
    let num_ds_blocks = (num_tx_blocks / TX_BLOCKS_PER_DS_BLOCK) + 1;
    let num_transactions = node.consensus.get_num_transactions()?;
    let ds_block_rate = tx_block_rate / TX_BLOCKS_PER_DS_BLOCK as f64;

    // num_txns_ds_epoch
    let current_epoch = node.get_finalized_block_number()? / TX_BLOCKS_PER_DS_BLOCK;
    let current_epoch_first = current_epoch * TX_BLOCKS_PER_DS_BLOCK;
    let mut num_txns_ds_epoch = 0;
    for i in current_epoch_first..node.get_finalized_block_number()? {
        let block = node
            .get_block(i)?
            .ok_or_else(|| anyhow!("Block not found"))?;
        num_txns_ds_epoch += block.transactions.len();
    }

    // num_txns_tx_epoch
    let finalized_block = node.get_finalized_block()?;
    let num_txns_tx_epoch = match finalized_block {
        Some(block) => block.transactions.len(),
        None => 0,
    };

    Ok(BlockchainInfo {
        num_peers: num_peers as u16,
        num_tx_blocks,
        num_ds_blocks,
        num_transactions: num_transactions as u64,
        transaction_rate,
        tx_block_rate,
        ds_block_rate,
        current_mini_epoch: num_tx_blocks,
        current_ds_epoch: num_ds_blocks,
        num_txns_ds_epoch: num_txns_ds_epoch as u64,
        num_txns_tx_epoch: num_txns_tx_epoch as u64,
        sharding_structure,
    })
}

// GetNumTxBlocks
fn get_num_tx_blocks(_: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    let node = node.read();

    Ok(node.get_finalized_block_number()?.to_string())
}

// GetSmartContractState
fn get_smart_contract_state(params: Params, node: &Arc<RwLock<Node>>) -> Result<Value> {
    let mut seq = params.sequence();
    let address: ZilAddress = seq.next()?;
    let address: Address = address.into();

    let node = node.read();

    // First get the account and check that its a scilla account
    let block = node
        .get_block(BlockId::finalized())?
        .ok_or_else(|| anyhow!("Unable to get finalized block!"))?;

    let state = node.get_state(&block)?;
    if !state.has_account(address)? {
        return Err(anyhow!(
            "Address does not exist: {}",
            hex::encode(address.0)
        ));
    }
    let account = state.get_account(address)?;

    let result = json!({
        "_balance": ZilAmount::from_amount(account.balance).to_string(),
    });
    let Value::Object(mut result) = result else {
        unreachable!()
    };

    if account.code.is_scilla() {
        let limit = node.config.state_rpc_limit;

        let trie = state.get_account_trie(address)?;
        for (i, (k, v)) in trie.iter().enumerate() {
            if i >= limit {
                return Err(anyhow!(
                    "State of contract returned has size greater than the allowed maximum"
                ));
            }

            let (var_name, indices) = split_storage_key(&k)?;
            let mut var = result.entry(var_name.clone());

            for index in indices.iter() {
                let next = var.or_insert_with(|| Value::Object(Default::default()));
                let Value::Object(next) = next else {
                    unreachable!()
                };
                let key: String = serde_json::from_slice(index)?;
                var = next.entry(key.clone());
            }

            let field_defs = match &account.code {
                Code::Scilla { types, .. } => types,
                _ => unreachable!(),
            };
            let (_, depth) = field_defs.get(&var_name).unwrap();
            let depth = *depth as usize;

            let convert_result = serde_json::from_slice(&v);
            if depth > 0 && indices.len() < depth {
                if convert_result.is_err() {
                    var.or_insert(Value::Object(Default::default()));
                }
            } else {
                var.or_insert(convert_result?);
            }
        }

        // Insert empty maps to the state. Empty maps are not returned by the trie iterator.
        let field_defs = match &account.code {
            Code::Scilla { types, .. } => types,
            _ => unreachable!(),
        };
        for (var_name, (type_, _)) in field_defs.iter() {
            if type_.starts_with("Map") {
                result
                    .entry(var_name)
                    .or_insert(Value::Object(Default::default()));
            }
        }
    }

    Ok(result.into())
}

// GetSmartContractCode
fn get_smart_contract_code(params: Params, node: &Arc<RwLock<Node>>) -> Result<Value> {
    let address: ZilAddress = params.one()?;
    let address: Address = address.into();

    let node = node.read();
    let block = node
        .get_block(BlockId::finalized())?
        .ok_or_else(|| anyhow!("Unable to get the finalized block!"))?;
    let state = node.get_state(&block)?;

    if !state.has_account(address)? {
        return Err(ErrorObject::owned(
            RPCErrorCode::RpcInvalidAddressOrKey as i32,
            format!("Address does not exist: {}", address),
            None::<()>,
        )
        .into());
    }
    let account = state.get_account(address)?;

    let (code, type_) = match account.code {
        Code::Evm(ref bytes) => (hex::encode(bytes), "evm"),
        Code::Scilla { code, .. } => (code, "scilla"),
    };

    Ok(json!({ "code": code, "type": type_ }))
}

// GetSmartContractInit
fn get_smart_contract_init(params: Params, node: &Arc<RwLock<Node>>) -> Result<Vec<ParamValue>> {
    let address: ZilAddress = params.one()?;
    let address: Address = address.into();

    let node = node.read();
    let block = node
        .get_block(BlockId::finalized())?
        .ok_or_else(|| anyhow!("Unable to get the finalized block!"))?;

    let state = node.get_state(&block)?;

    if !state.has_account(address)? {
        return Err(ErrorObject::owned(
            RPCErrorCode::RpcInvalidAddressOrKey as i32,
            "Address does not exist".to_string(),
            None::<()>,
        )
        .into());
    }
    let account = state.get_account(address)?;

    let Some((_, init_data)) = account.code.scilla_code_and_init_data() else {
        return Err(anyhow!("Address does not exist"));
    };

    Ok(init_data.to_vec())
}

// GetTransactionsForTxBlock
fn get_transactions_for_tx_block(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<Vec<Vec<String>>> {
    let block_number: String = params.one()?;
    let block_number: u64 = block_number.parse()?;

    let node = node.read();
    let Some(block) = node.get_block(block_number)? else {
        return Err(anyhow!("Tx Block does not exist"));
    };
    if block.transactions.is_empty() {
        return Err(anyhow!("TxBlock has no transactions"));
    }

    Ok(vec![
        block
            .transactions
            .into_iter()
            .map(|h| B256::from(h).to_hex_no_prefix())
            .collect(),
    ])
}

pub const TRANSACTIONS_PER_PAGE: usize = 2500;
pub const TX_BLOCKS_PER_DS_BLOCK: u64 = 100;

// GetTxBlock
fn get_tx_block(params: Params, node: &Arc<RwLock<Node>>) -> Result<Option<zil::TxBlock>> {
    let block_number: String = params.one()?;
    let block_number: u64 = block_number.parse()?;

    let node = node.read();
    let Some(block) = node.get_block(block_number)? else {
        return Ok(None);
    };
    if block.number() > node.get_finalized_height()? {
        return Err(anyhow!("Block not finalized"));
    }
    let txn_fees = get_txn_fees_for_block(&node, block.hash())?;
    let block: zil::TxBlock = zil::TxBlock::new(&block, txn_fees);

    Ok(Some(block))
}

fn get_txn_fees_for_block(node: &Node, hash: Hash) -> Result<EvmGas> {
    Ok(node
        .get_transaction_receipts_in_block(hash)?
        .iter()
        .fold(EvmGas(0), |acc, txnrcpt| acc + txnrcpt.gas_used))
}

// GetTxBlockVerbose
fn get_tx_block_verbose(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<Option<zil::TxBlockVerbose>> {
    let block_number: String = params.one()?;
    let block_number: u64 = block_number.parse()?;

    let node = node.read();
    let Some(block) = node.get_block(block_number)? else {
        return Ok(None);
    };
    if block.number() > node.get_finalized_height()? {
        return Err(anyhow!("Block not finalized"));
    }
    let proposer = node
        .get_proposer_reward_address(block.header)?
        .expect("No proposer");
    let txn_fees = get_txn_fees_for_block(&node, block.hash())?;
    let block: zil::TxBlockVerbose = zil::TxBlockVerbose::new(&block, txn_fees, proposer);

    Ok(Some(block))
}

// GetSmartContracts
fn get_smart_contracts(params: Params, node: &Arc<RwLock<Node>>) -> Result<Vec<SmartContract>> {
    let address: ZilAddress = params.one()?;
    let address: Address = address.into();
    let node = node.read();

    let block = node
        .get_finalized_block()?
        .ok_or_else(|| anyhow!("Unable to get the finalized block!"))?;

    let state = node.get_state(&block)?;

    if !state.has_account(address)? {
        return Err(ErrorObject::owned(
            RPCErrorCode::RpcInvalidAddressOrKey as i32,
            "Address does not exist".to_string(),
            None::<()>,
        )
        .into());
    }

    let account = state.get_account(address)?;

    if !account.code.is_eoa() {
        return Err(ErrorObject::owned(
            RPCErrorCode::RpcInvalidAddressOrKey as i32,
            "A contract account queried".to_string(),
            None::<()>,
        )
        .into());
    }

    let nonce = account.nonce;

    let mut contracts = vec![];

    for i in 0..nonce {
        let contract_address = zil_contract_address(address, i);

        let is_scilla = node
            .get_state(&block)?
            .get_account(contract_address)?
            .code
            .scilla_code_and_init_data()
            .is_some();

        // Note that we only expose created Scilla contracts in this API.
        if is_scilla {
            contracts.push(SmartContract {
                address: contract_address,
            });
        }
    }

    Ok(contracts)
}

fn get_example_ds_block_verbose(dsblocknum: u64, txblocknum: u64) -> DSBlockVerbose {
    DSBlockVerbose {
        b1: vec![false, false, false],
        b2: vec![false, false],
        cs1: String::from(
            "FBA696961142862169D03EED67DD302EAB91333CBC4EEFE7EDB230515DA31DC1B9746EEEE5E7C105685E22C483B1021867B3775D30215CA66D5D81543E9FE8B5",
        ),
        prev_dshash: String::from(
            "585373fb2c607b324afbe8f592e43b40d0091bbcef56c158e0879ced69648c8e",
        ),
        header: DSBlockHeaderVerbose {
            block_num: dsblocknum.to_string(),
            committee_hash: String::from(
                "da38b3b21b26b71835bb1545246a0a248f97003de302ae20d70aeaf854403029",
            ),
            difficulty: 95,
            difficulty_ds: 156,
            epoch_num: txblocknum.to_string(),
            gas_price: String::from("2000000000"),
            members_ejected: vec![],
            po_wwinners: vec![],
            po_wwinners_ip: vec![],
            prev_hash: String::from(
                "585373fb2c607b324afbe8f592e43b40d0091bbcef56c158e0879ced69648c8e",
            ),
            reserved_field: String::from(
                "0000000000000000000000000000000000000000000000000000000000000000",
            ),
            swinfo: SWInfo {
                scilla: vec![],
                zilliqa: vec![],
            },
            sharding_hash: String::from(
                "3216a33bfd4801e1907e72c7d529cef99c38d57cd281d0e9d726639fd9882d25",
            ),
            timestamp: String::from("1606443830834512"),
            version: 2,
        },
        signature: String::from(
            "7EE023C56602A17F2C8ABA2BEF290386D7C2CE1ABD8E3621573802FA67B243DE60B3EBEE5C4CCFDB697C80127B99CB384DAFEB44F70CD7569F2816DB950877BB",
        ),
    }
}

fn get_example_ds_block(dsblocknum: u64, txblocknum: u64) -> DSBlock {
    get_example_ds_block_verbose(dsblocknum, txblocknum).into()
}

// GetDSBlock
pub fn get_ds_block(params: Params, _node: &Arc<RwLock<Node>>) -> Result<DSBlock> {
    // Dummy implementation
    let block_number: String = params.one()?;
    let block_number: u64 = block_number.parse()?;
    Ok(get_example_ds_block(
        block_number,
        block_number * TX_BLOCKS_PER_DS_BLOCK,
    ))
}

// GetDSBlockVerbose
pub fn get_ds_block_verbose(params: Params, _node: &Arc<RwLock<Node>>) -> Result<DSBlockVerbose> {
    // Dummy implementation
    let block_number: String = params.one()?;
    let block_number: u64 = block_number.parse()?;
    Ok(get_example_ds_block_verbose(
        block_number,
        block_number * TX_BLOCKS_PER_DS_BLOCK,
    ))
}

// GetLatestDSBlock
pub fn get_latest_ds_block(_params: Params, node: &Arc<RwLock<Node>>) -> Result<DSBlock> {
    // Dummy implementation
    let node = node.read();
    let num_tx_blocks = node.get_finalized_block_number()?;
    let num_ds_blocks = (num_tx_blocks / TX_BLOCKS_PER_DS_BLOCK) + 1;
    Ok(get_example_ds_block(num_ds_blocks, num_tx_blocks))
}

// GetCurrentDSComm
pub fn get_current_ds_comm(
    _params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<GetCurrentDSCommResult> {
    // Dummy implementation
    let node = node.read();
    let num_tx_blocks = node.get_finalized_block_number()?;
    let num_ds_blocks = (num_tx_blocks / TX_BLOCKS_PER_DS_BLOCK) + 1;
    Ok(GetCurrentDSCommResult {
        current_dsepoch: num_ds_blocks.to_string(),
        current_tx_epoch: num_tx_blocks.to_string(),
        num_of_dsguard: 420,
        dscomm: vec![],
    })
}

// GetCurrentDSEpoch
pub fn get_current_ds_epoch(_params: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    // Dummy implementation
    let node = node.read();
    let num_tx_blocks = node.get_finalized_block_number()?;
    let num_ds_blocks = (num_tx_blocks / TX_BLOCKS_PER_DS_BLOCK) + 1;
    Ok(num_ds_blocks.to_string())
}

// DSBlockListing
pub fn ds_block_listing(params: Params, node: &Arc<RwLock<Node>>) -> Result<DSBlockListingResult> {
    // Dummy implementation
    let num_tx_blocks = node.read().get_finalized_block_number()?;

    let num_ds_blocks = (num_tx_blocks / TX_BLOCKS_PER_DS_BLOCK)
        + if num_tx_blocks % TX_BLOCKS_PER_DS_BLOCK == 0 {
            0
        } else {
            1
        };
    let max_pages = num_ds_blocks / 10 + if num_ds_blocks % 10 == 0 { 0 } else { 1 };
    let page_requested: u64 = params.one()?;

    if page_requested == 0 || page_requested > max_pages {
        return Err(anyhow!(format!(
            "Page out of range. Valid range is 1 to {}",
            max_pages
        )));
    }

    let end_blocknum = num_ds_blocks - ((page_requested - 1) * 10);
    let base_blocknum = end_blocknum.saturating_sub(10);
    let listings: Vec<DSBlockListing> = (base_blocknum..end_blocknum)
        .rev()
        .map(|blocknum| DSBlockListing {
            block_num: blocknum,
            hash: "4DEED80AFDCC89D5B691DCB54CCB846AD9D823D448A56ACAC4DBE5E1213244C7".to_string(),
        })
        .collect();

    Ok(DSBlockListingResult {
        data: listings,
        max_pages: max_pages.try_into()?,
    })
}

// utility function to calculate the tx block rate for get_ds_block_rate and get_tx_block_rate
pub fn calculate_tx_block_rate(node: &Arc<RwLock<Node>>) -> Result<f64> {
    let node = node.read();
    let max_measurement_blocks = 5;
    let height = node.get_finalized_block_number()?;
    if height == 0 {
        return Ok(0.0);
    }
    let measurement_blocks = height.min(max_measurement_blocks);
    let start_measure_block = node
        .get_block(height - measurement_blocks + 1)?
        .ok_or(anyhow!("Unable to get block"))?;
    let start_measure_time = start_measure_block.header.timestamp;
    let end_measure_time = SystemTime::now();
    let elapsed_time = end_measure_time.duration_since(start_measure_time)?;
    let tx_block_rate = measurement_blocks as f64 / elapsed_time.as_secs_f64();
    Ok(tx_block_rate)
}

// GetDSBlockRate
pub fn get_ds_block_rate(_params: Params, node: &Arc<RwLock<Node>>) -> Result<DSBlockRateResult> {
    let tx_block_rate = calculate_tx_block_rate(node)?;
    let ds_block_rate = tx_block_rate / TX_BLOCKS_PER_DS_BLOCK as f64;
    Ok(DSBlockRateResult {
        rate: ds_block_rate,
    })
}

// GetTxBlockRate
fn get_tx_block_rate(_params: Params, node: &Arc<RwLock<Node>>) -> Result<TXBlockRateResult> {
    let tx_block_rate = calculate_tx_block_rate(node)?;
    Ok(TXBlockRateResult {
        rate: tx_block_rate,
    })
}

// TxBlockListing
fn tx_block_listing(params: Params, node: &Arc<RwLock<Node>>) -> Result<TxBlockListingResult> {
    let page_number: u64 = params.one()?;

    let node = node.read();
    let num_tx_blocks = node.get_finalized_block_number()?;
    let max_pages = (num_tx_blocks / 10) + if num_tx_blocks % 10 == 0 { 0 } else { 1 };

    if page_number == 0 || page_number > max_pages {
        return Err(anyhow!(format!(
            "Page out of range. Valid range is 1 to {}",
            max_pages
        )));
    }

    let end_block = num_tx_blocks - ((page_number - 1) * 10);
    let start_block = end_block.saturating_sub(10);

    let listings: Vec<TxBlockListing> = (start_block..end_block)
        .rev()
        .filter_map(|block_number| {
            node.get_block(block_number)
                .ok()
                .flatten()
                .map(|block| TxBlockListing {
                    block_num: block.number(),
                    hash: block.hash().to_string(),
                })
        })
        .collect();

    Ok(TxBlockListingResult {
        data: listings,
        max_pages,
    })
}

// GetNumPeers
fn get_num_peers(_params: Params, node: &Arc<RwLock<Node>>) -> Result<u64> {
    let node = node.read();
    let num_peers = node.get_peer_num();
    Ok(num_peers as u64)
}

// GetTransactionRate
// Calculates transaction rate over the most recent block
fn get_tx_rate(_params: Params, node: &Arc<RwLock<Node>>) -> Result<f64> {
    let node = node.read();
    let head_block_num = node.get_finalized_block_number()?;
    if head_block_num <= 1 {
        return Ok(0.0);
    }
    let prev_block_num = head_block_num - 1;
    let head_block = node
        .get_block(head_block_num)?
        .ok_or(anyhow!("Unable to get block"))?;
    let prev_block = node
        .get_block(prev_block_num)?
        .ok_or(anyhow!("Unable to get block"))?;
    let transactions_both = prev_block.transactions.len() + head_block.transactions.len();
    let time_between = head_block
        .header
        .timestamp
        .duration_since(prev_block.header.timestamp)?;
    let transaction_rate = transactions_both as f64 / time_between.as_secs_f64();
    Ok(transaction_rate)
}

// GetTransactionsForTxBlockEx
fn get_transactions_for_tx_block_ex(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<TxnsForTxBlockExResponse> {
    let mut seq = params.sequence();
    let block_number: String = seq.next()?;
    let page_number: String = seq.next()?;
    let block_number: u64 = block_number.parse()?;
    let page_number: usize = page_number.parse()?;

    let node = node.read();
    let block = node
        .get_block(block_number)?
        .ok_or_else(|| anyhow!("Block not found"))?;
    if block.number() > node.get_finalized_height()? {
        return Err(anyhow!("Block not finalized"));
    }

    let total_transactions = block.transactions.len();
    let num_pages = (total_transactions / TRANSACTIONS_PER_PAGE)
        + (if total_transactions % TRANSACTIONS_PER_PAGE != 0 {
            1
        } else {
            0
        });

    // Ensure page is within bounds
    if page_number >= num_pages {
        return Ok(TxnsForTxBlockExResponse {
            curr_page: page_number as u64,
            num_pages: num_pages as u64,
            transactions: vec![],
        });
    }

    let start = std::cmp::min(page_number * TRANSACTIONS_PER_PAGE, total_transactions);

    let end = std::cmp::min(start + TRANSACTIONS_PER_PAGE, total_transactions);
    let slice = block.transactions[start..end].to_vec();

    Ok(TxnsForTxBlockExResponse {
        curr_page: page_number as u64,
        num_pages: num_pages as u64,
        transactions: slice
            .into_iter()
            .map(|h| B256::from(h).to_hex_no_prefix())
            .collect(),
    })
}

// GetTransactionsForTxBlockEx
fn extract_transaction_bodies(block: &Block, node: &Node) -> Result<Vec<TransactionBody>> {
    let mut transactions = Vec::with_capacity(block.transactions.len());
    for hash in &block.transactions {
        let tx = node
            .get_transaction_by_hash(*hash)?
            .ok_or(anyhow!("Transaction hash missing"))?;
        let nonce = tx.tx.nonce().unwrap_or_default();
        let amount = tx.tx.zil_amount();
        let gas_price = tx.tx.gas_price_per_scilla_gas();
        let gas_limit = tx.tx.gas_limit_scilla();
        let receipt = node
            .get_transaction_receipt(*hash)?
            .ok_or(anyhow!("Transaction receipt missing"))?;
        let receipt_response = TransactionReceiptResponse {
            cumulative_gas: ScillaGas::from(receipt.cumulative_gas_used).to_string(),
            epoch_num: block.number().to_string(),
            success: receipt.success,
        };
        let (version, to_addr, sender_pub_key, signature, _code, _data) = match tx.tx {
            SignedTransaction::Zilliqa { tx, sig, key } => (
                ((tx.chain_id as u32) << 16) | 1,
                tx.to_addr,
                key.to_encoded_point(true).as_bytes().to_hex(),
                <[u8; 64]>::from(sig.to_bytes()).to_hex(),
                (!tx.code.is_empty()).then_some(tx.code),
                (!tx.data.is_empty()).then_some(tx.data),
            ),
            SignedTransaction::Legacy { tx, sig } => (
                ((tx.chain_id.unwrap_or_default() as u32) << 16) | 2,
                tx.to.to().copied().unwrap_or_default(),
                sig.recover_from_prehash(&tx.signature_hash())?
                    .to_sec1_bytes()
                    .to_hex(),
                sig.as_bytes().to_hex(),
                tx.to.is_create().then(|| hex::encode(&tx.input)),
                tx.to.is_call().then(|| hex::encode(&tx.input)),
            ),
            SignedTransaction::Eip2930 { tx, sig } => (
                ((tx.chain_id as u32) << 16) | 3,
                tx.to.to().copied().unwrap_or_default(),
                sig.recover_from_prehash(&tx.signature_hash())?
                    .to_sec1_bytes()
                    .to_hex(),
                sig.as_bytes().to_hex(),
                tx.to.is_create().then(|| hex::encode(&tx.input)),
                tx.to.is_call().then(|| hex::encode(&tx.input)),
            ),
            SignedTransaction::Eip1559 { tx, sig } => (
                ((tx.chain_id as u32) << 16) | 4,
                tx.to.to().copied().unwrap_or_default(),
                sig.recover_from_prehash(&tx.signature_hash())?
                    .to_sec1_bytes()
                    .to_hex(),
                sig.as_bytes().to_hex(),
                tx.to.is_create().then(|| hex::encode(&tx.input)),
                tx.to.is_call().then(|| hex::encode(&tx.input)),
            ),
            SignedTransaction::Intershard { tx, .. } => (
                ((tx.chain_id as u32) << 16) | 20,
                tx.to_addr.unwrap_or_default(),
                String::new(),
                String::new(),
                tx.to_addr.is_none().then(|| hex::encode(&tx.payload)),
                tx.to_addr.is_some().then(|| hex::encode(&tx.payload)),
            ),
        };
        let body = TransactionBody {
            id: tx.hash.to_string(),
            amount: amount.to_string(),
            gas_limit: gas_limit.to_string(),
            gas_price: gas_price.to_string(),
            nonce: nonce.to_string(),
            receipt: receipt_response,
            sender_pub_key,
            signature,
            to_addr: to_addr.to_string(),
            version: version.to_string(),
        };
        transactions.push(body);
    }
    Ok(transactions)
}

// GetTxnBodiesForTxBlock
fn get_txn_bodies_for_tx_block(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<Vec<TransactionBody>> {
    let params: Vec<String> = params.parse()?;
    let block_number: u64 = params[0].parse()?;

    let node = node.read();
    let block = node
        .get_block(block_number)?
        .ok_or_else(|| anyhow!("Block not found"))?;

    if block.number() > node.get_finalized_height()? {
        return Err(anyhow!("Block not finalized"));
    }

    extract_transaction_bodies(&block, &node)
}

// GetTxnBodiesForTxBlockEx
fn get_txn_bodies_for_tx_block_ex(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<TxnBodiesForTxBlockExResponse> {
    let params: Vec<String> = params.parse()?;
    let block_number: u64 = params[0].parse()?;
    let page_number: usize = params[1].parse()?;

    let node = node.read();
    let block = node
        .get_block(block_number)?
        .ok_or_else(|| anyhow!("Block not found"))?;

    if block.number() > node.get_finalized_height()? {
        return Err(anyhow!("Block not finalized"));
    }

    let total_transactions = block.transactions.len();
    let num_pages = (total_transactions / TRANSACTIONS_PER_PAGE)
        + (if total_transactions % TRANSACTIONS_PER_PAGE != 0 {
            1
        } else {
            0
        });

    // Ensure page is within bounds
    if page_number >= num_pages {
        return Ok(TxnBodiesForTxBlockExResponse {
            curr_page: page_number as u64,
            num_pages: num_pages as u64,
            transactions: vec![],
        });
    }

    let start = std::cmp::min(page_number * TRANSACTIONS_PER_PAGE, total_transactions);
    let end = std::cmp::min(start + TRANSACTIONS_PER_PAGE, total_transactions);

    let transactions = extract_transaction_bodies(&block, &node)?
        .into_iter()
        .skip(start)
        .take(end - start)
        .collect();

    Ok(TxnBodiesForTxBlockExResponse {
        curr_page: page_number as u64,
        num_pages: num_pages as u64,
        transactions,
    })
}

// GetNumDSBlocks
fn get_num_ds_blocks(_params: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    let node = node.read();
    let num_tx_blocks = node.get_finalized_block_number()?;
    let num_ds_blocks = (num_tx_blocks / TX_BLOCKS_PER_DS_BLOCK) + 1;
    Ok(num_ds_blocks.to_string())
}

// GetRecentTransactions
fn get_recent_transactions(
    _params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<RecentTransactionsResponse> {
    let node = node.read();
    let mut block_number = node.get_finalized_block_number()?;
    let mut txns = Vec::new();
    let mut blocks_searched = 0;
    while block_number > 0 && txns.len() < 100 && blocks_searched < 100 {
        let block = match node.get_block(block_number)? {
            Some(block) => block,
            None => continue,
        };
        for txn in block.transactions {
            txns.push(txn.to_string());
            if txns.len() >= 100 {
                break;
            }
        }
        block_number -= 1;
        blocks_searched += 1;
    }

    Ok(RecentTransactionsResponse {
        number: txns.len() as u64,
        txn_hashes: txns,
    })
}

// GetNumTransactions
fn get_num_transactions(_params: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    let node = node.read();
    let num_transactions = node.consensus.get_num_transactions()?;
    Ok(num_transactions.to_string())
}

// GetNumTxnsTXEpoch
fn get_num_txns_tx_epoch(_params: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    let node = node.read();
    let finalized_block = node.get_finalized_block()?;
    let num_transactions = match finalized_block {
        Some(block) => block.transactions.len(),
        None => 0,
    };
    Ok(num_transactions.to_string())
}

// GetNumTxnsDSEpoch
fn get_num_txns_ds_epoch(_params: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    let node = node.read();
    let ds_epoch_size = TX_BLOCKS_PER_DS_BLOCK;
    let current_epoch = node.get_finalized_block_number()? / ds_epoch_size;
    let current_epoch_first = current_epoch * ds_epoch_size;
    let mut num_txns_epoch = 0;
    for i in current_epoch_first..node.get_finalized_block_number()? {
        let block = node
            .get_block(i)?
            .ok_or_else(|| anyhow!("Block not found"))?;
        num_txns_epoch += block.transactions.len();
    }
    Ok(num_txns_epoch.to_string())
}

// GetTotalCoinSupplyAsZil
fn get_total_coin_supply_as_zil_amount(
    _params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<ZilAmount> {
    let node = node.read();
    let finalized_block = node.get_block(BlockId::finalized())?.unwrap();
    let finalized_block_number = finalized_block.number();
    let null_address_balance = node
        .consensus
        .state_at(finalized_block_number)?
        .unwrap()
        .get_account(Address::ZERO)
        .unwrap()
        .balance;
    let native_supply = node.config.consensus.total_native_token_supply.0;
    let state = node.consensus.state_at(finalized_block_number)?.unwrap();
    let stakers = state.get_stakers(finalized_block.header)?;
    let validators_stake: u128 = stakers
        .into_iter()
        .filter(|staker_pubkey| {
            let reward_address = state.get_reward_address(*staker_pubkey).unwrap();
            match reward_address {
                Some(address) => address == Address::ZERO,
                None => false,
            }
        })
        .map(|staker_pubkey| {
            state
                .get_stake(staker_pubkey, finalized_block.header)
                .unwrap()
                .unwrap()
                .get()
        })
        .sum();

    Ok(ZilAmount::from_amount(
        native_supply - null_address_balance - validators_stake,
    ))
}

// GetTotalCoinSupply
fn get_total_coin_supply(params: Params, node: &Arc<RwLock<Node>>) -> Result<String> {
    Ok(get_total_coin_supply_as_zil_amount(params, node)?.to_float_string())
}

// GetTotalCoinSupplyAsInt
fn get_total_coin_supply_as_int(params: Params, node: &Arc<RwLock<Node>>) -> Result<u128> {
    Ok(get_total_coin_supply_as_zil_amount(params, node)?.to_zils())
}

// GetMinerInfo
fn get_miner_info(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<MinerInfo> {
    // This endpoint was previously queries by DS block number, which no longer exists, and
    // neither do DS committees, so it now returns placeholder data for all queries to stay ZQ1 compatible.

    Ok(MinerInfo {
        dscommittee: vec![],
        shards: vec![],
    })
}

// GetNodeType
fn get_node_type(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<String> {
    Ok("Seed".into())
}

// GetPrevDifficulty
fn get_prev_difficulty(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<u64> {
    Ok(0)
}

// GetPrevDSDifficulty
fn get_prev_ds_difficulty(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<u64> {
    Ok(0)
}

// GetShardingStructure
fn get_sharding_structure(_params: Params, node: &Arc<RwLock<Node>>) -> Result<ShardingStructure> {
    let node = node.read();
    let num_peers = node.get_peer_num();

    Ok(ShardingStructure {
        num_peers: vec![num_peers as u64],
    })
}

// GetSmartContractSubState
fn get_smart_contract_sub_state(params: Params, node: &Arc<RwLock<Node>>) -> Result<Value> {
    let mut seq = params.sequence();
    let address: ZilAddress = seq.next()?;
    let address: Address = address.into();
    let requested_var_name: &str = match seq.next()? {
        "" => return get_smart_contract_state(params, node),
        x => x,
    };
    let requested_indices: Vec<String> = seq.next()?;
    let node = node.read();
    if requested_indices.len() > node.config.state_rpc_limit {
        return Err(anyhow!(
            "Requested indices exceed the limit of {}",
            node.config.state_rpc_limit
        ));
    }

    // First get the account and check that its a scilla account
    let block = node
        .get_finalized_block()?
        .ok_or_else(|| anyhow!("Unable to get finalized block!"))?;

    let state = node.get_state(&block)?;

    if !state.has_account(address)? {
        return Err(ErrorObject::owned(
            RPCErrorCode::RpcInvalidAddressOrKey as i32,
            "Address does not exist".to_string(),
            None::<()>,
        )
        .into());
    }

    let account = state.get_account(address)?;

    let mut result = serde_json::Map::new();

    if account.code.clone().scilla_code_and_init_data().is_some() {
        let trie = state.get_account_trie(address)?;

        let indicies_encoded = requested_indices
            .iter()
            .map(|x| serde_json::to_vec(&x))
            .collect::<std::result::Result<Vec<_>, _>>()?;
        let prefix = storage_key(requested_var_name, &indicies_encoded);
        let mut n = 0;
        for (k, v) in trie.iter_by_prefix(&prefix)? {
            n += 1;
            if n > node.config.state_rpc_limit {
                return Err(anyhow!(
                    "Requested indices exceed the limit of {}",
                    node.config.state_rpc_limit
                ));
            }

            let (var_name, indices) = split_storage_key(&k)?;
            let mut var = result.entry(var_name.clone());

            for index in indices.iter() {
                let next = var.or_insert_with(|| Value::Object(Default::default()));
                let Value::Object(next) = next else {
                    unreachable!()
                };
                let key: String = serde_json::from_slice(index)?;
                var = next.entry(key.clone());
            }

            let code = &account.code;

            let field_defs = match code {
                Code::Scilla { types, .. } => types.clone(),
                _ => unreachable!(),
            };
            let (_, depth) = field_defs.get(&var_name).unwrap();
            let depth = *depth as usize;

            let convert_result = serde_json::from_slice(&v);
            if depth > 0 && indices.len() < depth {
                if convert_result.is_err() {
                    var.or_insert(Value::Object(Default::default()));
                }
            } else {
                var.or_insert(convert_result?);
            }
        }

        // If the requested indices are empty, the whole map is likely requested.
        // So, we need to insert an empty map into the sub state because the trie iterator does not return empty maps.
        if requested_indices.is_empty() {
            let field_defs = match &account.code {
                Code::Scilla { types, .. } => types,
                _ => unreachable!(),
            };
            if let Some((var_name, _)) = field_defs.iter().find(|(var_name, (type_, _))| {
                type_.starts_with("Map") && *var_name == requested_var_name
            }) {
                result
                    .entry(var_name)
                    .or_insert(Value::Object(Default::default()));
            }
        }
    }
    if result.is_empty() {
        Ok(Value::Null)
    } else {
        Ok(result.into())
    }
}

// GetSoftConfirmedTransaction
fn get_soft_confirmed_transaction(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<GetTxResponse> {
    get_transaction(params, node)
}

// GetStateProof
fn get_state_proof(_params: Params, _node: &Arc<RwLock<Node>>) -> Result<StateProofResponse> {
    // State proof isn't meaningful in ZQ2
    Ok(StateProofResponse {
        account_proof: vec![],
        state_proof: vec![],
    })
}

// GetTransactionStatus
fn get_transaction_status(
    params: Params,
    node: &Arc<RwLock<Node>>,
) -> Result<TransactionStatusResponse> {
    let jsonrpc_error_data: Option<String> = None;
    let hash: B256 = params.one()?;
    let hash: Hash = Hash(hash.0);

    let node = node.read();
    let transaction =
        node.get_transaction_by_hash(hash)?
            .ok_or(jsonrpsee::types::ErrorObject::owned(
                RPCErrorCode::RpcDatabaseError as i32,
                "Txn Hash not found".to_string(),
                jsonrpc_error_data.clone(),
            ))?;
    let receipt = node.get_transaction_receipt(hash)?;

    let (block, success) = if let Some(receipt) = &receipt {
        (node.get_block(receipt.block_hash)?, receipt.success)
    } else {
        (None, false)
    };

    // Determine transaction state
    let state = if receipt.is_some_and(|receipt| !receipt.errors.is_empty()) {
        TransactionState::Error
    } else {
        match &block {
            Some(block) => match node.resolve_block_number(BlockNumberOrTag::Finalized)? {
                Some(x) if x.number() >= block.number() => TransactionState::Finalized,
                _ => TransactionState::Pending,
            },
            None => match node.consensus.get_pending_or_queued(&transaction)? {
                Some(PendingOrQueued::Pending) => TransactionState::Pending,
                Some(PendingOrQueued::Queued) => TransactionState::Queued,
                None => panic!("Transaction not found in block or pending/queued"),
            },
        }
    };

    TransactionStatusResponse::new(transaction, success, block, state)
}

#[cfg(test)]
mod tests {

    #[test]
    fn test_hex_checksum() {
        use alloy::primitives::{Address, address};

        use crate::api::zilliqa::to_zil_checksum_string;

        let cases: Vec<(Address, &str)> = vec![
            (
                address!("0000000000000000000000000000000000000002"),
                "0000000000000000000000000000000000000002",
            ),
            (
                address!("1234567890123456789012345678901234567890"),
                "1234567890123456789012345678901234567890",
            ),
            (
                address!("12a45b789d1f345c789def456789012be3467890"),
                "12a45b789D1F345c789dEf456789012bE3467890",
            ),
            (
                address!("f61477d7919478e5affe1fbd9a0cdceee9fde42d"),
                "f61477D7919478e5AfFe1fbd9A0CDCeee9fdE42d",
            ),
            (
                address!("4d76f701e16d7d481de292499718db36450d6a18"),
                "4d76f701E16D7d481dE292499718db36450d6A18",
            ),
            (
                address!("6e1757590ce532ff0f0e100139e36b7ee8049ce1"),
                "6e1757590ce532Ff0F0e100139e36b7eE8049ce1",
            ),
        ];
        for (address, good) in cases.iter() {
            let summed = to_zil_checksum_string(address);
            assert_eq!(&summed, good)
        }
    }
}

```

`zilliqa/src/bin/convert-key.rs`:

```rs
use std::io;

use alloy::primitives::Address;
use anyhow::Result;
use serde::Deserialize;
use serde_json::json;
use zilliqa::crypto::{SecretKey, TransactionPublicKey};

#[derive(Deserialize)]
struct Input {
    secret_key: String,
    chain_id: u64,
    control_address: Option<String>,
}

fn main() -> Result<()> {
    let mut buffer = String::new();
    io::stdin().read_line(&mut buffer)?;

    let input: Input = serde_json::from_str(&buffer)?;

    let secret_key = SecretKey::from_hex(&input.secret_key)?;

    let key_bytes = secret_key.as_bytes();
    let ecdsa_key = k256::ecdsa::SigningKey::from_slice(&key_bytes).unwrap();

    let tx_pubkey = TransactionPublicKey::Ecdsa(k256::ecdsa::VerifyingKey::from(&ecdsa_key), true);

    // default to address derived from pub key
    let address = match input.control_address {
        None => tx_pubkey.into_addr(),
        Some(addr) => addr.parse::<Address>().unwrap(),
    };

    let output = json!({
        "bls_public_key": secret_key.node_public_key(),
        "peer_id": secret_key.to_libp2p_keypair().public().to_peer_id(),
        "tx_pubkey": tx_pubkey,
        "control_address": address,
        "deposit_auth_signature": secret_key.deposit_auth_signature(input.chain_id, address).to_string(),
    });

    println!("{output}");

    Ok(())
}

```

`zilliqa/src/bin/zilliqa.rs`:

```rs
use std::{
    backtrace::{Backtrace, BacktraceStatus},
    fs,
    path::PathBuf,
};

use anyhow::{Result, anyhow};
use clap::Parser;
use opentelemetry_otlp::{ExportConfig, WithExportConfig};
use opentelemetry_sdk::metrics::PeriodicReader;
use tracing_subscriber::EnvFilter;
use zilliqa::{cfg::Config, crypto::SecretKey, p2p_node::P2pNode};

#[derive(Parser, Debug)]
struct Args {
    #[arg(value_parser = SecretKey::from_hex)]
    secret_key: SecretKey,
    #[clap(long, short, default_values = ["config.toml"])]
    config_file: Vec<PathBuf>,
    #[clap(long, default_value = "false")]
    log_json: bool,
}

#[tokio::main]
async fn main() -> Result<()> {
    let args = Args::parse();

    let builder = tracing_subscriber::fmt()
        .with_env_filter(EnvFilter::from_default_env())
        .with_line_number(true);
    if args.log_json {
        builder.json().init();
    } else {
        builder.init();
    }

    // Set a panic hook that records the panic as a `tracing` event at the `ERROR` verbosity level.
    std::panic::set_hook(Box::new(|panic| {
        let message = match panic.payload().downcast_ref::<&'static str>() {
            Some(s) => *s,
            None => match panic.payload().downcast_ref::<String>() {
                Some(s) => &s[..],
                None => "Box<dyn Any>",
            },
        };
        let thread = std::thread::current();
        let thread_name = thread.name().unwrap_or("<unnamed>");

        let backtrace = Backtrace::capture();
        let backtrace =
            (backtrace.status() == BacktraceStatus::Captured).then(|| backtrace.to_string());

        match (panic.location(), backtrace) {
            (None, None) => {
                tracing::error!(thread_name, message);
            }
            (None, Some(backtrace)) => {
                tracing::error!(thread_name, message, %backtrace);
            }
            (Some(location), None) => {
                tracing::error!(
                    thread_name,
                    message,
                    panic.file = location.file(),
                    panic.line = location.line(),
                    panic.column = location.column(),
                );
            }
            (Some(location), Some(backtrace)) => {
                tracing::error!(
                    thread_name,
                    message,
                    panic.file = location.file(),
                    panic.line = location.line(),
                    panic.column = location.column(),
                    %backtrace,
                );
            }
        }
    }));

    let mut merged_config = toml::Table::new();
    for config_file in args.config_file {
        let config = fs::read_to_string(&config_file)?;
        let config: toml::Table = toml::from_str(&config)?;
        for key in config.keys() {
            if merged_config.contains_key(key) {
                return Err(anyhow!(
                    "configuration conflict: {config_file:?} contained a key {key:?} that was already included in an earlier file"
                ));
            }
        }
        merged_config.extend(config);
    }

    let config: Config = serde::Deserialize::deserialize(merged_config)?;

    assert!(
        !config.nodes.is_empty(),
        "At least one shard must be configured"
    );

    if let Some(endpoint) = &config.otlp_collector_endpoint {
        let export_config = ExportConfig {
            endpoint: Some(endpoint.clone()),
            ..Default::default()
        };
        let exporter = opentelemetry_otlp::MetricExporter::builder()
            .with_tonic()
            .with_export_config(export_config)
            .build()?;
        let reader = PeriodicReader::builder(exporter).build();
        let provider = opentelemetry_sdk::metrics::SdkMeterProvider::builder()
            .with_reader(reader)
            .build();
        opentelemetry::global::set_meter_provider(provider);
    };

    let mut node = P2pNode::new(args.secret_key, config.clone())?;

    node.add_shard_node(config.nodes.first().unwrap().clone())
        .await?;

    node.start().await
}

```

`zilliqa/src/blockhooks.rs`:

```rs
use alloy::primitives::Address;
use anyhow::Result;
use ethabi::{Event, Log, RawLog, Token};
use tracing::warn;

use crate::{
    contracts,
    message::IntershardCall,
    state::contract_addr,
    transaction::{EvmGas, TransactionReceipt},
};

fn filter_receipts(
    receipts: &[TransactionReceipt],
    event: Event,
    emitter: Address,
) -> Result<Vec<Log>> {
    let logs: Result<Vec<_>, _> = receipts
        .iter()
        .flat_map(|receipt| &receipt.logs)
        .filter_map(|log| log.as_evm()) // Only consider EVM logs
        .filter(|log| {
            log.address == emitter
                && ethabi::ethereum_types::H256(log.topics[0].0) == event.signature()
        })
        .map(|log| {
            event
                // parse_log_whole can't be used here because it doesn't seem to work
                // with dynamically-sized types (e.g. `bytes`), throwing a spurious error
                .parse_log(RawLog {
                    topics: log
                        .topics
                        .iter()
                        .map(|t| ethabi::ethereum_types::H256(t.0))
                        .collect(),
                    data: log.data.clone(),
                })
                .map_err(|e| {
                    warn!("Error parsing event log: {e}. The log was: {log:?}");
                    e
                })
        })
        .collect();

    Ok(logs?)
}

pub fn get_launch_shard_messages(receipts: &[TransactionReceipt]) -> Result<Vec<u64>> {
    let shard_logs = filter_receipts(
        receipts,
        contracts::shard_registry::SHARD_ADDED_EVT.clone(),
        contract_addr::SHARD_REGISTRY,
    )?;
    Ok(shard_logs
        .into_iter()
        .filter_map(|log| {
            log.params
                .into_iter()
                .find(|param| param.name == "id")
                .and_then(|param| param.value.into_uint())
                .map_or_else(
                    || {
                        warn!("ShardAdded event does not contain an id!");
                        None
                    },
                    |uint| Some(uint.as_u64()),
                )
        })
        .collect())
}

pub fn get_link_creation_messages(receipts: &[TransactionReceipt]) -> Result<Vec<(u64, u64)>> {
    let link_logs = filter_receipts(
        receipts,
        contracts::shard_registry::LINK_ADDED_EVT.clone(),
        contract_addr::SHARD_REGISTRY,
    )?;
    // TODO: this is very ugly
    // I wonder if there's a better way to parse events in general
    Ok(link_logs
        .into_iter()
        .filter_map(|log| {
            let (names, values): (Vec<_>, Vec<_>) = log
                .params
                .into_iter()
                .map(|param| (param.name, param.value))
                .unzip();
            if names != ["from", "to"] {
                warn!("LinkAdded event does not contain expected (from, to) values!");
                None
            } else {
                let mut values = values.into_iter();
                Some((
                    values.next().unwrap().into_uint().unwrap().as_u64(),
                    values.next().unwrap().into_uint().unwrap().as_u64(),
                ))
            }
        })
        .collect())
}

pub fn get_cross_shard_messages(
    receipts: &[TransactionReceipt],
) -> Result<Vec<(u64, IntershardCall)>> {
    let bridge_logs = filter_receipts(
        receipts,
        contracts::intershard_bridge::RELAYED_EVT.clone(),
        contract_addr::INTERSHARD_BRIDGE,
    )?;
    Ok(bridge_logs
        .into_iter()
        .filter_map(|Log { params }| {
            let values = params
                .into_iter()
                .map(|param| param.value)
                .collect::<Vec<_>>();
            // First we type-check the event values for sanity
            if !Token::types_check(
                &values,
                &contracts::intershard_bridge::RELAYED_EVT
                    .clone()
                    .inputs
                    .into_iter()
                    .map(|p| p.kind)
                    .collect::<Vec<_>>(),
            ) {
                warn!("`Relayed` event had unexpected number or type of parameters!");
                return None;
            }
            // Now that they are all known to match expected values, we can make liberal
            // use of `unwrap()`.
            // Note that ordering is also important here.
            let mut values = values.into_iter();
            let destination_shard = values.next().unwrap().into_uint().unwrap().as_u64();
            Some((
                destination_shard,
                IntershardCall {
                    source_address: Address::new(values.next().unwrap().into_address().unwrap().0),
                    target_address: if values.next().unwrap().into_bool().unwrap() {
                        values.next();
                        None
                    } else {
                        Some(Address::new(
                            values.next().unwrap().into_address().unwrap().0,
                        ))
                    },
                    source_chain_id: values.next().unwrap().into_uint().unwrap().as_u64(),
                    bridge_nonce: values.next().unwrap().into_uint().unwrap().as_u64(),
                    calldata: values.next().unwrap().into_bytes().unwrap(),
                    gas_limit: EvmGas(values.next().unwrap().into_uint().unwrap().as_u64()),
                    gas_price: values.next().unwrap().into_uint().unwrap().as_u128(),
                },
            ))
        })
        .collect())
}

```

`zilliqa/src/cfg.rs`:

```rs
use std::{ops::Deref, str::FromStr, time::Duration};

use alloy::{primitives::Address, rlp::Encodable};
use anyhow::{Result, anyhow};
use libp2p::{Multiaddr, PeerId};
use rand::{Rng, distributions::Alphanumeric};
use revm::primitives::address;
use serde::{Deserialize, Deserializer, Serialize, Serializer, de};
use serde_json::json;

use crate::{
    crypto::{Hash, NodePublicKey},
    transaction::EvmGas,
};

// Note that z2 constructs instances of this to save as a configuration so it must be both
// serializable and deserializable.
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct Config {
    pub network: String,
    /// Individual configuration for every node to run.
    #[serde(default)]
    pub nodes: Vec<NodeConfig>,
    /// The port to listen for P2P messages on. Optional - If not provided a random port will be used.
    #[serde(default)]
    pub p2p_port: u16,
    /// External address for this node. This is the address at which it can be reached by other nodes. This should
    /// include the P2P port. If this is not provided, we will trust other nodes to tell us our external address.
    /// However, be warned that this is insecure and unreliable in real-world networks and we will remove this
    /// behaviour at some point in the future (#1101).
    #[serde(default)]
    pub external_address: Option<Multiaddr>,
    /// The address of another node to dial when this node starts. To join the network, a node must know about at least
    /// one other existing node in the network.
    #[serde(default)]
    pub bootstrap_address: OneOrMany<(PeerId, Multiaddr)>,
    /// The base address of the OTLP collector. If not set, metrics will not be exported.
    #[serde(default)]
    pub otlp_collector_endpoint: Option<String>,
}

#[derive(Debug, Clone)]
pub struct OneOrMany<T>(pub Vec<T>);

impl<T> Default for OneOrMany<T> {
    fn default() -> Self {
        Self(vec![])
    }
}

impl<T: Serialize> Serialize for OneOrMany<T> {
    fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        if self.0.len() == 1 {
            self.0[0].serialize(serializer)
        } else {
            self.0.serialize(serializer)
        }
    }
}

impl<'de, T: Deserialize<'de>> Deserialize<'de> for OneOrMany<T> {
    fn deserialize<D>(deserializer: D) -> std::result::Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        #[derive(Deserialize)]
        #[serde(untagged)]
        enum Inner<T> {
            One(T),
            Many(Vec<T>),
        }

        match Inner::deserialize(deserializer)? {
            Inner::One(t) => Ok(OneOrMany(vec![t])),
            Inner::Many(t) => Ok(OneOrMany(t)),
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(untagged)]
pub enum EnabledApi {
    EnableAll(String),
    Enabled {
        namespace: String,
        apis: Vec<String>,
    },
}

impl EnabledApi {
    pub fn enabled(&self, api: &str) -> bool {
        // APIs with no namespace default to the 'zilliqa' namespace.
        let (ns, method) = api.split_once('_').unwrap_or(("zilliqa", api));
        match self {
            EnabledApi::EnableAll(namespace) => namespace == ns,
            EnabledApi::Enabled { namespace, apis } => {
                namespace == ns && apis.iter().any(|m| m == method)
            }
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct ApiServer {
    /// The port to listen for JSON-RPC requests on.
    pub port: u16,
    /// RPC APIs to enable.
    pub enabled_apis: Vec<EnabledApi>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct SyncConfig {
    /// The maximum number of blocks to have outstanding requests for at a time when syncing.
    #[serde(default = "max_blocks_in_flight_default")]
    pub max_blocks_in_flight: usize,
    /// The maximum number of blocks to request in a single message when syncing.
    #[serde(default = "block_request_batch_size_default")]
    pub block_request_batch_size: usize,
    /// The N number of historical blocks to be kept in the DB during pruning. N >= 300.
    #[serde(default = "u64_max")]
    pub prune_interval: u64,
    /// Lowest block to sync from, during passive-sync.
    /// Cannot be set if prune_interval is set.
    #[serde(default = "u64_max")]
    pub base_height: u64,
    /// Service passive-sync flag
    #[serde(default)]
    pub ignore_passive: bool,
}

impl Default for SyncConfig {
    fn default() -> Self {
        Self {
            max_blocks_in_flight: max_blocks_in_flight_default(),
            block_request_batch_size: block_request_batch_size_default(),
            prune_interval: u64_max(),
            base_height: u64_max(),
            ignore_passive: false,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct NodeConfig {
    /// RPC API endpoints to expose.
    #[serde(default)]
    pub api_servers: Vec<ApiServer>,
    /// Chain identifier. Doubles as shard_id internally.
    #[serde(default = "eth_chain_id_default")]
    pub eth_chain_id: u64,
    /// Consensus-specific data.
    pub consensus: ConsensusConfig,
    /// The maximum duration between a recieved block's timestamp and the current time. Defaults to 10 seconds.
    #[serde(default = "allowed_timestamp_skew_default")]
    pub allowed_timestamp_skew: Duration,
    /// The location of persistence data. If not set, uses a temporary path.
    #[serde(default)]
    pub data_dir: Option<String>,
    /// Size of the in-memory state trie cache, in bytes. Defaults to 256 MiB.
    #[serde(default = "state_cache_size_default")]
    pub state_cache_size: usize,
    /// Persistence checkpoint to load.
    #[serde(default)]
    pub load_checkpoint: Option<Checkpoint>,
    /// Whether to enable exporting checkpoint state checkpoint files.
    #[serde(default)]
    pub do_checkpoints: bool,
    /// The maximum number of blocks we will send to another node in a single message.
    #[serde(default = "block_request_limit_default")]
    pub block_request_limit: usize,
    /// The maximum number of key value pairs allowed to be returned within the response of the `GetSmartContractState` RPC. Defaults to no limit.
    #[serde(default = "state_rpc_limit_default")]
    pub state_rpc_limit: usize,
    /// When a block request to a peer fails, do not send another request to this peer for this amount of time.
    /// Defaults to 10 seconds.
    #[serde(default = "failed_request_sleep_duration_default")]
    pub failed_request_sleep_duration: Duration,
    /// Enable additional indices used by some Otterscan APIs. Enabling this will use more disk space and block processing will take longer.
    #[serde(default)]
    pub enable_ots_indices: bool,
    /// Maximum allowed RPC response size
    #[serde(default = "max_rpc_response_size_default")]
    pub max_rpc_response_size: u32,
    /// Sync configuration
    #[serde(default)]
    pub sync: SyncConfig,
}

impl Default for NodeConfig {
    fn default() -> Self {
        NodeConfig {
            api_servers: vec![],
            eth_chain_id: eth_chain_id_default(),
            consensus: ConsensusConfig::default(),
            allowed_timestamp_skew: allowed_timestamp_skew_default(),
            data_dir: None,
            state_cache_size: state_cache_size_default(),
            load_checkpoint: None,
            do_checkpoints: false,
            block_request_limit: block_request_limit_default(),
            sync: SyncConfig {
                max_blocks_in_flight: max_blocks_in_flight_default(),
                block_request_batch_size: block_request_batch_size_default(),
                base_height: u64_max(),
                prune_interval: u64_max(),
                ignore_passive: false,
            },
            state_rpc_limit: state_rpc_limit_default(),
            failed_request_sleep_duration: failed_request_sleep_duration_default(),
            enable_ots_indices: false,
            max_rpc_response_size: max_rpc_response_size_default(),
        }
    }
}

impl NodeConfig {
    pub fn validate(&self) -> Result<()> {
        if let serde_json::Value::Object(map) =
            serde_json::to_value(self.consensus.contract_upgrades.clone())?
        {
            for (contract, block_height) in map {
                if block_height.as_u64().unwrap_or(0) % self.consensus.blocks_per_epoch != 0 {
                    return Err(anyhow!(
                        "Contract upgrades must be configured to occur at epoch boundaries. blocks_per_epoch: {}, contract {} configured to be upgraded block: {}",
                        self.consensus.blocks_per_epoch,
                        contract,
                        block_height
                    ));
                }
            }
        }
        if self.sync.base_height != u64_max() && self.sync.prune_interval != u64_max() {
            return Err(anyhow!(
                "base_height and prune_interval cannot be set at the same time"
            ));
        }

        // when set, >> 15 to avoid pruning forks; > 256 to be EVM-safe; arbitrarily picked.
        if self.sync.prune_interval < crate::sync::MIN_PRUNE_INTERVAL {
            return Err(anyhow!(
                "prune_interval must be at least {}",
                crate::sync::MIN_PRUNE_INTERVAL
            ));
        }
        // 100 is a reasonable minimum for a node to be useful.
        if self.sync.block_request_batch_size < 100 {
            return Err(anyhow!("block_request_batch_size must be at least 100"));
        }
        // 1000 would saturate a typical node.
        if self.sync.max_blocks_in_flight > 1000 {
            return Err(anyhow!("max_blocks_in_flight must be at most 1000"));
        }
        Ok(())
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct Checkpoint {
    /// Location of the checkpoint
    pub file: String,
    /// Trusted hash of the checkpoint block
    #[serde(
        serialize_with = "serialize_hash_hex",
        deserialize_with = "deserialize_hash_hex"
    )]
    pub hash: Hash,
}

fn serialize_hash_hex<S>(hash: &Hash, serializer: S) -> Result<S::Ok, S::Error>
where
    S: serde::Serializer,
{
    hex::encode(hash.0).serialize(serializer)
}

fn deserialize_hash_hex<'de, D>(deserializer: D) -> Result<Hash, D::Error>
where
    D: de::Deserializer<'de>,
{
    let s = <String>::deserialize(deserializer)?;
    let bytes = hex::decode(s).unwrap();
    Hash::try_from(bytes.as_slice()).map_err(|_| {
        de::Error::invalid_value(de::Unexpected::Bytes(&bytes), &"a 32-byte hex value")
    })
}

pub fn u64_max() -> u64 {
    u64::MAX
}

pub fn allowed_timestamp_skew_default() -> Duration {
    Duration::from_secs(60)
}

pub fn state_cache_size_default() -> usize {
    256 * 1024 * 1024 // 256 MiB
}

pub fn eth_chain_id_default() -> u64 {
    700 + 0x8000
}

pub fn block_request_limit_default() -> usize {
    100
}

pub fn max_blocks_in_flight_default() -> usize {
    1000
}

pub fn block_request_batch_size_default() -> usize {
    100
}

pub fn max_rpc_response_size_default() -> u32 {
    10 * 1024 * 1024 // 10 MB
}

pub fn state_rpc_limit_default() -> usize {
    // isize maximum because toml serialisation supports i64 integers
    isize::MAX as usize
}

pub fn failed_request_sleep_duration_default() -> Duration {
    Duration::from_secs(10)
}

/// Wrapper for [u128] that (de)serializes with a string. `serde_toml` does not support `u128`s.
#[derive(Copy, Clone, Debug)]
pub struct Amount(pub u128);

impl From<u128> for Amount {
    fn from(value: u128) -> Self {
        Amount(value)
    }
}

impl Deref for Amount {
    type Target = u128;

    fn deref(&self) -> &Self::Target {
        &self.0
    }
}

impl Serialize for Amount {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        self.0.to_string().serialize(serializer)
    }
}

impl<'de> Deserialize<'de> for Amount {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        let mut res = String::deserialize(deserializer)?;
        // Remove underscores
        res.retain(|c| c != '_');
        Ok(Amount(
            u128::from_str(&res).map_err(serde::de::Error::custom)?,
        ))
    }
}

#[derive(Clone, Serialize, Deserialize, Debug)]
pub struct ScillaExtLibsPathInZq2(pub String);

#[derive(Clone, Serialize, Deserialize, Debug)]
pub struct ScillaExtLibsPathInScilla(pub String);

#[derive(Clone, Serialize, Deserialize, Debug)]
pub struct ScillaExtLibsPath {
    /// Where are the external libraries stored in zq2 servers' filesystem
    pub zq2: ScillaExtLibsPathInZq2,
    /// Where are the external libraries stored in scilla servers' filesystem
    pub scilla: ScillaExtLibsPathInScilla,
}

impl ScillaExtLibsPath {
    pub fn generate_random_subdirs(&self) -> (ScillaExtLibsPathInZq2, ScillaExtLibsPathInScilla) {
        let sub_directory: String = rand::thread_rng()
            .sample_iter(&Alphanumeric)
            .take(10)
            .map(char::from)
            .collect();

        (
            ScillaExtLibsPathInZq2(format!("{}/{}", self.zq2.0, sub_directory)),
            ScillaExtLibsPathInScilla(format!("{}/{}", self.scilla.0, sub_directory)),
        )
    }
}

#[derive(Clone, Serialize, Deserialize, Debug)]
#[serde(deny_unknown_fields)]
pub struct ConsensusConfig {
    /// If main, deploy a shard registry contract.
    #[serde(default = "default_true")]
    pub is_main: bool,
    /// If not main, parent main shard.
    #[serde(default)]
    pub main_shard_id: Option<u64>,
    /// The maximum time to wait for consensus to proceed as normal, before proposing a new view.
    #[serde(default = "consensus_timeout_default")]
    pub consensus_timeout: Duration,
    /// The initially staked deposits in the deposit contract at genesis, composed of
    /// (public key, peerId, amount, reward address) tuples.
    #[serde(default)]
    pub genesis_deposits: Vec<GenesisDeposit>,
    /// Accounts that will be pre-funded at genesis.
    #[serde(default)]
    pub genesis_accounts: Vec<(Address, Amount)>,
    /// The expected time between blocks when no views are missed.
    #[serde(default = "block_time_default")]
    pub block_time: Duration,
    /// Address of the Scilla server. Defaults to "http://localhost:62831".
    #[serde(default = "scilla_address_default")]
    pub scilla_address: String,
    /// Where (in the Scilla server's filesystem) is the library directory containing Scilla library functions?
    #[serde(default = "scilla_stdlib_dir_default")]
    pub scilla_stdlib_dir: String,
    /// Where are the external libraries are stored on zq2 and scilla server's filesystem so that scilla server can find them?
    #[serde(default = "scilla_ext_libs_path_default")]
    pub scilla_ext_libs_path: ScillaExtLibsPath,
    /// Directory in which the Unix domain socket used by the Scilla state server is created. If the Scilla process is
    /// running in Docker, this directory should be mounted inside the container too. Defaults to
    /// "/tmp/scilla-state-server".
    #[serde(default = "scilla_server_socket_directory_default")]
    pub scilla_server_socket_directory: String,
    /// Reward amount issued per hour, in Wei.
    pub rewards_per_hour: Amount,
    /// Number of blocks per hour. The reward per block is set at (rewards_per_hour/blocks_per_hour) Wei.
    pub blocks_per_hour: u64,
    /// The minimum stake passed into the deposit contract constructor at genesis, in Wei. Subsequent changes to this
    /// parameter will have no effect. You must not use this parameter at run-time; obtain the minimum stake in effect
    /// from the contract - otherwise if this value ever changes, there will be a mismatch between what the deposit
    /// contract believes and what the validators believe to be the minimum stake.
    pub minimum_stake: Amount,
    /// Maximum amount of gas permitted in a single block; any transactions over this
    /// will be held until the next block. The white paper specifies this as 84_000_000.
    pub eth_block_gas_limit: EvmGas,
    #[serde(default = "blocks_per_epoch_default")]
    pub blocks_per_epoch: u64,
    #[serde(default = "epochs_per_checkpoint_default")]
    pub epochs_per_checkpoint: u64,
    /// The gas price, in Wei per unit of EVM gas.
    pub gas_price: Amount,
    /// The total supply of native token in the network in Wei. Any funds which are not immediately assigned to an account (via genesis_accounts and genesis_deposits env vars) will be assigned to the zero account (0x0).
    #[serde(default = "total_native_token_supply_default")]
    pub total_native_token_supply: Amount,
    /// The block heights at which we perform EIP-1967 contract upgrades
    /// Contract upgrades occur only at epoch boundaries, ie at block heights which are a multiple of blocks_per_epoch
    #[serde(default)]
    pub contract_upgrades: ContractUpgrades,
    /// The initial fork configuration at genesis block. This provides a complete description of the execution behavior
    /// at the genesis block.
    #[serde(default = "genesis_fork_default")]
    pub genesis_fork: Fork,
    /// Forks in block execution logic. Each entry describes the difference in logic and the block height at which that
    /// difference applies.
    #[serde(default)]
    pub forks: Vec<ForkDelta>,
    /// Interval at which NewView messages are broadcast when node is in timeout
    /// Defaut of 0 means never broadcast
    #[serde(default = "new_view_broadcast_interval_default")]
    pub new_view_broadcast_interval: Duration,
}

impl ConsensusConfig {
    /// Generates a list of forks by applying the delta forks initially to the genesis fork and then to the previous one.
    /// The genesis fork is the initial fork configuration at the genesis block.
    pub fn get_forks(&self) -> Result<Forks> {
        if self.genesis_fork.at_height != 0 {
            return Err(anyhow!("first fork must start at height 0"));
        }

        let mut delta_forks = self.forks.clone();
        delta_forks.sort_unstable_by_key(|f| f.at_height);

        let forks =
            delta_forks
                .into_iter()
                .fold(vec![self.genesis_fork.clone()], |mut forks, delta| {
                    let last_fork = forks.last().unwrap(); // Safe to call unwrap because we always have genesis_fork
                    let new_fork = last_fork.apply_delta_fork(&delta);
                    forks.push(new_fork);
                    forks
                });

        Ok(Forks(forks))
    }
}

impl Default for ConsensusConfig {
    fn default() -> Self {
        ConsensusConfig {
            is_main: default_true(),
            main_shard_id: None,
            consensus_timeout: consensus_timeout_default(),
            genesis_deposits: vec![],
            genesis_accounts: vec![],
            block_time: block_time_default(),
            scilla_address: scilla_address_default(),
            scilla_stdlib_dir: scilla_stdlib_dir_default(),
            scilla_ext_libs_path: scilla_ext_libs_path_default(),
            scilla_server_socket_directory: scilla_server_socket_directory_default(),
            rewards_per_hour: 204_000_000_000_000_000_000_000u128.into(),
            blocks_per_hour: 3600 * 40,
            minimum_stake: 32_000_000_000_000_000_000u128.into(),
            eth_block_gas_limit: EvmGas(84000000),
            blocks_per_epoch: blocks_per_epoch_default(),
            epochs_per_checkpoint: epochs_per_checkpoint_default(),
            gas_price: 4_761_904_800_000u128.into(),
            total_native_token_supply: total_native_token_supply_default(),
            contract_upgrades: ContractUpgrades::default(),
            forks: vec![],
            genesis_fork: genesis_fork_default(),
            new_view_broadcast_interval: new_view_broadcast_interval_default(),
        }
    }
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct Forks(Vec<Fork>);

impl Forks {
    pub fn get(&self, height: u64) -> &Fork {
        // Binary search to find the fork at the specified height. If an entry was not found at exactly the specified
        // height, the `Err` returned from `binary_search_by_key` will contain the index where an element with this
        // height could be inserted. By subtracting one from this, we get the maximum entry with a height less than the
        // searched height.
        let index = self
            .0
            .binary_search_by_key(&height, |f| f.at_height)
            .unwrap_or_else(|i| i - 1);
        &self.0[index]
    }

    pub fn find_height_fork_first_activated(&self, fork_name: ForkName) -> Option<u64> {
        let mut sorted_fork = self.0.clone();
        sorted_fork.sort_by_key(|item| item.at_height);
        for fork in sorted_fork.iter() {
            if match fork_name {
                ForkName::ExecutableBlocks => fork.executable_blocks,
                ForkName::FailedScillaCallFromGasExemptCallerCausesRevert => {
                    fork.failed_scilla_call_from_gas_exempt_caller_causes_revert
                }
                ForkName::CallMode1SetsCallerToParentCaller => {
                    fork.call_mode_1_sets_caller_to_parent_caller
                }
                ForkName::ScillaMessagesCanCallEvmContracts => {
                    fork.scilla_messages_can_call_evm_contracts
                }
                ForkName::ScillaContractCreationIncrementsAccountBalance => {
                    fork.scilla_contract_creation_increments_account_balance
                }
                ForkName::ScillaJsonPreserveOrder => fork.scilla_json_preserve_order,
                ForkName::ScillaCallRespectsEvmStateChanges => {
                    fork.scilla_call_respects_evm_state_changes
                }
                ForkName::OnlyMutatedAccountsUpdateState => fork.only_mutated_accounts_update_state,
                ForkName::ScillaCallGasExemptAddrs => {
                    fork.scilla_call_gas_exempt_addrs.length() != 0
                }
                ForkName::ScillaBlockNumberReturnsCurrentBlock => {
                    fork.scilla_block_number_returns_current_block
                }
                ForkName::ScillaMapsAreEncodedCorrectly => fork.scilla_maps_are_encoded_correctly,
                ForkName::FundAccountsFromZeroAccount => {
                    !fork.fund_accounts_from_zero_account.is_empty()
                }
                ForkName::ScillaFailedTxnCorrectBalanceDeduction => {
                    fork.scilla_failed_txn_correct_balance_deduction
                }
                ForkName::ScillaTransitionsProperOrder => fork.scilla_transition_proper_order,
                ForkName::EvmToScillaValueTransferZero => fork.evm_to_scilla_value_transfer_zero,
                ForkName::RestoreXsgdContract => fork.restore_xsgd_contract,
                ForkName::EvmExecFailureCausesScillaWhitelistedAddrToFail => {
                    fork.evm_exec_failure_causes_scilla_whitelisted_addr_to_fail
                }
                ForkName::RevertRestoreXsgdContract => fork.revert_restore_xsgd_contract,
                ForkName::ScillaFixContractCodeRemovalOnEvmTx => {
                    fork.scilla_fix_contract_code_removal_on_evm_tx
                }
            } {
                return Some(fork.at_height);
            }
        }
        None
    }
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct Fork {
    pub at_height: u64,
    pub executable_blocks: bool,
    pub failed_scilla_call_from_gas_exempt_caller_causes_revert: bool,
    pub call_mode_1_sets_caller_to_parent_caller: bool,
    pub scilla_messages_can_call_evm_contracts: bool,
    pub scilla_contract_creation_increments_account_balance: bool,
    pub scilla_json_preserve_order: bool,
    pub scilla_call_respects_evm_state_changes: bool,
    pub only_mutated_accounts_update_state: bool,
    pub scilla_call_gas_exempt_addrs: Vec<Address>,
    pub scilla_block_number_returns_current_block: bool,
    pub scilla_maps_are_encoded_correctly: bool,
    pub transfer_gas_fee_to_zero_account: bool,
    pub apply_scilla_delta_when_evm_succeeded: bool,
    pub apply_state_changes_only_if_transaction_succeeds: bool,
    pub scilla_deduct_funds_from_actual_sender: bool,
    pub fund_accounts_from_zero_account: Vec<(Address, Amount)>,
    pub scilla_delta_maps_are_applied_correctly: bool,
    pub scilla_server_unlimited_response_size: bool,
    pub scilla_failed_txn_correct_balance_deduction: bool,
    pub scilla_transition_proper_order: bool,
    pub evm_to_scilla_value_transfer_zero: bool,
    pub restore_xsgd_contract: bool,
    pub evm_exec_failure_causes_scilla_whitelisted_addr_to_fail: bool,
    pub revert_restore_xsgd_contract: bool,
    pub scilla_fix_contract_code_removal_on_evm_tx: bool,
}

pub enum ForkName {
    ExecutableBlocks,
    FailedScillaCallFromGasExemptCallerCausesRevert,
    CallMode1SetsCallerToParentCaller,
    ScillaMessagesCanCallEvmContracts,
    ScillaContractCreationIncrementsAccountBalance,
    ScillaJsonPreserveOrder,
    ScillaCallRespectsEvmStateChanges,
    OnlyMutatedAccountsUpdateState,
    ScillaCallGasExemptAddrs,
    ScillaBlockNumberReturnsCurrentBlock,
    ScillaMapsAreEncodedCorrectly,
    FundAccountsFromZeroAccount,
    ScillaFailedTxnCorrectBalanceDeduction,
    ScillaTransitionsProperOrder,
    EvmToScillaValueTransferZero,
    RestoreXsgdContract,
    EvmExecFailureCausesScillaWhitelistedAddrToFail,
    RevertRestoreXsgdContract,
    ScillaFixContractCodeRemovalOnEvmTx,
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct ForkDelta {
    pub at_height: u64,
    /// If true then transactions can be executed against blocks.
    /// Currently used to mark the height at which ZQ1 blocks end and ZQ2 blocks begin in converted persistence networks. This is required because their state root hashes are set to Hash::ZERO.
    pub executable_blocks: Option<bool>,
    /// If true, if a caller who is in the `scilla_call_gas_exempt_addrs` list makes a call to the `scilla_call`
    /// precompile and the inner Scilla call fails, the entire transaction will revert. If false, the normal EVM
    /// semantics apply where the caller can decide how to act based on the success of the inner call.
    pub failed_scilla_call_from_gas_exempt_caller_causes_revert: Option<bool>,
    /// If true, if a call is made to the `scilla_call` precompile with `call_mode` / `keep_origin` set to `1`, the
    /// `_sender` of the inner Scilla call will be set to the caller of the current call-stack. If false, the `_sender`
    /// will be set to the original transaction signer.
    ///
    /// For example:
    /// A (EOA) -> B (EVM) -> C (EVM) -> D (Scilla)
    ///
    /// When this flag is true, `D` will see the `_sender` as `B`. When this flag is false, `D` will see the `_sender`
    /// as `A`.
    pub call_mode_1_sets_caller_to_parent_caller: Option<bool>,
    /// If true, when a Scilla message is sent to an EVM contract, the EVM contract will be treated as if it was an
    /// EOA (i.e. any ZIL passed will be transferred to the contract and execution will continue). If false, sending a
    /// Scilla message to an EVM contract will cause the Scilla transaction to fail.
    pub scilla_messages_can_call_evm_contracts: Option<bool>,
    /// If true, when a contract is deployed, if the contract address is already funded,
    /// the contract balance will be sum of the existing balance and the amount sent in the deployment transaction.
    /// If false, the contract balance will be the amount sent in the deployment transaction.
    pub scilla_contract_creation_increments_account_balance: Option<bool>,
    /// If true, JSON maps that are passed to Scilla will be in their original order. If false, the entries will be
    /// sorted by their keys.
    pub scilla_json_preserve_order: Option<bool>,
    /// If true, interop calls to the `scilla_call` precompile will correctly see state changes already made by the EVM
    /// before that point in the transaction's execution. Also both Scilla and EVM will be able to update the same
    /// accounts without state changes being lost. If false, state changes can be lost if Scilla and EVM attempt to
    /// update the same account. This can sometimes lead to mined transactions which don't increase the caller's nonce.
    pub scilla_call_respects_evm_state_changes: Option<bool>,
    // If true, when an account is accessed but not mutated as part of transaction execution, we will not change the
    // state of that account in the state trie. If false, we will always update state to the read value of the account.
    // Most of the time this does not make a difference, because we would just be writing back the same value we read.
    // However, in some edge cases (e.g. precompiles) setting this value to `false` results in spurious writes of
    // default accounts to the state trie.
    pub only_mutated_accounts_update_state: Option<bool>,
    /// Calls to the `scilla_call` precompile from these addresses cost a different amount of gas. If the provided gas
    /// limit is not enough, the call will still succeed and we will charge as much gas as we can. This hack exists due
    /// to important contracts deployed on Zilliqa 1's mainnet that pass the incorrect gas limit to `scilla_call`.
    /// Zilliqa 1's implementation was broken and accepted these calls and these contracts are now widely used and
    /// bridged to other chains. Adding a value to this list in a [ForkDelta] will append it to the total list of
    /// exempt addresses.
    #[serde(default)]
    pub scilla_call_gas_exempt_addrs: Vec<Address>,
    /// If true, querying the `BLOCKNUMBER` from Scilla will correctly return the current block number (i.e. the one
    /// the transaction is about to be included in). If false, it will return the previous block number.
    pub scilla_block_number_returns_current_block: Option<bool>,
    /// If true, nested Scilla maps are returned to the Scilla intepreter in the correct format and keys are encoded
    /// properly. If false, Scilla transactions will work but they will be incorrect in undetermined ways.
    pub scilla_maps_are_encoded_correctly: Option<bool>,
    /// If true, the total gas paid by all transactions in a block is transferred to the zero address.
    /// This keeps the total supply of the network constant. If false, we still transfer funds to the zero address,
    /// but with an incorrect gas price of 1 Wei per gas.
    pub transfer_gas_fee_to_zero_account: Option<bool>,
    /// If true, when there are successful interop calls and in the end EVM transaction fails,
    /// no state changes are applied for affected accounts by interop calls
    pub apply_scilla_delta_when_evm_succeeded: Option<bool>,
    /// If true, only apply state changes if the transaction succeeds. If false, apply state changes even if the
    /// transaction fails.
    pub apply_state_changes_only_if_transaction_succeeds: Option<bool>,
    /// if true, funds are deducted from the sender of scilla message rather than the origin
    pub scilla_deduct_funds_from_actual_sender: Option<bool>,
    /// Send funds from zero account to faucet account
    pub fund_accounts_from_zero_account: Option<Vec<(Address, Amount)>>,
    /// If true, Scilla state deltas containing maps are applied correctly. If false, they are applied in an
    /// unspecified and incorrect way.
    pub scilla_delta_maps_are_applied_correctly: Option<bool>,
    /// If true, the Zilliqa process can send the Scilla process an unlimited (actually 1 GiB) amount of data in one
    /// call. If false, the size is limited to 10 MiB. Any responses larger than this will lead to a failed
    /// transaction.
    pub scilla_server_unlimited_response_size: Option<bool>,
    /// If true, for failed scilla transaction there will be only fee taken from sender balance and possible
    /// balance subtractions caused by scilla transitions will be discarded
    pub scilla_failed_txn_correct_balance_deduction: Option<bool>,
    /// If true, scilla transitions are pushed on the stack onto stack in the same order as they were
    /// emitted from scilla call
    pub scilla_transition_proper_order: Option<bool>,
    /// If true, values transfers from evm to scilla contracts are always reset to 0
    pub evm_to_scilla_value_transfer_zero: Option<bool>,
    /// If true, re-write XSGD contract to address 0x173CA6770aA56eb00511Dac8e6E13B3D7f16A5a5's code
    pub restore_xsgd_contract: Option<bool>,
    /// If true, any failed evm action (call, create, create2, etc) will automatically make
    /// entire transaction fail if there's been a call to whitelisted zrc2 contract via scilla precompile
    pub evm_exec_failure_causes_scilla_whitelisted_addr_to_fail: Option<bool>,
    /// If true, set address 0x173CA6770aA56eb00511Dac8e6E13B3D7f16A5a5's code to "0x"
    pub revert_restore_xsgd_contract: Option<bool>,
    /// If true, an evm tx (legacy or eip1559) should not clear a Scilla contract's code when its address is interacted with
    pub scilla_fix_contract_code_removal_on_evm_tx: Option<bool>,
}

impl Fork {
    pub fn apply_delta_fork(&self, delta: &ForkDelta) -> Fork {
        Fork {
            at_height: delta.at_height,
            executable_blocks: delta.executable_blocks.unwrap_or(self.executable_blocks),
            failed_scilla_call_from_gas_exempt_caller_causes_revert: delta
                .failed_scilla_call_from_gas_exempt_caller_causes_revert
                .unwrap_or(self.failed_scilla_call_from_gas_exempt_caller_causes_revert),
            call_mode_1_sets_caller_to_parent_caller: delta
                .call_mode_1_sets_caller_to_parent_caller
                .unwrap_or(self.call_mode_1_sets_caller_to_parent_caller),
            scilla_messages_can_call_evm_contracts: delta
                .scilla_messages_can_call_evm_contracts
                .unwrap_or(self.scilla_messages_can_call_evm_contracts),
            scilla_contract_creation_increments_account_balance: delta
                .scilla_contract_creation_increments_account_balance
                .unwrap_or(self.scilla_contract_creation_increments_account_balance),
            scilla_json_preserve_order: delta
                .scilla_json_preserve_order
                .unwrap_or(self.scilla_json_preserve_order),
            scilla_call_respects_evm_state_changes: delta
                .scilla_call_respects_evm_state_changes
                .unwrap_or(self.scilla_call_respects_evm_state_changes),
            only_mutated_accounts_update_state: delta
                .only_mutated_accounts_update_state
                .unwrap_or(self.only_mutated_accounts_update_state),
            scilla_call_gas_exempt_addrs: {
                let mut addrs = self.scilla_call_gas_exempt_addrs.clone();
                addrs.extend_from_slice(&delta.scilla_call_gas_exempt_addrs);
                addrs
            },
            scilla_block_number_returns_current_block: delta
                .scilla_block_number_returns_current_block
                .unwrap_or(self.scilla_block_number_returns_current_block),
            scilla_maps_are_encoded_correctly: delta
                .scilla_maps_are_encoded_correctly
                .unwrap_or(self.scilla_maps_are_encoded_correctly),
            transfer_gas_fee_to_zero_account: delta
                .transfer_gas_fee_to_zero_account
                .unwrap_or(self.transfer_gas_fee_to_zero_account),
            apply_scilla_delta_when_evm_succeeded: delta
                .apply_scilla_delta_when_evm_succeeded
                .unwrap_or(self.apply_scilla_delta_when_evm_succeeded),
            apply_state_changes_only_if_transaction_succeeds: delta
                .apply_state_changes_only_if_transaction_succeeds
                .unwrap_or(self.apply_state_changes_only_if_transaction_succeeds),
            scilla_deduct_funds_from_actual_sender: delta
                .scilla_deduct_funds_from_actual_sender
                .unwrap_or(self.scilla_deduct_funds_from_actual_sender),
            fund_accounts_from_zero_account: delta
                .fund_accounts_from_zero_account
                .clone()
                .unwrap_or_default(),
            scilla_delta_maps_are_applied_correctly: delta
                .scilla_delta_maps_are_applied_correctly
                .unwrap_or(self.scilla_delta_maps_are_applied_correctly),
            scilla_server_unlimited_response_size: delta
                .scilla_server_unlimited_response_size
                .unwrap_or(self.scilla_server_unlimited_response_size),
            scilla_failed_txn_correct_balance_deduction: delta
                .scilla_failed_txn_correct_balance_deduction
                .unwrap_or(self.scilla_failed_txn_correct_balance_deduction),
            scilla_transition_proper_order: delta
                .scilla_transition_proper_order
                .unwrap_or(self.scilla_transition_proper_order),
            evm_to_scilla_value_transfer_zero: delta
                .evm_to_scilla_value_transfer_zero
                .unwrap_or(self.evm_to_scilla_value_transfer_zero),
            restore_xsgd_contract: delta
                .restore_xsgd_contract
                .unwrap_or(self.restore_xsgd_contract),
            evm_exec_failure_causes_scilla_whitelisted_addr_to_fail: delta
                .evm_exec_failure_causes_scilla_whitelisted_addr_to_fail
                .unwrap_or(self.evm_exec_failure_causes_scilla_whitelisted_addr_to_fail),
            revert_restore_xsgd_contract: delta
                .revert_restore_xsgd_contract
                .unwrap_or(self.revert_restore_xsgd_contract),
            scilla_fix_contract_code_removal_on_evm_tx: delta
                .scilla_fix_contract_code_removal_on_evm_tx
                .unwrap_or(self.scilla_fix_contract_code_removal_on_evm_tx),
        }
    }
}

/// Scilla Code to be restored via restore_xsgd_contract
pub const XSGD_MAINNET_ADDR: Address = address!("0x173CA6770aA56eb00511Dac8e6E13B3D7f16A5a5");
pub const XSGD_CODE: &str = "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";

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct GenesisDeposit {
    pub public_key: NodePublicKey,
    pub peer_id: PeerId,
    pub stake: Amount,
    pub reward_address: Address,
    pub control_address: Address,
}

pub fn consensus_timeout_default() -> Duration {
    Duration::from_secs(15)
}

pub fn block_time_default() -> Duration {
    Duration::from_millis(1000)
}

pub fn scilla_address_default() -> String {
    String::from("http://localhost:62831")
}

// This path is as viewed from Scilla, not zq2.
pub fn scilla_stdlib_dir_default() -> String {
    String::from("/scilla/0/_build/default/src/stdlib/")
}

pub fn scilla_ext_libs_path_default() -> ScillaExtLibsPath {
    ScillaExtLibsPath {
        zq2: ScillaExtLibsPathInZq2(String::from("/tmp/scilla_ext_libs")),
        scilla: ScillaExtLibsPathInScilla(String::from("/scilla_ext_libs")),
    }
}

pub fn scilla_server_socket_directory_default() -> String {
    String::from("/tmp/scilla-state-server")
}

pub fn blocks_per_epoch_default() -> u64 {
    3600
}

pub fn epochs_per_checkpoint_default() -> u64 {
    24
}

fn default_true() -> bool {
    true
}

pub fn total_native_token_supply_default() -> Amount {
    Amount::from(21_000_000_000_000_000_000_000_000_000)
}

pub fn withdrawal_period_default() -> u64 {
    // 2 weeks worth of blocks with 1 second block time
    2 * 7 * 24 * 60 * 60
}

/// The default implementation returns a single fork at the genesis block, with the most up-to-date
/// execution logic.
pub fn genesis_fork_default() -> Fork {
    Fork {
        at_height: 0,
        executable_blocks: true,
        failed_scilla_call_from_gas_exempt_caller_causes_revert: true,
        call_mode_1_sets_caller_to_parent_caller: true,
        scilla_messages_can_call_evm_contracts: true,
        scilla_contract_creation_increments_account_balance: true,
        scilla_json_preserve_order: true,
        scilla_call_respects_evm_state_changes: true,
        only_mutated_accounts_update_state: true,
        scilla_call_gas_exempt_addrs: vec![],
        scilla_block_number_returns_current_block: true,
        scilla_maps_are_encoded_correctly: true,
        transfer_gas_fee_to_zero_account: true,
        apply_scilla_delta_when_evm_succeeded: true,
        apply_state_changes_only_if_transaction_succeeds: true,
        scilla_deduct_funds_from_actual_sender: true,
        fund_accounts_from_zero_account: vec![],
        scilla_delta_maps_are_applied_correctly: true,
        scilla_server_unlimited_response_size: true,
        scilla_failed_txn_correct_balance_deduction: true,
        scilla_transition_proper_order: true,
        evm_to_scilla_value_transfer_zero: true,
        restore_xsgd_contract: true,
        evm_exec_failure_causes_scilla_whitelisted_addr_to_fail: true,
        revert_restore_xsgd_contract: true,
        scilla_fix_contract_code_removal_on_evm_tx: true,
    }
}

pub fn new_view_broadcast_interval_default() -> Duration {
    Duration::from_secs(300)
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ReinitialiseParams {
    /// The minimum number of blocks a staker must wait before being able to withdraw unstaked funds
    pub withdrawal_period: u64,
}

impl Default for ReinitialiseParams {
    fn default() -> Self {
        Self {
            withdrawal_period: withdrawal_period_default(),
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ContractUpgradeConfig {
    pub height: u64,
    pub reinitialise_params: Option<ReinitialiseParams>,
}

impl ContractUpgradeConfig {
    pub fn from_height(height: u64) -> Self {
        Self {
            height,
            reinitialise_params: None,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ContractUpgrades {
    pub deposit_v3: Option<ContractUpgradeConfig>,
    pub deposit_v4: Option<ContractUpgradeConfig>,
    pub deposit_v5: Option<ContractUpgradeConfig>,
}

impl ContractUpgrades {
    pub fn new(
        deposit_v3: Option<ContractUpgradeConfig>,
        deposit_v4: Option<ContractUpgradeConfig>,
        deposit_v5: Option<ContractUpgradeConfig>,
    ) -> ContractUpgrades {
        Self {
            deposit_v3,
            deposit_v4,
            deposit_v5,
        }
    }
    pub fn to_toml(&self) -> toml::Value {
        // toml doesn't like Option types. We need to manually map items in struct removing keys for None values as we go
        // ContractUpgrades's values are only either u64, None or a json object
        fn serde_value_to_toml_value(input: serde_json::Value) -> toml::Value {
            toml::Value::Table(
                input
                    .as_object()
                    .unwrap()
                    .clone()
                    .into_iter()
                    .filter_map(|(k, v)| {
                        if v.is_null() {
                            // Ignore None values
                            None
                        } else if v.is_u64() {
                            // Parse ints
                            Some((k, toml::Value::Integer(v.as_u64().unwrap() as i64)))
                        } else {
                            // Recursively parse objects
                            Some((k, serde_value_to_toml_value(v)))
                        }
                    })
                    .collect(),
            )
        }
        serde_value_to_toml_value(json!(self))
    }
}

impl Default for ContractUpgrades {
    fn default() -> Self {
        Self {
            deposit_v3: None,
            deposit_v4: None,
            deposit_v5: Some(ContractUpgradeConfig {
                height: 0,
                reinitialise_params: Some(ReinitialiseParams::default()),
            }),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_get_forks_with_no_forks() {
        let config = ConsensusConfig {
            genesis_fork: genesis_fork_default(),
            forks: vec![],
            ..Default::default()
        };

        let forks = config.get_forks().unwrap();
        assert_eq!(forks.0.len(), 1);
        assert_eq!(forks.get(0).at_height, 0);
    }

    #[test]
    fn test_get_forks_with_one_fork() {
        let config = ConsensusConfig {
            genesis_fork: genesis_fork_default(),
            forks: vec![ForkDelta {
                at_height: 10,
                executable_blocks: None,
                failed_scilla_call_from_gas_exempt_caller_causes_revert: None,
                call_mode_1_sets_caller_to_parent_caller: Some(false),
                scilla_messages_can_call_evm_contracts: None,
                scilla_contract_creation_increments_account_balance: Some(false),
                scilla_json_preserve_order: None,
                scilla_call_respects_evm_state_changes: None,
                only_mutated_accounts_update_state: None,
                scilla_call_gas_exempt_addrs: vec![],
                scilla_block_number_returns_current_block: None,
                scilla_maps_are_encoded_correctly: None,
                transfer_gas_fee_to_zero_account: None,
                apply_scilla_delta_when_evm_succeeded: None,
                apply_state_changes_only_if_transaction_succeeds: None,
                scilla_deduct_funds_from_actual_sender: None,
                fund_accounts_from_zero_account: None,
                scilla_delta_maps_are_applied_correctly: None,
                scilla_server_unlimited_response_size: None,
                scilla_failed_txn_correct_balance_deduction: None,
                scilla_transition_proper_order: None,
                evm_to_scilla_value_transfer_zero: None,
                restore_xsgd_contract: None,
                evm_exec_failure_causes_scilla_whitelisted_addr_to_fail: None,
                revert_restore_xsgd_contract: None,
                scilla_fix_contract_code_removal_on_evm_tx: None,
            }],
            ..Default::default()
        };

        let forks = config.get_forks().unwrap();
        assert_eq!(forks.0.len(), 2);
        assert_eq!(forks.get(0).at_height, 0);
        assert_eq!(forks.get(11).at_height, 10);
        assert!(!forks.get(10).call_mode_1_sets_caller_to_parent_caller);
        assert!(
            !forks
                .get(10)
                .scilla_contract_creation_increments_account_balance
        );
    }

    #[test]
    fn test_get_forks_with_multiple_forks() {
        let config = ConsensusConfig {
            genesis_fork: genesis_fork_default(),
            forks: vec![
                ForkDelta {
                    at_height: 10,
                    executable_blocks: Some(true),
                    failed_scilla_call_from_gas_exempt_caller_causes_revert: Some(true),
                    call_mode_1_sets_caller_to_parent_caller: None,
                    scilla_messages_can_call_evm_contracts: Some(true),
                    scilla_contract_creation_increments_account_balance: None,
                    scilla_json_preserve_order: Some(true),
                    scilla_call_respects_evm_state_changes: None,
                    only_mutated_accounts_update_state: None,
                    scilla_call_gas_exempt_addrs: vec![],
                    scilla_block_number_returns_current_block: None,
                    scilla_maps_are_encoded_correctly: None,
                    transfer_gas_fee_to_zero_account: None,
                    apply_scilla_delta_when_evm_succeeded: None,
                    apply_state_changes_only_if_transaction_succeeds: None,
                    scilla_deduct_funds_from_actual_sender: None,
                    fund_accounts_from_zero_account: None,
                    scilla_delta_maps_are_applied_correctly: None,
                    scilla_server_unlimited_response_size: None,
                    scilla_failed_txn_correct_balance_deduction: None,
                    scilla_transition_proper_order: None,
                    evm_to_scilla_value_transfer_zero: None,
                    restore_xsgd_contract: None,
                    evm_exec_failure_causes_scilla_whitelisted_addr_to_fail: None,
                    revert_restore_xsgd_contract: None,
                    scilla_fix_contract_code_removal_on_evm_tx: None,
                },
                ForkDelta {
                    at_height: 20,
                    executable_blocks: Some(true),
                    failed_scilla_call_from_gas_exempt_caller_causes_revert: Some(false),
                    call_mode_1_sets_caller_to_parent_caller: Some(true),
                    scilla_messages_can_call_evm_contracts: Some(false),
                    scilla_contract_creation_increments_account_balance: Some(true),
                    scilla_json_preserve_order: Some(true),
                    scilla_call_respects_evm_state_changes: None,
                    only_mutated_accounts_update_state: None,
                    scilla_call_gas_exempt_addrs: vec![],
                    scilla_block_number_returns_current_block: None,
                    scilla_maps_are_encoded_correctly: None,
                    transfer_gas_fee_to_zero_account: None,
                    apply_scilla_delta_when_evm_succeeded: None,
                    apply_state_changes_only_if_transaction_succeeds: None,
                    scilla_deduct_funds_from_actual_sender: None,
                    fund_accounts_from_zero_account: None,
                    scilla_delta_maps_are_applied_correctly: None,
                    scilla_server_unlimited_response_size: None,
                    scilla_failed_txn_correct_balance_deduction: None,
                    scilla_transition_proper_order: None,
                    evm_to_scilla_value_transfer_zero: None,
                    restore_xsgd_contract: None,
                    evm_exec_failure_causes_scilla_whitelisted_addr_to_fail: None,
                    revert_restore_xsgd_contract: None,
                    scilla_fix_contract_code_removal_on_evm_tx: None,
                },
            ],
            ..Default::default()
        };

        let forks = config.get_forks().unwrap();
        assert_eq!(forks.0.len(), 3);
        assert_eq!(forks.get(0).at_height, 0);
        assert_eq!(forks.get(11).at_height, 10);
        assert_eq!(forks.get(21).at_height, 20);
        assert!(
            forks
                .get(10)
                .failed_scilla_call_from_gas_exempt_caller_causes_revert
        );
        assert!(forks.get(11).scilla_messages_can_call_evm_contracts);
        assert!(
            !forks
                .get(20)
                .failed_scilla_call_from_gas_exempt_caller_causes_revert
        );
        assert!(forks.get(20).call_mode_1_sets_caller_to_parent_caller);
        assert!(!forks.get(20).scilla_messages_can_call_evm_contracts);
        assert!(
            forks
                .get(20)
                .scilla_contract_creation_increments_account_balance
        );
    }

    #[test]
    fn test_get_forks_with_unsorted_forks() {
        let config = ConsensusConfig {
            genesis_fork: genesis_fork_default(),
            forks: vec![
                ForkDelta {
                    at_height: 20,
                    executable_blocks: Some(true),
                    failed_scilla_call_from_gas_exempt_caller_causes_revert: Some(false),
                    call_mode_1_sets_caller_to_parent_caller: None,
                    scilla_messages_can_call_evm_contracts: None,
                    scilla_contract_creation_increments_account_balance: None,
                    scilla_json_preserve_order: None,
                    scilla_call_respects_evm_state_changes: None,
                    only_mutated_accounts_update_state: None,
                    scilla_call_gas_exempt_addrs: vec![],
                    scilla_block_number_returns_current_block: None,
                    scilla_maps_are_encoded_correctly: None,
                    transfer_gas_fee_to_zero_account: None,
                    apply_scilla_delta_when_evm_succeeded: None,
                    apply_state_changes_only_if_transaction_succeeds: None,
                    scilla_deduct_funds_from_actual_sender: None,
                    fund_accounts_from_zero_account: None,
                    scilla_delta_maps_are_applied_correctly: None,
                    scilla_server_unlimited_response_size: None,
                    scilla_failed_txn_correct_balance_deduction: None,
                    scilla_transition_proper_order: None,
                    evm_to_scilla_value_transfer_zero: None,
                    restore_xsgd_contract: None,
                    evm_exec_failure_causes_scilla_whitelisted_addr_to_fail: None,
                    revert_restore_xsgd_contract: None,
                    scilla_fix_contract_code_removal_on_evm_tx: None,
                },
                ForkDelta {
                    at_height: 10,
                    executable_blocks: Some(true),
                    failed_scilla_call_from_gas_exempt_caller_causes_revert: None,
                    call_mode_1_sets_caller_to_parent_caller: None,
                    scilla_messages_can_call_evm_contracts: None,
                    scilla_contract_creation_increments_account_balance: None,
                    scilla_json_preserve_order: None,
                    scilla_call_respects_evm_state_changes: None,
                    only_mutated_accounts_update_state: None,
                    scilla_call_gas_exempt_addrs: vec![],
                    scilla_block_number_returns_current_block: None,
                    scilla_maps_are_encoded_correctly: None,
                    transfer_gas_fee_to_zero_account: None,
                    apply_scilla_delta_when_evm_succeeded: None,
                    apply_state_changes_only_if_transaction_succeeds: None,
                    scilla_deduct_funds_from_actual_sender: None,
                    fund_accounts_from_zero_account: None,
                    scilla_delta_maps_are_applied_correctly: None,
                    scilla_server_unlimited_response_size: None,
                    scilla_failed_txn_correct_balance_deduction: None,
                    scilla_transition_proper_order: None,
                    evm_to_scilla_value_transfer_zero: None,
                    restore_xsgd_contract: None,
                    evm_exec_failure_causes_scilla_whitelisted_addr_to_fail: None,
                    revert_restore_xsgd_contract: None,
                    scilla_fix_contract_code_removal_on_evm_tx: None,
                },
            ],
            ..Default::default()
        };

        let forks = config.get_forks().unwrap();
        assert_eq!(forks.0.len(), 3);
        assert_eq!(forks.get(0).at_height, 0);
        assert_eq!(forks.get(12).at_height, 10);
        assert_eq!(forks.get(22).at_height, 20);

        assert!(
            forks
                .get(10)
                .failed_scilla_call_from_gas_exempt_caller_causes_revert
        );
        assert!(
            !forks
                .get(20)
                .failed_scilla_call_from_gas_exempt_caller_causes_revert
        );
    }

    #[test]
    fn test_get_forks_with_missing_genesis_fork() {
        let config = ConsensusConfig {
            genesis_fork: Fork {
                at_height: 1,
                executable_blocks: true,
                failed_scilla_call_from_gas_exempt_caller_causes_revert: true,
                call_mode_1_sets_caller_to_parent_caller: true,
                scilla_messages_can_call_evm_contracts: true,
                scilla_contract_creation_increments_account_balance: true,
                scilla_json_preserve_order: true,
                scilla_call_respects_evm_state_changes: true,
                only_mutated_accounts_update_state: true,
                scilla_call_gas_exempt_addrs: vec![],
                scilla_block_number_returns_current_block: true,
                scilla_maps_are_encoded_correctly: true,
                transfer_gas_fee_to_zero_account: true,
                apply_scilla_delta_when_evm_succeeded: true,
                apply_state_changes_only_if_transaction_succeeds: true,
                scilla_deduct_funds_from_actual_sender: true,
                fund_accounts_from_zero_account: vec![],
                scilla_delta_maps_are_applied_correctly: true,
                scilla_server_unlimited_response_size: true,
                scilla_failed_txn_correct_balance_deduction: true,
                scilla_transition_proper_order: true,
                evm_to_scilla_value_transfer_zero: true,
                restore_xsgd_contract: true,
                evm_exec_failure_causes_scilla_whitelisted_addr_to_fail: true,
                revert_restore_xsgd_contract: true,
                scilla_fix_contract_code_removal_on_evm_tx: true,
            },
            forks: vec![],
            ..Default::default()
        };

        let result = config.get_forks();
        assert!(result.is_err());
    }

    #[test]
    fn test_get_forks_boundary_cases() {
        let config = ConsensusConfig {
            genesis_fork: genesis_fork_default(),
            forks: vec![
                ForkDelta {
                    at_height: 10,
                    executable_blocks: None,
                    failed_scilla_call_from_gas_exempt_caller_causes_revert: None,
                    call_mode_1_sets_caller_to_parent_caller: None,
                    scilla_messages_can_call_evm_contracts: None,
                    scilla_contract_creation_increments_account_balance: None,
                    scilla_json_preserve_order: None,
                    scilla_call_respects_evm_state_changes: None,
                    only_mutated_accounts_update_state: None,
                    scilla_call_gas_exempt_addrs: vec![],
                    scilla_block_number_returns_current_block: None,
                    scilla_maps_are_encoded_correctly: None,
                    transfer_gas_fee_to_zero_account: None,
                    apply_scilla_delta_when_evm_succeeded: None,
                    apply_state_changes_only_if_transaction_succeeds: None,
                    scilla_deduct_funds_from_actual_sender: None,
                    fund_accounts_from_zero_account: None,
                    scilla_delta_maps_are_applied_correctly: None,
                    scilla_server_unlimited_response_size: None,
                    scilla_failed_txn_correct_balance_deduction: None,
                    scilla_transition_proper_order: None,
                    evm_to_scilla_value_transfer_zero: None,
                    restore_xsgd_contract: None,
                    evm_exec_failure_causes_scilla_whitelisted_addr_to_fail: None,
                    revert_restore_xsgd_contract: None,
                    scilla_fix_contract_code_removal_on_evm_tx: None,
                },
                ForkDelta {
                    at_height: 20,
                    executable_blocks: None,
                    failed_scilla_call_from_gas_exempt_caller_causes_revert: None,
                    call_mode_1_sets_caller_to_parent_caller: None,
                    scilla_messages_can_call_evm_contracts: None,
                    scilla_contract_creation_increments_account_balance: None,
                    scilla_json_preserve_order: None,
                    scilla_call_respects_evm_state_changes: None,
                    only_mutated_accounts_update_state: None,
                    scilla_call_gas_exempt_addrs: vec![],
                    scilla_block_number_returns_current_block: None,
                    scilla_maps_are_encoded_correctly: None,
                    transfer_gas_fee_to_zero_account: None,
                    apply_scilla_delta_when_evm_succeeded: None,
                    apply_state_changes_only_if_transaction_succeeds: None,
                    scilla_deduct_funds_from_actual_sender: None,
                    fund_accounts_from_zero_account: None,
                    scilla_delta_maps_are_applied_correctly: None,
                    scilla_server_unlimited_response_size: None,
                    scilla_failed_txn_correct_balance_deduction: None,
                    scilla_transition_proper_order: None,
                    evm_to_scilla_value_transfer_zero: None,
                    restore_xsgd_contract: None,
                    evm_exec_failure_causes_scilla_whitelisted_addr_to_fail: None,
                    revert_restore_xsgd_contract: None,
                    scilla_fix_contract_code_removal_on_evm_tx: None,
                },
            ],
            ..Default::default()
        };

        let forks = config.get_forks().unwrap();
        assert_eq!(forks.get(9).at_height, 0);
        assert_eq!(forks.get(10).at_height, 10);
        assert_eq!(forks.get(19).at_height, 10);
        assert_eq!(forks.get(20).at_height, 20);
        assert_eq!(forks.get(22).at_height, 20);
    }
}

```

`zilliqa/src/consensus.rs`:

```rs
use std::{
    cell::LazyCell,
    collections::{BTreeMap, HashMap},
    error::Error,
    fmt::Display,
    sync::{
        Arc,
        atomic::{AtomicBool, Ordering},
    },
    time::Duration,
};

use alloy::primitives::{Address, U256};
use anyhow::{Context, Result, anyhow};
use bitvec::{bitarr, order::Msb0};
use dashmap::DashMap;
use eth_trie::{EthTrie, MemoryDB, Trie};
use itertools::Itertools;
use k256::pkcs8::der::DateTime;
use libp2p::PeerId;
use opentelemetry::KeyValue;
use parking_lot::{Mutex, RwLock, RwLockWriteGuard};
use revm::Inspector;
use serde::{Deserialize, Serialize};
use tokio::sync::{broadcast, mpsc::UnboundedSender};
use tracing::*;

use crate::{
    api::types::eth::SyncingStruct,
    blockhooks,
    cfg::{ConsensusConfig, ForkName, NodeConfig, XSGD_CODE, XSGD_MAINNET_ADDR},
    constants::{EXPONENTIAL_BACKOFF_TIMEOUT_MULTIPLIER, TIME_TO_ALLOW_PROPOSAL_BROADCAST},
    crypto::{BlsSignature, Hash, NodePublicKey, SecretKey, verify_messages},
    db::{self, Db},
    exec::{PendingState, TransactionApplyResult},
    inspector::{self, ScillaInspector, TouchedAddressInspector},
    message::{
        AggregateQc, BitArray, BitSlice, Block, BlockHeader, BlockRef, BlockStrategy,
        ExternalMessage, GossipSubTopic, InternalMessage, MAX_COMMITTEE_SIZE, NewView, Proposal,
        QuorumCertificate, Vote,
    },
    node::{MessageSender, NetworkMessage},
    pool::{
        PendingOrQueued, TransactionPool, TxAddResult, TxPoolContent, TxPoolContentFrom,
        TxPoolStatus,
    },
    state::{Code, State},
    sync::{Sync, SyncPeers},
    time::SystemTime,
    transaction::{EvmGas, SignedTransaction, TransactionReceipt, VerifiedTransaction},
};

#[derive(Clone, Debug, Serialize)]
pub struct NewViewVote {
    signatures: Vec<BlsSignature>,
    pub cosigned: BitArray,
    cosigned_weight: u128,
    qcs: BTreeMap<usize, QuorumCertificate>,
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub struct Validator {
    pub public_key: NodePublicKey,
    pub peer_id: PeerId,
}

impl PartialEq for Validator {
    fn eq(&self, other: &Self) -> bool {
        self.peer_id == other.peer_id
    }
}

impl Eq for Validator {}

impl PartialOrd for Validator {
    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
        Some(self.cmp(other))
    }
}

impl Ord for Validator {
    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
        self.peer_id.cmp(&other.peer_id)
    }
}

#[derive(Debug)]
struct MissingBlockError(BlockRef);

impl Display for MissingBlockError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "missing block: {:?}", self.0)
    }
}

impl Error for MissingBlockError {}

impl From<u64> for MissingBlockError {
    fn from(view: u64) -> Self {
        MissingBlockError(BlockRef::View(view))
    }
}

impl From<Hash> for MissingBlockError {
    fn from(hash: Hash) -> Self {
        MissingBlockError(BlockRef::Hash(hash))
    }
}

#[derive(Debug, Clone, Serialize)]
pub struct BlockVotes {
    pub signatures: Vec<BlsSignature>,
    pub cosigned: BitArray,
    pub cosigned_weight: u128,
    pub supermajority_reached: bool,
}

impl Default for BlockVotes {
    fn default() -> BlockVotes {
        BlockVotes {
            signatures: Vec::new(),
            cosigned: bitarr![u8, Msb0; 0; MAX_COMMITTEE_SIZE],
            cosigned_weight: 0,
            supermajority_reached: false,
        }
    }
}

type EarlyProposal = (
    Block,
    Vec<VerifiedTransaction>,
    EthTrie<MemoryDB>,
    EthTrie<MemoryDB>,
    u128, // Cumulative gas fee which will be sent to ZERO account
);

#[derive(Debug)]
struct ReceiptsCache {
    hash: Hash,
    receipts: HashMap<Hash, (TransactionReceipt, Vec<Address>)>,
}

impl Default for ReceiptsCache {
    fn default() -> Self {
        Self {
            hash: Hash::ZERO,
            receipts: Default::default(),
        }
    }
}

impl ReceiptsCache {
    fn insert(&mut self, hash: Hash, receipt: TransactionReceipt, touched_addresses: Vec<Address>) {
        self.receipts.insert(hash, (receipt, touched_addresses));
    }

    fn set_hash(&mut self, hash: Hash) {
        self.hash = hash;
    }

    fn remove(&mut self, hash: &Hash) -> Option<(TransactionReceipt, Vec<Address>)> {
        self.receipts.remove(hash)
    }

    fn clear(&mut self) {
        self.hash = Hash::ZERO;
        self.receipts.clear();
    }
}

/// The consensus algorithm is pipelined fast-hotstuff, as given in this paper: https://arxiv.org/pdf/2010.11454.pdf
///
/// The algorithm can be condensed down into the following explanation:
/// - Blocks must contain either a QuorumCertificate (QC), or an aggregated QuorumCertificate (aggQC).
/// - A QuorumCertificate is an aggregation of signatures of threshold validators against a block hash (the previous block)
/// - An aggQC is an aggregation of threshold QC.
/// - at each time step, a.k.a 'view' a leader is chosen (based on view number) from the validators (committee) to propose a block
/// - committee members vote (create a signature) on the block proposal
/// - after threshold signatures are aggregated, a QC is formed which points to the block proposal
///
/// Happy path:
/// - Start at genesis, there is only a block with a dummy QC which everyone sees (exceptional case).
/// - everyone advances view to 1
/// - validators vote on genesis
/// - a high QC (QC pointing to the highest known hash) is formed from the validators votes on genesis
/// - everyone advances view to 2
/// - next leader proposes a block
/// - validators vote on block 1 -> new high QC... and so on.
///
/// Unhappy path:
/// - In the unhappy path, there is the possibility of forks (for example if you executed the block proposal).
/// - In this case, the view will time out with no leader successfully proposing a block.
/// - From this point forward, block view =/= block number
/// - The view will increment on all or some nodes. The timeout for view increments doubles each time,
///   which guarantees all nodes eventually are on the same view
/// - Nodes send a NewView message, which is a signature over the view, and their highQC
/// - This is collected to form an aggQC
/// - This aggQC is used to propose a block
/// - The votes on that block form the next highQC
///
#[derive(Debug)]
pub struct Consensus {
    secret_key: SecretKey,
    config: NodeConfig,
    message_sender: MessageSender,
    reset_timeout: UnboundedSender<Duration>,
    pub sync: Sync,
    pub votes: DashMap<Hash, BlockVotes>,
    /// Votes for a block we don't have stored. They are retained in case we receive the block later.
    // TODO(#719): Consider how to limit the size of this.
    pub buffered_votes: DashMap<Hash, Vec<(PeerId, Vote)>>,
    pub new_views: DashMap<u64, NewViewVote>,
    network_message_cache: Option<NetworkMessage>,
    pub high_qc: QuorumCertificate,
    /// The account store.
    state: State,
    /// The persistence database
    db: Arc<Db>,
    receipts_cache: Mutex<ReceiptsCache>,
    /// Actions that act on newly created blocks
    pub transaction_pool: RwLock<TransactionPool>,
    /// Pending proposal. Gets created as soon as we become aware that we are leader for this view.
    early_proposal: RwLock<Option<EarlyProposal>>,
    /// Flag indicating that block broadcasting should be postponed at least until block_time is reached
    create_next_block_on_timeout: AtomicBool,
    /// Timestamp of most recent view change
    view_updated_at: RwLock<SystemTime>,
    pub new_blocks: broadcast::Sender<BlockHeader>,
    pub new_receipts: broadcast::Sender<(TransactionReceipt, usize)>,
    pub new_transactions: broadcast::Sender<VerifiedTransaction>,
    pub new_transaction_hashes: broadcast::Sender<Hash>,
    /// Used for testing and test network recovery
    force_view: Option<(u64, DateTime)>,
    /// Mark if this node is in the committee at it's current head block height
    in_committee: bool,
}

impl Consensus {
    // determined empirically
    const PROP_SIZE_THRESHOLD: usize = 921 * 1024; // 90% of 1MB
    // view buffer size limit
    const VIEW_BUFFER_THRESHOLD: usize = 1000;

    pub fn new(
        secret_key: SecretKey,
        config: NodeConfig,
        message_sender: MessageSender,
        reset_timeout: UnboundedSender<Duration>,
        db: Arc<Db>,
        peers: Arc<SyncPeers>,
    ) -> Result<Self> {
        trace!(
            "Opening database in {:?} for shard {}",
            config.data_dir, config.eth_chain_id
        );

        // Start chain from checkpoint. Load data file and initialise data in tables
        let mut checkpoint_data = None;
        if let Some(checkpoint) = &config.load_checkpoint {
            trace!("Loading state from checkpoint: {:?}", checkpoint);
            checkpoint_data = db.load_trusted_checkpoint(
                &checkpoint.file,
                &checkpoint.hash,
                config.eth_chain_id,
            )?;
        }

        let latest_block = db
            .get_finalized_view()?
            .and_then(|view| {
                db.get_block_hash_by_view(view)
                    .expect("no header found at view {view}")
            })
            .and_then(|hash| {
                db.get_block_by_hash(&hash)
                    .expect("no block found for hash {hash}")
            });

        let mut state = if let Some(latest_block) = &latest_block {
            trace!("Loading state from latest block");
            State::new_at_root(
                db.state_trie()?,
                latest_block.state_root_hash().into(),
                config.clone(),
                db.clone(),
            )
        } else {
            trace!("Constructing new state from genesis");
            State::new_with_genesis(db.state_trie()?, config.clone(), db.clone())
        }?;

        let (latest_block, latest_block_view) = match latest_block {
            Some(l) => (Some(l.clone()), l.view()),
            None => {
                let genesis = Block::genesis(state.root_hash()?);
                (Some(genesis.clone()), 0)
            }
        };

        let (start_view, high_qc) = {
            match db.get_high_qc()? {
                Some(qc) => {
                    let high_block = db
                        .get_block_by_hash(&qc.block_hash)?
                        .ok_or_else(|| anyhow!("missing block that high QC points to!"))?;
                    let finalized_view = db
                        .get_finalized_view()?
                        .ok_or_else(|| anyhow!("missing latest finalized view!"))?;
                    let finalized_block = db
                        .get_block_by_view(finalized_view)?
                        .ok_or_else(|| anyhow!("missing finalized block!"))?;

                    // If latest view was written to disk then always start from there. Otherwise start from (highest out of high block and finalised block) + 1
                    let start_view = db
                        .get_view()?
                        .or_else(|| {
                            Some(std::cmp::max(high_block.view(), finalized_block.view()) + 1)
                        })
                        .unwrap();

                    trace!(
                        "recovery: high_block view {0}, finalized_number {1}, start_view {2}",
                        high_block.view(),
                        finalized_view,
                        start_view
                    );

                    if finalized_view > high_block.view() {
                        // We know of a finalized view higher than the view in finalized_number; start there.
                        state.set_to_root(finalized_block.header.state_root_hash.into());
                    } else {
                        // The high_block contains the latest finalized view. Start there.
                        state.set_to_root(high_block.header.state_root_hash.into());
                    }

                    info!(
                        "During recovery, starting consensus at view {}, finalised view {}",
                        start_view, finalized_view
                    );
                    (start_view, qc)
                }
                None => {
                    let start_view = 1;
                    let finalized_view = 0;
                    // We always mark view 1 as voted even though we haven't voted yet, because we can only send a
                    // `Vote` for the genesis block. We can never send `NewView(1)`.
                    db.set_view(start_view, true)?;
                    db.set_finalized_view(finalized_view)?;
                    (start_view, QuorumCertificate::genesis())
                }
            }
        };

        let sync = Sync::new(
            &config,
            db.clone(),
            &latest_block,
            message_sender.clone(),
            peers.clone(),
        )?;

        let mut consensus = Consensus {
            secret_key,
            config,
            sync,
            message_sender,
            reset_timeout,
            votes: DashMap::new(),
            buffered_votes: DashMap::new(),
            new_views: DashMap::new(),
            network_message_cache: None,
            high_qc,
            state,
            db,
            receipts_cache: Default::default(),
            transaction_pool: Default::default(),
            early_proposal: Default::default(),
            create_next_block_on_timeout: AtomicBool::new(false),
            view_updated_at: RwLock::new(SystemTime::now()),
            new_blocks: broadcast::Sender::new(4),
            new_receipts: broadcast::Sender::new(128),
            new_transactions: broadcast::Sender::new(128),
            new_transaction_hashes: broadcast::Sender::new(128),
            force_view: None,
            in_committee: true,
        };

        // If we're at genesis, add the genesis block and return
        if latest_block_view == 0 {
            if let Some(genesis) = latest_block {
                // The genesis block might already be stored and we were interrupted before we got a
                // QC for it.
                if consensus.get_block(&genesis.hash())?.is_none() {
                    consensus.add_block(None, genesis.clone())?;
                }
            }
            // treat genesis as finalized
            consensus.set_finalized_view(latest_block_view)?;
            return Ok(consensus);
        }

        // If we started from a checkpoint, execute the checkpointed block now
        if let Some((block, transactions, parent)) = checkpoint_data {
            consensus.execute_block(
                None,
                &block,
                transactions,
                &consensus
                    .state
                    .at_root(parent.state_root_hash().into())
                    .get_stakers(block.header)?,
            )?;
        }

        // If timestamp of when current high_qc was written exists then use it to estimate the minimum number of blocks the network has moved on since shut down
        // This is useful in scenarios in which consensus has failed since this node went down
        if let Some(latest_high_qc_timestamp) = consensus.db.get_high_qc_updated_at()? {
            let view_diff = Consensus::minimum_views_in_time_difference(
                latest_high_qc_timestamp.elapsed()?,
                consensus.config.consensus.consensus_timeout,
            );
            let min_view_since_high_qc_updated = high_qc.view + 1 + view_diff;
            if min_view_since_high_qc_updated > start_view {
                info!(
                    "Based on elapsed clock time of {} seconds since lastest high_qc update, we are atleast {} views above our current high_qc view. This is larger than our stored view so jump to new start_view {}",
                    latest_high_qc_timestamp.elapsed()?.as_secs(),
                    view_diff,
                    min_view_since_high_qc_updated
                );
                consensus
                    .db
                    .set_view(min_view_since_high_qc_updated, false)?;
            }
        }

        // Set self.network_message_cache incase the network is stuck
        if consensus.db.get_voted_in_view()? {
            let block = consensus.head_block();
            if let Some(leader) = consensus.leader_at_block(&block, consensus.get_view()?) {
                consensus.build_vote(leader.peer_id, consensus.vote_from_block(&block));
            }
        } else {
            consensus.build_new_view()?;
        }

        Ok(consensus)
    }

    fn build_new_view(&mut self) -> Result<NetworkMessage> {
        let view = self.get_view()?;
        let block = self.get_block(&self.high_qc.block_hash)?.ok_or_else(|| {
            anyhow!("missing block corresponding to our high qc - this should never happen")
        })?;
        let leader = self.leader_at_block(&block, view);
        let new_view_message = (
            leader.map(|leader: Validator| leader.peer_id),
            ExternalMessage::NewView(Box::new(NewView::new(
                self.secret_key,
                self.high_qc,
                view,
                self.secret_key.node_public_key(),
            ))),
        );

        self.network_message_cache = Some(new_view_message.clone());
        Ok(new_view_message)
    }

    fn build_vote(&mut self, peer_id: PeerId, vote: Vote) -> NetworkMessage {
        let network_msg = (Some(peer_id), ExternalMessage::Vote(Box::new(vote)));
        self.network_message_cache = Some(network_msg.clone());
        network_msg
    }

    pub fn public_key(&self) -> NodePublicKey {
        self.secret_key.node_public_key()
    }

    pub fn head_block(&self) -> Block {
        let highest_block_number = self
            .db
            .get_highest_canonical_block_number()
            .unwrap()
            .unwrap();
        self.db
            .get_canonical_block_by_number(highest_block_number)
            .unwrap()
            .unwrap()
    }

    pub fn get_highest_canonical_block_number(&self) -> u64 {
        self.db
            .get_highest_canonical_block_number()
            .unwrap()
            .unwrap()
    }

    /// Function is called when the node has no other work to do. Check if:
    ///     - Block should be proposed if we are leader
    ///     - View should be timed out because no proposal received in time
    ///     - Current view's NewView or Vote should be re-published
    pub fn timeout(&mut self) -> Result<Option<NetworkMessage>> {
        let view = self.get_view()?;
        // We never want to timeout while on view 1
        if view == 1 {
            let block = self
                .get_block_by_view(0)
                .unwrap()
                .ok_or_else(|| anyhow!("missing block"))?;
            // Get the list of stakers for the next block.
            let next_block_header = BlockHeader {
                number: block.number() + 1,
                ..block.header
            };
            let stakers = self.state.get_stakers(next_block_header)?;
            // If we're in the genesis committee, vote again.
            if stakers.iter().any(|v| *v == self.public_key()) {
                info!(
                    "timeout in view: {:?}, we will vote for block rather than incrementing view, block hash: {}",
                    view,
                    block.hash()
                );
                let leader = self.leader_at_block(&block, view).unwrap();
                let vote = self.vote_from_block(&block);
                let network_msg = self.build_vote(leader.peer_id, vote);
                return Ok(Some(network_msg));
            } else {
                info!(
                    "We are on view: {:?} but we are not a validator, so we are waiting.",
                    view
                );
            }

            return Ok(None);
        }

        let (
            milliseconds_since_last_view_change,
            milliseconds_remaining_of_block_time,
            exponential_backoff_timeout,
        ) = self.get_consensus_timeout_params()?;
        trace!(
            milliseconds_since_last_view_change,
            exponential_backoff_timeout,
            milliseconds_remaining_of_block_time,
            "timeout reached create_next_block_on_timeout: {:?}",
            self.create_next_block_on_timeout
        );

        if self.create_next_block_on_timeout.load(Ordering::SeqCst) {
            // Check if enough time elapsed to propose block
            if milliseconds_remaining_of_block_time == 0 {
                match self.propose_new_block(None) {
                    Ok(Some(network_message)) => {
                        self.create_next_block_on_timeout
                            .store(false, Ordering::SeqCst);
                        return Ok(Some(network_message));
                    }
                    Ok(None) => {
                        error!("Failed to finalise block proposal.");
                        self.create_next_block_on_timeout
                            .store(false, Ordering::SeqCst);
                        self.early_proposal_clear()?;
                    }
                    Err(e) => error!("Failed to finalise proposal: {e}"),
                };
            } else {
                self.reset_timeout
                    .send(Duration::from_millis(milliseconds_remaining_of_block_time))?;
                return Ok(None);
            }
        }

        // If we are not leader then consider whether we want to timeout - the timeout duration doubles every time, so it
        // Should eventually have all nodes on the same view
        if milliseconds_since_last_view_change < exponential_backoff_timeout {
            trace!(
                "Not proceeding with view change. Current view: {} - time since last: {}, timeout requires: {}",
                view, milliseconds_since_last_view_change, exponential_backoff_timeout
            );

            // Resend NewView message for this view if timeout period is a multiple of consensus_timeout
            if (milliseconds_since_last_view_change
                > self.config.consensus.consensus_timeout.as_millis() as u64)
                && !self.config.consensus.new_view_broadcast_interval.is_zero()
                && (Duration::from_millis(milliseconds_since_last_view_change).as_secs()
                    % self.config.consensus.new_view_broadcast_interval.as_secs())
                    == 0
            {
                match self.network_message_cache.clone() {
                    Some((_, ExternalMessage::NewView(new_view))) => {
                        // If new_view message is not for this view then it must be outdated
                        if new_view.view == self.get_view()? {
                            // When re-sending new view messages we broadcast them, rather than only sending them to the
                            // view leader. This speeds up network recovery when many nodes have different high QCs.
                            self.new_view(self.peer_id(), *new_view.clone())?;
                            return Ok(Some((None, ExternalMessage::NewView(new_view))));
                        }
                    }
                    Some((peer, ExternalMessage::Vote(vote))) => {
                        if vote.view + 1 == self.get_view()? {
                            return Ok(Some((peer, ExternalMessage::Vote(vote))));
                        }
                    }
                    _ => {}
                }
            }

            return Ok(None);
        }

        trace!(
            "Considering view change: view: {} time since: {} timeout: {} last known view: {}, last height: {}, last hash: {}",
            view,
            milliseconds_since_last_view_change,
            exponential_backoff_timeout,
            self.high_qc.view,
            self.head_block().number(),
            self.head_block().hash()
        );

        let block = self.get_block(&self.high_qc.block_hash)?.ok_or_else(|| {
            anyhow!("missing block corresponding to our high qc - this should never happen")
        })?;

        // Get the list of stakers for the next block.
        let next_block_header = BlockHeader {
            number: block.number() + 1,
            ..block.header
        };
        let stakers = self
            .state
            .at_root(block.state_root_hash().into())
            .get_stakers(next_block_header)?;
        if !stakers.iter().any(|v| *v == self.public_key()) {
            debug!(
                "can't vote for new view, we aren't in the committee of length {:?}",
                stakers.len()
            );
            return Ok(None);
        }

        let next_view = view + 1;
        let next_exponential_backoff_timeout = self.exponential_backoff_timeout(next_view);
        info!(
            "***** TIMEOUT: View is now {} -> {}. Next view change in {}ms",
            view, next_view, next_exponential_backoff_timeout
        );

        self.set_view(next_view, false)?;
        let new_view = self.build_new_view()?;
        Ok(Some(new_view))
    }

    /// All values returned in milliseconds
    pub fn get_consensus_timeout_params(&self) -> Result<(u64, u64, u64)> {
        let view = self.get_view()?;
        let milliseconds_since_last_view_change = SystemTime::now()
            .duration_since(*self.view_updated_at.read())
            .unwrap_or_default();
        let mut milliseconds_remaining_of_block_time = self
            .config
            .consensus
            .block_time
            .saturating_sub(milliseconds_since_last_view_change);

        // In order to maintain close to 1 second block times we broadcast 1-TIME_TO_ALLOW_PROPOSAL_BROADCAST seconds after the previous block to allow for network messages and block processing
        if self.config.consensus.block_time > TIME_TO_ALLOW_PROPOSAL_BROADCAST {
            milliseconds_remaining_of_block_time = milliseconds_remaining_of_block_time
                .saturating_sub(TIME_TO_ALLOW_PROPOSAL_BROADCAST);
        }

        let mut exponential_backoff_timeout = self.exponential_backoff_timeout(view);

        // Override exponential_backoff_timeout in forced set view scenario
        match self.force_view {
            Some((forced_view, timeout_instant)) if view == forced_view => {
                exponential_backoff_timeout = SystemTime::from(timeout_instant)
                    .duration_since(SystemTime::now())?
                    .saturating_sub(milliseconds_since_last_view_change)
                    .as_millis() as u64;
            }
            _ => {}
        }

        Ok((
            milliseconds_since_last_view_change.as_millis() as u64,
            milliseconds_remaining_of_block_time.as_millis() as u64,
            exponential_backoff_timeout,
        ))
    }

    pub fn peer_id(&self) -> PeerId {
        self.secret_key.to_libp2p_keypair().public().to_peer_id()
    }

    /// Validate and process a fully formed proposal
    pub fn proposal(
        &mut self,
        from: PeerId,
        proposal: Proposal,
        during_sync: bool,
    ) -> Result<Option<NetworkMessage>> {
        if self.sync.am_syncing()? && !during_sync {
            debug!("skipping block proposal, we are currently syncing");
            return Ok(None);
        }

        self.cleanup_votes()?;

        let (block, transactions) = proposal.into_parts();
        let head_block = self.head_block();
        let mut view = self.get_view()?;

        info!(
            block_view = block.view(),
            block_number = block.number(),
            txns = transactions.len(),
            "handling block proposal {}",
            block.hash()
        );

        if self.db.contains_block(&block.hash())? {
            trace!("ignoring block proposal, block store contains this block already");
            return Ok(None);
        }

        if !during_sync && block.view() <= head_block.header.view {
            warn!(
                "Rejecting block - view not greater than our current head block! {} vs {}",
                block.view(),
                head_block.header.view
            );
            return Ok(None);
        }

        if block.gas_limit() > self.config.consensus.eth_block_gas_limit
            || block.gas_used() > block.gas_limit()
        {
            warn!(
                "Block gas used/limit check failed. Used: {}, Limit: {}, config limit: {}",
                block.gas_used(),
                block.gas_limit(),
                self.config.consensus.eth_block_gas_limit
            );
            return Ok(None);
        }

        if let Err(e) = self.check_block(&block, during_sync) {
            warn!(?e, "invalid block proposal received!");
            return Ok(None);
        }

        self.update_high_qc_and_view(block.agg.is_some(), block.header.qc)?;

        let proposal_view = block.view();
        let parent = self
            .get_block(&block.parent_hash())?
            .ok_or_else(|| anyhow!("missing block parent"))?;

        trace!("checking if block view {} is safe", block.view());

        // If the proposed block is safe, vote for it and advance to the next round.
        if self.check_safe_block(&block)? {
            // If the proposed block is safe but outdated then add to block cache - we may need it later
            let outdated = block.view() < view;
            let process_immediately = !outdated || during_sync;
            if !process_immediately {
                trace!(
                    "proposal is outdated: {} < {} but may be useful in the future, buffering",
                    block.view(),
                    view
                );
                return Ok(None);
            }

            trace!(
                "block view {} number {} aka {} is safe",
                block.view(),
                block.number(),
                block.hash()
            );

            if head_block.hash() != parent.hash() || block.number() != head_block.header.number + 1
            {
                warn!(
                    "******* Fork detected! \nHead block: {:?} \nBlock prop: {:?}. We are node {}",
                    head_block,
                    block,
                    self.peer_id()
                );
                self.deal_with_fork(&block)?;
            }

            // Must make sure state root hash is set to the parent's state root hash before applying transactions
            if self.state.root_hash()? != parent.state_root_hash() {
                warn!(
                    "state root hash prior to block execution mismatch, expected: {:?}, actual: {:?}, head: {:?}",
                    parent.state_root_hash(),
                    self.state.root_hash()?,
                    head_block
                );
                self.state.set_to_root(parent.state_root_hash().into());
            }
            let stakers: Vec<_> = self.state.get_stakers(block.header)?;

            // It is possible to source Proposals from own storage during sync, which alters the source of the Proposal.
            // Only allow from == self, for fast-forwarding, in normal case but not during sync
            let from = (self.peer_id() != from || !during_sync).then_some(from);
            self.execute_block(from, &block, transactions, &stakers)?;

            if view != proposal_view + 1 {
                view = proposal_view + 1;
                // We will send a vote in this view.
                self.set_view(view, true)?;
                debug!("*** setting view to proposal view... view is now {}", view);
            }

            if let Some((_, buffered_votes)) = self.buffered_votes.remove(&block.hash()) {
                // If we've buffered votes for this block, process them now.
                let count = buffered_votes.len();
                for (i, (from, vote)) in buffered_votes.into_iter().enumerate() {
                    trace!("applying buffered vote {} of {count}", i + 1);
                    if let Some(network_message) = self.vote(from, vote)? {
                        // If we reached the supermajority while processing this vote, send the next block proposal.
                        // Further votes are ignored (including our own).
                        // TODO(#720): We should prioritise our own vote.
                        trace!("supermajority reached, sending next proposal");
                        return Ok(Some(network_message));
                    }
                    // A bit hacky: processing of our buffered votes may have resulted in an early_proposal be created and awaiting empty block timeout for broadcast. In this case we must return now
                    let early_proposal = self.early_proposal.read();
                    if self.create_next_block_on_timeout.load(Ordering::SeqCst)
                        && early_proposal.is_some()
                        && early_proposal.as_ref().unwrap().0.view() == proposal_view + 1
                    {
                        trace!("supermajority reached, early proposal awaiting broadcast");
                        return Ok(None);
                    }
                }

                // If we reach this point, we had some buffered votes but they were not sufficient to reach a
                // supermajority.
            }

            // Get the list of stakers for the next block.
            let next_block_header = BlockHeader {
                number: block.number() + 1,
                ..block.header
            };
            let stakers = self.state.get_stakers(next_block_header)?;

            if !stakers.iter().any(|v| *v == self.public_key()) {
                self.in_committee(false)?;
                debug!(
                    "can't vote for block proposal, we aren't in the committee of length {:?}",
                    stakers.len()
                );
                return Ok(None);
            } else {
                self.in_committee(true)?;
                let vote = self.vote_from_block(&block);
                let next_leader = self.leader_at_block(&block, view);

                if self.create_next_block_on_timeout.load(Ordering::SeqCst) {
                    warn!("Create block on timeout set. Clearing");
                    self.create_next_block_on_timeout
                        .store(false, Ordering::SeqCst);
                }

                // Clear early_proposal in case it exists.
                self.early_proposal_clear()?;

                let Some(next_leader) = next_leader else {
                    warn!("Next leader is currently not reachable, has it joined committee yet?");
                    return Ok(None);
                };

                if !during_sync {
                    trace!(proposal_view, ?next_leader, "voting for block");
                    let network_message = self.build_vote(next_leader.peer_id, vote);
                    return Ok(Some(network_message));
                }
            }
        } else {
            trace!("block is not safe");
        }

        Ok(None)
    }

    /// For a given State apply a Proposal's rewards. Must be performed at the tail-end of the Proposal's processing.
    /// Note that the algorithm below is mentioned in cfg.rs - if you change the way
    /// rewards are calculated, please change the comments in the configuration structure there.
    fn apply_rewards_late_at(
        parent_block: &Block,
        at_state: &mut State,
        config: &ConsensusConfig,
        committee: &[NodePublicKey],
        proposer: NodePublicKey,
        block: &Block,
    ) -> Result<()> {
        let earned_reward = LazyCell::new(|| {
            let meter = opentelemetry::global::meter("zilliqa");
            meter
                .f64_counter("validator_earned_reward")
                .with_unit("ZIL")
                .build()
        });

        debug!("apply late rewards in view {}", block.view());
        let rewards_per_block: u128 = *config.rewards_per_hour / config.blocks_per_hour as u128;

        // Get the reward addresses from the parent state
        let parent_state = at_state.at_root(parent_block.state_root_hash().into());

        let proposer_address = parent_state.get_reward_address(proposer)?;

        let cosigner_stake: Vec<_> = committee
            .iter()
            .enumerate()
            .filter(|(i, _)| block.header.qc.cosigned[*i])
            .map(|(_, pub_key)| {
                let reward_address = parent_state.get_reward_address(*pub_key).unwrap();
                let stake = parent_state
                    .get_stake(*pub_key, block.header)
                    .unwrap()
                    .unwrap()
                    .get();
                (reward_address, stake)
            })
            .collect();

        let total_cosigner_stake = cosigner_stake.iter().fold(0, |sum, c| sum + c.1);
        if total_cosigner_stake == 0 {
            return Err(anyhow!("total stake is 0"));
        }

        // Track total awards given out. This may be different to rewards_per_block because we round down on division when we split the rewards
        let mut total_rewards_issued = 0;

        // Reward the Proposer
        if let Some(proposer_address) = proposer_address {
            let reward = rewards_per_block / 2;
            at_state.mutate_account(proposer_address, |a| {
                a.balance = a
                    .balance
                    .checked_add(reward)
                    .ok_or_else(|| anyhow!("Overflow occured in proposer account balance"))?;
                Ok(())
            })?;
            total_rewards_issued += reward;

            let attributes = [
                KeyValue::new("address", format!("{proposer_address:?}")),
                KeyValue::new("role", "proposer"),
            ];
            earned_reward.add((reward as f64) / 1e18, &attributes);
        }

        // Reward the committee
        for (reward_address, stake) in cosigner_stake {
            if let Some(cosigner) = reward_address {
                let reward = (U256::from(rewards_per_block / 2) * U256::from(stake)
                    / U256::from(total_cosigner_stake))
                .to::<u128>();
                at_state.mutate_account(cosigner, |a| {
                    a.balance = a
                        .balance
                        .checked_add(reward)
                        .ok_or(anyhow!("Overflow occured in cosigner account balance"))?;
                    Ok(())
                })?;
                total_rewards_issued += reward;

                let attributes = [
                    KeyValue::new("address", format!("{cosigner:?}")),
                    KeyValue::new("role", "cosigner"),
                ];
                earned_reward.add((reward as f64) / 1e18, &attributes);
            }
        }

        // ZIP-9: Fund rewards amount from zero account
        at_state.mutate_account(Address::ZERO, |a| {
            a.balance = a
                .balance
                .checked_sub(total_rewards_issued)
                .ok_or(anyhow!("No funds left in zero account"))?;
            Ok(())
        })?;

        Ok(())
    }

    /// For a given State apply the given transaction
    pub fn apply_transaction_at<I: Inspector<PendingState> + ScillaInspector>(
        state: &mut State,
        txn: VerifiedTransaction,
        current_block: BlockHeader,
        inspector: I,
        enable_inspector: bool,
    ) -> Result<Option<TransactionApplyResult>> {
        let hash = txn.hash;

        let result =
            state.apply_transaction(txn.clone(), current_block, inspector, enable_inspector);
        let result = match result {
            Ok(r) => r,
            Err(error) => {
                warn!(?hash, ?error, "transaction failed to execute");
                return Ok(None);
            }
        };

        if !result.success() {
            info!("Transaction was a failure...");
        }

        Ok(Some(result))
    }

    pub fn txpool_content(&mut self) -> TxPoolContent {
        let mut pool = self.transaction_pool.write();
        pool.update_with_state(&self.state);
        pool.preview_content()
    }

    pub fn txpool_content_from(&mut self, address: &Address) -> TxPoolContentFrom {
        let mut pool = self.transaction_pool.write();
        pool.update_with_state(&self.state);
        pool.preview_content_from(address)
    }

    pub fn txpool_status(&mut self) -> TxPoolStatus {
        let mut pool = self.transaction_pool.write();
        pool.update_with_state(&self.state);
        pool.preview_status()
    }

    pub fn get_pending_or_queued(
        &self,
        txn: &VerifiedTransaction,
    ) -> Result<Option<PendingOrQueued>> {
        let mut pool = self.transaction_pool.write();
        pool.update_with_state(&self.state);
        pool.get_pending_or_queued(txn)
    }

    /// This is total transactions for the account, including both executed and pending
    pub fn pending_transaction_count(&self, account_address: Address) -> u64 {
        let mut pool = self.transaction_pool.write();
        let account_data = self.state.must_get_account(account_address);
        let current_nonce = account_data.nonce;
        pool.update_with_account(&account_address, &account_data);

        current_nonce + pool.account_pending_transaction_count(&account_address)
    }

    pub fn get_touched_transactions(&self, address: Address) -> Result<Vec<Hash>> {
        if !self.config.enable_ots_indices {
            return Err(anyhow!("Otterscan indices are disabled"));
        }

        self.db.get_touched_transactions(address)
    }

    /// Clear up anything in memory that is no longer required. This is to avoid memory leaks.
    pub fn cleanup_votes(&self) -> Result<()> {
        // Wrt votes, we only care about votes on hashes for the current view or higher
        let finalized_view = self.get_finalized_view()?;
        self.votes.retain(|key, _| {
            if let Ok(Some(block)) = self.get_block(key) {
                // Remove votes for blocks that have been finalized. However, note that the block hashes which are keys
                // into `self.votes` are the parent hash of the (potential) block that is being voted on. Therefore, we
                // subtract one in this condition to ensure there is no chance of removing votes for blocks that still
                // have a chance of being mined. It is possible this is unnecessary, since `self.finalized_view` is
                // already at least 2 views behind the head of the chain, but keeping one extra vote in memory doesn't
                // cost much and does make us more confident that we won't dispose of valid votes.
                if block.view() < finalized_view.saturating_sub(1) {
                    trace!(block_view = %block.view(), block_hash = %key, "cleaning vote");
                    return false;
                }
            } else {
                warn!("Missing block for vote (this shouldn't happen), removing from memory");
                trace!(block_hash = %key, "cleaning vote");
                return false;
            }

            true
        });

        // Wrt new views, we only care about new views for the current view or higher
        let view = self.get_view()?;
        self.new_views.retain(|k, _| *k >= view);
        Ok(())
    }

    /// Process a Vote message
    pub fn vote(&self, peer_id: PeerId, vote: Vote) -> Result<Option<NetworkMessage>> {
        let block_hash = vote.block_hash;
        let block_view = vote.view;
        let current_view = self.get_view()?;
        info!(block_view, current_view, %block_hash, "handling vote from: {:?}", peer_id);

        // if the vote is too old; or too new
        if block_view + 1 < current_view {
            trace!("vote is too old");
            return Ok(None);
        } else if block_view > current_view + 500 {
            // when stuck in exponential backoff, +500 is effectively forever;
            // when active syncing at ~30 blk/s, means that we're > 3 views behind.
            // in either case, that vote is quite meaningless at this point and can be ignored.
            trace!("vote is too early");
            return Ok(None);
        }

        // Verify the signature in the vote matches the public key in the vote. This tells us that the vote was created
        // by the owner of `vote.public_key`, but we don't yet know that a vote from that node is valid. In other
        // words, a malicious node which is not part of the consensus committee may send us a vote and this check will
        // still pass. We later validate that the owner of `vote.public_key` is a valid voter.
        vote.verify()?;

        // Retrieve the actual block this vote is for.
        let Some(block) = self.get_block(&block_hash)? else {
            // We try to limit the size of the buffered votes to prevent memory exhaustion.
            // If the buffered votes exceed the threshold, we purge as many stale votes as possible.
            // While this is not guaranteed to reduce the size of the buffered votes, it is a best-effort attempt.
            if self.buffered_votes.len() > Self::VIEW_BUFFER_THRESHOLD {
                self.buffered_votes.retain(|_hash, votes| {
                    // purge stale votes
                    votes.first().map(|(_p, v)| v.view + 1).unwrap_or_default() >= current_view
                });
            }
            // If we don't have the block yet, we buffer the vote in case we recieve the block later. Note that we
            // don't know the leader of this view without the block, so we may be storing this unnecessarily, however
            // non-malicious nodes should only have sent us this vote if they thought we were the leader.
            let mut buf = self.buffered_votes.entry(block_hash).or_default();
            if buf.len() < MAX_COMMITTEE_SIZE {
                // we only ever need 2/3 of the committee, so it should not exceed this number.
                trace!("vote for unknown block, buffering");
                buf.push((peer_id, vote));
            } else {
                error!(%peer_id, view=%block_view, "vote for unknown block, dropping");
            }
            return Ok(None);
        };

        // if we are not the leader of the round in which the vote counts
        // The vote is in the happy path (?) - so the view is block view + 1
        if !self.are_we_leader_for_view(block_hash, block_view + 1) {
            trace!(
                vote_view = block_view + 1,
                ?block_hash,
                "skipping vote, not the leader"
            );
            return Ok(None);
        }

        let executed_block = BlockHeader {
            number: block.header.number + 1,
            ..Default::default()
        };

        let committee = self
            .state
            .at_root(block.state_root_hash().into())
            .get_stakers(executed_block)?;

        // verify the sender's signature on block_hash
        let Some((index, _)) = committee
            .iter()
            .enumerate()
            .find(|&(_, &v)| v == vote.public_key)
        else {
            warn!("Skipping vote outside of committee");
            return Ok(None);
        };

        let mut votes = self.votes.entry(block_hash).or_default();

        if votes.supermajority_reached {
            info!(
                "(vote) supermajority already reached in this view {}",
                current_view
            );
            return Ok(None);
        }

        // if the vote is new, store it
        if !votes.cosigned[index] {
            votes.signatures.push(vote.signature());
            votes.cosigned.set(index, true);
            // Update state to root pointed by voted block (in meantime it might have changed!)
            let state = self.state.at_root(block.state_root_hash().into());
            let Some(weight) = state.get_stake(vote.public_key, executed_block)? else {
                return Err(anyhow!("vote from validator without stake"));
            };
            votes.cosigned_weight += weight.get();

            let total_weight = self.total_weight(&committee, executed_block);
            votes.supermajority_reached = votes.cosigned_weight * 3 > total_weight * 2;

            trace!(
                cosigned_weight = votes.cosigned_weight,
                supermajority_reached = votes.supermajority_reached,
                total_weight,
                current_view,
                vote_view = block_view + 1,
                "storing vote"
            );
            // if we are already in the round in which the vote counts and have reached supermajority
            if votes.supermajority_reached {
                // We propose new block immediately if it is the first view
                // Otherwise the block will be proposed on timeout
                if current_view == 1 {
                    return self.propose_new_block(Some(&votes));
                }

                self.early_proposal_assemble_at(None)?;

                // It is possible that we have collected votes for a forked block. Do not propose in that case.
                let early_proposal = self.early_proposal.read();
                if let Some((block, _, _, _, _)) = early_proposal.as_ref() {
                    if block.parent_hash() == block_hash {
                        std::mem::drop(early_proposal);
                        return self.ready_for_block_proposal(Some(&votes));
                    }
                }
            }
        }

        // Either way assemble early proposal now if it doesnt already exist
        self.early_proposal_assemble_at(None)?;

        Ok(None)
    }

    /// Finalise self.early_proposal.
    /// This should only run after majority QC or aggQC are available.
    /// It applies the rewards and produces the final Proposal.
    fn early_proposal_finish_at(
        &self,
        mut proposal: Block,
        cumulative_gas_fee: u128,
        votes: Option<&BlockVotes>,
    ) -> Result<Option<Block>> {
        // Retrieve parent block data
        let parent_block = self
            .get_block(&proposal.parent_hash())?
            .context("missing parent block")?;
        let parent_block_hash = parent_block.hash();

        let mut state = self.state.at_root(proposal.state_root_hash().into());

        // Compute the majority QC. If aggQC exists then QC is already set to correct value.
        let (final_qc, committee) = match proposal.agg {
            Some(_) => {
                let committee: Vec<_> = self.committee_for_hash(proposal.header.qc.block_hash)?;
                (proposal.header.qc, committee)
            }
            None => {
                // Check for majority
                let votes = match votes {
                    Some(v) => v,
                    None => match self.votes.get(&parent_block_hash) {
                        Some(v) => &v.clone(),
                        None => {
                            warn!("tried to finalise a proposal without any votes");
                            return Ok(None);
                        }
                    },
                };
                if !votes.supermajority_reached {
                    warn!("tried to finalise a proposal without majority");
                    return Ok(None);
                };
                // Retrieve the previous leader and committee - for rewards
                let committee = self
                    .state
                    .at_root(parent_block.state_root_hash().into())
                    .get_stakers(proposal.header)?;
                (
                    self.qc_from_bits(
                        parent_block_hash,
                        &votes.signatures,
                        votes.cosigned,
                        parent_block.view(),
                    ),
                    committee,
                )
            }
        };
        proposal.header.qc = final_qc;

        self.apply_proposal_to_state(
            &mut state,
            &proposal,
            &parent_block,
            &committee,
            cumulative_gas_fee,
        )?;

        // Finalise the proposal with final QC and state.
        let proposal = Block::from_qc(
            self.secret_key,
            proposal.header.view,
            proposal.header.number,
            // majority QC
            final_qc,
            proposal.agg,
            // post-reward updated state
            state.root_hash()?,
            proposal.header.transactions_root_hash,
            proposal.header.receipts_root_hash,
            proposal.transactions,
            proposal.header.timestamp, // set block timestamp to **start** point of assembly.
            proposal.header.gas_used,
            proposal.header.gas_limit,
        );
        self.receipts_cache
            .lock()
            .set_hash(proposal.header.receipts_root_hash);

        // Return the final proposal
        Ok(Some(proposal))
    }

    /// Assemble self.early_proposal.
    /// This is performed before the majority QC is available.
    /// It does all the needed work but with a dummy QC.
    fn early_proposal_assemble_at(&self, agg: Option<AggregateQc>) -> Result<()> {
        let view = self.get_view()?;
        {
            let early_proposal = self.early_proposal.read();
            if early_proposal.is_some() && early_proposal.as_ref().unwrap().0.view() == view {
                return Ok(());
            }
        }

        let (qc, parent) = match agg {
            // Create dummy QC for now if aggQC not provided
            None => {
                // Start with highest canonical block
                let num = self
                    .db
                    .get_highest_canonical_block_number()?
                    .context("no canonical blocks")?; // get highest canonical block number
                let block = self
                    .get_canonical_block_by_number(num)?
                    .context("missing canonical block")?; // retrieve highest canonical block
                (
                    QuorumCertificate::new_with_identity(block.hash(), block.view()),
                    block,
                )
            }
            Some(ref agg) => {
                let qc = self.get_highest_from_agg(agg)?;
                let parent = self
                    .get_block(&qc.block_hash)?
                    .ok_or_else(|| anyhow!("missing block"))?;
                (qc, parent)
            }
        };

        // This is a partial header of a block that will be proposed with some transactions executed below.
        // It is needed so that each transaction is executed within proper block context (the block it belongs to)
        let executed_block_header = BlockHeader {
            view,
            number: parent.header.number + 1,
            timestamp: SystemTime::max(SystemTime::now(), parent.timestamp()), // block timestamp at **start** of assembly, not end.
            gas_limit: self.config.consensus.eth_block_gas_limit,
            ..BlockHeader::default()
        };

        debug!(
            "assemble early proposal view {} block number {}",
            executed_block_header.view, executed_block_header.number
        );

        // Ensure sane state
        let mut state = self.state.clone();
        if state.root_hash()? != parent.state_root_hash() {
            warn!(
                "state root hash mismatch, expected: {:?}, actual: {:?}",
                parent.state_root_hash(),
                state.root_hash()?
            );
        }

        // Clear internal receipt cache.
        // Since this is a speed enhancement, we're ignoring scenarios where the receipts cache may hold receipts for more than one proposal.
        self.receipts_cache.lock().clear();

        // Internal states
        let mut receipts_trie = EthTrie::new(Arc::new(MemoryDB::new(true)));
        let mut transactions_trie: EthTrie<MemoryDB> = EthTrie::new(Arc::new(MemoryDB::new(true)));
        let applied_txs = Vec::<VerifiedTransaction>::new();

        // Generate the early proposal
        // Some critical parts are dummy/missing:
        // a. Majority QC is missing
        // b. Rewards have not been applied
        // c. transactions have not been added
        let proposal = Block::from_qc(
            self.secret_key,
            executed_block_header.view,
            executed_block_header.number,
            qc,
            agg,
            parent.state_root_hash(), // late state before transactions or rewards are applied
            Hash(transactions_trie.root_hash()?.into()),
            Hash(receipts_trie.root_hash()?.into()),
            vec![],
            executed_block_header.timestamp,
            EvmGas(0),
            executed_block_header.gas_limit,
        );

        let mut early_proposal = self.early_proposal.write();
        *early_proposal = Some((proposal, applied_txs, transactions_trie, receipts_trie, 0));
        self.early_proposal_apply_transactions(self.transaction_pool.write(), early_proposal)?;
        Ok(())
    }

    /// Updates self.early_proposal data (proposal, applied_transactions, transactions_trie, receipts_trie) to include any transactions in the mempool
    fn early_proposal_apply_transactions(
        &self,
        mut pool: RwLockWriteGuard<TransactionPool>,
        mut early_proposal: RwLockWriteGuard<Option<EarlyProposal>>,
    ) -> Result<()> {
        if early_proposal.is_none() {
            error!("could not apply transactions to early_proposal because it does not exist");
            return Ok(());
        }

        let mut state = self.state.clone();

        let proposal = early_proposal.as_ref().unwrap().0.clone();

        // Use state root hash of current early proposal
        state.set_to_root(proposal.state_root_hash().into());
        // Internal states
        let mut threshold_size = Self::PROP_SIZE_THRESHOLD;
        let mut gas_left = proposal.header.gas_limit - proposal.header.gas_used;
        let mut tx_index_in_block = proposal.transactions.len();

        // update the pool with the current state
        pool.update_with_state(&state);

        // Assemble new block with whatever is in the mempool
        while let Some(tx) = pool.pop_best_if(|txn| {
            // First - check if we have time left to process txns and give enough time for block propagation
            let (_, milliseconds_remaining_of_block_time, _) =
                self.get_consensus_timeout_params().unwrap();

            if milliseconds_remaining_of_block_time == 0 {
                debug!(
                    "stopped adding txs to block number {} because block time is reached",
                    proposal.header.number,
                );
                return false;
            }

            if gas_left < txn.tx.gas_limit() {
                debug!(?gas_left, gas_limit = ?txn.tx.gas_limit(), "block out of space");
                return false;
            }

            if txn.encoded_size() > threshold_size {
                debug!("ran out of size");
                return false;
            }

            true
        }) {
            let tx = tx.clone();

            // Apply specific txn
            let mut inspector = TouchedAddressInspector::default();
            let result = Self::apply_transaction_at(
                &mut state,
                tx.clone(),
                proposal.header,
                &mut inspector,
                self.config.enable_ots_indices,
            )?;
            // Update the pool with the new state
            pool.update_with_state(&state);

            // Skip transactions whose execution resulted in an error and drop them.
            let Some(result) = result else {
                warn!("Dropping failed transaction: {:?}", tx.hash);
                continue;
            };

            // Reduce balance size threshold
            threshold_size -= tx.encoded_size();

            // Reduce remaining gas in this block
            gas_left = gas_left
                .checked_sub(result.gas_used())
                .ok_or_else(|| anyhow!("gas_used > gas_limit"))?;

            let gas_fee = result.gas_used().0 as u128 * tx.tx.gas_price_per_evm_gas();

            // Grab and update early_proposal data in own scope to avoid multiple mutable references to self
            {
                let (proposal, applied_txs, transactions_trie, receipts_trie, cumulative_gas_fee) =
                    early_proposal.as_mut().unwrap();

                *cumulative_gas_fee += gas_fee;
                transactions_trie.insert(tx.hash.as_bytes(), tx.hash.as_bytes())?;

                let receipt = Self::create_txn_receipt(
                    result,
                    tx.hash,
                    tx_index_in_block,
                    self.config.consensus.eth_block_gas_limit - gas_left,
                );

                let receipt_hash = receipt.compute_hash();
                debug!(
                    "During assembly in view: {}, transaction with hash: {:?} produced receipt: {:?}, receipt hash: {:?}",
                    proposal.header.view, tx.hash, receipt, receipt_hash
                );
                receipts_trie.insert(receipt_hash.as_bytes(), receipt_hash.as_bytes())?;

                // Forwarding cache
                let addresses = inspector.touched.into_iter().collect_vec();
                self.receipts_cache
                    .lock()
                    .insert(tx.hash, receipt, addresses);

                tx_index_in_block += 1;
                applied_txs.push(tx);
            }
        }
        std::mem::drop(pool);

        let (_, applied_txs, _, _, _) = early_proposal.as_ref().unwrap();
        self.db.with_sqlite_tx(|sqlite_tx| {
            for tx in applied_txs {
                self.db
                    .insert_transaction_with_db_tx(sqlite_tx, &tx.hash, tx)?;
            }
            Ok(())
        })?;

        // Grab and update early_proposal data in own scope to avoid multiple mutable references to Self
        {
            let (proposal, applied_txs, transactions_trie, receipts_trie, _) =
                early_proposal.as_mut().unwrap();

            let applied_transaction_hashes = applied_txs.iter().map(|tx| tx.hash).collect_vec();
            trace!(
                "applied {} transactions to early block for view {}",
                tx_index_in_block - proposal.transactions.len(),
                proposal.header.view
            );

            // Update proposal with transactions added
            proposal.header.state_root_hash = state.root_hash()?;
            proposal.header.transactions_root_hash = Hash(transactions_trie.root_hash()?.into());
            proposal.header.receipts_root_hash = Hash(receipts_trie.root_hash()?.into());
            proposal.transactions = applied_transaction_hashes;
            proposal.header.gas_used = proposal.header.gas_limit - gas_left;
        }

        // as a future improvement, process the proposal before broadcasting it
        Ok(())
    }

    /// Clear early_proposal and add it's transactions back to pool.
    /// This function should be called only when something has gone wrong.
    fn early_proposal_clear(&self) -> Result<()> {
        if let Some((_, txns, _, _, _)) = self.early_proposal.write().take() {
            let mut pool = self.transaction_pool.write();
            pool.update_with_state(&self.state);
            for txn in txns.into_iter().rev() {
                let account = self.state.get_account(txn.signer)?;
                let _added = pool.insert_transaction_forced(txn, &account, false);
            }
            warn!("early_proposal cleared. This is a consequence of some incorrect behaviour.");
        }
        Ok(())
    }

    /// Called when node has become leader and is ready to publish a Proposal.
    /// Either propose now or set timeout to allow for txs to come in.
    fn ready_for_block_proposal(
        &self,
        votes: Option<&BlockVotes>,
    ) -> Result<Option<NetworkMessage>> {
        // Check if there's enough time to wait on a timeout and then propagate an empty block in the network before other participants trigger NewView
        let (milliseconds_since_last_view_change, milliseconds_remaining_of_block_time, _) =
            self.get_consensus_timeout_params()?;

        if milliseconds_remaining_of_block_time == 0 {
            return self.propose_new_block(votes);
        }

        // Reset the timeout and wake up again once it has been at least `block_time` since
        // the last view change. At this point we should be ready to produce a new block.
        self.create_next_block_on_timeout
            .store(true, Ordering::SeqCst);
        self.reset_timeout.send(
            self.config
                .consensus
                .block_time
                .saturating_sub(Duration::from_millis(milliseconds_since_last_view_change)),
        )?;
        trace!(
            "will propose new proposal on timeout for view {}",
            self.get_view()?
        );

        Ok(None)
    }

    /// Assembles a Pending block: the block which the node _would_ propose if they were leader.
    fn assemble_pending_block_at(&self, state: &mut State) -> Result<Option<Block>> {
        // Start with highest canonical block
        let num = self
            .db
            .get_highest_canonical_block_number()?
            .context("no canonical blocks")?; // get highest canonical block number
        let block = self
            .get_canonical_block_by_number(num)?
            .context("missing canonical block")?; // retrieve highest canonical block

        // Generate early QC
        let early_qc = QuorumCertificate::new_with_identity(block.hash(), block.view());
        let parent = self
            .get_block(&early_qc.block_hash)?
            .context("missing parent block")?;

        // Set state to that of parent
        state.set_to_root(block.state_root_hash().into());

        // Internal states
        let mut threshold_size = Self::PROP_SIZE_THRESHOLD;
        let mut gas_left = self.config.consensus.eth_block_gas_limit;
        let mut receipts_trie = EthTrie::new(Arc::new(MemoryDB::new(true)));
        let mut transactions_trie = EthTrie::new(Arc::new(MemoryDB::new(true)));
        let mut tx_index_in_block = 0;
        let mut applied_transaction_hashes = Vec::<Hash>::new();

        // This is a partial header of a block that will be proposed with some transactions executed below.
        // It is needed so that each transaction is executed within proper block context (the block it belongs to)
        let executed_block_header = BlockHeader {
            view: self.get_view()?,
            number: parent.header.number + 1,
            timestamp: SystemTime::max(SystemTime::now(), parent.header.timestamp),
            gas_limit: gas_left,
            ..BlockHeader::default()
        };

        // Clone the pool
        // This isn't perfect performance-wise, but it does mean that we aren't dealing with transactions that don't fit into the block
        let mut cloned_pool = self.transaction_pool.read().clone();
        cloned_pool.update_with_state(state);

        while let Some(txn) = cloned_pool.pop_best_if(|txn| {
            // First - check if we have time left to process txns and give enough time for block propagation
            let (_, milliseconds_remaining_of_block_time, _) =
                self.get_consensus_timeout_params().unwrap();

            if milliseconds_remaining_of_block_time == 0 {
                return false;
            }

            if gas_left < txn.tx.gas_limit() {
                debug!(?gas_left, gas_limit = ?txn.tx.gas_limit(), "block out of space");
                return false;
            }

            if txn.encoded_size() > threshold_size {
                debug!("ran out of size");
                return false;
            }

            true
        }) {
            // Apply specific txn
            let result = Self::apply_transaction_at(
                state,
                txn.clone(),
                executed_block_header,
                inspector::noop(),
                false,
            )?;
            self.db.insert_transaction(&txn.hash, &txn)?;

            // Skip transactions whose execution resulted in an error
            let Some(result) = result else {
                continue;
            };

            // Reduce remaining gas in this block
            gas_left = gas_left
                .checked_sub(result.gas_used())
                .ok_or_else(|| anyhow!("gas_used > gas_limit"))?;

            // Reduce balance size threshold
            threshold_size -= txn.encoded_size();

            // Do necessary work to assemble the transaction
            transactions_trie.insert(txn.hash.as_bytes(), txn.hash.as_bytes())?;

            let receipt = Self::create_txn_receipt(
                result,
                txn.hash,
                tx_index_in_block,
                self.config.consensus.eth_block_gas_limit - gas_left,
            );
            let receipt_hash = receipt.compute_hash();
            receipts_trie.insert(receipt_hash.as_bytes(), receipt_hash.as_bytes())?;

            tx_index_in_block += 1;
            applied_transaction_hashes.push(txn.hash);
        }

        // Generate the pending proposal, with dummy data
        let proposal = Block::from_qc(
            self.secret_key,
            executed_block_header.view,
            executed_block_header.number,
            early_qc, // dummy QC for early proposal
            None,
            state.root_hash()?, // late state before rewards are applied
            Hash(transactions_trie.root_hash()?.into()),
            Hash(receipts_trie.root_hash()?.into()),
            applied_transaction_hashes,
            executed_block_header.timestamp,
            executed_block_header.gas_limit - gas_left,
            executed_block_header.gas_limit,
        );

        // Return the pending block
        Ok(Some(proposal))
    }

    /// Produces the Proposal block by taking and finalising early_proposal.
    /// It must return a final Proposal with correct QC, regardless of whether it is empty or not.
    fn propose_new_block(&self, votes: Option<&BlockVotes>) -> Result<Option<NetworkMessage>> {
        // We expect early_proposal to exist already but try create incase it doesn't
        self.early_proposal_assemble_at(None)?;
        let mut early_proposal = self.early_proposal.write();
        let (pending_block, applied_txs, _, _, cumulative_gas_fee) = early_proposal.take().unwrap(); // safe to unwrap due to check above
        std::mem::drop(early_proposal);

        // intershard transactions are not meant to be broadcast
        let (mut broadcasted_transactions, opaque_transactions): (Vec<_>, Vec<_>) = applied_txs
            .clone()
            .into_iter()
            .partition(|tx| !matches!(tx.tx, SignedTransaction::Intershard { .. }));
        // however, for the transactions that we are NOT broadcasting, we re-insert
        // them into the pool - this is because upon broadcasting the proposal, we will
        // have to re-execute it ourselves (in order to vote on it) and thus will
        // need those transactions again
        {
            let mut pool = self.transaction_pool.write();
            for tx in opaque_transactions {
                let account = self.state.get_account(tx.signer)?;
                pool.update_with_account(&tx.signer, &account);
                pool.insert_transaction(tx, &account, true);
            }
        }

        // finalise the proposal
        let Some(final_block) =
            self.early_proposal_finish_at(pending_block, cumulative_gas_fee, votes)?
        else {
            // Do not Propose.
            // Recover the proposed transactions into the pool.
            let mut pool = self.transaction_pool.write();
            while let Some(txn) = broadcasted_transactions.pop() {
                let account = self.state.get_account(txn.signer)?;
                pool.update_with_account(&txn.signer, &account);
                let added = pool.insert_transaction(txn, &account, false);
                assert!(added.was_added())
            }
            return Ok(None);
        };

        info!(proposal_hash = ?final_block.hash(), ?final_block.header.view, ?final_block.header.number, txns = final_block.transactions.len(), "######### proposing block");

        Ok(Some((
            None,
            ExternalMessage::Proposal(Proposal::from_parts(final_block, broadcasted_transactions)),
        )))
    }

    /// Insert transaction and add to transaction pool.
    pub fn handle_new_transactions(
        &self,
        verified_transactions: Vec<VerifiedTransaction>,
        from_broadcast: bool,
    ) -> Result<Vec<TxAddResult>> {
        let mut inserted = Vec::with_capacity(verified_transactions.len());
        let mut pool = self.transaction_pool.write();
        for txn in verified_transactions {
            info!(?txn, "seen new txn");
            inserted.push(self.new_transaction(txn, from_broadcast, &mut pool)?);
        }
        Ok(inserted)
    }

    pub fn try_early_proposal_after_txn_batch(&self) -> Result<()> {
        if self.create_next_block_on_timeout.load(Ordering::SeqCst) {
            let early_proposal = self.early_proposal.write();
            if early_proposal.is_some() {
                let pool = self.transaction_pool.write();
                if pool.has_txn_ready() {
                    trace!(
                        "add transaction to early proposal {}",
                        early_proposal.as_ref().unwrap().0.header.view
                    );

                    self.early_proposal_apply_transactions(pool, early_proposal)?;
                }
            }
        }
        Ok(())
    }

    /// Provides a preview of the early proposal.
    pub fn get_pending_block(&self) -> Result<Option<Block>> {
        let mut state = self.state.clone();

        let Some(pending_block) = self.assemble_pending_block_at(&mut state)? else {
            return Ok(None);
        };

        Ok(Some(pending_block))
    }

    fn are_we_leader_for_view(&self, parent_hash: Hash, view: u64) -> bool {
        match self.leader_for_view(parent_hash, view) {
            Some(leader) => leader == self.public_key(),
            None => false,
        }
    }

    fn leader_for_view(&self, parent_hash: Hash, view: u64) -> Option<NodePublicKey> {
        if let Ok(Some(parent)) = self.get_block(&parent_hash) {
            let leader = self.leader_at_block(&parent, view).unwrap();
            Some(leader.public_key)
        } else {
            if view > 1 {
                warn!(
                    "parent not found while determining leader for view {}",
                    view
                );
                return None;
            }
            let head_block = self.head_block();
            let leader = self.leader_at_block(&head_block, view).unwrap();
            Some(leader.public_key)
        }
    }

    fn committee_for_hash(&self, parent_hash: Hash) -> Result<Vec<NodePublicKey>> {
        let Ok(Some(parent)) = self.get_block(&parent_hash) else {
            // tracing::error!("parent block not found: {:?}", parent_hash);
            return Ok(Vec::new()); // return an empty vector instead of Err for graceful app-level error-handling
        };

        let parent_root_hash = parent.state_root_hash();

        let state = self.state.at_root(parent_root_hash.into());
        let executed_block = BlockHeader {
            number: parent.header.number + 1,
            ..Default::default()
        };

        let committee = state.get_stakers(executed_block)?;

        Ok(committee)
    }

    /// Process a NewView message
    pub fn new_view(&mut self, from: PeerId, new_view: NewView) -> Result<Option<NetworkMessage>> {
        info!(
            "Received new view for view: {:?} from: {:?}",
            new_view.view, from
        );

        if self.get_block(&new_view.qc.block_hash)?.is_none() {
            trace!("high_qc block does not exist for NewView. Attempting to fetch block via sync");
            self.sync.sync_from_probe()?;
            return Ok(None);
        }

        // Get the committee for the qc hash (should be highest?) for this view
        let committee: Vec<_> = self.committee_for_hash(new_view.qc.block_hash)?;
        // verify the sender's signature on the block hash
        let Some((index, public_key)) = committee
            .iter()
            .enumerate()
            .find(|&(_, &public_key)| public_key == new_view.public_key)
        else {
            debug!(
                "ignoring new view from unknown node (buffer?) - committee size is : {:?} hash is: {:?} high hash is: {:?}",
                committee.len(),
                new_view.qc.block_hash,
                self.high_qc.block_hash
            );
            return Ok(None);
        };

        new_view.verify(*public_key)?;

        // Update our high QC and view, even if we are not the leader of this view.
        self.update_high_qc_and_view(false, new_view.qc)?;

        let mut current_view = self.get_view()?;
        // if the vote is too old and does not count anymore
        if new_view.view < current_view {
            trace!(
                new_view.view,
                "Received a NewView which is too old for us, discarding. Our view is: {} and new_view is: {}",
                current_view,
                new_view.view
            );
            return Ok(None);
        }

        // The leader for this view should be chosen according to the parent of the highest QC
        // What happens when there are multiple QCs with different parents?
        // if we are not the leader of the round in which the vote counts
        if !self.are_we_leader_for_view(new_view.qc.block_hash, new_view.view) {
            trace!(new_view.view, "skipping new view, not the leader");
            return Ok(None);
        }

        let mut new_view_vote =
            self.new_views
                .entry(new_view.view)
                .or_insert_with(|| NewViewVote {
                    signatures: Vec::new(),
                    cosigned: bitarr![u8, Msb0; 0; MAX_COMMITTEE_SIZE],
                    cosigned_weight: 0,
                    qcs: BTreeMap::new(),
                });

        let Ok(Some(parent)) = self.get_block(&new_view.qc.block_hash) else {
            return Err(anyhow!(
                "parent block not found: {:?}",
                new_view.qc.block_hash
            ));
        };
        let executed_block = BlockHeader {
            number: parent.header.number + 1,
            ..Default::default()
        };

        let mut supermajority = false;

        // if the vote is new, store it
        if !new_view_vote.cosigned[index] {
            new_view_vote.cosigned.set(index, true);
            new_view_vote.signatures.push(new_view.signature);

            let Ok(Some(parent)) = self.get_block(&new_view.qc.block_hash) else {
                return Err(anyhow!(
                    "parent block not found: {:?}",
                    new_view.qc.block_hash
                ));
            };
            // Update state to root pointed by voted block (in meantime it might have changed!)
            self.state.set_to_root(parent.state_root_hash().into());
            let Some(weight) = self.state.get_stake(new_view.public_key, executed_block)? else {
                return Err(anyhow!("vote from validator without stake"));
            };
            new_view_vote.cosigned_weight += weight.get();
            new_view_vote.qcs.insert(index, new_view.qc);

            supermajority = new_view_vote.cosigned_weight * 3
                > self.total_weight(&committee, executed_block) * 2;

            let num_signers = new_view_vote.signatures.len();

            trace!(
                num_signers,
                cosigned_weight = new_view_vote.cosigned_weight,
                supermajority,
                current_view,
                new_view.view,
                "storing vote for new view"
            );
            if supermajority {
                if current_view < new_view.view {
                    info!(
                        "forcibly updating view to {} as majority is ahead",
                        new_view.view
                    );
                    current_view = new_view.view;
                    self.set_view(current_view, false)?;
                }

                // if we are already in the round in which the vote counts and have reached supermajority we can propose a block
                if new_view.view == current_view {
                    // todo: the aggregate qc is an aggregated signature on the qcs, view and validator index which can be batch verified
                    let agg = self.aggregate_qc_from_indexes(
                        new_view.view,
                        &new_view_vote.qcs,
                        &new_view_vote.signatures,
                        new_view_vote.cosigned,
                    )?;

                    info!(
                        view = current_view,
                        "######### creating proposal block from new view"
                    );

                    // We now have a valid aggQC so can create early_block with it
                    self.early_proposal_assemble_at(Some(agg))?;

                    // as a future improvement, process the proposal before broadcasting it
                    return self.ready_for_block_proposal(None);

                    // we don't want to keep the collected votes if we proposed a new block
                    // we should remove the collected votes if we couldn't reach supermajority within the view
                }
            }
        }
        if supermajority {
            // Cleanup
            self.new_views.remove(&new_view.view);
        }

        Ok(None)
    }

    /// Returns (flag, outcome).
    /// flag is true if the transaction was newly added to the pool - ie. if it validated correctly and has not been seen before.
    pub fn new_transaction(
        &self,
        txn: VerifiedTransaction,
        from_broadcast: bool,
        pool: &mut RwLockWriteGuard<TransactionPool>,
    ) -> Result<TxAddResult> {
        if self.db.contains_transaction(&txn.hash)? {
            debug!("Transaction {:?} already in mempool", txn.hash);
            return Ok(TxAddResult::Duplicate(txn.hash));
        }

        // Perform insertion under early state, if available
        let early_account = match self.early_proposal.read().as_ref() {
            Some((block, _, _, _, _)) => {
                let state = self.state.at_root(block.state_root_hash().into());
                state.get_account(txn.signer)?
            }
            _ => self.state.get_account(txn.signer)?,
        };

        let eth_chain_id = self.config.eth_chain_id;

        let validation_result = txn.tx.validate(
            &early_account,
            self.config.consensus.eth_block_gas_limit,
            eth_chain_id,
        )?;
        if !validation_result.is_ok() {
            debug!(
                "Unable to validate txn with hash: {:?}, from: {:?}, nonce: {:?} : {:?}",
                txn.hash,
                txn.signer,
                txn.tx.nonce(),
                validation_result,
            );
            return Ok(TxAddResult::ValidationFailed(validation_result));
        }

        let txn_hash = txn.hash;

        let insert_result = pool.insert_transaction(txn.clone(), &early_account, from_broadcast);
        if insert_result.was_added() {
            let _ = self.new_transaction_hashes.send(txn_hash);

            // Avoid cloning the transaction if there aren't any subscriptions to send it to.
            if self.new_transactions.receiver_count() != 0 {
                let _ = self.new_transactions.send(txn.clone());
            }
        }
        Ok(insert_result)
    }

    pub fn get_transaction_by_hash(&self, hash: Hash) -> Result<Option<VerifiedTransaction>> {
        Ok(match self.db.get_transaction(&hash)? {
            Some(tx) => Some(tx),
            None => self.transaction_pool.read().get_transaction(&hash).cloned(),
        })
    }

    pub fn get_transaction_receipt(&self, hash: &Hash) -> Result<Option<TransactionReceipt>> {
        let Some(block_hash) = self.db.get_block_hash_reverse_index(hash)? else {
            return Ok(None);
        };
        let block_receipts = self.db.get_transaction_receipts_in_block(&block_hash)?;
        Ok(block_receipts
            .into_iter()
            .find(|receipt| receipt.tx_hash == *hash))
    }

    fn update_high_qc_and_view(
        &mut self,
        from_agg: bool,
        new_high_qc: QuorumCertificate,
    ) -> Result<()> {
        let view = self.get_view()?;
        let Some(new_high_qc_block) = self.db.get_block_by_hash(&new_high_qc.block_hash)? else {
            // We don't set high_qc to a qc if we don't have its block.
            warn!("Recieved potential high QC but didn't have the corresponding block");
            return Ok(());
        };

        let new_high_qc_view = new_high_qc_block.view();

        if self.high_qc.block_hash == Hash::ZERO {
            trace!(
                "received high qc, self high_qc is currently uninitialized, setting to the new one."
            );
            self.db.set_high_qc(new_high_qc)?;
            self.high_qc = new_high_qc;
        } else {
            let current_high_qc_view = self
                .get_block(&self.high_qc.block_hash)?
                .ok_or_else(|| {
                    anyhow!("missing block corresponding to our high qc - this should never happen")
                })?
                .view();
            // If `from_agg` then we always release the lock because the supermajority has a different high_qc.
            if from_agg || new_high_qc_view > current_high_qc_view {
                trace!(
                    new_high_qc_view,
                    current_high_qc_view,
                    current_view = view,
                    "updating high qc"
                );
                self.db.set_high_qc(new_high_qc)?;
                self.high_qc = new_high_qc;
                if new_high_qc_view >= view {
                    self.set_view(new_high_qc_view + 1, false)?;
                }
            }
        }

        Ok(())
    }

    fn aggregate_qc_from_indexes(
        &self,
        view: u64,
        qcs: &BTreeMap<usize, QuorumCertificate>,
        signatures: &[BlsSignature],
        cosigned: BitArray,
    ) -> Result<AggregateQc> {
        assert_eq!(qcs.len(), signatures.len());

        Ok(AggregateQc {
            signature: BlsSignature::aggregate(signatures)?,
            cosigned,
            view,
            // Because qcs is a map from index to qc, this will
            // end up as a list in ascending order of index, which
            // is what we want to correspond with the way
            // batch_verify_agg_signature() will attempt to verify
            // them.
            qcs: qcs.values().cloned().collect::<Vec<QuorumCertificate>>(),
        })
    }

    fn qc_from_bits(
        &self,
        block_hash: Hash,
        signatures: &[BlsSignature],
        cosigned: BitArray,
        view: u64,
    ) -> QuorumCertificate {
        // we've already verified the signatures upon receipt of the responses so there's no need to do it again
        QuorumCertificate::new(signatures, cosigned, block_hash, view)
    }

    fn block_extends_from(&self, block: &Block, ancestor: &Block) -> Result<bool> {
        // todo: the block extends from another block through a chain of parent hashes and not qcs
        // make ticket for this
        let mut current = block.clone();
        while current.view() > ancestor.view() {
            let Some(next) = self.get_block(&current.parent_hash())? else {
                warn!(
                    "Missing block when traversing to find ancestor! Current parent hash: {:?} {:?}",
                    current.parent_hash(),
                    current
                );
                return Err(MissingBlockError::from(current.parent_hash()).into());
            };
            current = next;
        }

        Ok(current.view() == 0 || current.hash() == ancestor.hash())
    }

    fn check_safe_block(&mut self, proposal: &Block) -> Result<bool> {
        let Some(qc_block) = self.get_block(&proposal.parent_hash())? else {
            trace!("could not get qc for block: {}", proposal.parent_hash());
            return Ok(false);
        };
        match proposal.agg {
            // we check elsewhere that qc is the highest among the qcs in the agg
            Some(_) => match self.block_extends_from(proposal, &qc_block) {
                Ok(true) => {
                    self.check_and_commit(proposal)?;
                    Ok(true)
                }
                Ok(false) => {
                    trace!("block does not extend from parent");
                    Ok(false)
                }
                Err(e) => {
                    trace!(?e, "error checking block extension");
                    Ok(false)
                }
            },
            None => {
                if proposal.view() == 0 || proposal.view() == qc_block.view() + 1 {
                    self.check_and_commit(proposal)?;
                    Ok(true)
                } else {
                    trace!(
                        "block does not extend from parent, {} != {} + 1",
                        proposal.view(),
                        qc_block.view()
                    );
                    Ok(false)
                }
            }
        }
    }

    /// Check if a new proposal allows an older block to become finalized.
    /// Errors iff the proposal's parent is not known.
    fn check_and_commit(&mut self, proposal: &Block) -> Result<()> {
        // The condition for a block to be finalized is if there is a direct two-chain. From the paper:
        // Once a replica is convinced, it checks
        // if a two-chain is formed over the top of the parent of the
        // block pointed by the highQC (the first chain in the two-chain
        // formed has to be a one-direct chain in case of pipelined Fast-
        // HotStuff). Then a replica can safely commit the parent of the
        // block pointed by the highQC.

        let Some(qc_block) = self.get_block(&proposal.parent_hash())? else {
            warn!("missing qc block when checking whether to finalize!");
            return Err(MissingBlockError::from(proposal.parent_hash()).into());
        };

        // If we don't have the parent (e.g. genesis, or pruned node), we can't finalize, so just exit
        let Some(qc_parent) = self.get_block(&qc_block.parent_hash())? else {
            warn!("missing qc parent block when checking whether to finalize!");
            return Ok(());
        };

        // If we have a one-direct chain, we can finalize the parent regardless of the proposal's view number
        if qc_parent.view() + 1 == qc_block.view() {
            self.finalize_block(qc_parent)?;
        } else {
            warn!(
                "Cannot finalize block {} with view {} and number {} because of child {} with view {} and number {}",
                qc_parent.hash(),
                qc_parent.view(),
                qc_parent.number(),
                qc_block.hash(),
                qc_block.view(),
                qc_block.number()
            );
        }

        Ok(())
    }

    /// Saves the finalized tip view, and runs all hooks for the newly finalized block
    fn finalize_block(&mut self, block: Block) -> Result<()> {
        trace!(
            "Finalizing block {} at view {} num {}",
            block.hash(),
            block.view(),
            block.number()
        );
        self.set_finalized_view(block.view())?;

        let receipts = self.db.get_transaction_receipts_in_block(&block.hash())?;

        for (destination_shard, intershard_call) in blockhooks::get_cross_shard_messages(&receipts)?
        {
            self.message_sender.send_message_to_shard(
                destination_shard,
                InternalMessage::IntershardCall(intershard_call),
            )?;
        }

        if self.config.consensus.is_main {
            // Main shard will join all new shards
            for new_shard_id in blockhooks::get_launch_shard_messages(&receipts)? {
                self.message_sender
                    .send_message_to_coordinator(InternalMessage::LaunchShard(new_shard_id))?;
            }

            // Main shard also hosts the shard registry, so will be notified of newly established
            // links. Notify corresponding shard nodes of said links, if any
            for (from, to) in blockhooks::get_link_creation_messages(&receipts)? {
                self.message_sender
                    .send_message_to_shard(to, InternalMessage::LaunchLink(from))?;
            }
        }

        if self.block_is_first_in_epoch(block.number())
            && !block.is_genesis()
            && self.config.do_checkpoints
            && self.epoch_is_checkpoint(self.epoch_number(block.number()))
        {
            if let Some(checkpoint_path) = self.db.get_checkpoint_dir()? {
                let parent = self
                    .db
                    .get_block_by_hash(&block.parent_hash())?
                    .ok_or(anyhow!(
                        "Trying to checkpoint block, but we don't have its parent"
                    ))?;
                let transactions: Vec<SignedTransaction> = block
                    .transactions
                    .iter()
                    .map(|txn_hash| {
                        let tx = self.db.get_transaction(txn_hash)?.ok_or(anyhow!(
                            "failed to fetch transaction {} for checkpoint parent {}",
                            txn_hash,
                            parent.hash()
                        ))?;
                        Ok::<_, anyhow::Error>(tx.tx)
                    })
                    .collect::<Result<Vec<SignedTransaction>>>()?;

                self.message_sender.send_message_to_coordinator(
                    InternalMessage::ExportBlockCheckpoint(
                        Box::new(block),
                        transactions,
                        Box::new(parent),
                        self.db.state_trie()?.clone(),
                        checkpoint_path,
                    ),
                )?;
            }
        }

        Ok(())
    }

    /// Trigger a checkpoint, for debugging.
    /// Returns (file_name, block_hash). At some time after you call this function, hopefully a checkpoint will end up in the file
    pub fn checkpoint_at(&self, block_number: u64) -> Result<(String, String)> {
        let block = self
            .get_canonical_block_by_number(block_number)?
            .ok_or(anyhow!("No such block number {block_number}"))?;
        let parent = self
            .db
            .get_block_by_hash(&block.parent_hash())?
            .ok_or(anyhow!(
                "Trying to checkpoint block, but we don't have its parent"
            ))?;
        let transactions: Vec<SignedTransaction> = block
            .transactions
            .iter()
            .map(|txn_hash| {
                let tx = self.db.get_transaction(txn_hash)?.ok_or(anyhow!(
                    "failed to fetch transaction {} for checkpoint parent {}",
                    txn_hash,
                    parent.hash()
                ))?;
                Ok::<_, anyhow::Error>(tx.tx)
            })
            .collect::<Result<Vec<SignedTransaction>>>()?;
        let checkpoint_dir = self
            .db
            .get_checkpoint_dir()?
            .ok_or(anyhow!("No checkpoint directory configured"))?;
        let file_name = db::get_checkpoint_filename(checkpoint_dir.clone(), &block)?;
        let hash = block.hash();
        self.message_sender
            .send_message_to_coordinator(InternalMessage::ExportBlockCheckpoint(
                Box::new(block),
                transactions,
                Box::new(parent),
                self.db.state_trie()?.clone(),
                checkpoint_dir,
            ))?;
        Ok((file_name.display().to_string(), hash.to_string()))
    }

    /// Check the validity of a block. Returns `Err(_, true)` if this block could become valid in the future and
    /// `Err(_, false)` if this block could never be valid.
    fn check_block(&self, block: &Block, during_sync: bool) -> Result<()> {
        block.verify_hash()?;

        if block.view() == 0 {
            // We only check a block if we receive it from an external source. We obviously already have the genesis
            // block, so we aren't ever expecting to receive it.
            return Err(anyhow!("tried to check genesis block"));
        }

        let Some(parent) = self.get_block(&block.parent_hash())? else {
            warn!(
                "Missing parent block while trying to check validity of block number {}",
                block.number()
            );
            return Err(MissingBlockError::from(block.parent_hash()).into());
        };

        let finalized_view = self.get_finalized_view()?;
        let Some(finalized_block) = self.get_block_by_view(finalized_view)? else {
            return Err(MissingBlockError::from(finalized_view).into());
        };
        if block.view() < finalized_block.view() {
            return Err(anyhow!(
                "block is too old: view is {} but we have finalized {}",
                block.view(),
                finalized_block.view()
            ));
        }

        // Derive the proposer from the block's view
        let Some(proposer) = self.leader_at_block(&parent, block.view()) else {
            return Err(anyhow!(
                "Failed to find leader. Block number {}, Parent number {}",
                block.number(),
                parent.number(),
            ));
        };

        // Verify the proposer's signature on the block
        let verified = proposer
            .public_key
            .verify(block.hash().as_bytes(), block.signature());

        let committee = self
            .state
            .at_root(parent.state_root_hash().into())
            .get_stakers(block.header)?;

        if verified.is_err() {
            info!(?block, "Unable to verify block = ");
            return Err(anyhow!(
                "invalid block signature found! block hash: {:?} block view: {:?} committee len {:?}",
                block.hash(),
                block.view(),
                committee.len()
            ));
        }

        // Check if the co-signers of the block's QC represent the supermajority.
        self.check_quorum_in_bits(
            &block.header.qc.cosigned,
            &committee,
            parent.state_root_hash(),
            block,
        )?;

        // Verify the block's QC signature - note the parent should be the committee the QC
        // was signed over.
        self.verify_qc_signature(&block.header.qc, committee.clone())?;
        if let Some(agg) = &block.agg {
            // Check if the signers of the block's aggregate QC represent the supermajority
            self.check_quorum_in_indices(
                &agg.cosigned,
                &committee,
                parent.state_root_hash(),
                block,
            )?;
            // Verify the aggregate QC's signature
            self.batch_verify_agg_signature(agg, &committee)?;
        }

        // Retrieve the highest among the aggregated QCs and check if it equals the block's QC.
        let block_high_qc = self.get_high_qc_from_block(block)?;
        let Some(block_high_qc_block) = self.get_block(&block_high_qc.block_hash)? else {
            warn!("missing finalized block");
            return Err(MissingBlockError::from(block_high_qc.block_hash).into());
        };
        // Prevent the creation of forks from the already committed chain
        if block_high_qc_block.view() < finalized_block.view() {
            warn!(
                "invalid block - high QC view is {} while finalized is {}. Our High QC: {}, block: {:?}",
                block_high_qc_block.view(),
                finalized_block.view(),
                self.high_qc,
                block
            );
            return Err(anyhow!(
                "invalid block - high QC view is {} while finalized is {}",
                block_high_qc_block.view(),
                finalized_block.view()
            ));
        }

        // This block's timestamp must be greater than or equal to the parent block's timestamp.
        if block.timestamp() < parent.timestamp() {
            return Err(anyhow!("timestamp decreased from parent"));
        }

        // This block's timestamp should be at most `self.allowed_timestamp_skew` away from the current time. Note this
        // can be either forwards or backwards in time.
        let difference = block
            .timestamp()
            .elapsed()
            .unwrap_or_else(|err| err.duration());
        if !during_sync && difference > self.config.allowed_timestamp_skew {
            return Err(anyhow!(
                "timestamp difference for block {} greater than allowed skew: {difference:?}",
                block.view()
            ));
        }

        // Blocks must be in sequential order
        if block.header.number != parent.header.number + 1 {
            return Err(anyhow!(
                "block number is not sequential: {} != {} + 1",
                block.header.number,
                parent.header.number
            ));
        }

        if !self.block_extends_from(block, &finalized_block)? {
            warn!(
                "invalid block {:?}, does not extend finalized block {:?} our head is {:?}",
                block,
                finalized_block,
                self.head_block()
            );

            return Err(anyhow!(
                "invalid block, does not extend from finalized block"
            ));
        }
        Ok(())
    }

    // Receives availability and passes it on to the block store.
    pub fn receive_block_availability(
        &mut self,
        from: PeerId,
        _availability: &Option<Vec<BlockStrategy>>,
    ) -> Result<()> {
        trace!("Received block availability from {:?}", from);
        Ok(()) // FIXME: Stub
    }

    // Checks for the validity of a block and adds it to our block store if valid.
    // Returns true when the block is valid and newly seen and false otherwise.
    // Optionally returns a proposal that should be sent as the result of this newly received block. This occurs when
    // the node has buffered votes for a block it doesn't know about and later receives that block, resulting in a new
    // block proposal.
    pub fn receive_block(&mut self, from: PeerId, proposal: Proposal) -> Result<Option<Proposal>> {
        trace!(
            "received block: {} number: {}, view: {}",
            proposal.hash(),
            proposal.number(),
            proposal.view()
        );
        let result = self.proposal(from, proposal, true)?;
        // Processing the received block can either result in:
        // * A `Proposal`, if we have buffered votes for this block which form a supermajority, meaning we can
        // propose the next block.
        // * A `Vote`, if the block is valid and we are in the proposed block's committee. However, this block
        // occured in the past, meaning our vote is no longer valid.
        // Therefore, we filter the result to only include `Proposal`s. This avoids us sending useless `Vote`s
        // to the network while syncing.
        Ok(result.and_then(|(_, message)| message.into_proposal()))
    }

    fn add_block(&self, from: Option<PeerId>, block: Block) -> Result<()> {
        let hash = block.hash();
        debug!(?from, ?hash, ?block.header.view, ?block.header.number, "added block");
        let _ = self.new_blocks.send(block.header);
        self.db.insert_block(&block)?;
        Ok(())
    }

    fn block_is_first_in_epoch(&self, number: u64) -> bool {
        number % self.config.consensus.blocks_per_epoch == 0
    }

    fn epoch_number(&self, block_number: u64) -> u64 {
        // This will need additonal tracking if we ever allow blocks_per_epoch to be changed
        block_number / self.config.consensus.blocks_per_epoch
    }

    fn epoch_is_checkpoint(&self, epoch_number: u64) -> bool {
        epoch_number % self.config.consensus.epochs_per_checkpoint == 0
    }

    fn vote_from_block(&self, block: &Block) -> Vote {
        Vote::new(
            self.secret_key,
            block.hash(),
            self.secret_key.node_public_key(),
            block.view(),
        )
    }

    fn get_high_qc_from_block(&self, block: &Block) -> Result<QuorumCertificate> {
        let Some(agg) = &block.agg else {
            return Ok(block.header.qc);
        };

        let high_qc = self.get_highest_from_agg(agg)?;

        if block.header.qc != high_qc {
            return Err(anyhow!("qc mismatch"));
        }

        Ok(block.header.qc)
    }

    pub fn get_block(&self, key: &Hash) -> Result<Option<Block>> {
        self.db.get_block_by_hash(key)
    }

    pub fn get_block_by_view(&self, view: u64) -> Result<Option<Block>> {
        self.db.get_block_by_view(view)
    }

    pub fn get_canonical_block_by_number(&self, number: u64) -> Result<Option<Block>> {
        self.db.get_canonical_block_by_number(number)
    }

    fn set_finalized_view(&self, view: u64) -> Result<()> {
        self.db.set_finalized_view(view)
    }

    pub fn get_finalized_view(&self) -> Result<u64> {
        Ok(self.db.get_finalized_view()?.unwrap_or_else(|| {
            warn!("no finalised view found in table. Defaulting to 0");
            0
        }))
    }

    fn set_view(&self, view: u64, voted: bool) -> Result<()> {
        if self.db.set_view(view, voted)? {
            *self.view_updated_at.write() = SystemTime::now();
        } else {
            warn!(
                "Tried to set view to lower or same value - this is incorrect. value: {}",
                view
            );
        }
        Ok(())
    }

    pub fn get_view(&self) -> Result<u64> {
        Ok(self.db.get_view()?.unwrap_or_else(|| {
            warn!("no view found in table. Defaulting to 0");
            0
        }))
    }

    /// Calculate how long we should wait before timing out for this view
    pub fn exponential_backoff_timeout(&self, view: u64) -> u64 {
        let view_difference = view.saturating_sub(self.high_qc.view) as u32;
        // in view N our highQC is the one we obtained in view N-1 (or before) and its view is N-2 (or lower)
        // in other words, the current view is always at least 2 views ahead of the highQC's view
        // i.e. to get `consensus_timeout_ms * 2^0` we have to subtract 2 from `view_difference`
        let consensus_timeout = self.config.consensus.consensus_timeout.as_millis() as f32;
        (consensus_timeout
            * (EXPONENTIAL_BACKOFF_TIMEOUT_MULTIPLIER)
                .powi(view_difference.saturating_sub(2) as i32))
        .floor() as u64
    }

    /// Find minimum number of views which could have passed by in the given time difference.
    /// We assume that no valid proposals have been finalised in this time.
    pub fn minimum_views_in_time_difference(
        time_difference: Duration,
        consensus_timeout: Duration,
    ) -> u64 {
        let normalised_time_difference =
            (time_difference.as_millis() / consensus_timeout.as_millis()) as f32;
        let mut views = 0;
        let mut total = 0.0;
        loop {
            total += (EXPONENTIAL_BACKOFF_TIMEOUT_MULTIPLIER).powi(views);
            if total > normalised_time_difference {
                break;
            }
            views += 1;
        }
        views as u64
    }

    pub fn state(&self) -> &State {
        &self.state
    }

    pub fn state_mut(&mut self) -> &mut State {
        &mut self.state
    }

    pub fn state_at(&self, number: u64) -> Result<Option<State>> {
        Ok(self
            .db
            .get_canonical_block_by_number(number)?
            .map(|block| self.state.at_root(block.state_root_hash().into())))
    }

    pub fn try_get_state_at(&self, number: u64) -> Result<State> {
        self.state_at(number)?
            .ok_or_else(|| anyhow!("No block at height {number}"))
    }

    fn get_highest_from_agg(&self, agg: &AggregateQc) -> Result<QuorumCertificate> {
        agg.qcs
            .iter()
            .max_by_key(|qc| qc.view)
            .copied()
            .ok_or_else(|| anyhow!("no qcs in agg"))
    }

    fn verify_qc_signature(
        &self,
        qc: &QuorumCertificate,
        public_keys: Vec<NodePublicKey>,
    ) -> Result<()> {
        let len = public_keys.len();
        match qc.verify(public_keys) {
            true => Ok(()),
            false => {
                warn!(
                    "invalid qc signature found when verifying! Public keys: {:?}. QC: {}",
                    len, qc
                );
                Err(anyhow!("invalid qc signature found!"))
            }
        }
    }

    fn batch_verify_agg_signature(
        &self,
        agg: &AggregateQc,
        committee: &[NodePublicKey],
    ) -> Result<()> {
        let mut public_keys = Vec::new();
        for (index, bit) in agg.cosigned.iter().enumerate() {
            if *bit {
                public_keys.push(*committee.get(index).unwrap());
            }
        }

        let messages: Vec<_> = agg
            .qcs
            .iter()
            .zip(public_keys.iter())
            .map(|(qc, key)| {
                let mut bytes = Vec::new();
                bytes.extend_from_slice(qc.compute_hash().as_bytes());
                bytes.extend_from_slice(&key.as_bytes());
                bytes.extend_from_slice(&agg.view.to_be_bytes());
                bytes
            })
            .collect();
        let messages: Vec<_> = messages.iter().map(|m| m.as_slice()).collect();

        verify_messages(agg.signature, &messages, &public_keys)?;
        Ok(())
    }

    // TODO: Consider if these checking functions should be implemented at the deposit contract level instead?

    fn check_quorum_in_bits(
        &self,
        cosigned: &BitSlice,
        committee: &[NodePublicKey],
        parent_state_hash: Hash,
        block: &Block,
    ) -> Result<()> {
        let parent_state = self.state.at_root(parent_state_hash.into());

        let (total_weight, cosigned_sum) = committee
            .iter()
            .enumerate()
            .map(|(i, public_key)| {
                (
                    i,
                    parent_state
                        .get_stake(*public_key, block.header)
                        .unwrap()
                        .unwrap()
                        .get(),
                )
            })
            .fold((0, 0), |(total_weight, cosigned_sum), (i, stake)| {
                (
                    total_weight + stake,
                    cosigned_sum + cosigned[i].then_some(stake).unwrap_or_default(),
                )
            });

        if cosigned_sum * 3 <= total_weight * 2 {
            return Err(anyhow!("no quorum"));
        }

        Ok(())
    }

    fn check_quorum_in_indices(
        &self,
        signers: &BitSlice,
        committee: &[NodePublicKey],
        parent_state_hash: Hash,
        block: &Block,
    ) -> Result<()> {
        let parent_state = self.state.at_root(parent_state_hash.into());

        let cosigned_sum: u128 = signers
            .iter()
            .enumerate()
            .map(|(i, bit)| {
                if *bit {
                    let public_key = committee.get(i).unwrap();
                    let stake = parent_state
                        .get_stake(*public_key, block.header)
                        .unwrap()
                        .unwrap();
                    stake.get()
                } else {
                    0
                }
            })
            .sum();

        if cosigned_sum * 3 <= self.total_weight(committee, block.header) * 2 {
            return Err(anyhow!("no quorum"));
        }

        Ok(())
    }

    pub fn leader_at_block(&self, block: &Block, view: u64) -> Option<Validator> {
        let state_at = self.state.at_root(block.state_root_hash().into());

        let executed_block = BlockHeader {
            number: block.header.number + 1,
            ..Default::default()
        };
        let Ok(public_key) = state_at.leader(view, executed_block) else {
            return None;
        };

        let Ok(Some(peer_id)) = state_at.get_peer_id(public_key) else {
            return None;
        };

        Some(Validator {
            public_key,
            peer_id,
        })
    }

    fn total_weight(&self, committee: &[NodePublicKey], executed_block: BlockHeader) -> u128 {
        committee
            .iter()
            .map(|&pub_key| {
                let stake = self
                    .state
                    .get_stake(pub_key, executed_block)
                    .unwrap()
                    .unwrap();
                stake.get()
            })
            .sum()
    }

    /// Deal with the fork to this block. The block is assumed to be valid to switch to.
    /// Set the current head block to the parent of the proposed block,
    /// This will make it so the block is ready to become the new head
    fn deal_with_fork(&mut self, block: &Block) -> Result<()> {
        // To generically deal with forks where the proposed block could be at any height, we
        // Find the common ancestor (backward) of the head block and the new block
        // Then, revert the blocks from the head block to the common ancestor
        // Then, apply the blocks (forward) from the common ancestor to the parent of the new block
        let mut head = self.head_block();
        let mut head_height = head.number();
        let mut proposed_block = block.clone();
        let mut proposed_block_height = block.number();
        trace!(
            "Dealing with fork: between head block {} (height {}), and proposed block {} (height {})",
            head.hash(),
            head_height,
            proposed_block.hash(),
            proposed_block_height
        );

        // Need to make sure both pointers are at the same height
        while head_height > proposed_block_height {
            trace!("Stepping back head block pointer");
            head = self.get_block(&head.parent_hash())?.unwrap();
            head_height = head.number();
        }

        while proposed_block_height > head_height {
            trace!("Stepping back proposed block pointer");
            proposed_block = self.get_block(&proposed_block.parent_hash())?.unwrap();
            proposed_block_height = proposed_block.number();
        }

        // We now have both hash pointers at the same height, we can walk back until they are equal.
        while head.hash() != proposed_block.hash() {
            trace!("Stepping back both pointers");
            head = self.get_block(&head.parent_hash())?.unwrap();
            proposed_block = self.get_block(&proposed_block.parent_hash())?.unwrap();
        }
        trace!(
            "common ancestor found: block number: {}, view: {}, hash: {}",
            head.number(),
            head.view(),
            head.hash()
        );

        // Now, we want to revert the blocks until the head block is the common ancestor
        while self.head_block().hash() != head.hash() {
            let head_block = self.head_block();
            let parent_block = self.get_block(&head_block.parent_hash())?.ok_or_else(|| {
                anyhow!(
                    "missing block parent when reverting blocks: {}",
                    head_block.parent_hash()
                )
            })?;

            if head_block.header.view == 0 {
                panic!("genesis block is not supposed to be reverted");
            }

            trace!(
                "Reverting block number: {}, view: {}, hash: {}",
                head_block.number(),
                head_block.view(),
                head_block.hash()
            );
            // block store doesn't require anything, it will just hold blocks that may now be invalid

            // State is easily set - must be to the parent block, though
            trace!(
                "Setting state to: {} aka block: number: {}, view: {}, hash: {}",
                parent_block.state_root_hash(),
                parent_block.number(),
                parent_block.view(),
                parent_block.hash()
            );
            self.state
                .set_to_root(parent_block.state_root_hash().into());

            // block transactions need to be removed from self.transactions and re-injected
            let mut pool = self.transaction_pool.write();
            for tx_hash in &head_block.transactions {
                let orig_tx = self.db.get_transaction(tx_hash)?.unwrap();

                // Insert this unwound transaction back into the transaction pool.
                let account = self.state.get_account(orig_tx.signer)?;
                pool.insert_transaction(orig_tx, &account, true);
            }

            // this block is no longer in the main chain
            self.db.mark_block_as_non_canonical(head_block.hash())?;
        }

        // Now, we execute forward from the common ancestor to the new block parent which can
        // be required in rare cases.
        // We have the chain of blocks from the ancestor upwards to the proposed block via walking back.
        // We also keep track of the hash of the block of the previous iteration of this loop, to detect infinite loops
        // and give up.
        let mut last_block = block.hash();
        while self.head_block().hash() != block.parent_hash() {
            trace!("Advancing the head block to prepare for proposed block fork.");
            let head_block_for_log = self.head_block();
            trace!(
                "Head block number: {}, view: {}, hash: {}",
                head_block_for_log.number(),
                head_block_for_log.view(),
                head_block_for_log.hash()
            );
            trace!("desired block hash: {}", block.parent_hash());

            let desired_block_height = self.head_block().number() + 1;
            // Pointer to parent of proposed block
            let mut block_pointer = self
                .get_block(&block.parent_hash())?
                .ok_or_else(|| anyhow!("missing block when advancing head block pointer"))?;

            if block_pointer.header.number < desired_block_height {
                panic!("block height mismatch when advancing head block pointer");
            }

            // Update pointer to be the next block in the proposed block's chain which the node's chain has not yet executed
            while block_pointer.header.number != desired_block_height {
                block_pointer = self
                    .get_block(&block_pointer.parent_hash())?
                    .ok_or_else(|| anyhow!("missing block when advancing head block pointer"))?;
            }

            if block_pointer.hash() == last_block {
                return Err(anyhow!("entered loop while dealing with fork"));
            }
            last_block = block_pointer.hash();

            // We now have the block pointer at the desired height, we can apply it.
            trace!(
                "Fork execution of block number: {}, view: {}, hash: {}",
                block_pointer.number(),
                block_pointer.view(),
                block_pointer.hash()
            );
            let transactions = block_pointer.transactions.clone();
            let transactions = transactions
                .iter()
                .map(|tx_hash| self.db.get_transaction(tx_hash).unwrap().unwrap().tx)
                .collect();
            let parent = self
                .get_block(&block_pointer.parent_hash())?
                .ok_or_else(|| anyhow!("missing parent"))?;
            let committee: Vec<_> = self
                .state
                .at_root(parent.state_root_hash().into())
                .get_stakers(block_pointer.header)?;
            self.execute_block(None, &block_pointer, transactions, &committee)?;
        }

        Ok(())
    }

    fn execute_block(
        &mut self,
        from: Option<PeerId>,
        block: &Block,
        transactions: Vec<SignedTransaction>,
        committee: &[NodePublicKey],
    ) -> Result<()> {
        debug!("Executing block: {:?}", block.header);

        let parent = self
            .get_block(&block.parent_hash())?
            .ok_or_else(|| anyhow!("missing parent block when executing block!"))?;

        if !transactions.is_empty() {
            trace!("applying {} transactions to state", transactions.len());
        }

        {
            // Early return if it is safe to fast-forward
            let mut receipts_cache = self.receipts_cache.lock();
            if receipts_cache.hash == block.receipts_root_hash()
                && from.is_some_and(|peer_id| peer_id == self.peer_id())
            {
                debug!(
                    "fast-forward self-proposal view {} block number {}",
                    block.header.view, block.header.number
                );

                let mut block_receipts = Vec::new();

                for (tx_index, txn_hash) in block.transactions.iter().enumerate() {
                    let (receipt, addresses) = receipts_cache
                        .remove(txn_hash)
                        .expect("receipt cached during proposal assembly");

                    // Recover set of receipts
                    block_receipts.push((receipt, tx_index));

                    // Apply 'touched-address' from cache
                    for address in addresses {
                        self.db.add_touched_address(address, *txn_hash)?;
                    }
                }
                // fast-forward state
                self.state.set_to_root(block.state_root_hash().into());

                // broadcast/commit receipts
                return self.broadcast_commit_receipts(from, block, block_receipts);
            };
        }

        let mut pool = self.transaction_pool.write();
        pool.update_with_state(&self.state);
        let mut verified_txns = Vec::new();

        // We re-inject any missing Intershard transactions (or really, any missing
        // transactions) from our mempool. If any txs are unavailable in both the
        // message or locally, the proposal cannot be applied
        for (idx, tx_hash) in block.transactions.iter().enumerate() {
            // Prefer to insert verified txn from pool. This is faster.
            let txn = match pool.get_transaction(tx_hash) {
                Some(txn) => txn.clone(),
                _ => match transactions
                    .get(idx)
                    .map(|sig_tx| sig_tx.clone().verify())
                    .transpose()?
                {
                    // Otherwise, recover txn from proposal. This is slower.
                    Some(txn) if txn.hash == *tx_hash => txn,
                    _ => {
                        warn!(
                            "Proposal {} at view {} referenced a transaction {} that was neither included in the broadcast nor found locally - cannot apply block",
                            block.hash(),
                            block.view(),
                            tx_hash
                        );
                        return Ok(());
                    }
                },
            };
            verified_txns.push(txn);
        }

        let mut block_receipts = Vec::new();
        let mut cumulative_gas_used = EvmGas(0);
        let mut receipts_trie = EthTrie::new(Arc::new(MemoryDB::new(true)));
        let mut transactions_trie = EthTrie::new(Arc::new(MemoryDB::new(true)));
        let mut cumulative_gas_fee = 0_u128;

        let transaction_hashes = verified_txns
            .iter()
            .map(|tx| format!("{:?}", tx.hash))
            .join(",");

        let mut touched_addresses = vec![];
        for (tx_index, txn) in verified_txns.iter().enumerate() {
            self.new_transaction(txn.clone(), true, &mut pool)?;
            let tx_hash = txn.hash;
            let mut inspector = TouchedAddressInspector::default();
            let result = Self::apply_transaction_at(
                &mut self.state,
                txn.clone(),
                block.header,
                &mut inspector,
                self.config.enable_ots_indices,
            )?
            .ok_or_else(|| anyhow!("proposed transaction failed to execute"))?;
            pool.mark_executed(txn);
            for address in inspector.touched {
                touched_addresses.push((address, tx_hash));
            }

            let gas_used = result.gas_used();
            cumulative_gas_used += gas_used;

            if cumulative_gas_used > block.gas_limit() {
                warn!("Cumulative gas used by executing transactions exceeded block limit!");
                return Ok(());
            }

            let gas_fee = gas_used.0 as u128 * txn.tx.gas_price_per_evm_gas();
            cumulative_gas_fee = cumulative_gas_fee
                .checked_add(gas_fee)
                .ok_or_else(|| anyhow!("Overflow occurred in cumulative gas fee calculation"))?;

            let receipt = Self::create_txn_receipt(result, tx_hash, tx_index, cumulative_gas_used);

            let receipt_hash = receipt.compute_hash();

            debug!(
                "During execution in view: {}, transaction with hash: {:?} produced receipt: {:?}, receipt hash: {:?}",
                self.get_view()?,
                tx_hash,
                receipt,
                receipt_hash
            );
            receipts_trie.insert(receipt_hash.as_bytes(), receipt_hash.as_bytes())?;

            transactions_trie.insert(tx_hash.as_bytes(), tx_hash.as_bytes())?;

            debug!(?receipt, "applied transaction {:?}", receipt);
            block_receipts.push((receipt, tx_index));
        }
        std::mem::drop(pool);

        self.db.with_sqlite_tx(|sqlite_tx| {
            for txn in &verified_txns {
                self.db
                    .insert_transaction_with_db_tx(sqlite_tx, &txn.hash, txn)?;
            }
            for (addr, txn_hash) in touched_addresses {
                self.db
                    .add_touched_address_with_db_tx(sqlite_tx, addr, txn_hash)?;
            }
            Ok(())
        })?;

        if cumulative_gas_used != block.gas_used() {
            warn!(
                "Cumulative gas used by executing all transactions: {cumulative_gas_used} is different than the one provided in the block: {}",
                block.gas_used()
            );
            return Ok(());
        }

        let receipts_root_hash: Hash = receipts_trie.root_hash()?.into();
        if block.header.receipts_root_hash != receipts_root_hash {
            warn!(
                "Block number: {}, Receipt root mismatch. Specified in block: {} vs computed: {}, txn_hashes: {}",
                block.number(),
                block.header.receipts_root_hash,
                receipts_root_hash,
                transaction_hashes
            );
            return Ok(());
        }

        let transactions_root_hash: Hash = transactions_trie.root_hash()?.into();
        if block.header.transactions_root_hash != transactions_root_hash {
            warn!(
                "Block number: {}, Transactions root mismatch. Specified in block: {} vs computed: {}, txn_hashes: {}",
                block.number(),
                block.header.transactions_root_hash,
                transactions_root_hash,
                transaction_hashes
            );
            return Ok(());
        }

        let mut state = self.state.clone();
        self.apply_proposal_to_state(&mut state, block, &parent, committee, cumulative_gas_fee)?;
        self.state = state;

        if self.state.root_hash()? != block.state_root_hash() {
            warn!(
                "State root hash mismatch! Our state hash: {}, block hash: {:?} block prop: {:?}",
                self.state.root_hash()?,
                block.state_root_hash(),
                block,
            );
            return Err(anyhow!(
                "state root hash mismatch, expected: {:?}, actual: {:?}",
                block.state_root_hash(),
                self.state.root_hash()
            ));
        }

        self.broadcast_commit_receipts(from, block, block_receipts)
    }

    fn apply_proposal_to_state(
        &self,
        state: &mut State,
        block: &Block,
        parent: &Block,
        committee: &[NodePublicKey],
        cumulative_gas_fee: u128,
    ) -> Result<()> {
        // Apply the rewards of previous round
        let proposer = self.leader_at_block(parent, block.view()).unwrap();
        Self::apply_rewards_late_at(
            parent,
            state,
            &self.config.consensus,
            committee,
            proposer.public_key,
            block,
        )?;

        // ZIP-9: Sink gas to zero account
        let fork = state.forks.get(block.header.number).clone();
        let gas_fee_amount = if fork.transfer_gas_fee_to_zero_account {
            cumulative_gas_fee
        } else {
            block.gas_used().0 as u128
        };

        state.mutate_account(Address::ZERO, |a| {
            a.balance = a
                .balance
                .checked_add(gas_fee_amount)
                .ok_or(anyhow!("Overflow occurred in zero account balance"))?;
            Ok(())
        })?;

        if !fork.fund_accounts_from_zero_account.is_empty() {
            if let Some(fork_height) = self
                .state
                .forks
                .find_height_fork_first_activated(ForkName::FundAccountsFromZeroAccount)
            {
                if fork_height == block.header.number {
                    for address_amount_pair in fork.fund_accounts_from_zero_account.clone() {
                        state.mutate_account(Address::ZERO, |a| {
                            a.balance = a
                                .balance
                                .checked_sub(*address_amount_pair.1)
                                .ok_or(anyhow!("Underflow occurred in zero account balance"))?;
                            Ok(())
                        })?;
                        state.mutate_account(address_amount_pair.0, |a| {
                            a.balance = a
                                .balance
                                .checked_add(*address_amount_pair.1)
                                .ok_or(anyhow!("Overflow occurred in Faucet account balance"))?;
                            Ok(())
                        })?;
                    }
                }
            };
        }

        if fork.restore_xsgd_contract {
            if let Some(fork_height) = self
                .state
                .forks
                .find_height_fork_first_activated(ForkName::RestoreXsgdContract)
            {
                if fork_height == block.header.number {
                    let code: Code = serde_json::from_slice(&hex::decode(XSGD_CODE)?)?;
                    state.mutate_account(XSGD_MAINNET_ADDR, |a| {
                        a.code = code;
                        Ok(())
                    })?;
                }
            }
        }
        if fork.revert_restore_xsgd_contract {
            if let Some(fork_height) = self
                .state
                .forks
                .find_height_fork_first_activated(ForkName::RevertRestoreXsgdContract)
            {
                if fork_height == block.header.number {
                    state.mutate_account(XSGD_MAINNET_ADDR, |a| {
                        a.code = Code::Evm(vec![]);
                        Ok(())
                    })?;
                }
            }
        }

        if self.block_is_first_in_epoch(block.header.number) {
            // Update state with any contract upgrades for this block
            state.contract_upgrade_apply_state_change(&self.config.consensus, block.header)?;
        }

        Ok(())
    }

    fn broadcast_commit_receipts(
        &self,
        from: Option<PeerId>,
        block: &Block,
        mut block_receipts: Vec<(TransactionReceipt, usize)>,
    ) -> Result<()> {
        // Broadcast receipts
        for (receipt, tx_index) in &mut block_receipts {
            receipt.block_hash = block.hash();
            // Avoid cloning the receipt if there are no subscriptions to send it to.
            if self.new_receipts.receiver_count() != 0 {
                let _ = self.new_receipts.send((receipt.clone(), *tx_index));
            }
        }

        // Important - only add blocks we are going to execute because they can potentially
        // overwrite the mapping of block height to block, which there should only be one of.
        // for example, this HAS to be after the deal with fork call
        if !self.db.contains_block(&block.hash())? {
            // Only tell the block store where this block came from if it wasn't from ourselves.
            let from = from.filter(|peer_id| *peer_id != self.peer_id());
            // If we were the proposer we would've already processed the block, hence the check
            self.add_block(from, block.clone())?;
        }
        {
            // helper scope to shadow db, to avoid moving it into the closure
            // closure has to be move to take ownership of block_receipts
            let db = &self.db;
            self.db.with_sqlite_tx(move |sqlite_tx| {
                for (receipt, _) in block_receipts {
                    db.insert_transaction_receipt_with_db_tx(sqlite_tx, receipt)?;
                }
                Ok(())
            })?;
        }

        self.db.mark_block_as_canonical(block.hash())?;

        Ok(())
    }

    fn create_txn_receipt(
        apply_result: TransactionApplyResult,
        tx_hash: Hash,
        tx_index: usize,
        cumulative_gas_used: EvmGas,
    ) -> TransactionReceipt {
        let success = apply_result.success();
        let contract_address = apply_result.contract_address();
        let gas_used = apply_result.gas_used();
        let accepted = apply_result.accepted();
        let (logs, transitions, errors, exceptions) = apply_result.into_parts();

        TransactionReceipt {
            tx_hash,
            block_hash: Hash::ZERO,
            index: tx_index as u64,
            success,
            contract_address,
            logs,
            transitions,
            gas_used,
            cumulative_gas_used,
            accepted,
            errors,
            exceptions,
        }
    }

    pub fn get_num_transactions(&self) -> Result<usize> {
        let count = self.db.get_total_transaction_count()?;
        Ok(count)
    }

    pub fn get_sync_data(&self) -> Result<Option<SyncingStruct>> {
        self.sync.get_sync_data()
    }

    /// This function is intended for use only by admin_forceView API. It is dangerous and should not be touched outside of testing or test network recovery.
    ///
    /// Force set our view and override exponential timeout such that view timeouts at given timestamp
    /// View value must be larger than current
    pub fn force_view(&mut self, view: u64, timeout_at: String) -> Result<()> {
        if self.get_view()? > view {
            return Err(anyhow!(
                "view cannot be forced into lower view than current"
            ));
        }
        match timeout_at.parse::<DateTime>() {
            Ok(datetime) => self.force_view = Some((view, datetime)),
            Err(_) => {
                return Err(anyhow!(
                    "timeout date must be in format 2001-01-02T12:13:14Z"
                ));
            }
        };
        self.set_view(view, false)?;

        // Build a new view - We assume the network is stuck.
        if !self.db.get_voted_in_view()? {
            self.build_new_view()?;
        }
        Ok(())
    }

    fn in_committee(&mut self, val: bool) -> Result<()> {
        if val && !self.in_committee {
            self.in_committee = true;
            self.message_sender.send_message_to_coordinator(
                InternalMessage::SubscribeToGossipSubTopic(GossipSubTopic::Validator(
                    self.config.eth_chain_id,
                )),
            )?;
        }
        if !val && self.in_committee {
            self.in_committee = false;
            self.message_sender.send_message_to_coordinator(
                InternalMessage::UnsubscribeFromGossipSubTopic(GossipSubTopic::Validator(
                    self.config.eth_chain_id,
                )),
            )?;
        }
        Ok(())
    }

    pub fn clear_mempool(&self) {
        self.transaction_pool.write().clear();
    }
}

```

`zilliqa/src/constants.rs`:

```rs
use std::time::Duration;

use crate::transaction::{EvmGas, ScillaGas};

// How big data slot a transaction can use
pub const EVM_TX_SLOT_IN_BYTES: usize = 32 * 1024;

// Maximum size of a transaction (4 slots)
pub const EVM_MAX_TX_INPUT_SIZE: usize = 4 * EVM_TX_SLOT_IN_BYTES; // 128KB

// Maximum bytecode size to permit for a contract
pub const EVM_MAX_CODE_SIZE: usize = 24576;

// Maximum init code to permit in create operations.
pub const EVM_MAX_INIT_CODE_SIZE: usize = 2 * EVM_MAX_CODE_SIZE;

// Minimum gas required for EVM transaction (without input data)
pub const EVM_MIN_GAS_UNITS: EvmGas = EvmGas(21000);

// Maximum code size allowed for zil transactions (imported from ZQ1)
pub const ZIL_MAX_CODE_SIZE: usize = 76800;

// Gas needed for invoking scilla contract
pub const ZIL_CONTRACT_INVOKE_GAS: usize = 10;

// Gas needed for creating scilla contract
pub const ZIL_CONTRACT_CREATE_GAS: usize = 50;

// Gas needed for making transfer using ZIL transaction
pub const ZIL_NORMAL_TXN_GAS: usize = 50;

// Maximum rate at which to send availability requests
pub const REQUEST_PEER_VIEW_AVAILABILITY_NOT_BEFORE: Duration = Duration::from_secs(300);

// We assume that every node has the last ALWAYS_RETAIN_LAST_N_BLOCKS blocks, otherwise
// it's hard ever to catch up. Set this too large and syncing will be hard because we will
// keep asking recently started nodes for blocks they don't have. Set it too small and
// it will be hard because we'll need to keep waiting for availability.
// Set to 10 because this is small enough that the statement is usually true (almost every node
// will have the last 10 blocks), but large enough that we can realistically fetch blocks
// near the head (set this to 1, for example, and we will loop requesting availability - at
// least until proposal broadcasts save us - see the comment at the top of block_cache.rs for
// details).
pub const RETAINS_LAST_N_BLOCKS: u64 = 10;

// How long do we wait before retrying a request to a peer?

// WARNING: these must be at least 1000*max_blocks_in_flight.
// All requests get this number of ms.
pub const BLOCK_REQUEST_RESPONSE_TIMEOUT: Duration = Duration::from_millis(4000);

// log2 of the number of ways in the block cache. Max 8.
pub const BLOCK_CACHE_LOG2_WAYS: usize = 4;
/// The block cache will deliberately keep this number of entries near the highest known view
/// so that it can catch up quickly when it reaches the current head of the chain.
/// Not required for correctness.
pub const BLOCK_CACHE_HEAD_BUFFER_ENTRIES: usize = 1024;

/// Max pending requests per peer
pub const MAX_PENDING_BLOCK_REQUESTS_PER_PEER: usize = 16;

/// Number of previous blocks to examine at each level of fork counter. Should be
/// set small enough to avoid serious database load, but large enough to jump any
/// plausible fork reasonably quickly.
pub const EXAMINE_BLOCKS_PER_FORK_COUNT: usize = 16;

// Gas costs.
pub const SCILLA_TRANSFER: ScillaGas = ScillaGas(50);
pub const SCILLA_INVOKE_CHECKER: ScillaGas = ScillaGas(100);
pub const SCILLA_INVOKE_RUNNER: ScillaGas = ScillaGas(300);

// Consensus
// Roughly how long to allow between finish propocessing of a Proposal and it being received by peers
pub const TIME_TO_ALLOW_PROPOSAL_BROADCAST: Duration = Duration::from_millis(100);

// Exponentional backoff timeout increases by this multiple for each view missed
pub const EXPONENTIAL_BACKOFF_TIMEOUT_MULTIPLIER: f32 = 1.25f32;

```

`zilliqa/src/contracts/mod.rs`:

```rs
pub use deposit_v2 as deposit;
use serde_json::Value;

pub mod deposit_init {
    use ethabi::{Constructor, Function};
    use once_cell::sync::Lazy;

    use super::{Contract, contract};

    static CONTRACT: Lazy<Contract> =
        Lazy::new(|| contract("src/contracts/deposit_v1.sol", "DepositInit"));
    pub static CONSTRUCTOR: Lazy<Constructor> =
        Lazy::new(|| CONTRACT.abi.constructor().unwrap().clone());
    pub static INITIALIZE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("initialize").unwrap().clone());
    pub static UPGRADE_TO_AND_CALL: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("upgradeToAndCall").unwrap().clone());
    pub static VERSION: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("version").unwrap().clone());
    pub static GET_STAKERS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getStakers").unwrap().clone());
    pub static BYTECODE: Lazy<Vec<u8>> = Lazy::new(|| CONTRACT.bytecode.clone());
}

pub mod deposit_v2 {
    use ethabi::{Constructor, Function};
    use once_cell::sync::Lazy;

    use super::{Contract, contract};

    pub static CONTRACT: Lazy<Contract> =
        Lazy::new(|| contract("src/contracts/deposit_v2.sol", "Deposit"));
    pub static CONSTRUCTOR: Lazy<Constructor> =
        Lazy::new(|| CONTRACT.abi.constructor().unwrap().clone());
    pub static REINITIALIZE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("reinitialize").unwrap().clone());
    pub static UPGRADE_TO_AND_CALL: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("upgradeToAndCall").unwrap().clone());
    pub static VERSION: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("version").unwrap().clone());

    pub static BYTECODE: Lazy<Vec<u8>> = Lazy::new(|| CONTRACT.bytecode.clone());
    pub static LEADER_AT_VIEW: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("leaderAtView").unwrap().clone());
    pub static DEPOSIT: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("deposit").unwrap().clone());
    pub static DEPOSIT_TOPUP: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("depositTopup").unwrap().clone());
    pub static UNSTAKE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("unstake").unwrap().clone());
    pub static CURRENT_EPOCH: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("currentEpoch").unwrap().clone());
    pub static GET_STAKE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getStake").unwrap().clone());
    pub static GET_REWARD_ADDRESS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getRewardAddress").unwrap().clone());
    pub static GET_PEER_ID: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getPeerId").unwrap().clone());
    pub static GET_STAKERS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getStakers").unwrap().clone());
    pub static GET_TOTAL_STAKE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getTotalStake").unwrap().clone());
    pub static COMMITTEE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("committee").unwrap().clone());
    pub static MIN_DEPOSIT: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("minimumStake").unwrap().clone());
    pub static MAX_STAKERS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("maximumStakers").unwrap().clone());
    pub static BLOCKS_PER_EPOCH: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("blocksPerEpoch").unwrap().clone());
}

pub mod deposit_v3 {
    use ethabi::{Constructor, Function};
    use once_cell::sync::Lazy;

    use super::{Contract, contract};

    pub static CONTRACT: Lazy<Contract> =
        Lazy::new(|| contract("src/contracts/deposit_v3.sol", "Deposit"));
    pub static CONSTRUCTOR: Lazy<Constructor> =
        Lazy::new(|| CONTRACT.abi.constructor().unwrap().clone());
    pub static REINITIALIZE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("reinitialize").unwrap().clone());
    pub static UPGRADE_TO_AND_CALL: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("upgradeToAndCall").unwrap().clone());
    pub static VERSION: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("version").unwrap().clone());

    pub static BYTECODE: Lazy<Vec<u8>> = Lazy::new(|| CONTRACT.bytecode.clone());
    pub static LEADER_AT_VIEW: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("leaderAtView").unwrap().clone());
    pub static DEPOSIT: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("deposit").unwrap().clone());
    pub static DEPOSIT_TOPUP: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("depositTopup").unwrap().clone());
    pub static UNSTAKE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("unstake").unwrap().clone());
    pub static CURRENT_EPOCH: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("currentEpoch").unwrap().clone());
    pub static GET_STAKE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getStake").unwrap().clone());
    pub static GET_REWARD_ADDRESS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getRewardAddress").unwrap().clone());
    pub static GET_SIGNING_ADDRESS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getSigningAddress").unwrap().clone());
    pub static GET_CONTROL_ADDRESS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getControlAddress").unwrap().clone());
    pub static SET_SIGNING_ADDRESS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("setSigningAddress").unwrap().clone());
    pub static SET_CONTROL_ADDRESS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("setControlAddress").unwrap().clone());
    pub static GET_PEER_ID: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getPeerId").unwrap().clone());
    pub static GET_STAKERS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getStakers").unwrap().clone());
    pub static GET_TOTAL_STAKE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getTotalStake").unwrap().clone());
    pub static COMMITTEE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("committee").unwrap().clone());
    pub static MIN_DEPOSIT: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("minimumStake").unwrap().clone());
    pub static MAX_STAKERS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("maximumStakers").unwrap().clone());
    pub static BLOCKS_PER_EPOCH: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("blocksPerEpoch").unwrap().clone());
}

pub mod deposit_v4 {
    use ethabi::{Constructor, Function};
    use once_cell::sync::Lazy;

    use super::{Contract, contract};

    pub static CONTRACT: Lazy<Contract> =
        Lazy::new(|| contract("src/contracts/deposit_v4.sol", "Deposit"));
    pub static CONSTRUCTOR: Lazy<Constructor> =
        Lazy::new(|| CONTRACT.abi.constructor().unwrap().clone());
    pub static REINITIALIZE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("reinitialize").unwrap().clone());
    pub static UPGRADE_TO_AND_CALL: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("upgradeToAndCall").unwrap().clone());
    pub static VERSION: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("version").unwrap().clone());

    pub static BYTECODE: Lazy<Vec<u8>> = Lazy::new(|| CONTRACT.bytecode.clone());
    pub static LEADER_AT_VIEW: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("leaderAtView").unwrap().clone());
    pub static DEPOSIT: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("deposit").unwrap().clone());
    pub static DEPOSIT_TOPUP: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("depositTopup").unwrap().clone());
    pub static UNSTAKE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("unstake").unwrap().clone());
    pub static CURRENT_EPOCH: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("currentEpoch").unwrap().clone());
    pub static GET_STAKE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getStake").unwrap().clone());
    pub static GET_REWARD_ADDRESS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getRewardAddress").unwrap().clone());
    pub static GET_SIGNING_ADDRESS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getSigningAddress").unwrap().clone());
    pub static GET_CONTROL_ADDRESS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getControlAddress").unwrap().clone());
    pub static SET_SIGNING_ADDRESS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("setSigningAddress").unwrap().clone());
    pub static SET_CONTROL_ADDRESS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("setControlAddress").unwrap().clone());
    pub static GET_PEER_ID: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getPeerId").unwrap().clone());
    pub static GET_STAKERS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getStakers").unwrap().clone());
    pub static GET_TOTAL_STAKE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getTotalStake").unwrap().clone());
    pub static COMMITTEE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("committee").unwrap().clone());
    pub static MIN_DEPOSIT: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("minimumStake").unwrap().clone());
    pub static MAX_STAKERS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("maximumStakers").unwrap().clone());
    pub static BLOCKS_PER_EPOCH: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("blocksPerEpoch").unwrap().clone());
}

pub mod deposit_v5 {
    use ethabi::{Constructor, Function};
    use once_cell::sync::Lazy;

    use super::{Contract, contract};

    pub static CONTRACT: Lazy<Contract> =
        Lazy::new(|| contract("src/contracts/deposit_v5.sol", "Deposit"));
    pub static CONSTRUCTOR: Lazy<Constructor> =
        Lazy::new(|| CONTRACT.abi.constructor().unwrap().clone());
    pub static REINITIALIZE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("reinitialize").unwrap().clone());
    pub static UPGRADE_TO_AND_CALL: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("upgradeToAndCall").unwrap().clone());
    pub static VERSION: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("version").unwrap().clone());

    pub static BYTECODE: Lazy<Vec<u8>> = Lazy::new(|| CONTRACT.bytecode.clone());
    pub static LEADER_AT_VIEW: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("leaderAtView").unwrap().clone());
    pub static DEPOSIT: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("deposit").unwrap().clone());
    pub static DEPOSIT_TOPUP: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("depositTopup").unwrap().clone());
    pub static UNSTAKE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("unstake").unwrap().clone());
    pub static CURRENT_EPOCH: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("currentEpoch").unwrap().clone());
    pub static GET_STAKE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getStake").unwrap().clone());
    pub static GET_REWARD_ADDRESS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getRewardAddress").unwrap().clone());
    pub static GET_SIGNING_ADDRESS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getSigningAddress").unwrap().clone());
    pub static GET_CONTROL_ADDRESS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getControlAddress").unwrap().clone());
    pub static SET_SIGNING_ADDRESS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("setSigningAddress").unwrap().clone());
    pub static SET_CONTROL_ADDRESS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("setControlAddress").unwrap().clone());
    pub static GET_PEER_ID: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getPeerId").unwrap().clone());
    pub static GET_STAKERS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getStakers").unwrap().clone());
    pub static GET_TOTAL_STAKE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("getTotalStake").unwrap().clone());
    pub static COMMITTEE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("committee").unwrap().clone());
    pub static MIN_DEPOSIT: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("minimumStake").unwrap().clone());
    pub static MAX_STAKERS: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("maximumStakers").unwrap().clone());
    pub static BLOCKS_PER_EPOCH: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("blocksPerEpoch").unwrap().clone());
    pub static WITHDRAWAL_PERIOD: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("withdrawalPeriod").unwrap().clone());
}

pub mod shard {
    use ethabi::Constructor;
    use once_cell::sync::Lazy;

    use super::{Contract, contract};

    static CONTRACT: Lazy<Contract> = Lazy::new(|| contract("src/contracts/shard.sol", "Shard"));

    pub static BYTECODE: Lazy<Vec<u8>> = Lazy::new(|| CONTRACT.bytecode.clone());
    pub static CONSTRUCTOR: Lazy<Constructor> =
        Lazy::new(|| CONTRACT.abi.constructor().unwrap().clone());
}

pub mod intershard_bridge {
    use ethabi::{Constructor, Event, Function};
    use once_cell::sync::Lazy;

    use super::{Contract, contract};

    static CONTRACT: Lazy<Contract> =
        Lazy::new(|| contract("src/contracts/intershard_bridge.sol", "IntershardBridge"));

    pub static BYTECODE: Lazy<Vec<u8>> = Lazy::new(|| CONTRACT.bytecode.clone());
    pub static CONSTRUCTOR: Lazy<Constructor> =
        Lazy::new(|| CONTRACT.abi.constructor().unwrap().clone());
    pub static BRIDGE: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("bridge").unwrap().clone());
    pub static RELAYED_EVT: Lazy<Event> =
        Lazy::new(|| CONTRACT.abi.event("Relayed").unwrap().clone());
}

pub mod shard_registry {
    use ethabi::{Constructor, Event, Function};
    use once_cell::sync::Lazy;

    use super::{Contract, contract};

    static CONTRACT: Lazy<Contract> =
        Lazy::new(|| contract("src/contracts/shard_registry.sol", "ShardRegistry"));

    pub static BYTECODE: Lazy<Vec<u8>> = Lazy::new(|| CONTRACT.bytecode.clone());
    pub static CONSTRUCTOR: Lazy<Constructor> =
        Lazy::new(|| CONTRACT.abi.constructor().unwrap().clone());

    pub static ADD_SHARD: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("addShard").unwrap().clone());
    pub static SHARD_ADDED_EVT: Lazy<Event> =
        Lazy::new(|| CONTRACT.abi.event("ShardAdded").unwrap().clone());

    pub static ADD_LINK: Lazy<Function> =
        Lazy::new(|| CONTRACT.abi.function("addLink").unwrap().clone());
    pub static LINK_ADDED_EVT: Lazy<Event> =
        Lazy::new(|| CONTRACT.abi.event("LinkAdded").unwrap().clone());
}

pub mod eip1967_proxy {
    use ethabi::{Constructor, Event};
    use once_cell::sync::Lazy;

    use super::{Contract, contract};

    static CONTRACT: Lazy<Contract> = Lazy::new(|| {
        contract(
            "../vendor/openzeppelin-contracts/contracts/proxy/ERC1967/ERC1967Proxy.sol",
            "ERC1967Proxy",
        )
    });

    pub static BYTECODE: Lazy<Vec<u8>> = Lazy::new(|| CONTRACT.bytecode.clone());
    pub static CONSTRUCTOR: Lazy<Constructor> =
        Lazy::new(|| CONTRACT.abi.constructor().unwrap().clone());

    pub static UPGRADED_EVT: Lazy<Event> =
        Lazy::new(|| CONTRACT.abi.event("Upgraded").unwrap().clone());
}

const COMPILED: &str = include_str!("compiled.json");

fn contract(src: &str, name: &str) -> Contract {
    let compiled = serde_json::from_str::<Value>(COMPILED).unwrap();
    let contract = &compiled["contracts"][src][name];
    let abi = serde_json::from_value(contract["abi"].clone()).unwrap();
    let bytecode = hex::decode(contract["evm"]["bytecode"]["object"].as_str().unwrap()).unwrap();

    Contract { abi, bytecode }
}

pub struct Contract {
    pub abi: ethabi::Contract,
    pub bytecode: Vec<u8>,
}

/// This test asserts the contract binaries in this module are correct and reproducible, by recompiling the source
/// files and checking the result is the same. This means we can keep the compiled source code in-tree, while also
/// asserting in CI that the compiled source code is genuine. The tests only run when the `test_contract_bytecode`
/// feature is enabled.
#[cfg(test)]
mod tests {
    use std::{fs::File, path::PathBuf};

    use foundry_compilers::{
        artifacts::{
            EvmVersion, Optimizer, Remapping, Settings, SolcInput, Source,
            output_selection::OutputSelection,
        },
        solc::SolcLanguage,
    };

    #[test]
    #[cfg_attr(not(feature = "test_contract_bytecode"), ignore)]
    fn compile_all() {
        let root = PathBuf::from(env!("CARGO_MANIFEST_DIR"));
        let input = SolcInput {
            language: SolcLanguage::Solidity,
            sources: Source::read_all([
                "src/contracts/deposit_v1.sol",
                "src/contracts/deposit_v2.sol",
                "src/contracts/deposit_v3.sol",
                "src/contracts/deposit_v4.sol",
                "src/contracts/deposit_v5.sol",
                "src/contracts/utils/deque.sol",
                "src/contracts/intershard_bridge.sol",
                "src/contracts/shard.sol",
                "src/contracts/shard_registry.sol",
                "../vendor/openzeppelin-contracts/contracts/proxy/ERC1967/ERC1967Proxy.sol",
            ])
            .unwrap(),
            settings: Settings {
                remappings: vec![
                    Remapping {
                        context: None,
                        name: "@openzeppelin/contracts-upgradeable".to_owned(),
                        path: "../vendor/openzeppelin-contracts-upgradeable/contracts".to_owned(),
                    },
                    Remapping {
                        context: None,
                        name: "@openzeppelin/contracts".to_owned(),
                        path: "../vendor/openzeppelin-contracts/contracts".to_owned(),
                    },
                ],
                optimizer: Optimizer {
                    enabled: Some(true),
                    runs: Some(4294967295),
                    details: None,
                },
                output_selection: OutputSelection::complete_output_selection(),
                evm_version: Some(EvmVersion::Shanghai),
                ..Default::default()
            },
        };

        let mut solc =
            foundry_compilers::solc::Solc::find_or_install(&semver::Version::new(0, 8, 28))
                .unwrap();
        solc.allow_paths.insert(PathBuf::from(
            "../vendor/openzeppelin-contracts-upgradeable",
        ));
        solc.allow_paths
            .insert(PathBuf::from("../vendor/openzeppelin-contracts"));

        let output = solc.compile_exact(&input).unwrap();
        if output.has_error() {
            for error in output.errors {
                eprintln!("{error}");
            }
            panic!("compilation failed");
        }
        let output_file = root.join("src").join("contracts").join("compiled.json");

        if std::env::var_os("ZQ_CONTRACT_TEST_BLESS").is_some() {
            let file = File::create(output_file).unwrap();
            serde_json::to_writer_pretty(file, &output).unwrap();

            println!("`compiled.json` updated, please commit these changes");
        } else {
            let file = File::open(output_file).unwrap();
            let current_output = serde_json::from_reader(file).unwrap();

            assert_eq!(output, current_output);
        }
    }
}

```

`zilliqa/src/crypto.rs`:

```rs
//! A collection of cryptographic primitives used by Zilliqa.
//!
//! The exact implementations of these primitives is an implementation detail for this module only and dependents
//! should not care about the implementations. This gives us some confidence that we could replace the implementations
//! in the future if we wanted to.

use std::fmt::Display;

use alloy::primitives::{Address, B256};
use anyhow::{Context, Result, anyhow};
use blsful::{
    AggregateSignature, Bls12381G2, Bls12381G2Impl, MultiPublicKey, MultiSignature, PublicKey,
    Signature, inner_types::Group, vsss_rs::ShareIdentifier,
};
use itertools::Itertools;
use k256::ecdsa::{Signature as EcdsaSignature, VerifyingKey, signature::hazmat::PrehashVerifier};
use serde::{
    Deserialize, Serialize,
    de::{self, Unexpected},
};
use sha3::{Digest, Keccak256};

/// The signature type used internally in consensus, to e.g. sign block proposals.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct BlsSignature(Signature<Bls12381G2Impl>);

impl BlsSignature {
    pub fn identity() -> BlsSignature {
        // Default to Basic signatures - it's the normal signature.
        BlsSignature(Signature::<Bls12381G2Impl>::Basic(
            blsful::inner_types::G2Projective::identity(),
        ))
    }

    pub fn from_bytes(bytes: &[u8]) -> Result<BlsSignature> {
        // Default to Basic signatures - it's the normal signature.
        Ok(BlsSignature(Signature::<Bls12381G2Impl>::Basic(
            // Underlying type is compressed G2Affine
            blsful::inner_types::G2Projective::from_compressed(bytes.try_into()?)
                .into_option()
                .context("bls signature error")?,
        )))
    }

    pub fn aggregate(signatures: &[BlsSignature]) -> Result<BlsSignature> {
        // IETF standards say N >= 1
        // Handles single case where N == 1, as AggregateSignature::from_signatures() only handles N > 1.
        // Reported upstream https://github.com/hyperledger-labs/agora-blsful/issues/10
        if signatures.len() < 2 {
            return Ok(BlsSignature(
                signatures.first().context("zero signatures")?.0,
            ));
        }

        let signatures = signatures.iter().map(|s: &BlsSignature| s.0).collect_vec();
        let asig = AggregateSignature::<Bls12381G2Impl>::from_signatures(signatures)?;
        Ok(BlsSignature(match asig {
            AggregateSignature::Basic(s) => Signature::Basic(s),
            AggregateSignature::MessageAugmentation(s) => Signature::MessageAugmentation(s),
            AggregateSignature::ProofOfPossession(s) => Signature::ProofOfPossession(s),
        }))
    }

    // Verify that the aggregated signature is valid for the given public keys and message.
    // That is, each public key has signed the message, and the aggregated signature is the
    // aggregation of those signatures.
    pub fn verify_aggregate(
        signature: &BlsSignature,
        message: &[u8],
        public_keys: Vec<NodePublicKey>,
    ) -> Result<()> {
        let keys = public_keys.iter().map(|p| p.0).collect_vec();
        let mpk = MultiPublicKey::<Bls12381G2Impl>::from_public_keys(keys);
        let msig = match signature.0 {
            Signature::Basic(s) => MultiSignature::Basic(s),
            Signature::MessageAugmentation(s) => MultiSignature::MessageAugmentation(s),
            Signature::ProofOfPossession(s) => MultiSignature::ProofOfPossession(s),
        };
        if msig.verify(mpk, message).is_err() {
            return Err(anyhow!("invalid QC aggregated signature!"));
        }
        Ok(())
    }

    pub fn to_bytes(self) -> Vec<u8> {
        self.0.as_raw_value().to_compressed().to_vec()
    }

    pub fn from_string(str: &str) -> Result<Self> {
        Self::from_bytes(&hex::decode(str)?)
    }
}

impl Display for BlsSignature {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", hex::encode(self.to_bytes()))
    }
}

pub fn verify_messages(
    signature: BlsSignature,
    messages: &[&[u8]],
    public_keys: &[NodePublicKey],
) -> Result<()> {
    let data = public_keys
        .iter()
        .zip(messages.iter())
        .map(|(a, &b)| (a.0, b))
        .collect_vec();
    let asig = match signature.0 {
        Signature::Basic(s) => AggregateSignature::Basic(s),
        Signature::MessageAugmentation(s) => AggregateSignature::MessageAugmentation(s),
        Signature::ProofOfPossession(s) => AggregateSignature::ProofOfPossession(s),
    };
    if asig.verify(data.as_slice()).is_err() {
        return Err(anyhow!("invalid signature"));
    }
    Ok(())
}

impl serde::Serialize for BlsSignature {
    fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        self.to_bytes().serialize(serializer)
    }
}

impl<'de> Deserialize<'de> for BlsSignature {
    fn deserialize<D>(deserializer: D) -> std::result::Result<Self, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        let bytes = <Vec<u8>>::deserialize(deserializer)?;
        BlsSignature::from_bytes(&bytes)
            .map_err(|_| de::Error::invalid_value(Unexpected::Bytes(&bytes), &"a signature"))
    }
}

/// The set signatures that are accepted for signing and validating transactions.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum TransactionSignature {
    Ecdsa(EcdsaSignature),
}

/// The public key type used internally in consensus, alongside `NodeSignature`.
#[derive(Debug, Clone, Copy, PartialEq)]
pub struct NodePublicKey(PublicKey<Bls12381G2Impl>);

impl NodePublicKey {
    pub fn from_bytes(bytes: &[u8]) -> Result<NodePublicKey> {
        Ok(NodePublicKey(PublicKey::<Bls12381G2Impl>::try_from(bytes)?))
    }

    pub fn as_bytes(&self) -> Vec<u8> {
        self.0.0.to_compressed().to_vec()
    }

    pub fn verify(&self, message: &[u8], signature: BlsSignature) -> Result<()> {
        if signature.0.verify(&self.0, message).is_err() {
            return Err(anyhow!("invalid signature"));
        }
        Ok(())
    }
}

impl Display for NodePublicKey {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", hex::encode(self.as_bytes()))
    }
}

impl serde::Serialize for NodePublicKey {
    fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        hex::encode(self.as_bytes()).serialize(serializer)
    }
}

impl<'de> Deserialize<'de> for NodePublicKey {
    fn deserialize<D>(deserializer: D) -> std::result::Result<Self, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        let s = <String>::deserialize(deserializer)?;
        let bytes = hex::decode(s).unwrap();
        NodePublicKey::from_bytes(&bytes)
            .map_err(|_| de::Error::invalid_value(Unexpected::Bytes(&bytes), &"a public key"))
    }
}

/// The set of public keys that are accepted for signing and validating transactions, each
/// corresponding to a variant of `TransactionSignature`.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum TransactionPublicKey {
    /// Ethereum-compatible ECDA signatures. The second element determines whether
    /// it is used for EIP155 compatible signatures (if false, assumes legacy ones).
    Ecdsa(VerifyingKey, bool),
}

impl TransactionPublicKey {
    pub fn verify(&self, message: &[u8], signature: TransactionSignature) -> Result<()> {
        let result = match (self, signature) {
            (TransactionPublicKey::Ecdsa(pubkey, _), TransactionSignature::Ecdsa(sig)) => {
                pubkey.verify_prehash(message, &sig).map_err(|e| anyhow!(e))
            }
            #[allow(unreachable_patterns)] // will be necessary with >1 signature types
            _ => Err(anyhow!("Mismatch between signature and public key type!")),
        };
        result.map_err(|_| anyhow!("Invalid signature"))
    }

    pub fn into_addr(&self) -> Address {
        let bytes = match self {
            Self::Ecdsa(key, _) => {
                // Remove the first byte before hashing - The first byte specifies the encoding tag.
                key.to_encoded_point(false).as_bytes()[1..].to_owned()
            }
        };
        Address::from_slice(&Keccak256::digest(bytes)[12..32])
    }
}
/// The secret key type used as the basis of all cryptography in the node.
/// Any of the `NodePublicKey` or `TransactionPublicKey`s, or a libp2p identity, can be derived
/// from this.
#[derive(Debug, Deserialize, Clone, Copy)]
pub struct SecretKey {
    bytes: [u8; 32],
}

impl SecretKey {
    /// Generates a random private key.
    pub fn new() -> Result<SecretKey> {
        let bls_temp = Bls12381G2::new_secret_key();
        Self::from_bytes(&bls_temp.to_be_bytes())
    }

    pub fn new_from_rng<R: rand::Rng + rand::CryptoRng>(rng: &mut R) -> Result<SecretKey> {
        let bls_temp = Bls12381G2::random_secret_key(rng);
        Self::from_bytes(&bls_temp.to_be_bytes())
    }

    pub fn from_bytes(bytes: &[u8]) -> Result<SecretKey> {
        let bytes: [u8; 32] = bytes.try_into()?;

        if bytes == [0; 32] {
            return Err(anyhow!("bytes are all zero"));
        }

        Ok(SecretKey { bytes })
    }

    pub fn from_hex(s: &str) -> Result<SecretKey> {
        let bytes_vec = hex::decode(s)?;
        Self::from_bytes(&bytes_vec)
    }

    pub fn as_bls(&self) -> blsful::SecretKey<Bls12381G2Impl> {
        blsful::SecretKey::<Bls12381G2Impl>::from_hash(self.bytes)
    }

    // Used in deposit_v2
    pub fn pop_prove(&self) -> blsful::ProofOfPossession<Bls12381G2Impl> {
        let sk = blsful::SecretKey::<Bls12381G2Impl>::from_hash(self.bytes);
        sk.proof_of_possession().expect("sk != 0")
    }

    /// Sigature for staking deposit contract authorisation.
    /// Sign over message made up of validator node's bls public key, chain_id and evm address.
    // Used in deposit_v3
    pub fn deposit_auth_signature(&self, chain_id: u64, address: Address) -> BlsSignature {
        let mut message = [0u8; 76];
        message[..48].copy_from_slice(&self.as_bls().public_key().0.to_compressed());
        message[48..56].copy_from_slice(&chain_id.to_be_bytes());
        message[56..].copy_from_slice(&address.0.to_vec());
        self.sign(&message)
    }

    pub fn as_bytes(&self) -> Vec<u8> {
        self.bytes.to_vec()
    }

    pub fn to_hex(&self) -> String {
        hex::encode(self.bytes)
    }

    pub fn sign(&self, message: &[u8]) -> BlsSignature {
        BlsSignature(
            self.as_bls()
                .sign(blsful::SignatureSchemes::Basic, message)
                .expect("sk != 0"),
        )
    }

    pub fn node_public_key(&self) -> NodePublicKey {
        NodePublicKey(self.as_bls().public_key())
    }

    pub fn to_libp2p_keypair(&self) -> libp2p::identity::Keypair {
        let keypair: libp2p::identity::ed25519::Keypair = libp2p::identity::ed25519::SecretKey::try_from_bytes(self.bytes)
            .expect("`SecretKey::from_bytes` returns an `Err` only when the length is not 32, we know the length is 32")
            .into();
        keypair.into()
    }

    pub fn to_evm_address(&self) -> Address {
        let ecdsa_key = k256::ecdsa::SigningKey::from_slice(&self.bytes).unwrap();
        let tx_pubkey =
            TransactionPublicKey::Ecdsa(k256::ecdsa::VerifyingKey::from(&ecdsa_key), true);
        tx_pubkey.into_addr()
    }
}

#[derive(Clone, Copy, Hash, PartialEq, Eq, PartialOrd, Ord, Serialize, Deserialize)]
pub struct Hash(pub [u8; 32]);

impl Hash {
    pub const ZERO: Hash = Hash([0; Hash::LEN]);
    pub const LEN: usize = 32;

    pub fn builder() -> HashBuilder {
        HashBuilder(Keccak256::new())
    }

    pub fn from_bytes(bytes: impl AsRef<[u8]>) -> Result<Self> {
        let bytes = bytes.as_ref();
        Ok(Hash(bytes.try_into()?))
    }

    pub fn as_bytes(&self) -> &[u8] {
        &self.0
    }
}

impl From<B256> for Hash {
    fn from(value: B256) -> Self {
        Self(value.0)
    }
}

impl From<Hash> for B256 {
    fn from(value: Hash) -> Self {
        Self(value.0)
    }
}

impl TryFrom<&[u8]> for Hash {
    type Error = anyhow::Error;
    fn try_from(value: &[u8]) -> std::result::Result<Self, Self::Error> {
        Ok(Self(<[u8; 32]>::try_from(value)?))
    }
}

impl Display for Hash {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", hex::encode(self.as_bytes()))
    }
}

impl std::fmt::Debug for Hash {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", hex::encode(self.as_bytes()))
    }
}

pub struct HashBuilder(Keccak256);

impl HashBuilder {
    pub fn finalize(self) -> Hash {
        Hash(self.0.finalize().into())
    }

    pub fn with(mut self, bytes: impl AsRef<[u8]>) -> Self {
        self.0.update(bytes.as_ref());

        self
    }

    pub fn with_optional(self, bytes_optional: Option<impl AsRef<[u8]>>) -> Self {
        if let Some(bytes) = bytes_optional {
            self.with(bytes)
        } else {
            self
        }
    }

    pub fn with_iter<T: AsRef<[u8]>>(mut self, bytes_iter: impl Iterator<Item = T>) -> Self {
        bytes_iter.for_each(|bytes| self.0.update(bytes.as_ref()));

        self
    }
}

```

`zilliqa/src/db.rs`:

```rs
use std::{
    collections::BTreeMap,
    fmt::Debug,
    fs::{self, File, OpenOptions},
    io::{BufReader, BufWriter, Read, Seek, SeekFrom, Write},
    ops::RangeInclusive,
    path::{Path, PathBuf},
    sync::{Arc, Mutex},
    time::Duration,
};

use alloy::primitives::Address;
use anyhow::{Context, Result, anyhow};
use eth_trie::{DB, EthTrie, MemoryDB, Trie};
use itertools::Itertools;
use lru_mem::LruCache;
use lz4::{Decoder, EncoderBuilder};
use rusqlite::{
    Connection, OptionalExtension, Row, ToSql, named_params,
    types::{FromSql, FromSqlError, ToSqlOutput},
};
use serde::{Deserialize, Serialize};
use tracing::{debug, warn};

use crate::{
    crypto::{BlsSignature, Hash},
    exec::{ScillaError, ScillaException, ScillaTransition},
    message::{AggregateQc, Block, BlockHeader, QuorumCertificate},
    state::Account,
    time::SystemTime,
    transaction::{EvmGas, Log, SignedTransaction, TransactionReceipt, VerifiedTransaction},
};

macro_rules! sqlify_with_bincode {
    ($type: ty) => {
        impl ToSql for $type {
            fn to_sql(&self) -> rusqlite::Result<ToSqlOutput<'_>> {
                let data = bincode::serialize(self)
                    .map_err(|e| rusqlite::Error::ToSqlConversionFailure(e))?;
                Ok(ToSqlOutput::from(data))
            }
        }
        impl FromSql for $type {
            fn column_result(
                value: rusqlite::types::ValueRef<'_>,
            ) -> rusqlite::types::FromSqlResult<Self> {
                let blob = value.as_blob()?;
                bincode::deserialize(blob).map_err(|e| FromSqlError::Other(e))
            }
        }
    };
}

/// Creates a thin wrapper for a type with proper From traits. To ease implementing To/FromSql on
/// foreign types.
macro_rules! make_wrapper {
    ($old: ty, $new: ident) => {
        paste::paste! {
            #[derive(Serialize, Deserialize)]
            struct $new($old);

            impl From<$old> for $new {
                fn from(value: $old) -> Self {
                    Self(value)
                }
            }

            impl From<$new> for $old {
                fn from(value: $new) -> Self {
                    value.0
                }
            }
        }
    };
}

sqlify_with_bincode!(AggregateQc);
sqlify_with_bincode!(QuorumCertificate);
sqlify_with_bincode!(BlsSignature);
sqlify_with_bincode!(SignedTransaction);

make_wrapper!(Vec<ScillaException>, VecScillaExceptionSqlable);
sqlify_with_bincode!(VecScillaExceptionSqlable);
make_wrapper!(BTreeMap<u64, Vec<ScillaError>>, MapScillaErrorSqlable);
sqlify_with_bincode!(MapScillaErrorSqlable);

make_wrapper!(Vec<Log>, VecLogSqlable);
sqlify_with_bincode!(VecLogSqlable);

make_wrapper!(Vec<ScillaTransition>, VecScillaTransitionSqlable);
sqlify_with_bincode!(VecScillaTransitionSqlable);

make_wrapper!(SystemTime, SystemTimeSqlable);
impl ToSql for SystemTimeSqlable {
    fn to_sql(&self) -> rusqlite::Result<ToSqlOutput<'_>> {
        use std::mem::size_of;

        let since_epoch = self.0.duration_since(SystemTime::UNIX_EPOCH).unwrap();

        let mut buf = [0u8; size_of::<u64>() + size_of::<u32>()];

        buf[..size_of::<u64>()].copy_from_slice(&since_epoch.as_secs().to_be_bytes()[..]);
        buf[size_of::<u64>()..].copy_from_slice(&since_epoch.subsec_nanos().to_be_bytes()[..]);

        Ok(ToSqlOutput::from(buf.to_vec()))
    }
}
impl FromSql for SystemTimeSqlable {
    fn column_result(value: rusqlite::types::ValueRef<'_>) -> rusqlite::types::FromSqlResult<Self> {
        use std::mem::size_of;

        let blob = value.as_blob()?;

        if blob.len() != size_of::<u64>() + size_of::<u32>() {
            return Err(FromSqlError::InvalidBlobSize {
                expected_size: size_of::<u64>() + size_of::<u32>(),
                blob_size: blob.len(),
            });
        }

        let mut secs_buf = [0u8; size_of::<u64>()];
        let mut subsec_nanos_buf = [0u8; size_of::<u32>()];

        secs_buf.copy_from_slice(&blob[..size_of::<u64>()]);
        subsec_nanos_buf.copy_from_slice(&blob[size_of::<u64>()..]);

        let secs = u64::from_be_bytes(secs_buf);
        let subsec_nanos = u32::from_be_bytes(subsec_nanos_buf);

        Ok(SystemTimeSqlable(
            SystemTime::UNIX_EPOCH + Duration::new(secs, subsec_nanos),
        ))
    }
}

make_wrapper!(Address, AddressSqlable);
impl ToSql for AddressSqlable {
    fn to_sql(&self) -> rusqlite::Result<ToSqlOutput<'_>> {
        Ok(ToSqlOutput::from(self.0.as_slice()))
    }
}
impl FromSql for AddressSqlable {
    fn column_result(value: rusqlite::types::ValueRef<'_>) -> rusqlite::types::FromSqlResult<Self> {
        Ok(AddressSqlable(Address::from(<[u8; 20]>::column_result(
            value,
        )?)))
    }
}

impl ToSql for Hash {
    fn to_sql(&self) -> rusqlite::Result<rusqlite::types::ToSqlOutput<'_>> {
        Ok(ToSqlOutput::from(self.0.to_vec()))
    }
}
impl FromSql for Hash {
    fn column_result(value: rusqlite::types::ValueRef<'_>) -> rusqlite::types::FromSqlResult<Self> {
        Ok(Hash(<[u8; 32]>::column_result(value)?))
    }
}

impl ToSql for EvmGas {
    fn to_sql(&self) -> rusqlite::Result<ToSqlOutput<'_>> {
        self.0.to_sql()
    }
}

impl FromSql for EvmGas {
    fn column_result(value: rusqlite::types::ValueRef<'_>) -> rusqlite::types::FromSqlResult<Self> {
        Ok(Self(u64::column_result(value)?))
    }
}

enum BlockFilter {
    Hash(Hash),
    View(u64),
    Height(u64),
    MaxHeight,
    MaxCanonicalByHeight,
}

const CHECKPOINT_HEADER_BYTES: [u8; 8] = *b"ZILCHKPT";

/// Version string that is written to disk along with the persisted database. This should be bumped whenever we make a
/// backwards incompatible change to our database format. This should be done rarely, since it forces all node
/// operators to re-sync.
const CURRENT_DB_VERSION: &str = "1";

#[derive(Debug)]
pub struct Db {
    db: Arc<Mutex<Connection>>,
    state_cache: Arc<Mutex<LruCache<Vec<u8>, Vec<u8>>>>,
    path: Option<Box<Path>>,
    /// The block height at which ZQ2 blocks begin.
    /// This value should be required only for proto networks to distinguise between ZQ1 and ZQ2 blocks.
    executable_blocks_height: Option<u64>,
}

impl Db {
    pub fn new<P>(
        data_dir: Option<P>,
        shard_id: u64,
        state_cache_size: usize,
        executable_blocks_height: Option<u64>,
    ) -> Result<Self>
    where
        P: AsRef<Path>,
    {
        let (connection, path) = match data_dir {
            Some(path) => {
                let path = path.as_ref().join(shard_id.to_string());
                fs::create_dir_all(&path).context(format!("Unable to create {path:?}"))?;

                let mut version_file = OpenOptions::new()
                    .create(true)
                    .truncate(false)
                    .read(true)
                    .write(true)
                    .open(path.join("version"))?;
                let mut version = String::new();
                version_file.read_to_string(&mut version)?;

                if !version.is_empty() && version != CURRENT_DB_VERSION {
                    return Err(anyhow!(
                        "data is incompatible with this version - please delete the data and re-sync"
                    ));
                }

                version_file.seek(SeekFrom::Start(0))?;
                version_file.write_all(CURRENT_DB_VERSION.as_bytes())?;

                let db_path = path.join("db.sqlite3");
                (
                    Connection::open(&db_path)
                        .context(format!("Cannot access sqlite db {0:?}", &db_path))?,
                    Some(path.into_boxed_path()),
                )
            }
            None => (Connection::open_in_memory()?, None),
        };

        // SQLite performance tweaks

        // large page_size is more compact/efficient
        connection.pragma_update(None, "page_size", 1 << 15)?;
        let page_size: i32 = connection.pragma_query_value(None, "page_size", |r| r.get(0))?;

        // reduced non-critical fsync() calls
        connection.pragma_update(None, "synchronous", "NORMAL")?;
        let synchronous: i8 = connection.pragma_query_value(None, "synchronous", |r| r.get(0))?;

        // store temporary tables/indices in-memory
        connection.pragma_update(None, "temp_store", "MEMORY")?;
        let temp_store: i8 = connection.pragma_query_value(None, "temp_store", |r| r.get(0))?;

        // general read/write performance improvement
        let journal_mode: String =
            connection.pragma_update_and_check(None, "journal_mode", "WAL", |r| r.get(0))?;

        // retain journal size of 32MB - based on observations
        let journal_size_limit: i32 =
            connection
                .pragma_update_and_check(None, "journal_size_limit", 1 << 25, |r| r.get(0))?;

        // cache 1-days data (256MB) in-memory
        connection.pragma_update(None, "cache_size", (1 << 28) / page_size)?;
        let cache_size: i32 = connection.pragma_query_value(None, "cache_size", |r| r.get(0))?;

        // increase size of prepared cache
        connection.set_prepared_statement_cache_capacity(128); // default is 16, which is small

        // enable QPSG - https://github.com/Zilliqa/zq2/issues/2870
        if !connection.set_db_config(
            rusqlite::config::DbConfig::SQLITE_DBCONFIG_ENABLE_QPSG,
            true,
        )? {
            tracing::warn!("QPSG disabled");
        }

        tracing::info!(
            ?journal_mode,
            ?journal_size_limit,
            ?synchronous,
            ?temp_store,
            ?page_size,
            ?cache_size,
            "PRAGMA"
        );

        // Add tracing - logs all SQL statements
        connection.trace_v2(
            rusqlite::trace::TraceEventCodes::SQLITE_TRACE_PROFILE,
            Some(|profile_event| {
                if let rusqlite::trace::TraceEvent::Profile(statement, duration) = profile_event {
                    let statement_txt = statement.expanded_sql();
                    let duration_secs = duration.as_secs();
                    tracing::trace!(duration_secs, statement_txt, "sql executed");
                    if duration_secs > 5 {
                        tracing::warn!(duration_secs, statement_txt, "sql execution took > 5s");
                    }
                }
            }),
        );

        Self::ensure_schema(&connection)?;

        Ok(Db {
            db: Arc::new(Mutex::new(connection)),
            state_cache: Arc::new(Mutex::new(LruCache::new(state_cache_size))),
            path,
            executable_blocks_height,
        })
    }

    fn ensure_schema(connection: &Connection) -> Result<()> {
        connection.execute_batch(
            "CREATE TABLE IF NOT EXISTS blocks (
                block_hash BLOB NOT NULL PRIMARY KEY,
                view INTEGER NOT NULL UNIQUE,
                height INTEGER NOT NULL,
                signature BLOB NOT NULL,
                state_root_hash BLOB NOT NULL,
                transactions_root_hash BLOB NOT NULL,
                receipts_root_hash BLOB NOT NULL,
                timestamp BLOB NOT NULL,
                gas_used INTEGER NOT NULL,
                gas_limit INTEGER NOT NULL,
                qc BLOB NOT NULL,
                agg BLOB,
                is_canonical BOOLEAN NOT NULL) WITHOUT ROWID;
            CREATE INDEX IF NOT EXISTS idx_blocks_height ON blocks(height);
            CREATE TABLE IF NOT EXISTS transactions (
                tx_hash BLOB NOT NULL PRIMARY KEY,
                data BLOB NOT NULL) WITHOUT ROWID;
            CREATE TABLE IF NOT EXISTS receipts (
                tx_hash BLOB NOT NULL PRIMARY KEY REFERENCES transactions (tx_hash) ON DELETE CASCADE,
                block_hash BLOB NOT NULL REFERENCES blocks (block_hash), -- the touched_address_index needs to be updated for all the txs in the block, so delete txs first - thus no cascade here
                tx_index INTEGER NOT NULL,
                success INTEGER NOT NULL,
                gas_used INTEGER NOT NULL,
                cumulative_gas_used INTEGER NOT NULL,
                contract_address BLOB,
                logs BLOB,
                transitions BLOB,
                accepted INTEGER,
                errors BLOB,
                exceptions BLOB);
            CREATE INDEX IF NOT EXISTS block_hash_index ON receipts (block_hash);
            CREATE TABLE IF NOT EXISTS touched_address_index (
                address BLOB,
                tx_hash BLOB REFERENCES transactions (tx_hash) ON DELETE CASCADE,
                PRIMARY KEY (address, tx_hash)) WITHOUT ROWID;
            CREATE TABLE IF NOT EXISTS tip_info (
                finalized_view INTEGER,
                view INTEGER,
                high_qc BLOB,
                high_qc_updated_at BLOB,
                _single_row INTEGER DEFAULT 0 NOT NULL UNIQUE CHECK (_single_row = 0)); -- max 1 row
            CREATE TABLE IF NOT EXISTS state_trie (key BLOB NOT NULL PRIMARY KEY, value BLOB NOT NULL) WITHOUT ROWID;
            ",
        )?;
        connection.execute_batch("
            CREATE TABLE IF NOT EXISTS schema_version (version INTEGER NOT NULL PRIMARY KEY) WITHOUT ROWID;
        ")?;
        // No version entries implies we are on version 0.
        let version = connection
            .query_row("SELECT MAX(version) FROM schema_version", [], |row| {
                row.get::<_, Option<u32>>(0)
            })?
            .unwrap_or_default();

        if version < 1 {
            connection.execute_batch(
                "
                BEGIN;

                INSERT INTO schema_version VALUES (1);

                ALTER TABLE tip_info ADD COLUMN voted_in_view BOOLEAN NOT NULL DEFAULT FALSE;

                COMMIT;
            ",
            )?;
        }

        if version < 2 {
            connection.execute_batch(
                "
                BEGIN;

                INSERT INTO schema_version VALUES (2);

                CREATE TABLE new_receipts (
                    tx_hash BLOB NOT NULL REFERENCES transactions (tx_hash),
                    block_hash BLOB NOT NULL REFERENCES blocks (block_hash),
                    tx_index INTEGER NOT NULL,
                    success INTEGER NOT NULL,
                    gas_used INTEGER NOT NULL,
                    cumulative_gas_used INTEGER NOT NULL,
                    contract_address BLOB,
                    logs BLOB,
                    transitions BLOB,
                    accepted INTEGER,
                    errors BLOB,
                    exceptions BLOB,
                    PRIMARY KEY (block_hash, tx_hash)
                );
                INSERT INTO new_receipts SELECT * FROM receipts;
                DROP TABLE receipts;
                ALTER TABLE new_receipts RENAME TO receipts;
                CREATE INDEX block_hash_index ON receipts (block_hash);

                COMMIT;
            ",
            )?;
        }

        if version < 3 {
            connection.execute_batch(
                "
                BEGIN;

                INSERT INTO schema_version VALUES (3);

                CREATE INDEX idx_receipts_tx_hash ON receipts (tx_hash);

                COMMIT;
            ",
            )?;
        }

        Ok(())
    }

    pub fn get_checkpoint_dir(&self) -> Result<Option<Box<Path>>> {
        let Some(base_path) = &self.path else {
            // If we don't have on-disk persistency, disable checkpoints too
            warn!(
                "Attempting to create checkpoint, but no persistence directory has been configured"
            );
            return Ok(None);
        };
        Ok(Some(base_path.join("checkpoints").into_boxed_path()))
    }

    /// Returns the lowest and highest block numbers of stored blocks
    pub fn available_range(&self) -> Result<RangeInclusive<u64>> {
        let db = self.db.lock().unwrap();
        // Doing it together is slow
        // sqlite> EXPLAIN QUERY PLAN SELECT MIN(height), MAX(height) FROM blocks;
        // QUERY PLAN
        // `--SCAN blocks USING COVERING INDEX idx_blocks_height
        let min = db
            .prepare_cached("SELECT MIN(height) FROM blocks")?
            .query_row([], |row| row.get::<_, u64>(0))
            .optional()?
            .unwrap_or_default();
        let max = db
            .prepare_cached("SELECT MAX(height) FROM blocks")?
            .query_row([], |row| row.get::<_, u64>(0))
            .optional()?
            .unwrap_or_default();
        Ok(min..=max)
    }

    /// Fetch checkpoint data from file and initialise db state
    /// Return checkpointed block and transactions which must be executed after this function
    /// Return None if checkpoint already loaded
    pub fn load_trusted_checkpoint<P: AsRef<Path>>(
        &self,
        path: P,
        hash: &Hash,
        our_shard_id: u64,
    ) -> Result<Option<(Block, Vec<SignedTransaction>, Block)>> {
        // For now, only support a single version: you want to load the latest checkpoint, anyway.
        const SUPPORTED_VERSION: u32 = 3;

        // Decompress file and write to temp file
        let input_file = File::open(path.as_ref())?;
        let buf_reader: BufReader<File> = BufReader::with_capacity(128 * 1024 * 1024, input_file);
        let mut reader = Decoder::new(buf_reader)?;
        let trie_storage = Arc::new(self.state_trie()?);
        let mut state_trie = EthTrie::new(trie_storage.clone());

        // Decode and validate header
        let mut header: [u8; 21] = [0u8; 21];
        reader.read_exact(&mut header)?;
        let header = header;
        if header[0..8] != CHECKPOINT_HEADER_BYTES // magic bytes
            || header[20] != b'\n'
        // header must end in newline
        {
            return Err(anyhow!("Invalid checkpoint file: invalid header"));
        }
        let version = u32::from_be_bytes(header[8..12].try_into()?);
        // Only support a single version right now.
        if version != SUPPORTED_VERSION {
            return Err(anyhow!("Invalid checkpoint file: unsupported version."));
        }
        let shard_id = u64::from_be_bytes(header[12..20].try_into()?);
        if shard_id != our_shard_id {
            return Err(anyhow!("Invalid checkpoint file: wrong shard ID."));
        }

        // Decode and validate checkpoint block, its transactions and parent block
        let mut block_len_buf = [0u8; std::mem::size_of::<u64>()];
        reader.read_exact(&mut block_len_buf)?;
        let mut block_ser = vec![0u8; usize::try_from(u64::from_be_bytes(block_len_buf))?];
        reader.read_exact(&mut block_ser)?;
        let block: Block = bincode::deserialize(&block_ser)?;
        if block.hash() != *hash {
            return Err(anyhow!("Checkpoint does not match trusted hash"));
        }
        block.verify_hash()?;

        let mut transactions_len_buf = [0u8; std::mem::size_of::<u64>()];
        reader.read_exact(&mut transactions_len_buf)?;
        let mut transactions_ser =
            vec![0u8; usize::try_from(u64::from_be_bytes(transactions_len_buf))?];
        reader.read_exact(&mut transactions_ser)?;
        let transactions: Vec<SignedTransaction> = bincode::deserialize(&transactions_ser)?;

        let mut parent_len_buf = [0u8; std::mem::size_of::<u64>()];
        reader.read_exact(&mut parent_len_buf)?;
        let mut parent_ser = vec![0u8; usize::try_from(u64::from_be_bytes(parent_len_buf))?];
        reader.read_exact(&mut parent_ser)?;
        let parent: Block = bincode::deserialize(&parent_ser)?;
        if block.parent_hash() != parent.hash() {
            return Err(anyhow!(
                "Invalid checkpoint file: parent's blockhash does not correspond to checkpoint block"
            ));
        }

        if state_trie.iter().next().is_some()
            || self.get_highest_canonical_block_number()?.is_some()
        {
            // If checkpointed block already exists then assume checkpoint load already complete. Return None
            if self.get_block_by_hash(&block.hash())?.is_some() {
                return Ok(None);
            }
            // This may not be strictly necessary, as in theory old values will, at worst, be orphaned
            // values not part of any state trie of any known block. With some effort, this could
            // even be supported.
            // However, without such explicit support, having old blocks MAY in fact cause
            // unexpected and unwanted behaviour. Thus we currently forbid loading a checkpoint in
            // a node that already contains previous state, until (and unless) there's ever a
            // usecase for going through the effort to support it and ensure it works as expected.
            if let Some(db_block) = self.get_block_by_hash(&parent.hash())? {
                if db_block.parent_hash() != parent.parent_hash() {
                    return Err(anyhow!(
                        "Inconsistent checkpoint file: block loaded from checkpoint and block stored in database with same hash have differing parent hashes"
                    ));
                } else {
                    // In this case, the database already has the block contained in this checkpoint. We assume the
                    // database contains the full state for that block too and thus return early, without actually
                    // loading the checkpoint file.
                    return Ok(Some((block, transactions, parent)));
                }
            } else {
                return Err(anyhow!(
                    "Inconsistent checkpoint file: block loaded from checkpoint file does not exist in non-empty database"
                ));
            }
        }

        // Helper function used for inserting entries from memory (which backs storage trie) into persistent storage
        let db_flush = |db: Arc<TrieStorage>, cache: Arc<MemoryDB>| -> Result<()> {
            let mut cache_storage = cache.storage.write();
            let (keys, values): (Vec<_>, Vec<_>) = cache_storage.drain().unzip();
            debug!("Doing write to db with total items {}", keys.len());
            db.insert_batch(keys, values)?;
            Ok(())
        };

        let mut processed_accounts = 0;
        let mut processed_storage_items = 0;
        // This is taken directly from batch_write. However, this can be as big as we think it's reasonable to be
        // (ideally multiples of `32766 / 2` so that batch writes are fully utilized)
        // TODO: consider putting this const somewhere else as long as we use sql-lite
        // Also see: https://www.sqlite.org/limits.html#max_variable_number
        let maximum_sql_parameters = 32766 / 2;
        const COMPUTE_ROOT_HASH_EVERY_ACCOUNTS: usize = 10000;
        let mem_storage = Arc::new(MemoryDB::new(true));

        // then decode state
        loop {
            // Read account key and the serialised Account
            let mut account_hash = [0u8; 32];
            match reader.read_exact(&mut account_hash) {
                // Read successful
                Ok(_) => (),
                // Break loop here if weve reached the end of the file
                Err(ref e) if e.kind() == std::io::ErrorKind::UnexpectedEof => {
                    break;
                }
                Err(e) => return Err(e.into()),
            };

            let mut serialised_account_len_buf = [0u8; std::mem::size_of::<u64>()];
            reader.read_exact(&mut serialised_account_len_buf)?;
            let mut serialised_account =
                vec![0u8; usize::try_from(u64::from_be_bytes(serialised_account_len_buf))?];
            reader.read_exact(&mut serialised_account)?;

            // Read entire account storage as a buffer
            let mut account_storage_len_buf = [0u8; std::mem::size_of::<u64>()];
            reader.read_exact(&mut account_storage_len_buf)?;
            let account_storage_len = usize::try_from(u64::from_be_bytes(account_storage_len_buf))?;
            let mut account_storage = vec![0u8; account_storage_len];
            reader.read_exact(&mut account_storage)?;

            // Pull out each storage key and value
            let mut account_trie = EthTrie::new(mem_storage.clone());
            let mut pointer: usize = 0;
            while account_storage_len > pointer {
                let storage_key_len_buf: &[u8] =
                    &account_storage[pointer..(pointer + std::mem::size_of::<u64>())];
                let storage_key_len =
                    usize::try_from(u64::from_be_bytes(storage_key_len_buf.try_into()?))?;
                pointer += std::mem::size_of::<u64>();
                let storage_key: &[u8] = &account_storage[pointer..(pointer + storage_key_len)];
                pointer += storage_key_len;

                let storage_val_len_buf: &[u8] =
                    &account_storage[pointer..(pointer + std::mem::size_of::<u64>())];
                let storage_val_len =
                    usize::try_from(u64::from_be_bytes(storage_val_len_buf.try_into()?))?;
                pointer += std::mem::size_of::<u64>();
                let storage_val: &[u8] = &account_storage[pointer..(pointer + storage_val_len)];
                pointer += storage_val_len;

                account_trie.insert(storage_key, storage_val)?;

                processed_storage_items += 1;
            }

            let account_trie_root =
                bincode::deserialize::<Account>(&serialised_account)?.storage_root;
            if account_trie.root_hash()?.as_slice() != account_trie_root {
                return Err(anyhow!(
                    "Invalid checkpoint file: account trie root hash mismatch: calculated {}, checkpoint file contained {}",
                    hex::encode(account_trie.root_hash()?.as_slice()),
                    hex::encode(account_trie_root)
                ));
            }
            if processed_storage_items > maximum_sql_parameters {
                db_flush(trie_storage.clone(), mem_storage.clone())?;
                processed_storage_items = 0;
            }

            state_trie.insert(&account_hash, &serialised_account)?;

            processed_accounts += 1;
            // Occasionally flush the cached state changes to disk to minimise memory usage.
            if processed_accounts % COMPUTE_ROOT_HASH_EVERY_ACCOUNTS == 0 {
                let _ = state_trie.root_hash()?;
            }
        }

        db_flush(trie_storage.clone(), mem_storage.clone())?;

        if state_trie.root_hash()? != parent.state_root_hash().0 {
            return Err(anyhow!("Invalid checkpoint file: state root hash mismatch"));
        }

        let parent_ref: &Block = &parent; // for moving into the closure
        self.with_sqlite_tx(move |tx| {
            self.insert_block_with_db_tx(tx, parent_ref)?;
            self.set_finalized_view_with_db_tx(tx, parent_ref.view())?;
            self.set_high_qc_with_db_tx(tx, block.header.qc)?;
            self.set_view_with_db_tx(tx, parent_ref.view() + 1, false)?;
            Ok(())
        })?;

        Ok(Some((block, transactions, parent)))
    }

    pub fn state_trie(&self) -> Result<TrieStorage> {
        Ok(TrieStorage {
            db: self.db.clone(),
            cache: self.state_cache.clone(),
        })
    }

    pub fn with_sqlite_tx(&self, operations: impl FnOnce(&Connection) -> Result<()>) -> Result<()> {
        let mut sqlite_tx = self.db.lock().unwrap();
        let sqlite_tx = sqlite_tx.transaction()?;
        operations(&sqlite_tx)?;
        Ok(sqlite_tx.commit()?)
    }

    pub fn get_block_hash_by_view(&self, view: u64) -> Result<Option<Hash>> {
        Ok(self
            .db
            .lock()
            .unwrap()
            .prepare_cached("SELECT block_hash FROM blocks WHERE view = ?1")?
            .query_row([view], |row| row.get(0))
            .optional()?)
    }

    pub fn set_finalized_view_with_db_tx(&self, sqlite_tx: &Connection, view: u64) -> Result<()> {
        sqlite_tx
            .prepare_cached("INSERT INTO tip_info (finalized_view) VALUES (?1) ON CONFLICT DO UPDATE SET finalized_view = ?1")?
            .execute([view])?;
        Ok(())
    }

    pub fn set_finalized_view(&self, view: u64) -> Result<()> {
        self.set_finalized_view_with_db_tx(&self.db.lock().unwrap(), view)
    }

    pub fn get_finalized_view(&self) -> Result<Option<u64>> {
        Ok(self
            .db
            .lock()
            .unwrap()
            .prepare_cached("SELECT finalized_view FROM tip_info")?
            .query_row((), |row| row.get(0))
            .optional()
            .unwrap_or(None))
    }

    /// Write view to table if view is larger than current. Return true if write was successful
    pub fn set_view_with_db_tx(
        &self,
        sqlite_tx: &Connection,
        view: u64,
        voted: bool,
    ) -> Result<bool> {
        let res = sqlite_tx
            .prepare_cached("INSERT INTO tip_info (view, voted_in_view) VALUES (?1, ?2) ON CONFLICT(_single_row) DO UPDATE SET view = ?1, voted_in_view = ?2 WHERE tip_info.view IS NULL OR tip_info.view < ?1",)?
            .execute((view, voted))?;
        Ok(res != 0)
    }

    pub fn set_view(&self, view: u64, voted: bool) -> Result<bool> {
        self.set_view_with_db_tx(&self.db.lock().unwrap(), view, voted)
    }

    pub fn get_view(&self) -> Result<Option<u64>> {
        Ok(self
            .db
            .lock()
            .unwrap()
            .prepare_cached("SELECT view FROM tip_info")?
            .query_row((), |row| row.get(0))
            .optional()
            .unwrap_or(None))
    }

    pub fn get_voted_in_view(&self) -> Result<bool> {
        Ok(self
            .db
            .lock()
            .unwrap()
            .prepare_cached("SELECT voted_in_view FROM tip_info")?
            .query_row((), |row| row.get(0))?)
    }

    pub fn get_highest_canonical_block_number(&self) -> Result<Option<u64>> {
        Ok(self
            .db
            .lock()
            .unwrap()
            .prepare_cached("SELECT MAX(height) FROM blocks WHERE is_canonical = 1")?
            .query_row((), |row| {
                row.get(0).map_err(|e| {
                    // workaround where MAX(height) returns NULL if there are no blocks, instead of a NoRows error
                    if let rusqlite::Error::InvalidColumnType(_, _, typ) = e {
                        if typ == rusqlite::types::Type::Null {
                            return rusqlite::Error::QueryReturnedNoRows;
                        }
                    }
                    e
                })
            })
            .optional()?)
    }

    pub fn get_highest_canonical_block(&self) -> Result<Option<Block>> {
        self.get_block(BlockFilter::MaxCanonicalByHeight)
    }

    pub fn set_high_qc_with_db_tx(
        &self,
        sqlite_tx: &Connection,
        high_qc: QuorumCertificate,
    ) -> Result<()> {
        sqlite_tx.prepare_cached("INSERT INTO tip_info (high_qc, high_qc_updated_at) VALUES (:high_qc, :timestamp) ON CONFLICT DO UPDATE SET high_qc = :high_qc, high_qc_updated_at = :timestamp",)?
        .execute(
            named_params! {
                ":high_qc": high_qc,
                ":timestamp": SystemTimeSqlable(SystemTime::now())
            })?;
        Ok(())
    }

    pub fn set_high_qc(&self, high_qc: QuorumCertificate) -> Result<()> {
        self.set_high_qc_with_db_tx(&self.db.lock().unwrap(), high_qc)
    }

    pub fn get_high_qc(&self) -> Result<Option<QuorumCertificate>> {
        Ok(self
            .db
            .lock()
            .unwrap()
            .prepare_cached("SELECT high_qc FROM tip_info")?
            .query_row((), |row| row.get(0))
            .optional()?
            .flatten())
    }

    pub fn get_high_qc_updated_at(&self) -> Result<Option<SystemTime>> {
        Ok(self
            .db
            .lock()
            .unwrap()
            .prepare_cached("SELECT high_qc_updated_at FROM tip_info")?
            .query_row((), |row| row.get::<_, SystemTimeSqlable>(0))
            .optional()
            .unwrap_or(None)
            .map(Into::<SystemTime>::into))
    }

    pub fn add_touched_address_with_db_tx(
        &self,
        sqlite_tx: &Connection,
        address: Address,
        txn_hash: Hash,
    ) -> Result<()> {
        sqlite_tx
            .prepare_cached(
                "INSERT OR IGNORE INTO touched_address_index (address, tx_hash) VALUES (?1, ?2)",
            )?
            .execute((AddressSqlable(address), txn_hash))?;
        Ok(())
    }

    pub fn add_touched_address(&self, address: Address, txn_hash: Hash) -> Result<()> {
        self.add_touched_address_with_db_tx(&self.db.lock().unwrap(), address, txn_hash)
    }

    pub fn get_touched_transactions(&self, address: Address) -> Result<Vec<Hash>> {
        // TODO: this is only ever used in one API, so keep an eye on performance - in case e.g.
        // the index table might need to be denormalised to simplify this lookup
        Ok(self
            .db
            .lock()
            .unwrap()
            .prepare_cached("SELECT tx_hash FROM touched_address_index JOIN receipts USING (tx_hash) JOIN blocks USING (block_hash) WHERE address = ?1 ORDER BY blocks.height, receipts.tx_index")?
            .query_map([AddressSqlable(address)], |row| row.get(0))?
            .collect::<Result<Vec<_>, _>>()?)
    }

    pub fn get_transaction(&self, txn_hash: &Hash) -> Result<Option<VerifiedTransaction>> {
        Ok(
            match self
                .db
                .lock()
                .unwrap()
                .prepare_cached("SELECT data FROM transactions WHERE tx_hash = ?1")?
                .query_row([txn_hash], |row| row.get(0))
                .optional()?
                .map(|x: SignedTransaction| x.verify_bypass())
            {
                Some(x) => Some(x?),
                None => None,
            },
        )
    }

    pub fn contains_transaction(&self, hash: &Hash) -> Result<bool> {
        Ok(self
            .db
            .lock()
            .unwrap()
            .prepare_cached("SELECT 1 FROM transactions WHERE tx_hash = ?1")?
            .query_row([hash], |row| row.get::<_, i64>(0))
            .optional()?
            .is_some())
    }

    pub fn insert_transaction_with_db_tx(
        &self,
        sqlite_tx: &Connection,
        hash: &Hash,
        tx: &VerifiedTransaction,
    ) -> Result<()> {
        sqlite_tx
            .prepare_cached("INSERT OR IGNORE INTO transactions (tx_hash, data) VALUES (?1, ?2)")?
            .execute((hash, tx.tx.clone()))?;
        Ok(())
    }

    /// Insert a transaction whose hash was precalculated, to save a call to calculate_hash() if it
    /// is already known
    pub fn insert_transaction(&self, hash: &Hash, tx: &VerifiedTransaction) -> Result<()> {
        self.insert_transaction_with_db_tx(&self.db.lock().unwrap(), hash, tx)
    }

    pub fn get_block_hash_reverse_index(&self, tx_hash: &Hash) -> Result<Option<Hash>> {
        Ok(self
            .db
            .lock()
            .unwrap()
            .prepare_cached("SELECT r.block_hash FROM receipts r INNER JOIN blocks b ON r.block_hash = b.block_hash WHERE r.tx_hash = ?1 AND b.is_canonical = TRUE")?
            .query_row([tx_hash], |row| row.get(0))
            .optional()?)
    }

    pub fn insert_block_with_db_tx(&self, sqlite_tx: &Connection, block: &Block) -> Result<()> {
        self.insert_block_with_hash_with_db_tx(sqlite_tx, block.hash(), block)
    }

    pub fn insert_block_with_hash_with_db_tx(
        &self,
        sqlite_tx: &Connection,
        hash: Hash,
        block: &Block,
    ) -> Result<()> {
        sqlite_tx.prepare_cached("INSERT INTO blocks
        (block_hash, view, height, qc, signature, state_root_hash, transactions_root_hash, receipts_root_hash, timestamp, gas_used, gas_limit, agg, is_canonical)
    VALUES (:block_hash, :view, :height, :qc, :signature, :state_root_hash, :transactions_root_hash, :receipts_root_hash, :timestamp, :gas_used, :gas_limit, :agg, TRUE)",)?.execute(
            named_params! {
                ":block_hash": hash,
                ":view": block.header.view,
                ":height": block.header.number,
                ":qc": block.header.qc,
                ":signature": block.header.signature,
                ":state_root_hash": block.header.state_root_hash,
                ":transactions_root_hash": block.header.transactions_root_hash,
                ":receipts_root_hash": block.header.receipts_root_hash,
                ":timestamp": SystemTimeSqlable(block.header.timestamp),
                ":gas_used": block.header.gas_used,
                ":gas_limit": block.header.gas_limit,
                ":agg": block.agg,
            })?;
        Ok(())
    }

    pub fn mark_block_as_canonical(&self, hash: Hash) -> Result<()> {
        self.db
            .lock()
            .unwrap()
            .prepare_cached("UPDATE blocks SET is_canonical = TRUE WHERE block_hash = ?1")?
            .execute([hash])?;
        Ok(())
    }

    pub fn mark_block_as_non_canonical(&self, hash: Hash) -> Result<()> {
        self.db
            .lock()
            .unwrap()
            .prepare_cached("UPDATE blocks SET is_canonical = FALSE WHERE block_hash = ?1")?
            .execute([hash])?;
        Ok(())
    }

    pub fn insert_block(&self, block: &Block) -> Result<()> {
        self.insert_block_with_db_tx(&self.db.lock().unwrap(), block)
    }

    pub fn remove_block(&self, block: &Block) -> Result<()> {
        self.db
            .lock()
            .unwrap()
            .prepare_cached("DELETE FROM blocks WHERE block_hash = ?1")?
            .execute([block.header.hash])?;
        Ok(())
    }

    /// Delete the block and its related transactions and receipts
    pub fn prune_block(&self, block: &Block, is_canonical: bool) -> Result<()> {
        let hash = block.hash();
        self.with_sqlite_tx(|db| {
            // get a list of transactions
            let txns = db
                .prepare_cached("SELECT tx_hash FROM receipts WHERE block_hash = ?1")?
                .query_map([hash], |row| row.get(0))?
                .collect::<Result<Vec<Hash>, _>>()?;

            // Delete child row, before deleting parents
            // https://github.com/Zilliqa/zq2/issues/2216#issuecomment-2812501876
            db.prepare_cached("DELETE FROM receipts WHERE block_hash = ?1")?
                .execute([hash])?;

            // Delete the block after all references are deleted
            db.prepare_cached("DELETE FROM blocks WHERE block_hash = ?1")?
                .execute([hash])?;

            // Delete all other references to this list of txns
            if is_canonical {
                for tx in txns {
                    // Deletes all other references to this txn; txn can only exist in one canonical block.
                    db.prepare_cached("DELETE FROM receipts WHERE tx_hash = ?1")?
                        .execute([tx])?;
                    // Delete the txn itself after all references are deleted
                    db.prepare_cached("DELETE FROM transactions WHERE tx_hash = ?1")?
                        .execute([tx])?;
                }
            }
            Ok(())
        })
    }

    pub fn get_blocks_by_height(&self, height: u64) -> Result<Vec<Block>> {
        let rows = self
            .db
            .lock()
            .unwrap()
            .prepare_cached("SELECT block_hash, view, height, qc, signature, state_root_hash, transactions_root_hash, receipts_root_hash, timestamp, gas_used, gas_limit, agg FROM blocks WHERE height = ?1")?
            .query_map([height], |row| Ok(Block {
                header: BlockHeader {
                    hash: row.get(0)?,
                    view: row.get(1)?,
                    number: row.get(2)?,
                    qc: row.get(3)?,
                    signature: row.get(4)?,
                    state_root_hash: row.get(5)?,
                    transactions_root_hash: row.get(6)?,
                    receipts_root_hash: row.get(7)?,
                    timestamp: row.get::<_, SystemTimeSqlable>(8)?.into(),
                    gas_used: row.get(9)?,
                    gas_limit: row.get(10)?,
                },
                agg: row.get(11)?,
                transactions: vec![],
            })
        )?.collect::<Result<Vec<_>, _>>()?;
        Ok(rows)
    }

    fn get_transactionless_block(&self, filter: BlockFilter) -> Result<Option<Block>> {
        fn make_block(row: &Row) -> rusqlite::Result<Block> {
            Ok(Block {
                header: BlockHeader {
                    hash: row.get(0)?,
                    view: row.get(1)?,
                    number: row.get(2)?,
                    qc: row.get(3)?,
                    signature: row.get(4)?,
                    state_root_hash: row.get(5)?,
                    transactions_root_hash: row.get(6)?,
                    receipts_root_hash: row.get(7)?,
                    timestamp: row.get::<_, SystemTimeSqlable>(8)?.into(),
                    gas_used: row.get(9)?,
                    gas_limit: row.get(10)?,
                },
                agg: row.get(11)?,
                transactions: vec![],
            })
        }
        macro_rules! query_block {
            ($cond: tt $(, $key:tt)*) => {
                self.db.lock().unwrap().prepare_cached(concat!("SELECT block_hash, view, height, qc, signature, state_root_hash, transactions_root_hash, receipts_root_hash, timestamp, gas_used, gas_limit, agg FROM blocks WHERE ", $cond),)?.query_row([$($key),*], make_block).optional()?
            };
        }
        // Remember to add to `query_planner_stability_guarantee()` test below
        Ok(match filter {
            BlockFilter::Hash(hash) => {
                query_block!("block_hash = ?1", hash)
            }
            BlockFilter::View(view) => {
                query_block!("view = ?1", view)
            }
            BlockFilter::Height(height) => {
                query_block!("height = ?1 AND is_canonical = TRUE", height)
            }
            // Compound SQL queries below, due to - https://github.com/Zilliqa/zq2/issues/2629
            BlockFilter::MaxCanonicalByHeight => {
                query_block!(
                    "is_canonical = true AND height = (SELECT MAX(height) FROM blocks WHERE is_canonical = TRUE)"
                )
            }
            BlockFilter::MaxHeight => {
                query_block!("height = (SELECT MAX(height) FROM blocks) LIMIT 1")
            }
        })
    }

    fn get_block(&self, filter: BlockFilter) -> Result<Option<Block>> {
        let Some(mut block) = self.get_transactionless_block(filter)? else {
            return Ok(None);
        };
        if self.executable_blocks_height.is_some()
            && block.header.number < self.executable_blocks_height.unwrap()
        {
            debug!("fetched ZQ1 block so setting state root hash to zeros");
            block.header.state_root_hash = Hash::ZERO;
        }
        let transaction_hashes = self
            .db
            .lock()
            .unwrap()
            .prepare_cached(
                "SELECT tx_hash FROM receipts WHERE block_hash = ?1 ORDER BY tx_index ASC",
            )?
            .query_map([block.header.hash], |row| row.get(0))?
            .collect::<Result<Vec<Hash>, _>>()?;
        block.transactions = transaction_hashes;
        Ok(Some(block))
    }

    pub fn get_block_by_hash(&self, block_hash: &Hash) -> Result<Option<Block>> {
        self.get_block(BlockFilter::Hash(*block_hash))
    }

    pub fn get_block_by_view(&self, view: u64) -> Result<Option<Block>> {
        self.get_block(BlockFilter::View(view))
    }

    pub fn get_canonical_block_by_number(&self, number: u64) -> Result<Option<Block>> {
        self.get_block(BlockFilter::Height(number))
    }

    pub fn get_highest_recorded_block(&self) -> Result<Option<Block>> {
        self.get_block(BlockFilter::MaxHeight)
    }

    pub fn contains_block(&self, block_hash: &Hash) -> Result<bool> {
        Ok(self
            .db
            .lock()
            .unwrap()
            .prepare_cached("SELECT 1 FROM blocks WHERE block_hash = ?1")?
            .query_row([block_hash], |row| row.get::<_, i64>(0))
            .optional()?
            .is_some())
    }

    pub fn contains_canonical_block(&self, block_hash: &Hash) -> Result<bool> {
        Ok(self
            .db
            .lock()
            .unwrap()
            .prepare_cached("SELECT 1 FROM blocks WHERE is_canonical = TRUE AND block_hash = ?1")?
            .query_row([block_hash], |row| row.get::<_, i64>(0))
            .optional()?
            .is_some())
    }

    fn make_receipt(row: &Row) -> rusqlite::Result<TransactionReceipt> {
        Ok(TransactionReceipt {
            tx_hash: row.get(0)?,
            block_hash: row.get(1)?,
            index: row.get(2)?,
            success: row.get(3)?,
            gas_used: row.get(4)?,
            cumulative_gas_used: row.get(5)?,
            contract_address: row.get::<_, Option<AddressSqlable>>(6)?.map(|a| a.into()),
            logs: row.get::<_, VecLogSqlable>(7)?.into(),
            transitions: row.get::<_, VecScillaTransitionSqlable>(8)?.into(),
            accepted: row.get(9)?,
            errors: row.get::<_, MapScillaErrorSqlable>(10)?.into(),
            exceptions: row.get::<_, VecScillaExceptionSqlable>(11)?.into(),
        })
    }

    pub fn insert_transaction_receipt_with_db_tx(
        &self,
        sqlite_tx: &Connection,
        receipt: TransactionReceipt,
    ) -> Result<()> {
        sqlite_tx.prepare_cached("INSERT OR IGNORE INTO receipts
                (tx_hash, block_hash, tx_index, success, gas_used, cumulative_gas_used, contract_address, logs, transitions, accepted, errors, exceptions)
            VALUES (:tx_hash, :block_hash, :tx_index, :success, :gas_used, :cumulative_gas_used, :contract_address, :logs, :transitions, :accepted, :errors, :exceptions)",)?.execute(
            named_params! {
                ":tx_hash": receipt.tx_hash,
                ":block_hash": receipt.block_hash,
                ":tx_index": receipt.index,
                ":success": receipt.success,
                ":gas_used": receipt.gas_used,
                ":cumulative_gas_used": receipt.cumulative_gas_used,
                ":contract_address": receipt.contract_address.map(AddressSqlable),
                ":logs": VecLogSqlable(receipt.logs),
                ":transitions": VecScillaTransitionSqlable(receipt.transitions),
                ":accepted": receipt.accepted,
                ":errors": MapScillaErrorSqlable(receipt.errors),
                ":exceptions": VecScillaExceptionSqlable(receipt.exceptions),
            })?;

        Ok(())
    }

    pub fn insert_transaction_receipt(&self, receipt: TransactionReceipt) -> Result<()> {
        self.insert_transaction_receipt_with_db_tx(&self.db.lock().unwrap(), receipt)
    }

    pub fn get_transaction_receipt(&self, txn_hash: &Hash) -> Result<Option<TransactionReceipt>> {
        Ok(self.db.lock().unwrap().prepare_cached("SELECT tx_hash, block_hash, tx_index, success, gas_used, cumulative_gas_used, contract_address, logs, transitions, accepted, errors, exceptions FROM receipts WHERE tx_hash = ?1",)?.query_row( [txn_hash], Self::make_receipt).optional()?)
    }

    pub fn get_transaction_receipts_in_block(
        &self,
        block_hash: &Hash,
    ) -> Result<Vec<TransactionReceipt>> {
        Ok(self.db.lock().unwrap().prepare_cached("SELECT tx_hash, block_hash, tx_index, success, gas_used, cumulative_gas_used, contract_address, logs, transitions, accepted, errors, exceptions FROM receipts WHERE block_hash = ?1 ORDER BY tx_index")?.query_map([block_hash], Self::make_receipt)?.collect::<Result<Vec<_>, _>>()?)
    }

    pub fn get_total_transaction_count(&self) -> Result<usize> {
        Ok(0)
    }
}

pub fn get_checkpoint_filename<P: AsRef<Path> + Debug>(
    output_dir: P,
    block: &Block,
) -> Result<PathBuf> {
    Ok(output_dir.as_ref().join(block.number().to_string()))
}

/// Build checkpoint and write to disk.
/// A description of the data written can be found in docs/checkpoints
pub fn checkpoint_block_with_state<P: AsRef<Path> + Debug>(
    block: &Block,
    transactions: &Vec<SignedTransaction>,
    parent: &Block,
    state_trie_storage: TrieStorage,
    shard_id: u64,
    output_dir: P,
) -> Result<()> {
    const VERSION: u32 = 3;

    fs::create_dir_all(&output_dir)?;

    let state_trie_storage = Arc::new(state_trie_storage);
    // quick sanity check
    if block.parent_hash() != parent.hash() {
        return Err(anyhow!(
            "Parent block parameter must match the checkpoint block's parent hash"
        ));
    }

    // Note: we ignore any existing file
    let output_filename = get_checkpoint_filename(output_dir, block)?;
    let temp_filename = output_filename.with_extension("part");
    let outfile_temp = File::create_new(&temp_filename)?;
    let mut writer = BufWriter::with_capacity(128 * 1024 * 1024, outfile_temp); // 128 MiB chunks

    // write the header:
    writer.write_all(&CHECKPOINT_HEADER_BYTES)?; // file identifier
    writer.write_all(&VERSION.to_be_bytes())?; // 4 BE bytes for version
    writer.write_all(&shard_id.to_be_bytes())?; // 8 BE bytes for shard ID
    writer.write_all(b"\n")?;

    // write the block...
    let block_ser = &bincode::serialize(&block)?;
    writer.write_all(&u64::try_from(block_ser.len())?.to_be_bytes())?;
    writer.write_all(block_ser)?;

    // write transactions
    let transactions_ser = &bincode::serialize(&transactions)?;
    writer.write_all(&u64::try_from(transactions_ser.len())?.to_be_bytes())?;
    writer.write_all(transactions_ser)?;

    // and its parent, to keep the qc tracked
    let parent_ser = &bincode::serialize(&parent)?;
    writer.write_all(&u64::try_from(parent_ser.len())?.to_be_bytes())?;
    writer.write_all(parent_ser)?;

    // then write state for each account
    let accounts =
        EthTrie::new(state_trie_storage.clone()).at_root(parent.state_root_hash().into());
    let account_storage = EthTrie::new(state_trie_storage);
    let mut account_key_buf = [0u8; 32]; // save a few allocations, since account keys are fixed length

    for (key, serialised_account) in accounts.iter() {
        // export the account itself
        account_key_buf.copy_from_slice(&key);
        writer.write_all(&account_key_buf)?;

        writer.write_all(&u64::try_from(serialised_account.len())?.to_be_bytes())?;
        writer.write_all(&serialised_account)?;

        // now write the entire account storage map
        let account_storage = account_storage
            .at_root(bincode::deserialize::<Account>(&serialised_account)?.storage_root);
        let mut account_storage_buf = vec![];
        for (storage_key, storage_val) in account_storage.iter() {
            account_storage_buf.extend_from_slice(&u64::try_from(storage_key.len())?.to_be_bytes());
            account_storage_buf.extend_from_slice(&storage_key);

            account_storage_buf.extend_from_slice(&u64::try_from(storage_val.len())?.to_be_bytes());
            account_storage_buf.extend_from_slice(&storage_val);
        }
        writer.write_all(&u64::try_from(account_storage_buf.len())?.to_be_bytes())?;
        writer.write_all(&account_storage_buf)?;
    }
    writer.flush()?;

    // lz4 compress and write to output
    compress_file(&temp_filename, &output_filename)?;

    fs::remove_file(temp_filename)?;

    Ok(())
}

/// Read temp file, compress usign lz4, write into output file
fn compress_file<P: AsRef<Path> + Debug>(input_file_path: P, output_file_path: P) -> Result<()> {
    let mut reader = BufReader::new(File::open(input_file_path)?);

    let mut encoder = EncoderBuilder::new().build(File::create(output_file_path)?)?;
    let mut buffer = [0u8; 1024 * 64]; // read 64KB chunks at a time
    loop {
        let bytes_read = reader.read(&mut buffer)?; // Read a chunk of decompressed data
        if bytes_read == 0 {
            break; // End of file
        }
        encoder.write_all(&buffer[..bytes_read])?;
    }
    encoder.finish().1?;

    Ok(())
}

/// An implementor of [eth_trie::DB] which uses a [Connection] to persist data.
#[derive(Debug, Clone)]
pub struct TrieStorage {
    db: Arc<Mutex<Connection>>,
    cache: Arc<Mutex<LruCache<Vec<u8>, Vec<u8>>>>,
}

impl TrieStorage {
    pub fn write_batch(
        &self,
        keys: Vec<Vec<u8>>,
        values: Vec<Vec<u8>>,
    ) -> Result<(), rusqlite::Error> {
        if keys.is_empty() {
            return Ok(());
        }

        assert_eq!(keys.len(), values.len());

        // https://www.sqlite.org/limits.html#max_variable_number
        let maximum_sql_parameters = 32766;
        // Each key-value pair needs two parameters.
        let chunk_size = maximum_sql_parameters / 2;

        let keys = keys.chunks(chunk_size);
        let values = values.chunks(chunk_size);

        for (keys, values) in keys.zip(values) {
            // Generate the SQL substring of the form "(?1, ?2), (?3, ?4), (?5, ?6), ...". There will be one pair of
            // parameters for each key. Note that parameters are one-indexed.
            #[allow(unstable_name_collisions)]
            let params_stmt: String = (0..keys.len())
                .map(|i| format!("(?{}, ?{})", i * 2 + 1, i * 2 + 2))
                .intersperse(",".to_owned())
                .collect();
            let query =
                format!("INSERT OR REPLACE INTO state_trie (key, value) VALUES {params_stmt}");

            let params = keys.iter().zip(values).flat_map(|(k, v)| [k, v]);
            self.db
                .lock()
                .unwrap()
                .prepare_cached(&query)?
                .execute(rusqlite::params_from_iter(params))?;
            for (key, value) in keys.iter().zip(values) {
                let _ = self
                    .cache
                    .lock()
                    .unwrap()
                    .insert(key.to_vec(), value.to_vec());
            }
        }
        Ok(())
    }
}

impl eth_trie::DB for TrieStorage {
    type Error = rusqlite::Error;

    fn get(&self, key: &[u8]) -> Result<Option<Vec<u8>>, Self::Error> {
        if let Some(cached) = self.cache.lock().unwrap().get(key).map(|v| v.to_vec()) {
            return Ok(Some(cached));
        }

        let value: Option<Vec<u8>> = self
            .db
            .lock()
            .unwrap()
            .prepare_cached("SELECT value FROM state_trie WHERE key = ?1")?
            .query_row([key], |row| row.get(0))
            .optional()?;

        let mut cache = self.cache.lock().unwrap();
        if !cache.contains(key) {
            if let Some(value) = &value {
                let _ = cache.insert(key.to_vec(), value.clone());
            }
        }

        Ok(value)
    }

    fn insert(&self, key: &[u8], value: Vec<u8>) -> Result<(), Self::Error> {
        self.db
            .lock()
            .unwrap()
            .prepare_cached("INSERT OR REPLACE INTO state_trie (key, value) VALUES (?1, ?2)")?
            .execute((key, &value))?;
        let _ = self.cache.lock().unwrap().insert(key.to_vec(), value);
        Ok(())
    }

    fn insert_batch(&self, keys: Vec<Vec<u8>>, values: Vec<Vec<u8>>) -> Result<(), Self::Error> {
        self.write_batch(keys, values)
    }

    fn remove(&self, _key: &[u8]) -> Result<(), Self::Error> {
        // we keep old state to function as an archive node, therefore no-op
        Ok(())
    }

    fn remove_batch(&self, _: &[Vec<u8>]) -> Result<(), Self::Error> {
        // we keep old state to function as an archive node, therefore no-op
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use alloy::consensus::EMPTY_ROOT_HASH;
    use rand::{
        Rng, SeedableRng,
        distributions::{Distribution, Uniform},
    };
    use rand_chacha::ChaCha8Rng;
    use tempfile::tempdir;

    use super::*;
    use crate::{crypto::SecretKey, state::State};

    #[test]
    fn query_planner_stability_guarantee() {
        let base_path = tempdir().unwrap();
        let base_path = base_path.path();
        let db = Db::new(Some(base_path), 0, 1024, None).unwrap();

        let sql = db.db.lock().unwrap();

        // Check that EXPLAIN works
        // sqlite> EXPLAIN QUERY PLAN SELECT min(height), max(height) FROM blocks;
        //         3|0|0|SCAN blocks USING COVERING INDEX idx_blocks_height
        let qp = sql
            .query_row_and_then(
                "EXPLAIN QUERY PLAN SELECT min(height), max(height) FROM blocks;",
                [],
                |r| r.get::<_, String>(3),
            )
            .unwrap();
        assert_eq!(
            qp,
            "SCAN blocks USING COVERING INDEX idx_blocks_height".to_string()
        );

        // List of queries to check - it doesn't have to be verbatim, just use the same set of indices i.e. validating assumptions
        let queries = vec![
            "SELECT MIN(height) FROM blocks",
            "SELECT MAX(height) FROM blocks",
            "SELECT block_hash FROM blocks WHERE view = ?1",
            "SELECT MAX(height) FROM blocks WHERE is_canonical = 1",
            "SELECT tx_hash FROM touched_address_index JOIN receipts USING (tx_hash) JOIN blocks USING (block_hash) WHERE address = ?1 ORDER BY blocks.height, receipts.tx_index",
            "SELECT data FROM transactions WHERE tx_hash = ?1",
            "SELECT r.block_hash FROM receipts r INNER JOIN blocks b ON r.block_hash = b.block_hash WHERE r.tx_hash = ?1 AND b.is_canonical = TRUE",
            "SELECT tx_hash FROM receipts WHERE block_hash = ?1",
            "SELECT block_hash, view, height, qc, signature, state_root_hash, transactions_root_hash, receipts_root_hash, timestamp, gas_used, gas_limit, agg FROM blocks WHERE height = ?1",
            "SELECT 1 FROM blocks WHERE is_canonical = TRUE AND block_hash = ?1",
            "SELECT tx_hash, block_hash, tx_index, success, gas_used, cumulative_gas_used, contract_address, logs, transitions, accepted, errors, exceptions FROM receipts WHERE tx_hash = ?1",
            "SELECT tx_hash, block_hash, tx_index, success, gas_used, cumulative_gas_used, contract_address, logs, transitions, accepted, errors, exceptions FROM receipts WHERE block_hash = ?1 ORDER BY tx_index",
            "SELECT block_hash, view, height, qc, signature, state_root_hash, transactions_root_hash, receipts_root_hash, timestamp, gas_used, gas_limit, agg FROM blocks WHERE is_canonical = true AND height = (SELECT MAX(height) FROM blocks WHERE is_canonical = TRUE)",
            "SELECT block_hash, view, height, qc, signature, state_root_hash, transactions_root_hash, receipts_root_hash, timestamp, gas_used, gas_limit, agg FROM blocks WHERE height = (SELECT MAX(height) FROM blocks) LIMIT 1",
            // TODO: Add more queries
        ];

        for query in queries {
            let explain = format!("EXPLAIN QUERY PLAN {query};");
            let plans = sql
                .prepare(&explain)
                .unwrap()
                .raw_query()
                .mapped(|r| r.get::<_, String>(3))
                .collect::<Result<Vec<_>, _>>()
                .unwrap();
            assert!(!plans.is_empty(), "{explain}");
            for plan in plans {
                assert!(!plan.is_empty(), "{explain}");
                // Check for any SCANs
                if plan.starts_with("SCAN") {
                    panic!("SQL regression {query} => {plan}");
                }
            }
        }
    }

    #[test]
    fn checkpoint_export_import() {
        let base_path = tempdir().unwrap();
        let base_path = base_path.path();
        let db = Db::new(Some(base_path), 0, 1024, None).unwrap();

        // Seed db with data
        let mut rng = ChaCha8Rng::seed_from_u64(0);
        let distribution = Uniform::new(1, 50);
        let mut root_trie = EthTrie::new(Arc::new(db.state_trie().unwrap()));
        for _ in 0..100 {
            let account_address: [u8; 20] = rng.r#gen();
            let mut account_trie = EthTrie::new(Arc::new(db.state_trie().unwrap()));
            let mut key = Vec::<u8>::with_capacity(50);
            let mut value = Vec::<u8>::with_capacity(50);
            for _ in 0..distribution.sample(&mut rng) {
                for _ in 0..distribution.sample(&mut rng) {
                    key.push(rng.r#gen());
                }
                for _ in 0..distribution.sample(&mut rng) {
                    value.push(rng.r#gen());
                }
                account_trie.insert(&key, &value).unwrap();
            }
            let account = Account {
                storage_root: account_trie.root_hash().unwrap(),
                ..Default::default()
            };
            root_trie
                .insert(
                    &State::account_key(account_address.into()).0,
                    &bincode::serialize(&account).unwrap(),
                )
                .unwrap();
        }

        let state_hash = root_trie.root_hash().unwrap();
        let checkpoint_parent = Block::genesis(state_hash.into());
        // bit of a hack to generate a successor block
        let mut qc2 = QuorumCertificate::genesis();
        qc2.block_hash = checkpoint_parent.hash();
        qc2.view = 1;
        let checkpoint_block = Block::from_qc(
            SecretKey::new().unwrap(),
            1,
            1,
            qc2,
            None,
            state_hash.into(),
            EMPTY_ROOT_HASH.into(),
            EMPTY_ROOT_HASH.into(),
            vec![],
            SystemTime::now(),
            EvmGas(0),
            EvmGas(0),
        );

        let checkpoint_path = db.get_checkpoint_dir().unwrap().unwrap();

        const SHARD_ID: u64 = 5000;

        let checkpoint_transactions = vec![];
        checkpoint_block_with_state(
            &checkpoint_block,
            &checkpoint_transactions,
            &checkpoint_parent,
            db.state_trie().unwrap(),
            SHARD_ID,
            &checkpoint_path,
        )
        .unwrap();

        // now load the checkpoint
        let (block, transactions, parent) = db
            .load_trusted_checkpoint(
                checkpoint_path.join(checkpoint_block.number().to_string()),
                &checkpoint_block.hash(),
                SHARD_ID,
            )
            .unwrap()
            .unwrap();
        assert_eq!(checkpoint_block, block);
        assert_eq!(checkpoint_transactions, transactions);
        assert_eq!(checkpoint_parent, parent);

        // load the checkpoint again, to ensure idempotency
        let (block, transactions, parent) = db
            .load_trusted_checkpoint(
                checkpoint_path.join(checkpoint_block.number().to_string()),
                &checkpoint_block.hash(),
                SHARD_ID,
            )
            .unwrap()
            .unwrap();
        assert_eq!(checkpoint_block, block);
        assert_eq!(checkpoint_transactions, transactions);
        assert_eq!(checkpoint_parent, parent);

        // Return None if checkpointed block already executed
        db.insert_block(&checkpoint_block).unwrap();
        let result = db
            .load_trusted_checkpoint(
                checkpoint_path.join(checkpoint_block.number().to_string()),
                &checkpoint_block.hash(),
                SHARD_ID,
            )
            .unwrap();
        assert!(result.is_none());
    }
}

```

`zilliqa/src/error.rs`:

```rs
use std::{
    error::Error,
    fmt::{self, Display, Formatter},
};

use alloy::{
    primitives::Bytes, rpc::types::error::EthRpcErrorCode, sol_types::decode_revert_reason,
};
use jsonrpsee::types::ErrorObjectOwned;
use revm::primitives::{ExecutionResult, HaltReason, OutOfGasError};

use crate::api::to_hex::ToHex;

pub fn ensure_success(result: ExecutionResult) -> Result<Bytes, TransactionError> {
    match result {
        ExecutionResult::Success { output, .. } => Ok(output.into_data()),
        ExecutionResult::Revert { output, .. } => {
            Err(TransactionError::Revert(RevertError::new(output)))
        }
        ExecutionResult::Halt { reason, gas_used } => match reason {
            HaltReason::OutOfGas(err) => match err {
                OutOfGasError::Basic => Err(TransactionError::BasicOutOfGas(gas_used)),
                OutOfGasError::MemoryLimit | OutOfGasError::Memory => {
                    Err(TransactionError::MemoryOutOfGas(gas_used))
                }
                OutOfGasError::Precompile => Err(TransactionError::PrecompileOutOfGas(gas_used)),
                OutOfGasError::InvalidOperand => {
                    Err(TransactionError::InvalidOperandOutOfGas(gas_used))
                }
            },
            reason => Err(TransactionError::EvmHalt(reason)),
        },
    }
}

/// An error from an executed transaction.
///
/// Many of the error strings and codes are de-facto standardised by other Ethereum clients.
///
// Much of this is derived from reth:
// https://github.com/paradigmxyz/reth/blob/bf44c9724f68d4aabc9ff1e27d278f36328b8d8f/crates/rpc/rpc-eth-types/src/error/mod.rs#L303
// Licensed under the Apache and MIT licenses.
#[derive(thiserror::Error, Debug)]
pub enum TransactionError {
    #[error(transparent)]
    Revert(RevertError),
    #[error("out of gas: gas required exceeds allowance: {0}")]
    BasicOutOfGas(u64),
    #[error("out of gas: gas exhausted during memory expansion: {0}")]
    MemoryOutOfGas(u64),
    #[error("out of gas: gas exhausted during precompiled contract execution: {0}")]
    PrecompileOutOfGas(u64),
    #[error("out of gas: invalid operand to an opcode: {0}")]
    InvalidOperandOutOfGas(u64),
    #[error("EVM error: {0:?}")]
    EvmHalt(HaltReason),
}

impl TransactionError {
    pub fn error_code(&self) -> i32 {
        match self {
            TransactionError::Revert(_) => EthRpcErrorCode::ExecutionError.code(),
            _ => EthRpcErrorCode::TransactionRejected.code(),
        }
    }
}

impl From<TransactionError> for ErrorObjectOwned {
    fn from(error: TransactionError) -> Self {
        let data = if let TransactionError::Revert(RevertError(ref output)) = error {
            output.as_ref().map(|o| o.to_hex())
        } else {
            None
        };

        ErrorObjectOwned::owned(error.error_code(), error.to_string(), data)
    }
}

#[derive(Debug)]
pub struct RevertError(Option<Bytes>);

impl RevertError {
    pub fn new(output: Bytes) -> Self {
        RevertError((!output.is_empty()).then_some(output))
    }
}

impl Error for RevertError {}

impl Display for RevertError {
    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
        f.write_str("execution reverted")?;
        if let Some(reason) = self.0.as_ref().and_then(|b| decode_revert_reason(b)) {
            write!(f, ": {reason}")?;
        }
        Ok(())
    }
}

```

`zilliqa/src/exec.rs`:

```rs
//! Manages execution of transactions on state.

use std::{
    collections::{BTreeMap, HashMap, hash_map::Entry},
    error::Error,
    fmt::{self, Display, Formatter},
    fs, mem,
    num::NonZeroU128,
    path::Path,
    sync::{Arc, MutexGuard},
};

use alloy::primitives::{Address, Bytes, U256, address, hex};
use anyhow::{Context, Result, anyhow};
use eth_trie::{EthTrie, Trie};
use ethabi::Token;
use jsonrpsee::types::ErrorObjectOwned;
use libp2p::PeerId;
use revm::{
    Database, DatabaseRef, Evm, GetInspector, Inspector, JournaledState, inspector_handle_register,
    primitives::{
        AccountInfo, B256, BlockEnv, Bytecode, Env, ExecutionResult, HaltReason, HandlerCfg,
        KECCAK_EMPTY, Output, ResultAndState, SpecId, TxEnv,
    },
};
use serde::{Deserialize, Serialize};
use serde_json::{Value, json};
use sha2::{Digest, Sha256};
use tracing::{debug, info, trace, warn};

use crate::{
    cfg::{Fork, ScillaExtLibsPath, ScillaExtLibsPathInScilla, ScillaExtLibsPathInZq2},
    constants, contracts,
    crypto::{Hash, NodePublicKey},
    db::TrieStorage,
    error::ensure_success,
    inspector::{self, ScillaInspector},
    message::{Block, BlockHeader},
    precompiles::{get_custom_precompiles, scilla_call_handle_register},
    scilla::{self, ParamValue, Scilla, split_storage_key, storage_key},
    state::{Account, Code, ContractInit, ExternalLibrary, State, contract_addr},
    time::SystemTime,
    transaction::{
        EvmGas, EvmLog, Log, ScillaGas, ScillaLog, Transaction, TxZilliqa, VerifiedTransaction,
        ZilAmount, total_scilla_gas_price,
    },
};

type ScillaResultAndState = (ScillaResult, HashMap<Address, PendingAccount>);

/// Data returned after applying a [Transaction] to [State].

#[derive(Clone)]
pub enum TransactionApplyResult {
    Evm(ResultAndState, Box<Env>),
    Scilla(ScillaResultAndState),
}

impl TransactionApplyResult {
    pub fn output(&self) -> Option<&[u8]> {
        match self {
            TransactionApplyResult::Evm(ResultAndState { result, .. }, ..) => {
                result.output().map(|b| b.as_ref())
            }
            TransactionApplyResult::Scilla(_) => None,
        }
    }

    pub fn success(&self) -> bool {
        match self {
            TransactionApplyResult::Evm(ResultAndState { result, .. }, ..) => result.is_success(),
            TransactionApplyResult::Scilla((ScillaResult { success, .. }, _)) => *success,
        }
    }

    pub fn contract_address(&self) -> Option<Address> {
        match self {
            TransactionApplyResult::Evm(
                ResultAndState {
                    result: ExecutionResult::Success { output, .. },
                    ..
                },
                ..,
            ) => output.address().copied(),
            TransactionApplyResult::Evm(_, _) => None,
            TransactionApplyResult::Scilla((
                ScillaResult {
                    contract_address, ..
                },
                _,
            )) => *contract_address,
        }
    }

    pub fn gas_used(&self) -> EvmGas {
        match self {
            TransactionApplyResult::Evm(ResultAndState { result, .. }, ..) => {
                EvmGas(result.gas_used())
            }
            TransactionApplyResult::Scilla((ScillaResult { gas_used, .. }, _)) => *gas_used,
        }
    }

    pub fn accepted(&self) -> Option<bool> {
        match self {
            TransactionApplyResult::Evm(_, _) => None,
            TransactionApplyResult::Scilla((ScillaResult { accepted, .. }, _)) => *accepted,
        }
    }

    pub fn exceptions(&self) -> &[ScillaException] {
        match self {
            TransactionApplyResult::Evm(_, _) => &[],
            TransactionApplyResult::Scilla((ScillaResult { exceptions, .. }, _)) => exceptions,
        }
    }

    #[allow(clippy::type_complexity)]
    pub fn into_parts(
        self,
    ) -> (
        Vec<Log>,
        Vec<ScillaTransition>,
        BTreeMap<u64, Vec<ScillaError>>,
        Vec<ScillaException>,
    ) {
        match self {
            TransactionApplyResult::Evm(ResultAndState { result, .. }, ..) => (
                result
                    .into_logs()
                    .into_iter()
                    .map(|l| {
                        let (topics, data) = l.data.split();
                        Log::Evm(EvmLog {
                            address: l.address,
                            topics,
                            data: data.to_vec(),
                        })
                    })
                    .collect(),
                Vec::new(),
                BTreeMap::new(),
                Vec::new(),
            ),
            TransactionApplyResult::Scilla((
                ScillaResult {
                    logs,
                    transitions,
                    errors,
                    exceptions,
                    ..
                },
                _,
            )) => (
                logs.into_iter().map(Log::Scilla).collect(),
                transitions,
                errors,
                exceptions,
            ),
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ScillaTransition {
    /// The address of the Scilla contract which initiated the transition.
    pub from: Address,
    /// The recipient of the transition.
    pub to: Address,
    /// The call depth of the transition.
    pub depth: u64,
    /// The value passed with the transition.
    pub amount: ZilAmount,
    /// The tag of the transition. If the recipient is a Scilla contract, this is the method that will be called.
    pub tag: String,
    /// Any parameters passed with the transition.
    pub params: String,
}

impl ScillaTransition {
    pub fn compute_hash(&self) -> Hash {
        Hash::builder()
            .with(self.from.0.as_slice())
            .with(self.to.0.as_slice())
            .with(self.depth.to_be_bytes())
            .with(self.amount.to_be_bytes())
            .with(self.tag.as_bytes())
            .with(self.params.as_bytes())
            .finalize()
    }
}

#[derive(Debug, Clone)]
pub struct ScillaResult {
    /// Whether the transaction succeeded and the resulting state changes were persisted.
    pub success: bool,
    /// If the transaction was a contract creation, the address of the resulting contract.
    pub contract_address: Option<Address>,
    /// The logs emitted by the transaction execution.
    pub logs: Vec<ScillaLog>,
    /// The gas paid by the transaction (in EVM gas units)
    pub gas_used: EvmGas,
    /// Scilla transitions executed by the transaction execution.
    pub transitions: Vec<ScillaTransition>,
    /// If the transaction was a call to a Scilla contract, whether the called contract accepted the ZIL sent to it.
    pub accepted: Option<bool>,
    /// Errors from calls to Scilla contracts. Indexed by the call depth of erroring contract.
    pub errors: BTreeMap<u64, Vec<ScillaError>>,
    /// Exceptions from calls to Scilla contracts.
    pub exceptions: Vec<ScillaException>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ScillaError {
    CheckerFailed,
    RunnerFailed,
    BalanceTransferFailed,
    ExecuteCmdFailed,
    ExecuteCmdTimeout,
    NoGasRemainingFound,
    NoAcceptedFound,
    CallContractFailed,
    CreateContractFailed,
    JsonOutputCorrupted,
    ContractNotExist,
    StateCorrupted,
    LogEntryInstallFailed,
    MessageCorrupted,
    ReceiptIsNull,
    MaxEdgesReached,
    ChainCallDiffShard,
    PreparationFailed,
    NoOutput,
    OutputIllegal,
    MapDepthMissing,
    GasNotSufficient,
    InternalError,
    LibraryAsRecipient,
    VersionInconsistent,
    LibraryExtractionFailed,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ScillaException {
    pub line: u64,
    pub message: String,
}

impl ScillaException {
    pub fn compute_hash(&self) -> Hash {
        Hash::builder()
            .with(self.line.to_be_bytes())
            .with(self.message.as_bytes())
            .finalize()
    }
}

impl From<u64> for ScillaError {
    fn from(val: u64) -> ScillaError {
        match val {
            0 => ScillaError::CheckerFailed,
            1 => ScillaError::RunnerFailed,
            2 => ScillaError::BalanceTransferFailed,
            3 => ScillaError::ExecuteCmdFailed,
            4 => ScillaError::ExecuteCmdTimeout,
            5 => ScillaError::NoGasRemainingFound,
            6 => ScillaError::NoAcceptedFound,
            7 => ScillaError::CallContractFailed,
            8 => ScillaError::CreateContractFailed,
            9 => ScillaError::JsonOutputCorrupted,
            10 => ScillaError::ContractNotExist,
            11 => ScillaError::StateCorrupted,
            12 => ScillaError::LogEntryInstallFailed,
            13 => ScillaError::MessageCorrupted,
            14 => ScillaError::ReceiptIsNull,
            15 => ScillaError::MaxEdgesReached,
            16 => ScillaError::ChainCallDiffShard,
            17 => ScillaError::PreparationFailed,
            18 => ScillaError::NoOutput,
            19 => ScillaError::OutputIllegal,
            20 => ScillaError::MapDepthMissing,
            21 => ScillaError::GasNotSufficient,
            22 => ScillaError::InternalError,
            23 => ScillaError::LibraryAsRecipient,
            24 => ScillaError::VersionInconsistent,
            25 => ScillaError::LibraryExtractionFailed,
            _ => unreachable!(),
        }
    }
}

impl From<scilla::Error> for ScillaException {
    fn from(e: scilla::Error) -> ScillaException {
        ScillaException {
            line: e.start_location.line,
            message: e.error_message,
        }
    }
}

// We need to define a custom error type for our [Database], which implements [Error].
#[derive(Debug)]
pub struct DatabaseError(anyhow::Error);

impl From<anyhow::Error> for DatabaseError {
    fn from(err: anyhow::Error) -> Self {
        DatabaseError(err)
    }
}

impl Display for DatabaseError {
    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
        write!(f, "{}", self.0)
    }
}

impl Error for DatabaseError {
    fn source(&self) -> Option<&(dyn Error + 'static)> {
        self.0.source()
    }
}

impl Database for PendingState {
    type Error = DatabaseError;

    fn basic(&mut self, address: Address) -> Result<Option<AccountInfo>, Self::Error> {
        (&self.pre_state).basic_ref(address)
    }

    fn code_by_hash(&mut self, code_hash: B256) -> Result<Bytecode, Self::Error> {
        (&self.pre_state).code_by_hash_ref(code_hash)
    }

    fn storage(&mut self, address: Address, index: U256) -> Result<U256, Self::Error> {
        (&self.pre_state).storage_ref(address, index)
    }

    fn block_hash(&mut self, number: u64) -> Result<B256, Self::Error> {
        (&self.pre_state).block_hash_ref(number)
    }
}

impl DatabaseRef for PendingState {
    type Error = DatabaseError;

    fn basic_ref(&self, address: Address) -> Result<Option<AccountInfo>, Self::Error> {
        (&self.pre_state).basic_ref(address)
    }

    fn code_by_hash_ref(&self, code_hash: B256) -> Result<Bytecode, Self::Error> {
        (&self.pre_state).code_by_hash_ref(code_hash)
    }

    fn storage_ref(&self, address: Address, index: U256) -> Result<U256, Self::Error> {
        (&self.pre_state).storage_ref(address, index)
    }

    fn block_hash_ref(&self, number: u64) -> Result<B256, Self::Error> {
        (&self.pre_state).block_hash_ref(number)
    }
}

impl Database for &State {
    type Error = DatabaseError;

    fn basic(&mut self, address: Address) -> Result<Option<AccountInfo>, Self::Error> {
        self.basic_ref(address)
    }

    fn code_by_hash(&mut self, code_hash: B256) -> Result<Bytecode, Self::Error> {
        self.code_by_hash_ref(code_hash)
    }

    fn storage(&mut self, address: Address, index: U256) -> Result<U256, Self::Error> {
        self.storage_ref(address, index)
    }

    fn block_hash(&mut self, number: u64) -> Result<B256, Self::Error> {
        self.block_hash_ref(number)
    }
}

impl DatabaseRef for &State {
    type Error = DatabaseError;

    fn basic_ref(&self, address: Address) -> Result<Option<AccountInfo>, Self::Error> {
        if !self.has_account(address)? {
            return Ok(None);
        }

        let account = self.get_account(address)?;
        let code = Bytecode::new_raw(account.code.evm_code().unwrap_or_default().into());
        let account_info = AccountInfo {
            balance: U256::from(account.balance),
            nonce: account.nonce,
            code_hash: code.hash_slow(),
            code: Some(code),
        };

        Ok(Some(account_info))
    }

    fn code_by_hash_ref(&self, _code_hash: B256) -> Result<Bytecode, Self::Error> {
        unimplemented!()
    }

    fn storage_ref(&self, address: Address, index: U256) -> Result<U256, Self::Error> {
        let index = B256::new(index.to_be_bytes());

        let result = self.get_account_storage(address, index)?;

        Ok(U256::from_be_bytes(result.0))
    }

    fn block_hash_ref(&self, number: u64) -> Result<B256, Self::Error> {
        Ok(self
            .get_canonical_block_by_number(number)?
            .map(|block| B256::new(block.hash().0))
            .unwrap_or_default())
    }
}

/// The external context used by [Evm].
pub struct ExternalContext<'a, I> {
    pub inspector: I,
    pub fork: &'a Fork,
    // This flag is only used for zq1 whitelisted contracts, and it's used to detect if the entire transaction should be marked as failed
    pub enforce_transaction_failure: bool,
    /// The caller of each call in the call-stack. This is needed because the `scilla_call` precompile needs to peek
    /// into the call-stack. This will always be non-empty and the first entry will be the transaction signer.
    pub callers: Vec<Address>,
    pub has_evm_failed: bool,
    pub has_touched_whitelisted_addresses: bool,
}

impl<I: Inspector<PendingState>> GetInspector<PendingState> for ExternalContext<'_, I> {
    fn get_inspector(&mut self) -> &mut impl Inspector<PendingState> {
        &mut self.inspector
    }
}

const SPEC_ID: SpecId = SpecId::SHANGHAI;

pub enum BaseFeeCheck {
    /// Transaction gas price will be validated to be at least the block gas price.
    Validate,
    /// Transaction gas price will not be validated.
    Ignore,
}

impl State {
    /// Used primarily during genesis to set up contracts for chain functionality.
    /// If override_address address is set, forces contract deployment to that addess.
    pub(crate) fn force_deploy_contract_evm(
        &mut self,
        creation_bytecode: Vec<u8>,
        override_address: Option<Address>,
        amount: u128,
    ) -> Result<Address> {
        let current_block = BlockHeader::genesis(Hash::ZERO);
        let (ResultAndState { result, mut state }, ..) = self.apply_transaction_evm(
            Address::ZERO,
            None,
            0,
            self.block_gas_limit,
            amount,
            creation_bytecode,
            None,
            current_block,
            inspector::noop(),
            false,
            BaseFeeCheck::Ignore,
            false,
        )?;

        match result {
            ExecutionResult::Success {
                output: Output::Create(_, Some(addr)),
                ..
            } => {
                let addr = if let Some(override_address) = override_address {
                    let override_address = Address::from(override_address.0);
                    let account = state
                        .remove(&addr)
                        .ok_or_else(|| anyhow!("deployment did not change the contract account"))?;
                    state.insert(override_address, account);
                    override_address
                } else {
                    addr
                };

                self.apply_delta_evm(&state, current_block.number)?;
                Ok(addr)
            }
            ExecutionResult::Success { .. } => Err(anyhow!("deployment did not create a contract")),
            ExecutionResult::Revert { .. } => Err(anyhow!("deployment reverted")),
            ExecutionResult::Halt { reason, .. } => Err(anyhow!("deployment halted: {reason:?}")),
        }
    }

    fn failed(
        mut result_and_state: ResultAndState,
        env: Box<Env>,
    ) -> Result<(ResultAndState, HashMap<Address, PendingAccount>, Box<Env>)> {
        result_and_state.state.clear();
        Ok((
            ResultAndState {
                result: ExecutionResult::Revert {
                    gas_used: result_and_state.result.gas_used(),
                    output: Bytes::default(),
                },
                state: result_and_state.state,
            },
            HashMap::new(),
            env,
        ))
    }

    #[allow(clippy::too_many_arguments)]
    pub fn apply_transaction_evm<I: Inspector<PendingState> + ScillaInspector>(
        &self,
        from_addr: Address,
        to_addr: Option<Address>,
        gas_price: u128,
        gas_limit: EvmGas,
        amount: u128,
        payload: Vec<u8>,
        nonce: Option<u64>,
        current_block: BlockHeader,
        inspector: I,
        enable_inspector: bool,
        base_fee_check: BaseFeeCheck,
        disable_eip3607: bool,
    ) -> Result<(ResultAndState, HashMap<Address, PendingAccount>, Box<Env>)> {
        let mut padded_view_number = [0u8; 32];
        padded_view_number[24..].copy_from_slice(&current_block.view.to_be_bytes());

        let external_context = ExternalContext {
            inspector,
            fork: self.forks.get(current_block.number),
            enforce_transaction_failure: false,
            callers: vec![from_addr],
            has_evm_failed: false,
            has_touched_whitelisted_addresses: false,
        };
        let pending_state = PendingState::new(self.clone());
        let mut evm = Evm::builder()
            .with_db(pending_state)
            .with_block_env(BlockEnv {
                number: U256::from(current_block.number),
                coinbase: Address::ZERO,
                timestamp: U256::from(
                    current_block
                        .timestamp
                        .duration_since(SystemTime::UNIX_EPOCH)
                        .unwrap_or_default()
                        .as_secs(),
                ),
                gas_limit: U256::from(self.block_gas_limit.0),
                basefee: U256::from(self.gas_price),
                difficulty: U256::from(1),
                prevrandao: Some(Hash::builder().with(padded_view_number).finalize().into()),
                blob_excess_gas_and_price: None,
            })
            .with_external_context(external_context)
            .with_handler_cfg(HandlerCfg { spec_id: SPEC_ID })
            .append_handler_register(scilla_call_handle_register)
            .modify_cfg_env(|c| {
                c.disable_eip3607 = disable_eip3607;
                c.chain_id = self.chain_id.eth;
                c.disable_base_fee = match base_fee_check {
                    BaseFeeCheck::Validate => false,
                    BaseFeeCheck::Ignore => true,
                };
            })
            .with_tx_env(TxEnv {
                caller: from_addr.0.into(),
                gas_limit: gas_limit.0,
                gas_price: U256::from(gas_price),
                transact_to: to_addr.into(),
                value: U256::from(amount),
                data: payload.clone().into(),
                nonce,
                chain_id: Some(self.chain_id.eth),
                access_list: vec![],
                gas_priority_fee: None,
                blob_hashes: vec![],
                max_fee_per_blob_gas: None,
                authorization_list: None,
            })
            .append_handler_register(|handler| {
                let precompiles = handler.pre_execution.load_precompiles();
                handler.pre_execution.load_precompiles = Arc::new(move || {
                    let mut precompiles = precompiles.clone();
                    precompiles.extend(get_custom_precompiles());
                    precompiles
                });
            });
        if enable_inspector {
            evm = evm.append_handler_register(inspector_handle_register);
        }
        let mut evm = evm.build();

        let result_and_state = evm.transact()?;
        let mut ctx_with_handler = evm.into_context_with_handler_cfg();

        // If the scilla precompile failed for whitelisted zq1 contract we mark the entire transaction as failed
        if ctx_with_handler
            .context
            .external
            .enforce_transaction_failure
        {
            return Self::failed(result_and_state, ctx_with_handler.context.evm.inner.env);
        }

        // If any of EVM (calls, creates, ...) failed and there was a call to whitelisted scilla address with interop precompile
        // then report entire transaction as failed
        let evm_exec_failure_causes_scilla_whitelisted_addr_to_fail = self
            .forks
            .get(current_block.number)
            .evm_exec_failure_causes_scilla_whitelisted_addr_to_fail;
        let ctx = &ctx_with_handler.context.external;
        if evm_exec_failure_causes_scilla_whitelisted_addr_to_fail
            && ctx.has_evm_failed
            && ctx.has_touched_whitelisted_addresses
        {
            return Self::failed(result_and_state, ctx_with_handler.context.evm.inner.env);
        }

        Ok((
            result_and_state,
            ctx_with_handler.context.evm.db.finalize(),
            ctx_with_handler.context.evm.inner.env,
        ))
    }

    // The rules here are somewhat odd, and inherited from ZQ1
    //
    // - Initially, we deduct the minimum cost from the account. If this fails, abort and deduct nothing.
    // - At the end of the txn, work out how much more to charge, and try to charge it
    //    * If this succeeds, we charge and reflect the results of the txn.
    //    * If it doesn't, we charge nothing (?!) and the state doesn't reflect the results of the txn.
    // - Failed scilla transactions don't count towards the block gas limit.
    // - Failed scilla transactions don't increment the nonce.
    // - If the user has enough gas to pay the deposit, but not to complete the txn, we neither increment the
    //   nonce nor charge the deposit :-(
    //
    // gas_used in the return value is used only for accounting towards the block gas limit - we need
    // to deduct gas charged to the user ourselves. Since our txns don't count towards block gas,
    // gas_used is always 0.
    fn apply_transaction_scilla(
        &mut self,
        from_addr: Address,
        txn: TxZilliqa,
        current_block: BlockHeader,
        inspector: impl ScillaInspector,
    ) -> Result<ScillaResultAndState> {
        let mut state = PendingState::new(self.try_clone()?);

        // Issue 1509 - for Scilla transitions, follow the legacy ZQ1 behaviour of deducting a small amount
        // of gas for the invocation and the rest of the gas once the txn has run.

        // let gas_limit = txn.gas_limit;
        let gas_price = txn.gas_price;

        let deposit_gas = txn.get_deposit_gas()?;
        let deposit = total_scilla_gas_price(deposit_gas, gas_price);
        trace!("scilla_txn: gas_price {gas_price} deposit_gas {deposit_gas} deposit {deposit}");

        if let Some(result) = state.deduct_from_account(from_addr, deposit, EvmGas(0))? {
            trace!("scilla_txn: Could not deduct deposit");
            return Ok((result, state.finalize()));
        }

        let fork = self.forks.get(current_block.number);

        let (result, mut new_state) = if txn.to_addr.is_zero() {
            scilla_create(
                state,
                self.scilla(),
                from_addr,
                txn,
                current_block,
                inspector,
                &self.scilla_ext_libs_path,
                fork,
            )
        } else {
            scilla_call(
                state,
                self.scilla(),
                from_addr,
                from_addr,
                txn.gas_limit,
                txn.to_addr,
                txn.amount,
                txn.data,
                inspector,
                &self.scilla_ext_libs_path,
                fork,
                current_block.number,
            )
        }?;

        let actual_gas_charged =
            total_scilla_gas_price(ScillaGas::from(result.gas_used), gas_price);
        let from = new_state.load_account(from_addr)?;
        from.account.nonce += 1;
        from.mark_touch();

        // If txn is successful deduct extra fee and keep balance changes intact
        if !fork.scilla_failed_txn_correct_balance_deduction || result.success {
            let to_charge = actual_gas_charged.checked_sub(&deposit);
            trace!("scilla_txn: actual_gas_used {actual_gas_charged} to_charge = {to_charge:?}");
            if let Some(extra_charge) = to_charge {
                // Deduct the remaining gas.
                // If we fail, Zilliqa 1 deducts nothing at all, and neither do we.
                if let Some(result) =
                    new_state.deduct_from_account(from_addr, extra_charge, EvmGas(0))?
                {
                    trace!("scilla_txn: cannot deduct remaining gas - txn failed");
                    let mut failed_state = PendingState::new(self.try_clone()?);
                    return Ok((result, failed_state.finalize()));
                }
            }
        } else {
            // If txn has failed - make sure only fee is deducted from sender account
            let original_acc = self.get_account(from_addr)?;
            from.account.balance = original_acc
                .balance
                .saturating_sub(actual_gas_charged.get());
        }
        trace!("scilla_txn completed successfully");
        Ok((result, new_state.finalize()))
    }

    /// Apply a transaction to the account state.
    pub fn apply_transaction<I: Inspector<PendingState> + ScillaInspector>(
        &mut self,
        txn: VerifiedTransaction,
        current_block: BlockHeader,
        inspector: I,
        enable_inspector: bool,
    ) -> Result<TransactionApplyResult> {
        let hash = txn.hash;
        let from_addr = txn.signer;
        let txn = txn.tx.into_transaction();

        info!(?hash, from = ?from_addr, to = ?txn.to_addr(), ?txn, "executing txn");

        let blessed = BLESSED_TRANSACTIONS.iter().any(|elem| elem.hash == hash);

        if let Transaction::Zilliqa(txn) = txn {
            let (result, state) =
                self.apply_transaction_scilla(from_addr, txn, current_block, inspector)?;

            let update_state_only_if_transaction_succeeds = self
                .forks
                .get(current_block.number)
                .apply_state_changes_only_if_transaction_succeeds;

            if !update_state_only_if_transaction_succeeds || result.success {
                self.apply_delta_scilla(&state, current_block.number)?;
            } else {
                // If the transaction rejected, we must update the nonce and balance of the sender account.
                let from_account = state
                    .get(&from_addr)
                    .ok_or(anyhow!("from account not found"))?;

                let mut storage = self.get_account_trie(from_addr)?;

                let account = Account {
                    nonce: from_account.account.nonce,
                    balance: from_account.account.balance,
                    code: from_account.account.code.clone(),
                    storage_root: storage.root_hash()?,
                };

                self.save_account(from_addr, account)?;
            }

            Ok(TransactionApplyResult::Scilla((result, state)))
        } else {
            let (ResultAndState { result, state }, scilla_state, env) = self
                .apply_transaction_evm(
                    from_addr,
                    txn.to_addr(),
                    txn.max_fee_per_gas(),
                    txn.gas_limit(),
                    txn.amount(),
                    txn.payload().to_vec(),
                    txn.nonce(),
                    current_block,
                    inspector,
                    enable_inspector,
                    if blessed {
                        BaseFeeCheck::Ignore
                    } else {
                        BaseFeeCheck::Validate
                    },
                    false,
                )?;

            self.apply_delta_evm(&state, current_block.number)?;
            let apply_scilla_delta_when_evm_succeeded = self
                .forks
                .get(current_block.number)
                .apply_scilla_delta_when_evm_succeeded;

            if apply_scilla_delta_when_evm_succeeded {
                if let ExecutionResult::Success { .. } = result {
                    self.apply_delta_scilla(&scilla_state, current_block.number)?;
                }
            } else {
                self.apply_delta_scilla(&scilla_state, current_block.number)?;
            }

            Ok(TransactionApplyResult::Evm(
                ResultAndState { result, state },
                env,
            ))
        }
    }

    /// Applies a state delta from a Scilla execution to the state.
    fn apply_delta_scilla(
        &mut self,
        state: &HashMap<Address, PendingAccount>,
        current_block_number: u64,
    ) -> Result<()> {
        let fork = self.forks.get(current_block_number);
        let only_mutated_accounts_update_state = fork.only_mutated_accounts_update_state;
        let scilla_delta_maps_are_applied_correctly = fork.scilla_delta_maps_are_applied_correctly;
        for (&address, account) in state {
            if only_mutated_accounts_update_state && !account.touched {
                continue;
            }

            // We shouldn't mutate accounts that were from EVM.
            assert!(!account.from_evm);

            let mut storage = self.get_account_trie(address)?;

            /// Recursively called internal function which assigns `value` at the correct key to `storage`.
            fn handle(
                scilla_delta_maps_are_applied_correctly: bool,
                storage: &mut EthTrie<TrieStorage>,
                var: &str,
                value: &StorageValue,
                indices: &mut Vec<Vec<u8>>,
            ) -> Result<()> {
                match value {
                    StorageValue::Map { map, complete } => {
                        // If this is a complete view of the map, delete any existing values first.
                        if *complete {
                            storage.remove_by_prefix(&storage_key(var, indices))?;
                        }

                        // We will iterate over each key-value pair in this map and make a recursive call to this
                        // function with the given value. Before each call, we need to make sure we update `indices`
                        // to include the key. To avoid changing the length of the `Vec` in each iteration, we first
                        // add a dummy index (`vec![]`) and update it before each call.
                        indices.push(vec![]);
                        for (k, v) in map {
                            indices.last_mut().unwrap().clone_from(k);
                            handle(
                                scilla_delta_maps_are_applied_correctly,
                                storage,
                                var,
                                v,
                                indices,
                            )?;
                        }
                        if scilla_delta_maps_are_applied_correctly {
                            indices.pop();
                        }
                    }
                    StorageValue::Value(Some(value)) => {
                        let key = storage_key(var, indices);
                        storage.insert(&key, value)?;
                    }
                    StorageValue::Value(None) => {
                        let key = storage_key(var, indices);
                        // A deletion may occur at any depth of the map. Therefore we remove all keys with the relevent
                        // prefix.
                        storage.remove_by_prefix(&key)?;
                    }
                }
                Ok(())
            }

            for (var, value) in &account.storage {
                handle(
                    scilla_delta_maps_are_applied_correctly,
                    &mut storage,
                    var,
                    value,
                    &mut vec![],
                )?;
            }

            let account = Account {
                nonce: account.account.nonce,
                balance: account.account.balance,
                code: account.account.code.clone(),
                storage_root: storage.root_hash()?,
            };

            self.save_account(address, account)?;
        }

        Ok(())
    }

    /// Applies a state delta from an EVM execution to the state.
    pub fn apply_delta_evm(
        &mut self,
        state: &revm::primitives::HashMap<Address, revm::primitives::Account>,
        current_block_number: u64,
    ) -> Result<()> {
        let only_mutated_accounts_update_state = self
            .forks
            .get(current_block_number)
            .only_mutated_accounts_update_state;
        for (&address, account) in state {
            if only_mutated_accounts_update_state && !account.is_touched() {
                continue;
            }

            let mut storage = self.get_account_trie(address)?;

            for (index, value) in account.changed_storage_slots() {
                let index = B256::new(index.to_be_bytes());
                let value = B256::new(value.present_value().to_be_bytes());
                trace!(?address, ?index, ?value, "update storage");

                storage.insert(
                    &Self::account_storage_key(address, index).0,
                    value.as_slice(),
                )?;
            }

            // `account.info.code` might be `None`, even though we always return `Some` for the account code in our
            // [DatabaseRef] implementation. However, this is only the case for empty code, so we handle this case
            // separately.
            let mut code = if account.info.code_hash == KECCAK_EMPTY {
                Code::Evm(vec![])
            } else {
                Code::Evm(
                    account
                        .info
                        .code
                        .as_ref()
                        .expect("code_by_hash is not used")
                        .original_bytes()
                        .to_vec(),
                )
            };

            if self
                .forks
                .get(current_block_number)
                .scilla_fix_contract_code_removal_on_evm_tx
            {
                // if contract is Scilla then fetch Code to include in Account update
                let mut pending_state = PendingState::new(self.try_clone()?);
                let zq2_account = pending_state.load_account(address)?;
                if zq2_account.account.code.is_scilla() {
                    code = zq2_account.account.code.clone()
                }
            }

            let account = Account {
                nonce: account.info.nonce,
                balance: account.info.balance.try_into()?,
                code,
                storage_root: storage.root_hash()?,
            };
            trace!(?address, ?account, "update account");
            self.save_account(address, account)?;
        }

        Ok(())
    }

    pub fn deposit_contract_version(&self, current_block: BlockHeader) -> Result<u128> {
        let result = self.call_contract(
            Address::ZERO,
            Some(contract_addr::DEPOSIT_PROXY),
            contracts::deposit::VERSION.encode_input(&[]).unwrap(),
            0,
            current_block,
            false,
        )?;
        contracts::deposit::VERSION.decode_output(&ensure_success(result)?)?[0]
            .clone()
            .into_uint()
            .map_or(Ok(0), |v| Ok(v.as_u128()))
    }

    pub fn leader(&self, view: u64, current_block: BlockHeader) -> Result<NodePublicKey> {
        let data = contracts::deposit::LEADER_AT_VIEW.encode_input(&[Token::Uint(view.into())])?;

        let result = self.call_contract(
            Address::ZERO,
            Some(contract_addr::DEPOSIT_PROXY),
            data,
            0,
            current_block,
            false,
        )?;
        let leader = ensure_success(result)?;

        NodePublicKey::from_bytes(
            &contracts::deposit::LEADER_AT_VIEW
                .decode_output(&leader)
                .unwrap()[0]
                .clone()
                .into_bytes()
                .unwrap(),
        )
    }

    pub fn get_stakers(&self, current_block: BlockHeader) -> Result<Vec<NodePublicKey>> {
        let data: Vec<u8> = contracts::deposit::GET_STAKERS.encode_input(&[])?;

        let result = self.call_contract(
            Address::ZERO,
            Some(contract_addr::DEPOSIT_PROXY),
            data,
            0,
            current_block,
            false,
        )?;
        let stakers = ensure_success(result)?;

        let stakers = contracts::deposit::GET_STAKERS
            .decode_output(&stakers)
            .unwrap()[0]
            .clone()
            .into_array()
            .unwrap();

        stakers
            .into_iter()
            .map(|k| NodePublicKey::from_bytes(&k.into_bytes().unwrap()))
            .collect()
    }

    pub fn committee(&self) -> Result<()> {
        let data = contracts::deposit::COMMITTEE.encode_input(&[])?;

        let result = self.call_contract(
            Address::ZERO,
            Some(contract_addr::DEPOSIT_PROXY),
            data,
            0,
            BlockHeader::default(),
            false,
        )?;
        let committee = ensure_success(result)?;
        let committee = contracts::deposit::COMMITTEE.decode_output(&committee)?;
        debug!("committee: {committee:?}");

        Ok(())
    }

    pub fn get_stake(
        &self,
        public_key: NodePublicKey,
        current_block: BlockHeader,
    ) -> Result<Option<NonZeroU128>> {
        let data =
            contracts::deposit::GET_STAKE.encode_input(&[Token::Bytes(public_key.as_bytes())])?;

        let result = self.call_contract(
            Address::ZERO,
            Some(contract_addr::DEPOSIT_PROXY),
            data,
            0,
            current_block,
            false,
        )?;
        let stake = ensure_success(result)?;

        let stake = NonZeroU128::new(U256::from_be_slice(&stake).to());

        Ok(stake)
    }

    pub fn get_reward_address(&self, public_key: NodePublicKey) -> Result<Option<Address>> {
        let data = contracts::deposit::GET_REWARD_ADDRESS
            .encode_input(&[Token::Bytes(public_key.as_bytes())])?;

        let result = self.call_contract(
            Address::ZERO,
            Some(contract_addr::DEPOSIT_PROXY),
            data,
            0,
            // The current block is not accessed when the native balance is read, so we just pass in some
            // dummy values.
            BlockHeader::default(),
            false,
        )?;
        let return_value = ensure_success(result)?;

        let addr = contracts::deposit::GET_REWARD_ADDRESS.decode_output(&return_value)?[0]
            .clone()
            .into_address()
            .unwrap();
        let addr = Address::new(addr.0);

        Ok((!addr.is_zero()).then_some(addr))
    }

    pub fn get_peer_id(&self, public_key: NodePublicKey) -> Result<Option<PeerId>> {
        let data =
            contracts::deposit::GET_PEER_ID.encode_input(&[Token::Bytes(public_key.as_bytes())])?;

        let result = self.call_contract(
            Address::ZERO,
            Some(contract_addr::DEPOSIT_PROXY),
            data,
            0,
            // The current block is not accessed when the native balance is read, so we just pass in some
            // dummy values.
            BlockHeader::default(),
            false,
        )?;
        let return_value = ensure_success(result)?;

        let data = contracts::deposit::GET_PEER_ID.decode_output(&return_value)?[0]
            .clone()
            .into_bytes()
            .unwrap();

        Ok(Some(PeerId::from_bytes(&data)?))
    }

    /// Returns the maximum gas a caller could pay for a given transaction. This is clamped the minimum of:
    /// 1. The block gas limit.
    /// 2. The gas limit specified by the caller.
    /// 3. The caller's balance after paying for any funds sent by the transaction.
    ///
    /// Returns an error if the caller does not have funds to pay for the transaction.
    fn max_gas_for_caller(
        &self,
        caller: Address,
        tx_value: u128,
        gas_price: u128,
        requested_gas_limit: Option<EvmGas>,
    ) -> Result<EvmGas> {
        let mut gas = self.block_gas_limit;

        if let Some(requested_gas_limit) = requested_gas_limit {
            gas = gas.min(requested_gas_limit);
        }

        if gas_price != 0 {
            let balance = self.get_account(caller)?.balance;
            // Calculate how much the caller has left to pay for gas after the transaction value is subtracted.
            let balance = balance.checked_sub(tx_value).ok_or_else(|| {
                anyhow!("caller has insufficient funds - has: {balance}, needs: {tx_value}")
            })?;
            // Calculate the gas the caller could pay for at this gas price.
            let max_gas = EvmGas((balance / gas_price) as u64);
            gas = gas.min(max_gas);
        }

        Ok(gas)
    }

    #[allow(clippy::too_many_arguments)]
    pub fn estimate_gas(
        &self,
        from_addr: Address,
        to_addr: Option<Address>,
        data: Vec<u8>,
        current_block: BlockHeader,
        gas: Option<EvmGas>,
        gas_price: Option<u128>,
        value: u128,
        disable_eip3607: bool,
    ) -> Result<u64> {
        let gas_price = gas_price.unwrap_or(self.gas_price);

        let mut max = self.max_gas_for_caller(from_addr, value, gas_price, gas)?.0;

        let upper_bound = max;

        // Check if estimation succeeds with the highest possible gas
        // We use the result as lower bound
        let mut min = self.estimate_gas_inner(
            from_addr,
            to_addr,
            data.clone(),
            current_block,
            EvmGas(upper_bound),
            gas_price,
            value,
            disable_eip3607,
        )?;

        // Execute the while loop iff (max - min)/max < MINIMUM_PERCENT_RATIO [%]
        const MINIMUM_PERCENT_RATIO: u64 = 3;

        // result should be somewhere in (min, max]
        while min < max {
            let break_cond = (max - min) <= (max * MINIMUM_PERCENT_RATIO) / 100;
            if break_cond {
                break;
            }
            let mid = (min + max) / 2;

            let (ResultAndState { result, .. }, ..) = self.apply_transaction_evm(
                from_addr,
                to_addr,
                gas_price,
                EvmGas(mid),
                value,
                data.clone(),
                None,
                current_block,
                inspector::noop(),
                false,
                BaseFeeCheck::Validate,
                disable_eip3607,
            )?;

            match result {
                ExecutionResult::Success { .. } => max = mid,
                ExecutionResult::Revert { .. } => min = mid + 1,
                ExecutionResult::Halt { reason, .. } => match reason {
                    HaltReason::OutOfGas(_) | HaltReason::InvalidFEOpcode => min = mid + 1,
                    _ => return Err(anyhow!("halted due to: {reason:?}")),
                },
            }
        }
        debug!("Estimated gas: {}", max);
        Ok(max)
    }
    #[allow(clippy::too_many_arguments)]
    fn estimate_gas_inner(
        &self,
        from_addr: Address,
        to_addr: Option<Address>,
        data: Vec<u8>,
        current_block: BlockHeader,
        gas: EvmGas,
        gas_price: u128,
        value: u128,
        disable_eip3607: bool,
    ) -> Result<u64> {
        let (ResultAndState { result, .. }, ..) = self.apply_transaction_evm(
            from_addr,
            to_addr,
            gas_price,
            gas,
            value,
            data.clone(),
            None,
            current_block,
            inspector::noop(),
            false,
            BaseFeeCheck::Validate,
            disable_eip3607,
        )?;

        let gas_used = result.gas_used();
        // Return an error if the transaction did not succeed
        ensure_success(result).map_err(ErrorObjectOwned::from)?;
        Ok(gas_used)
    }

    #[allow(clippy::too_many_arguments)]
    pub fn call_contract(
        &self,
        from_addr: Address,
        to_addr: Option<Address>,
        data: Vec<u8>,
        amount: u128,
        current_block: BlockHeader,
        disable_eip3607: bool,
    ) -> Result<ExecutionResult> {
        let (ResultAndState { result, .. }, ..) = self.apply_transaction_evm(
            from_addr,
            to_addr,
            0,
            self.block_gas_limit,
            amount,
            data,
            None,
            current_block,
            inspector::noop(),
            false,
            BaseFeeCheck::Ignore,
            disable_eip3607,
        )?;

        Ok(result)
    }

    /// Call contract and apply changes to state
    #[allow(clippy::too_many_arguments)]
    pub fn call_contract_apply(
        &mut self,
        from_addr: Address,
        to_addr: Option<Address>,
        data: Vec<u8>,
        amount: u128,
        current_block: BlockHeader,
    ) -> Result<ExecutionResult> {
        let (ResultAndState { result, state }, ..) = self.apply_transaction_evm(
            from_addr,
            to_addr,
            0,
            self.block_gas_limit,
            amount,
            data,
            None,
            current_block,
            inspector::noop(),
            false,
            BaseFeeCheck::Ignore,
            false,
        )?;
        self.apply_delta_evm(&state, current_block.number)?;

        Ok(result)
    }
}

/// Gets the contract address if a contract creation [TxZilliqa] is sent by `sender` with `nonce`.
pub fn zil_contract_address(sender: Address, nonce: u64) -> Address {
    let mut hasher = Sha256::new();
    hasher.update(sender.into_array());
    hasher.update(nonce.to_be_bytes());
    let hashed = hasher.finalize();
    Address::from_slice(&hashed[12..])
}

/// The account state during the execution of a Scilla transaction. Changes to the original state are kept in memory.
#[derive(Debug, Clone)]
pub struct PendingState {
    pub pre_state: State,
    pub new_state: HashMap<Address, PendingAccount>,
    // Read-only copy of the current cached EVM state. Only `Some` when this Scilla call is made by the `scilla_call`
    // precompile.
    pub evm_state: Option<JournaledState>,
}

/// Private helper function for `PendingState::load_account`. The only difference is that the fields of `PendingState`
/// are passed explicitly. This means the borrow-checker can see the reference we return only borrows from the
/// `new_state` field and thus we can later use `pre_state` without an error.
fn load_account<'a>(
    pre_state: &State,
    new_state: &'a mut HashMap<Address, PendingAccount>,
    evm_state: &Option<JournaledState>,
    address: Address,
) -> Result<&'a mut PendingAccount> {
    match (
        new_state.entry(address),
        evm_state.as_ref().and_then(|s| s.state.get(&address)),
    ) {
        (Entry::Occupied(entry), _) => Ok(entry.into_mut()),
        (Entry::Vacant(vac), Some(account)) => {
            let account = Account {
                nonce: account.info.nonce,
                balance: account.info.balance.to(),
                code: Code::Evm(if account.info.code_hash == KECCAK_EMPTY {
                    vec![]
                } else {
                    account
                        .info
                        .code
                        .as_ref()
                        .ok_or_else(|| anyhow!("account should have code"))?
                        .original_bytes()
                        .to_vec()
                }),
                storage_root: B256::ZERO, // There's no need to set this, since Scilla cannot query EVM contracts' state.
            };
            let account = PendingAccount {
                account,
                storage: BTreeMap::new(),
                from_evm: true,
                touched: false,
            };
            Ok(vac.insert(account))
        }
        (Entry::Vacant(vac), None) => {
            let account = pre_state.get_account(address)?;
            Ok(vac.insert(account.into()))
        }
    }
}

impl PendingState {
    pub fn new(state: State) -> Self {
        PendingState {
            pre_state: state,
            new_state: HashMap::new(),
            evm_state: None,
        }
    }

    pub fn zil_chain_id(&self) -> u64 {
        self.pre_state.chain_id.zil()
    }

    pub fn get_canonical_block_by_number(&self, block_number: u64) -> Result<Option<Block>> {
        self.pre_state.get_canonical_block_by_number(block_number)
    }

    pub fn get_highest_canonical_block_number(&self) -> Result<Option<u64>> {
        self.pre_state.get_highest_canonical_block_number()
    }

    pub fn touch(&mut self, address: Address) {
        if let Some(account) = self.new_state.get_mut(&address) {
            account.mark_touch();
        }
    }

    pub fn load_account(&mut self, address: Address) -> Result<&mut PendingAccount> {
        load_account(
            &self.pre_state,
            &mut self.new_state,
            &self.evm_state,
            address,
        )
    }

    pub fn load_var_info(&mut self, address: Address, variable: &str) -> Result<(&str, u8)> {
        let account = self.load_account(address)?;
        let Code::Scilla { types, .. } = &account.account.code else {
            return Err(anyhow!("not a scilla contract"));
        };
        let (ty, depth) = types
            .get(variable)
            .ok_or_else(|| anyhow!("missing type for variable: {variable}"))?;
        Ok((ty, *depth))
    }

    /// Set the value of a given variable at the given indices. This can be used for setting map values, unlike
    /// `load_storage`.
    pub fn set_storage(
        &mut self,
        address: Address,
        var_name: &str,
        indices: &[Vec<u8>],
        value: StorageValue,
    ) -> Result<()> {
        let account = load_account(
            &self.pre_state,
            &mut self.new_state,
            &self.evm_state,
            address,
        )?;

        let mut current = account
            .storage
            .entry(var_name.to_owned())
            .or_insert_with(StorageValue::incomplete_map);
        for key in indices {
            let current_map = match current {
                StorageValue::Map { map, .. } => map,
                StorageValue::Value(Some(_)) => {
                    return Err(anyhow!("expected a map"));
                }
                StorageValue::Value(None) => {
                    // This branch is unreachable because `update_state_value` in `ActiveCall` asserts that a deletion
                    // can only occur at the same depth as a variable.
                    unreachable!("deletes of whole maps are unsupported")
                }
            };
            let child = current_map
                .entry(key.clone())
                .or_insert_with(StorageValue::incomplete_map);
            current = child;
        }

        *current = value;

        Ok(())
    }

    pub fn load_storage(
        &mut self,
        address: Address,
        var_name: &str,
        indices: &[Vec<u8>],
    ) -> Result<&mut Option<Bytes>> {
        let account = load_account(
            &self.pre_state,
            &mut self.new_state,
            &self.evm_state,
            address,
        )?;

        fn get_cached<'a>(
            storage: &'a mut BTreeMap<String, StorageValue>,
            var_name: &str,
            indices: &[Vec<u8>],
        ) -> Result<(&'a mut StorageValue, bool)> {
            let mut cached = true;
            let mut current = storage.entry(var_name.to_owned()).or_insert_with(|| {
                cached = false;
                StorageValue::incomplete_map()
            });
            for key in indices {
                let current_map = match current {
                    StorageValue::Map { map, .. } => map,
                    StorageValue::Value(Some(_)) => {
                        return Err(anyhow!("expected a map"));
                    }
                    StorageValue::Value(None) => {
                        // This branch is unreachable because `update_state_value` in `ActiveCall` asserts that a deletion
                        // can only occur at the same depth as a variable.
                        unreachable!("deletes of whole maps are unsupported")
                    }
                };
                let child = current_map.entry(key.clone()).or_insert_with(|| {
                    cached = false;
                    StorageValue::incomplete_map()
                });
                current = child;
            }
            Ok((current, cached))
        }

        let (value, cached) = get_cached(&mut account.storage, var_name, indices)?;

        if !cached {
            let value_from_disk = self
                .pre_state
                .get_account_trie(address)?
                .get(&storage_key(var_name, indices))?;

            *value = StorageValue::Value(value_from_disk.map(|b| b.into()));
        }

        match value {
            StorageValue::Map { .. } => Err(anyhow!("expected bytes")),
            StorageValue::Value(value) => Ok(value),
        }
    }

    pub fn load_storage_by_prefix(
        &mut self,
        address: Address,
        var_name: &str,
        indices: &[Vec<u8>],
    ) -> Result<BTreeMap<Vec<u8>, StorageValue>> {
        let account = load_account(
            &self.pre_state,
            &mut self.new_state,
            &self.evm_state,
            address,
        )?;

        // Even if we have something cached for this prefix, we don't know if it is a full representation of the map.
        // It might have been the case that only a few subfields were cached. Therefore, we need to retrieve the full
        // map from disk and apply any cached (and potentially updated) values. In future, we should use the 'complete'
        // flag on maps to avoid needing to read from disk unconditionally.

        let values_from_disk: Vec<_> = self
            .pre_state
            .get_account_trie(address)?
            .iter_by_prefix(&storage_key(var_name, indices))?
            .collect();

        let mut map = StorageValue::complete_map();
        let cached = account.storage.get(var_name);

        // Un-flatten the values from disk into their true representation.
        for (k, v) in values_from_disk {
            let (disk_var_name, disk_indices) = split_storage_key(&k)?;
            if var_name != disk_var_name {
                // There is a hazard caused by the storage key format when a contract contains a variable which is a
                // prefix of another variable. For example, if a contract has a variable "foo" and another variable
                // "foobar", we call `.iter_by_prefix(storage_key("foo", [])) -> .iter_by_prefix("foo")` and mistakenly
                // obtain the values from both "foo" and "foobar". A more sensible format would have suffixed the
                // variable name with a `SEPARATOR` too, but it is awkward to change the format now. Instead, we filter
                // the results of the `iter_by_prefix` call here to exclude the 'extra' returned variables.
                trace!(var_name, disk_var_name, "scilla var name mismatch");
                continue;
            }
            assert!(disk_indices.starts_with(indices));

            let mut current_value = &mut map;
            let mut current_cached = cached;

            for index in disk_indices {
                if let Some(c) = current_cached {
                    match c {
                        StorageValue::Map { map, .. } => {
                            current_cached = map.get(&index);
                        }
                        // This branch can be hit in two cases:
                        // * Firstly, we expect the final index to point to a value in the cache, rather than a map.
                        // * Secondly, if a portion of the map has been deleted, then the cache can contain a `None`
                        // value at a greater height than the depth of the map.
                        StorageValue::Value(_) => {}
                    }
                }

                let map = match current_value {
                    StorageValue::Map { map, .. } => map,
                    StorageValue::Value(_) => {
                        return Err(anyhow!("expected map"));
                    }
                };
                // Note that we insert 'complete' maps here, because we know we are going to add *ALL* values from
                // with this prefix.
                current_value = map.entry(index).or_insert_with(StorageValue::complete_map);
            }

            *current_value = if let Some(cached) = current_cached {
                cached.clone()
            } else {
                StorageValue::Value(Some(v.into()))
            };
        }

        let map = match map {
            StorageValue::Map { map, .. } => map,
            StorageValue::Value(_) => {
                return Err(anyhow!("expected map"));
            }
        };

        Ok(map)
    }

    #[track_caller]
    pub fn deduct_from_account(
        &mut self,
        address: Address,
        amount: ZilAmount,
        gas_used: EvmGas,
    ) -> Result<Option<ScillaResult>> {
        let caller = std::panic::Location::caller();
        let account = self.load_account(address)?;
        account.mark_touch();
        trace!(
            "account balance = {0} sub {1}",
            account.account.balance,
            amount.get()
        );
        let Some(balance) = account.account.balance.checked_sub(amount.get()) else {
            info!("insufficient balance: {caller}");
            return Ok(Some(ScillaResult {
                success: false,
                contract_address: None,
                logs: vec![],
                gas_used,
                transitions: vec![],
                accepted: None,
                errors: [(0, vec![ScillaError::BalanceTransferFailed])]
                    .into_iter()
                    .collect(),
                exceptions: vec![],
            }));
        };
        account.account.balance = balance;
        Ok(None)
    }

    /// Return the changed state and resets the [PendingState] to its initial state in [PendingState::new].
    pub fn finalize(&mut self) -> HashMap<Address, PendingAccount> {
        mem::take(&mut self.new_state)
    }
}

#[derive(Clone, Debug)]
pub struct PendingAccount {
    pub account: Account,
    /// Cached values of updated or deleted storage. Note that deletions can happen at any level of a map.
    pub storage: BTreeMap<String, StorageValue>,
    pub from_evm: bool,
    pub touched: bool,
}

impl PendingAccount {
    pub fn mark_touch(&mut self) {
        self.touched = true;
    }
}

#[derive(Debug, Clone)]
pub enum StorageValue {
    Map {
        map: BTreeMap<Vec<u8>, StorageValue>,
        complete: bool,
    },
    /// A value can either be `Some(bytes)` to represent an updated value or `None` to represent a deleted value.
    Value(Option<Bytes>),
}

impl StorageValue {
    pub fn incomplete_map() -> StorageValue {
        StorageValue::Map {
            map: BTreeMap::new(),
            complete: false,
        }
    }

    pub fn complete_map() -> StorageValue {
        StorageValue::Map {
            map: BTreeMap::new(),
            complete: true,
        }
    }
}

impl From<Account> for PendingAccount {
    fn from(account: Account) -> PendingAccount {
        PendingAccount {
            account,
            storage: BTreeMap::new(),
            from_evm: false,
            touched: false,
        }
    }
}

pub fn store_external_libraries(
    state: &State,
    scilla_ext_libs_path: &ScillaExtLibsPath,
    ext_libraries: Vec<ExternalLibrary>,
) -> Result<(ScillaExtLibsPathInZq2, ScillaExtLibsPathInScilla)> {
    let (ext_libs_dir_in_zq2, ext_libs_dir_in_scilla) =
        scilla_ext_libs_path.generate_random_subdirs();

    let ext_libs_path = Path::new(&ext_libs_dir_in_zq2.0);
    std::fs::create_dir_all(ext_libs_path)?;

    for mut lib in ext_libraries {
        let account = state.get_account(lib.address)?;
        match &account.code {
            Code::Evm(_) => {
                return Err(anyhow!(
                    "Impossible to load an EVM contract as a Scilla library."
                ));
            }
            Code::Scilla {
                code, init_data, ..
            } => {
                let contract_init = ContractInit::new(init_data.clone());
                if !contract_init.is_library()? {
                    return Err(anyhow!(
                        "Impossible to load a non-library contract as a Scilla library."
                    ));
                }

                lib.name.retain(|c| c.is_alphanumeric() || c == '.');
                let file_path = ext_libs_path.join(&lib.name);

                fs::write(&file_path, code).with_context(|| {
                    format!("Failed to write the contract code to {:?}. library name: {}, library address: {}", file_path, lib.name, lib.address)
                })?;
            }
        }
    }
    Ok((ext_libs_dir_in_zq2, ext_libs_dir_in_scilla))
}

#[allow(clippy::too_many_arguments)]
fn scilla_create(
    mut state: PendingState,
    scilla: MutexGuard<'_, Scilla>,
    from_addr: Address,
    txn: TxZilliqa,
    current_block: BlockHeader,
    mut inspector: impl ScillaInspector,
    scilla_ext_libs_path: &ScillaExtLibsPath,
    fork: &Fork,
) -> Result<(ScillaResult, PendingState)> {
    if txn.data.is_empty() {
        return Err(anyhow!("contract creation without init data"));
    }

    if let Some(result) = state.deduct_from_account(from_addr, txn.amount, EvmGas(0))? {
        return Ok((result, state));
    }

    // The contract address is created with the account's current nonce. The transaction's nonce is one greater
    // than this.
    let contract_address = zil_contract_address(from_addr, txn.nonce - 1);

    let mut init_data: Vec<ParamValue> = serde_json::from_str(&txn.data)?;
    if !fork.scilla_json_preserve_order {
        for param_value in init_data.iter_mut() {
            param_value.value.sort_all_objects();
        }
    }

    init_data.extend([
        ParamValue {
            name: "_creation_block".to_string(),
            value: Value::String(current_block.number.to_string()),
            ty: "BNum".to_string(),
        },
        ParamValue {
            name: "_this_address".to_string(),
            value: Value::String(format!("{contract_address:#x}")),
            ty: "ByStr20".to_string(),
        },
    ]);

    let gas = txn.gas_limit;

    let Some(gas) = gas.checked_sub(constants::SCILLA_INVOKE_CHECKER) else {
        warn!("not enough gas to invoke scilla checker");
        return Ok((
            ScillaResult {
                success: false,
                contract_address: Some(contract_address),
                logs: vec![],
                gas_used: (txn.gas_limit - gas).into(),
                transitions: vec![],
                accepted: Some(false),
                errors: [(0, vec![ScillaError::GasNotSufficient])]
                    .into_iter()
                    .collect(),
                exceptions: vec![],
            },
            state,
        ));
    };

    let contract_init = ContractInit::new(init_data.clone());

    // We need to store external libraries used in the current contract. Scilla checker needs to import them to check the contract.
    let (ext_libs_dir_in_zq2, ext_libs_dir_in_scilla) = store_external_libraries(
        &state.pre_state,
        scilla_ext_libs_path,
        contract_init.external_libraries()?,
    )?;

    let _cleanup_ext_libs_guard = scopeguard::guard((), |_| {
        // We need to ensure that in any case, the external libs directory will be removed.
        let _ = std::fs::remove_dir_all(ext_libs_dir_in_zq2.0);
    });

    let check_output =
        match scilla.check_contract(&txn.code, gas, &contract_init, &ext_libs_dir_in_scilla)? {
            Ok(o) => o,
            Err(e) => {
                warn!(?e, "transaction failed");
                let gas = gas.min(e.gas_remaining);
                return Ok((
                    ScillaResult {
                        success: false,
                        contract_address: Some(contract_address),
                        logs: vec![],
                        gas_used: (txn.gas_limit - gas).into(),
                        transitions: vec![],
                        accepted: Some(false),
                        errors: [(0, vec![ScillaError::CreateContractFailed])]
                            .into_iter()
                            .collect(),
                        exceptions: e.errors.into_iter().map(Into::into).collect(),
                    },
                    state,
                ));
            }
        };

    debug!(?check_output);

    let gas = gas.min(check_output.gas_remaining);

    // If the contract is a library, contract info is empty.
    let contract_info = check_output.contract_info.unwrap_or_default();
    let types = contract_info
        .fields
        .into_iter()
        .map(|p| (p.name, (p.ty, p.depth as u8)))
        .collect();

    let transitions = contract_info.transitions;

    let account = state.load_account(contract_address)?;
    account.mark_touch();
    if fork.scilla_contract_creation_increments_account_balance {
        account.account.balance += txn.amount.get();
    } else {
        account.account.balance = txn.amount.get();
    }
    account.account.code = Code::Scilla {
        code: txn.code.clone(),
        init_data,
        types,
        transitions,
    };

    let Some(gas) = gas.checked_sub(constants::SCILLA_INVOKE_RUNNER) else {
        warn!("not enough gas to invoke scilla runner");
        return Ok((
            ScillaResult {
                success: false,
                contract_address: Some(contract_address),
                logs: vec![],
                gas_used: (txn.gas_limit - gas).into(),
                transitions: vec![],
                accepted: Some(false),
                errors: [(0, vec![ScillaError::GasNotSufficient])]
                    .into_iter()
                    .collect(),
                exceptions: vec![],
            },
            state,
        ));
    };

    let (create_output, state) = scilla.create_contract(
        state,
        contract_address,
        &txn.code,
        gas,
        txn.amount,
        &contract_init,
        &ext_libs_dir_in_scilla,
        fork,
        current_block.number,
    )?;
    let create_output = match create_output {
        Ok(o) => o,
        Err(e) => {
            warn!(?e, "transaction failed");
            let gas = gas.min(e.gas_remaining);
            return Ok((
                ScillaResult {
                    success: false,
                    contract_address: Some(contract_address),
                    logs: vec![],
                    gas_used: (txn.gas_limit - gas).into(),
                    transitions: vec![],
                    accepted: Some(false),
                    errors: [(0, vec![ScillaError::CreateContractFailed])]
                        .into_iter()
                        .collect(),
                    exceptions: e.errors.into_iter().map(Into::into).collect(),
                },
                state,
            ));
        }
    };

    debug!(?create_output);

    let gas = gas.min(create_output.gas_remaining);

    inspector.create(from_addr, contract_address, txn.amount.get());

    Ok((
        ScillaResult {
            success: true,
            contract_address: Some(contract_address),
            logs: vec![],
            gas_used: (txn.gas_limit - gas).into(),
            transitions: vec![],
            accepted: None,
            errors: BTreeMap::new(),
            exceptions: vec![],
        },
        state,
    ))
}

#[allow(clippy::too_many_arguments)]
pub fn scilla_call(
    state: PendingState,
    scilla: MutexGuard<'_, Scilla>,
    from_addr: Address,
    sender: Address,
    gas_limit: ScillaGas,
    to_addr: Address,
    amount: ZilAmount,
    data: String,
    mut inspector: impl ScillaInspector,
    scilla_ext_libs_path: &ScillaExtLibsPath,
    fork: &Fork,
    current_block: u64,
) -> Result<(ScillaResult, PendingState)> {
    let mut gas = gas_limit;

    let message = if !data.is_empty() {
        let mut m: Value = serde_json::from_str(&data)?;
        m["_amount"] = amount.to_string().into();
        m["_sender"] = format!("{sender:#x}").into();
        m["_origin"] = format!("{from_addr:#x}").into();
        Some(m)
    } else {
        None
    };

    let mut call_stack = vec![(0, sender, to_addr, amount, message)];
    let mut logs = vec![];
    let mut transitions = vec![];
    let mut root_contract_accepted = false;

    let mut state = Some(state);

    while let Some((depth, sender, to_addr, amount, message)) = call_stack.pop() {
        let mut current_state = state.take().expect("missing state");

        let contract = current_state.load_account(to_addr)?;
        let code_and_data = match &contract.account.code {
            // Note that EOAs are represented by [Code::Evm] with no code.
            Code::Evm(code) if fork.scilla_messages_can_call_evm_contracts || code.is_empty() => {
                None
            }
            Code::Scilla {
                code, init_data, ..
            } => Some((code, init_data)),
            // Calls to EVM contracts should fail because `fork.scilla_messages_can_call_evm_contract == false`.
            Code::Evm(_) => {
                return Ok((
                    ScillaResult {
                        success: false,
                        contract_address: None,
                        logs: vec![],
                        gas_used: (gas_limit - gas).into(),
                        transitions: vec![],
                        accepted: Some(false),
                        errors: [(depth, vec![ScillaError::CallContractFailed])]
                            .into_iter()
                            .collect(),
                        exceptions: vec![ScillaException {
                            line: 0,
                            message: "Scilla call to EVM contract".to_owned(),
                        }],
                    },
                    current_state,
                ));
            }
        };

        if let Some((code, init_data)) = code_and_data {
            // The `to_addr` is a Scilla contract, so we are going to invoke the Scilla interpreter.

            let Some(g) = gas.checked_sub(constants::SCILLA_INVOKE_RUNNER) else {
                warn!("not enough gas to invoke scilla runner");
                return Ok((
                    ScillaResult {
                        success: false,
                        contract_address: None,
                        logs: vec![],
                        gas_used: (gas_limit - gas).into(),
                        transitions: vec![],
                        accepted: Some(false),
                        errors: [(depth, vec![ScillaError::GasNotSufficient])]
                            .into_iter()
                            .collect(),
                        exceptions: vec![],
                    },
                    current_state,
                ));
            };
            gas = g;

            let code = code.clone();

            let contract_init = ContractInit::new(init_data.clone());

            let contract_balance = contract.account.balance;

            // We need to store external libraries used in the current contract. Scilla needs to import them to run the transition.
            let (ext_libs_dir_in_zq2, ext_libs_dir_in_scilla) = store_external_libraries(
                &current_state.pre_state,
                scilla_ext_libs_path,
                contract_init.external_libraries()?,
            )?;
            let _cleanup_ext_libs_guard = scopeguard::guard((), |_| {
                // We need to ensure that in any case, the external libs directory will be removed.
                let _ = std::fs::remove_dir_all(ext_libs_dir_in_zq2.0);
            });
            let (output, mut new_state) = scilla.invoke_contract(
                current_state,
                to_addr,
                &code,
                gas,
                ZilAmount::from_amount(contract_balance),
                &contract_init,
                message
                    .as_ref()
                    .ok_or_else(|| anyhow!("call to a Scilla contract without a message"))?,
                &ext_libs_dir_in_scilla,
                fork,
                current_block,
            )?;
            inspector.call(sender, to_addr, amount.get(), depth);

            let mut output = match output {
                Ok(o) => o,
                Err(e) => {
                    warn!(?e, "transaction failed");
                    let gas = gas.min(e.gas_remaining);
                    return Ok((
                        ScillaResult {
                            success: false,
                            contract_address: None,
                            logs: vec![],
                            gas_used: (gas_limit - gas).into(),
                            transitions: vec![],
                            accepted: Some(false),
                            errors: [(0, vec![ScillaError::CallContractFailed])]
                                .into_iter()
                                .collect(),
                            exceptions: e.errors.into_iter().map(Into::into).collect(),
                        },
                        new_state,
                    ));
                }
            };

            debug!(?output);

            gas = gas.min(output.gas_remaining);

            if output.accepted {
                if let Some(result) = new_state.deduct_from_account(sender, amount, EvmGas(0))? {
                    return Ok((result, new_state));
                }

                let to = new_state.load_account(to_addr)?;
                to.mark_touch();
                to.account.balance += amount.get();

                if depth == 0 {
                    root_contract_accepted = true;
                }
            }

            transitions.reserve(output.messages.len());
            call_stack.reserve(output.messages.len());

            // Ensure the order is preserved and transitions are dispatched in the same order
            // as they were emitted from contract
            if fork.scilla_transition_proper_order {
                output.messages.reverse();
            }

            for message in output.messages {
                transitions.push(ScillaTransition {
                    from: to_addr,
                    to: message.recipient,
                    depth: depth + 1,
                    amount: message.amount,
                    tag: message.tag.clone(),
                    params: serde_json::to_string(&message.params)?,
                });

                let next_message = json!({
                    "_tag": message.tag,
                    "_amount": message.amount.to_string(),
                    "_sender": format!("{to_addr:#x}"),
                    "_origin": format!("{from_addr:#x}"),
                    "params": message.params,
                });
                call_stack.push((
                    depth + 1,
                    to_addr,
                    message.recipient,
                    message.amount,
                    Some(next_message),
                ));
            }

            logs.reserve(output.events.len());
            for event in output.events {
                let log = ScillaLog {
                    address: to_addr,
                    event_name: event.event_name,
                    params: event.params,
                };
                logs.push(log);
            }

            state = Some(new_state);
        } else {
            // The `to_addr` is an EOA.
            let Some(g) = gas.checked_sub(constants::SCILLA_TRANSFER) else {
                warn!("not enough gas to make transfer");
                return Ok((
                    ScillaResult {
                        success: false,
                        contract_address: None,
                        logs: vec![],
                        gas_used: (gas_limit - gas).into(),
                        transitions: vec![],
                        accepted: Some(false),
                        errors: [(0, vec![ScillaError::GasNotSufficient])]
                            .into_iter()
                            .collect(),
                        exceptions: vec![],
                    },
                    current_state,
                ));
            };
            gas = g;

            let deduct_funds_from = match fork.scilla_deduct_funds_from_actual_sender {
                true => sender,
                false => from_addr,
            };

            if let Some(result) =
                current_state.deduct_from_account(deduct_funds_from, amount, EvmGas(0))?
            {
                return Ok((result, current_state));
            }

            let to = current_state.load_account(to_addr)?;
            to.mark_touch();
            to.account.balance += amount.get();

            inspector.transfer(from_addr, to_addr, amount.get(), depth);

            state = Some(current_state);
        }
    }

    Ok((
        ScillaResult {
            success: true,
            contract_address: None,
            logs,
            gas_used: (gas_limit - gas).into(),
            transitions,
            accepted: Some(root_contract_accepted),
            errors: BTreeMap::new(),
            exceptions: vec![],
        },
        state.take().expect("missing state"),
    ))
}

pub struct BlessedTransaction {
    pub hash: Hash,
    pub payload: Bytes,
    pub sender: Address,
    pub gas_limit: u64,
}

/// Blessed transactions bypass minimum gas price rules. These transactions have value to the network even at a lower
/// gas price, so we accept them anyway.
// It i s valuable to accept these transactions despite the low gas price, because it means the contract is deployed at the same address as other EVM-compatible chains.
// This means that contracts deployed using this proxy will be deployed to the same address as on other chains.
pub const BLESSED_TRANSACTIONS: [BlessedTransaction; 2] = [
    // Hash of the deployment transaction for the deterministic deployment proxy from
    // https://github.com/Arachnid/deterministic-deployment-proxy
    BlessedTransaction {
        hash: Hash(hex!(
            "eddf9e61fb9d8f5111840daef55e5fde0041f5702856532cdbb5a02998033d26"
        )),
        payload: Bytes::from_static(&hex!(
            "0xf8a58085174876e800830186a08080b853604580600e600039806000f350fe7fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffe03601600081602082378035828234f58015156039578182fd5b8082525050506014600cf31ba02222222222222222222222222222222222222222222222222222222222222222a02222222222222222222222222222222222222222222222222222222222222222"
        )),
        gas_limit: 1_000_000,
        sender: address!("0x3fab184622dc19b6109349b94811493bf2a45362"),
    },
    // Hash of the deployment transaction for the Multicall3
    // https://github.com/mds1/multicall?tab=readme-ov-file#new-deployments
    BlessedTransaction {
        hash: Hash(hex!(
            "0x07471adfe8f4ec553c1199f495be97fc8be8e0626ae307281c22534460184ed1"
        )),
        payload: Bytes::from_static(&hex!(
            "0xf90f538085174876e800830f42408080b90f00608060405234801561001057600080fd5b50610ee0806100206000396000f3fe6080604052600436106100f35760003560e01c80634d2301cc1161008a578063a8b0574e11610059578063a8b0574e1461025a578063bce38bd714610275578063c3077fa914610288578063ee82ac5e1461029b57600080fd5b80634d2301cc146101ec57806372425d9d1461022157806382ad56cb1461023457806386d516e81461024757600080fd5b80633408e470116100c65780633408e47014610191578063399542e9146101a45780633e64a696146101c657806342cbb15c146101d957600080fd5b80630f28c97d146100f8578063174dea711461011a578063252dba421461013a57806327e86d6e1461015b575b600080fd5b34801561010457600080fd5b50425b6040519081526020015b60405180910390f35b61012d610128366004610a85565b6102ba565b6040516101119190610bbe565b61014d610148366004610a85565b6104ef565b604051610111929190610bd8565b34801561016757600080fd5b50437fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff0140610107565b34801561019d57600080fd5b5046610107565b6101b76101b2366004610c60565b610690565b60405161011193929190610cba565b3480156101d257600080fd5b5048610107565b3480156101e557600080fd5b5043610107565b3480156101f857600080fd5b50610107610207366004610ce2565b73ffffffffffffffffffffffffffffffffffffffff163190565b34801561022d57600080fd5b5044610107565b61012d610242366004610a85565b6106ab565b34801561025357600080fd5b5045610107565b34801561026657600080fd5b50604051418152602001610111565b61012d610283366004610c60565b61085a565b6101b7610296366004610a85565b610a1a565b3480156102a757600080fd5b506101076102b6366004610d18565b4090565b60606000828067ffffffffffffffff8111156102d8576102d8610d31565b60405190808252806020026020018201604052801561031e57816020015b6040805180820190915260008152606060208201528152602001906001900390816102f65790505b5092503660005b8281101561047757600085828151811061034157610341610d60565b6020026020010151905087878381811061035d5761035d610d60565b905060200281019061036f9190610d8f565b6040810135958601959093506103886020850185610ce2565b73ffffffffffffffffffffffffffffffffffffffff16816103ac6060870187610dcd565b6040516103ba929190610e32565b60006040518083038185875af1925050503d80600081146103f7576040519150601f19603f3d011682016040523d82523d6000602084013e6103fc565b606091505b50602080850191909152901515808452908501351761046d577f08c379a000000000000000000000000000000000000000000000000000000000600052602060045260176024527f4d756c746963616c6c333a2063616c6c206661696c656400000000000000000060445260846000fd5b5050600101610325565b508234146104e6576040517f08c379a000000000000000000000000000000000000000000000000000000000815260206004820152601a60248201527f4d756c746963616c6c333a2076616c7565206d69736d6174636800000000000060448201526064015b60405180910390fd5b50505092915050565b436060828067ffffffffffffffff81111561050c5761050c610d31565b60405190808252806020026020018201604052801561053f57816020015b606081526020019060019003908161052a5790505b5091503660005b8281101561068657600087878381811061056257610562610d60565b90506020028101906105749190610e42565b92506105836020840184610ce2565b73ffffffffffffffffffffffffffffffffffffffff166105a66020850185610dcd565b6040516105b4929190610e32565b6000604051808303816000865af19150503d80600081146105f1576040519150601f19603f3d011682016040523d82523d6000602084013e6105f6565b606091505b5086848151811061060957610609610d60565b602090810291909101015290508061067d576040517f08c379a000000000000000000000000000000000000000000000000000000000815260206004820152601760248201527f4d756c746963616c6c333a2063616c6c206661696c656400000000000000000060448201526064016104dd565b50600101610546565b5050509250929050565b43804060606106a086868661085a565b905093509350939050565b6060818067ffffffffffffffff8111156106c7576106c7610d31565b60405190808252806020026020018201604052801561070d57816020015b6040805180820190915260008152606060208201528152602001906001900390816106e55790505b5091503660005b828110156104e657600084828151811061073057610730610d60565b6020026020010151905086868381811061074c5761074c610d60565b905060200281019061075e9190610e76565b925061076d6020840184610ce2565b73ffffffffffffffffffffffffffffffffffffffff166107906040850185610dcd565b60405161079e929190610e32565b6000604051808303816000865af19150503d80600081146107db576040519150601f19603f3d011682016040523d82523d6000602084013e6107e0565b606091505b506020808401919091529015158083529084013517610851577f08c379a000000000000000000000000000000000000000000000000000000000600052602060045260176024527f4d756c746963616c6c333a2063616c6c206661696c656400000000000000000060445260646000fd5b50600101610714565b6060818067ffffffffffffffff81111561087657610876610d31565b6040519080825280602002602001820160405280156108bc57816020015b6040805180820190915260008152606060208201528152602001906001900390816108945790505b5091503660005b82811015610a105760008482815181106108df576108df610d60565b602002602001015190508686838181106108fb576108fb610d60565b905060200281019061090d9190610e42565b925061091c6020840184610ce2565b73ffffffffffffffffffffffffffffffffffffffff1661093f6020850185610dcd565b60405161094d929190610e32565b6000604051808303816000865af19150503d806000811461098a576040519150601f19603f3d011682016040523d82523d6000602084013e61098f565b606091505b506020830152151581528715610a07578051610a07576040517f08c379a000000000000000000000000000000000000000000000000000000000815260206004820152601760248201527f4d756c746963616c6c333a2063616c6c206661696c656400000000000000000060448201526064016104dd565b506001016108c3565b5050509392505050565b6000806060610a2b60018686610690565b919790965090945092505050565b60008083601f840112610a4b57600080fd5b50813567ffffffffffffffff811115610a6357600080fd5b6020830191508360208260051b8501011115610a7e57600080fd5b9250929050565b60008060208385031215610a9857600080fd5b823567ffffffffffffffff811115610aaf57600080fd5b610abb85828601610a39565b90969095509350505050565b6000815180845260005b81811015610aed57602081850181015186830182015201610ad1565b81811115610aff576000602083870101525b50601f017fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffe0169290920160200192915050565b600082825180855260208086019550808260051b84010181860160005b84811015610bb1578583037fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffe001895281518051151584528401516040858501819052610b9d81860183610ac7565b9a86019a9450505090830190600101610b4f565b5090979650505050505050565b602081526000610bd16020830184610b32565b9392505050565b600060408201848352602060408185015281855180845260608601915060608160051b870101935082870160005b82811015610c52577fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffa0888703018452610c40868351610ac7565b95509284019290840190600101610c06565b509398975050505050505050565b600080600060408486031215610c7557600080fd5b83358015158114610c8557600080fd5b9250602084013567ffffffffffffffff811115610ca157600080fd5b610cad86828701610a39565b9497909650939450505050565b838152826020820152606060408201526000610cd96060830184610b32565b95945050505050565b600060208284031215610cf457600080fd5b813573ffffffffffffffffffffffffffffffffffffffff81168114610bd157600080fd5b600060208284031215610d2a57600080fd5b5035919050565b7f4e487b7100000000000000000000000000000000000000000000000000000000600052604160045260246000fd5b7f4e487b7100000000000000000000000000000000000000000000000000000000600052603260045260246000fd5b600082357fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff81833603018112610dc357600080fd5b9190910192915050565b60008083357fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffe1843603018112610e0257600080fd5b83018035915067ffffffffffffffff821115610e1d57600080fd5b602001915036819003821315610a7e57600080fd5b8183823760009101908152919050565b600082357fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffc1833603018112610dc357600080fd5b600082357fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffa1833603018112610dc357600080fdfea2646970667358221220bb2b5c71a328032f97c676ae39a1ec2148d3e5d6f73d95e9b17910152d61f16264736f6c634300080c00331ca0edce47092c0f398cebf3ffc267f05c8e7076e3b89445e0fe50f6332273d4569ba01b0b9d000e19b24c5869b0fc3b22b0d6fa47cd63316875cbbd577d76e6fde086"
        )),
        gas_limit: 10_000_000,
        sender: address!("0x05f32B3cC3888453ff71B01135B34FF8e41263F2"),
    },
];

```

`zilliqa/src/health.rs`:

```rs
use std::{error::Error, pin::Pin};

use futures::Future;
use http::{Method, Request, Response, StatusCode};
use hyper::body::Body;
use tower::{Service, layer::Layer};

/// [Layer] that responds to `GET /health` calls with a 200 status code.
pub struct HealthLayer;

impl<S> Layer<S> for HealthLayer {
    type Service = HealthRequest<S>;

    fn layer(&self, inner: S) -> Self::Service {
        HealthRequest { inner }
    }
}

#[derive(Clone)]
pub struct HealthRequest<S> {
    inner: S,
}

impl<S, B> Service<Request<B>> for HealthRequest<S>
where
    S: Service<Request<B>, Response = Response<B>>,
    S::Response: 'static,
    S::Error: Into<Box<dyn Error + Send + Sync>> + 'static,
    S::Future: Send + 'static,
    B: Body + Default + Send + 'static,
{
    type Response = S::Response;
    type Error = Box<dyn Error + Send + Sync + 'static>;
    type Future =
        Pin<Box<dyn Future<Output = Result<Self::Response, Self::Error>> + Send + 'static>>;

    fn poll_ready(
        &mut self,
        cx: &mut std::task::Context<'_>,
    ) -> std::task::Poll<Result<(), Self::Error>> {
        self.inner.poll_ready(cx).map_err(Into::into)
    }

    fn call(&mut self, req: Request<B>) -> Self::Future {
        if req.uri() == "/health" && req.method() == Method::GET {
            let response = hyper::Response::builder()
                .status(StatusCode::OK)
                .body(B::default())
                .unwrap();
            let res_fut = async move { Ok(response) };

            Box::pin(res_fut)
        } else {
            let fut = self.inner.call(req);
            let res_fut = async move {
                let res = fut.await.map_err(|err| err.into())?;
                Ok(res)
            };

            Box::pin(res_fut)
        }
    }
}

```

`zilliqa/src/inspector.rs`:

```rs
use std::collections::HashSet;

use alloy::primitives::{Address, U256};
use revm::{
    Database, EvmContext, Inspector,
    inspectors::NoOpInspector,
    interpreter::{CallInputs, CallOutcome, CallScheme, CreateInputs, CreateOutcome},
    primitives::CreateScheme,
};
use revm_inspectors::tracing::{
    FourByteInspector, MuxInspector, TracingInspector, js::JsInspector,
};

use crate::api::types::ots::{Operation, OperationType, TraceEntry, TraceEntryType};

/// Provides callbacks from the Scilla interpreter.
pub trait ScillaInspector {
    fn create(&mut self, creator: Address, contract_address: Address, amount: u128) {
        let _ = contract_address;
        let _ = creator;
        let _ = amount;
    }
    fn transfer(&mut self, from: Address, to: Address, amount: u128, depth: u64) {
        let _ = amount;
        let _ = to;
        let _ = from;
        let _ = depth;
    }
    fn call(&mut self, from: Address, to: Address, amount: u128, depth: u64) {
        let _ = to;
        let _ = from;
        let _ = amount;
        let _ = depth;
    }
}

impl<T: ScillaInspector> ScillaInspector for &mut T {
    fn create(&mut self, creator: Address, contract_address: Address, amount: u128) {
        (*self).create(creator, contract_address, amount);
    }

    fn transfer(&mut self, from: Address, to: Address, amount: u128, depth: u64) {
        (*self).transfer(from, to, amount, depth)
    }

    fn call(&mut self, from: Address, to: Address, amount: u128, depth: u64) {
        (*self).call(from, to, amount, depth)
    }
}

pub fn noop() -> NoOpInspector {
    NoOpInspector
}

impl ScillaInspector for NoOpInspector {}

impl ScillaInspector for FourByteInspector {}

impl ScillaInspector for MuxInspector {}

impl ScillaInspector for JsInspector {}

#[derive(Debug, Default)]
pub struct TouchedAddressInspector {
    pub touched: HashSet<Address>,
}

impl<DB: Database> Inspector<DB> for TouchedAddressInspector {
    fn call(&mut self, _: &mut EvmContext<DB>, inputs: &mut CallInputs) -> Option<CallOutcome> {
        self.touched.insert(inputs.caller);
        self.touched.insert(inputs.bytecode_address);
        self.touched.insert(inputs.target_address);
        None
    }

    fn create_end(
        &mut self,
        _: &mut EvmContext<DB>,
        inputs: &CreateInputs,
        outcome: CreateOutcome,
    ) -> CreateOutcome {
        self.touched.insert(inputs.caller);
        if let Some(address) = outcome.address {
            self.touched.insert(address);
        }
        outcome
    }

    fn selfdestruct(&mut self, contract: Address, target: Address, _: U256) {
        self.touched.insert(contract);
        self.touched.insert(target);
    }
}

impl ScillaInspector for TouchedAddressInspector {
    fn create(&mut self, creator: Address, contract_address: Address, _: u128) {
        self.touched.insert(creator);
        self.touched.insert(contract_address);
    }

    fn transfer(&mut self, from: Address, to: Address, _: u128, _: u64) {
        self.touched.insert(from);
        self.touched.insert(to);
    }

    fn call(&mut self, from: Address, to: Address, _: u128, _: u64) {
        self.touched.insert(from);
        self.touched.insert(to);
    }
}

#[derive(Debug)]
pub struct CreatorInspector {
    contract: Address,
    creator: Option<Address>,
}

impl CreatorInspector {
    pub fn new(contract: Address) -> Self {
        CreatorInspector {
            contract,
            creator: None,
        }
    }

    pub fn creator(&self) -> Option<Address> {
        self.creator
    }
}

impl<DB: Database> Inspector<DB> for CreatorInspector {
    fn create_end(
        &mut self,
        _: &mut EvmContext<DB>,
        inputs: &CreateInputs,
        outcome: CreateOutcome,
    ) -> CreateOutcome {
        if let Some(address) = outcome.address {
            if address == self.contract {
                self.creator = Some(inputs.caller);
            }
        }
        outcome
    }
}

impl ScillaInspector for CreatorInspector {
    fn create(&mut self, creator: Address, contract_address: Address, _: u128) {
        if contract_address == self.contract {
            self.creator = Some(creator);
        }
    }
}

#[derive(Debug, Default)]
pub struct OtterscanTraceInspector {
    entries: Vec<TraceEntry>,
}

impl OtterscanTraceInspector {
    pub fn entries(self) -> Vec<TraceEntry> {
        self.entries
    }
}

impl<DB: Database> Inspector<DB> for OtterscanTraceInspector {
    fn call(
        &mut self,
        context: &mut EvmContext<DB>,
        inputs: &mut CallInputs,
    ) -> Option<CallOutcome> {
        let ty = match inputs.scheme {
            CallScheme::Call => TraceEntryType::Call,
            CallScheme::CallCode => TraceEntryType::CallCode,
            CallScheme::DelegateCall => TraceEntryType::DelegateCall,
            CallScheme::StaticCall => TraceEntryType::StaticCall,
            CallScheme::ExtCall => TraceEntryType::ExtCall,
            CallScheme::ExtStaticCall => TraceEntryType::ExtStaticCall,
            CallScheme::ExtDelegateCall => TraceEntryType::ExtDelegateCall,
        };
        self.entries.push(TraceEntry {
            ty,
            depth: context.journaled_state.depth(),
            from: inputs.caller,
            to: inputs.target_address,
            value: inputs.transfer_value().map(|v| v.to()),
            input: inputs.input.to_vec(),
        });

        None
    }

    fn create(
        &mut self,
        context: &mut EvmContext<DB>,
        inputs: &mut CreateInputs,
    ) -> Option<CreateOutcome> {
        let ty = match inputs.scheme {
            CreateScheme::Create => TraceEntryType::Create,
            CreateScheme::Create2 { .. } => TraceEntryType::Create2,
        };
        let nonce = context.journaled_state.account(inputs.caller).info.nonce;
        self.entries.push(TraceEntry {
            ty,
            depth: context.journaled_state.depth(),
            from: inputs.caller,
            to: inputs.created_address(nonce),
            value: Some(inputs.value.to()),
            input: inputs.init_code.to_vec(),
        });

        None
    }

    fn selfdestruct(&mut self, contract: Address, target: Address, value: U256) {
        let depth = self.entries.last().map(|t| t.depth).unwrap_or_default();
        self.entries.push(TraceEntry {
            ty: TraceEntryType::SelfDestruct,
            depth,
            from: contract,
            to: target,
            value: Some(value.to()),
            input: vec![],
        });
    }
}

impl ScillaInspector for OtterscanTraceInspector {
    fn call(&mut self, from: Address, to: Address, amount: u128, depth: u64) {
        self.entries.push(TraceEntry {
            ty: TraceEntryType::Call,
            depth,
            from,
            to,
            value: Some(amount),
            input: vec![],
        })
    }

    fn create(&mut self, creator: Address, contract_address: Address, amount: u128) {
        self.entries.push(TraceEntry {
            ty: TraceEntryType::Create,
            depth: 0,
            from: creator,
            to: contract_address,
            value: Some(amount),
            input: vec![],
        })
    }

    fn transfer(&mut self, from: Address, to: Address, amount: u128, depth: u64) {
        self.entries.push(TraceEntry {
            ty: TraceEntryType::Call,
            depth,
            from,
            to,
            value: Some(amount),
            input: vec![],
        })
    }
}

/// Traces internal transfers within a transaction for Otterscan. Transfers at the top-level are deliberately filtered
/// out.
#[derive(Debug, Default)]
pub struct OtterscanOperationInspector {
    entries: Vec<Operation>,
}

impl OtterscanOperationInspector {
    pub fn entries(self) -> Vec<Operation> {
        self.entries
    }
}

impl<DB: Database> Inspector<DB> for OtterscanOperationInspector {
    fn call(
        &mut self,
        context: &mut EvmContext<DB>,
        inputs: &mut CallInputs,
    ) -> Option<CallOutcome> {
        if context.journaled_state.depth() != 0 && inputs.transfers_value() {
            self.entries.push(Operation {
                ty: OperationType::Transfer,
                from: inputs.caller,
                to: inputs.target_address,
                value: inputs.call_value().to(),
            });
        }

        None
    }

    fn create(
        &mut self,
        context: &mut EvmContext<DB>,
        inputs: &mut CreateInputs,
    ) -> Option<CreateOutcome> {
        if context.journaled_state.depth() != 0 {
            let ty = match inputs.scheme {
                CreateScheme::Create => OperationType::Create,
                CreateScheme::Create2 { .. } => OperationType::Create2,
            };
            let nonce = context.journaled_state.account(inputs.caller).info.nonce;
            self.entries.push(Operation {
                ty,
                from: inputs.caller,
                to: inputs.created_address(nonce),
                value: inputs.value.to(),
            });
        }

        None
    }

    fn selfdestruct(&mut self, contract: Address, target: Address, value: U256) {
        self.entries.push(Operation {
            ty: OperationType::SelfDestruct,
            from: contract,
            to: target,
            value: value.to(),
        });
    }
}

impl ScillaInspector for OtterscanOperationInspector {
    fn call(&mut self, from: Address, to: Address, amount: u128, depth: u64) {
        if depth != 0 && amount != 0 {
            self.entries.push(Operation {
                ty: OperationType::Transfer,
                from,
                to,
                value: amount,
            });
        }
    }

    fn transfer(&mut self, from: Address, to: Address, amount: u128, depth: u64) {
        if depth != 0 && amount != 0 {
            self.entries.push(Operation {
                ty: OperationType::Transfer,
                from,
                to,
                value: amount,
            });
        }
    }

    // Creates are always ignored because they are always at depth=0 for Scilla transactions.
}

impl ScillaInspector for TracingInspector {}

```

`zilliqa/src/lib.rs`:

```rs
pub mod api;
mod blockhooks;
pub mod cfg;
pub mod consensus;
pub mod constants;
pub mod contracts;
pub mod crypto;
pub mod db;
mod error;
pub mod exec;
mod health;
pub mod inspector;
pub mod message;
pub mod node;
pub mod node_launcher;
pub mod p2p_node;
mod pool;
mod precompiles;
pub mod range_map;
pub mod schnorr;
pub mod scilla;
mod scilla_proto;
pub mod serde_util;
pub mod state;
pub mod sync;
pub mod test_util;
pub mod time;
pub mod transaction;
pub mod zq1_proto;

```

`zilliqa/src/message.rs`:

```rs
use std::{
    collections::HashSet,
    fmt::{self, Display, Formatter},
    ops::Range,
    path::Path,
};

use alloy::primitives::Address;
use anyhow::{Result, anyhow};
use bitvec::{bitarr, order::Msb0};
use itertools::Either;
use libp2p::PeerId;
use serde::{Deserialize, Serialize};
use sha3::{Digest, Keccak256};

use crate::{
    crypto::{BlsSignature, Hash, NodePublicKey, SecretKey},
    db::TrieStorage,
    time::SystemTime,
    transaction::{EvmGas, SignedTransaction, TransactionReceipt, VerifiedTransaction},
};

/// The maximum number of validators in the consensus committee. This is passed to the deposit contract and we expect
/// it to reject deposits which would make the committee larger than this.
pub const MAX_COMMITTEE_SIZE: usize = 256;
pub type BitArray = bitvec::BitArr!(for MAX_COMMITTEE_SIZE, in u8, Msb0);
pub type BitSlice = bitvec::slice::BitSlice<u8, Msb0>;

/// A block proposal. The only difference between this and [Block] is that `transactions` contains the full transaction
/// bodies, rather than just hashes.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Proposal {
    pub header: BlockHeader,
    pub agg: Option<AggregateQc>,
    pub transactions: Vec<SignedTransaction>,
    pub opaque_transactions: Vec<Hash>,
}

impl Proposal {
    /// Constructs a Proposal from a block and a vector of verified transactions.
    /// ```Arguments```
    ///
    /// * `block`: the Block, including the header and the full list of transaction hashes
    ///   included in the block (and proposal)
    ///
    /// * `full_transactions`: the transactions whose full `Transaction` bodies will be
    ///   included in the proposal. The difference between `block.transactions` and
    ///   `full_transactions` make up the `opaque_transactions` (i.e. transactions only known
    ///   by their hash).
    pub fn from_parts(block: Block, full_transactions: Vec<VerifiedTransaction>) -> Self {
        Self::from_parts_with_hashes(
            block,
            full_transactions
                .into_iter()
                .map(|tx| (tx.tx, tx.hash))
                .collect(),
        )
    }

    /// Constructs a Proposal from a block and a vector of transactions alongside their hashes.
    /// This is analogous to `Proposal::from_parts()`, except for taking pairs of
    /// `(SignedTransaction, Hash)` instead of `VerifiedTransaction`s, to allow skipping
    /// verification calculations when it isn't relevant.
    pub fn from_parts_with_hashes(
        block: Block,
        full_transactions: Vec<(SignedTransaction, Hash)>,
    ) -> Self {
        let (tx_bodies, tx_hashes): (Vec<SignedTransaction>, HashSet<Hash>) =
            full_transactions.into_iter().unzip();
        Proposal {
            header: block.header,
            agg: block.agg,
            transactions: tx_bodies,
            opaque_transactions: block
                .transactions
                .into_iter()
                .filter(|hash| !tx_hashes.contains(hash))
                .collect(),
        }
    }

    pub fn into_parts(self) -> (Block, Vec<SignedTransaction>) {
        (
            Block {
                header: self.header,
                agg: self.agg,
                transactions: self
                    .transactions
                    .iter()
                    .map(|txn| txn.calculate_hash())
                    .chain(self.opaque_transactions)
                    .collect(),
            },
            self.transactions,
        )
    }

    pub fn hash(&self) -> Hash {
        self.header.hash
    }

    pub fn number(&self) -> u64 {
        self.header.number
    }

    pub fn view(&self) -> u64 {
        self.header.view
    }
}

#[derive(Debug, Copy, Clone, Serialize, Deserialize)]
pub struct Vote {
    /// A signature on the block_hash and view.
    signature: BlsSignature,
    pub block_hash: Hash,
    pub public_key: NodePublicKey,
    pub view: u64,
}

impl Vote {
    pub fn new(
        secret_key: SecretKey,
        block_hash: Hash,
        public_key: NodePublicKey,
        view: u64,
    ) -> Self {
        let mut bytes = Vec::new();
        bytes.extend_from_slice(block_hash.as_bytes());
        bytes.extend_from_slice(&view.to_be_bytes());

        Vote {
            signature: secret_key.sign(&bytes),
            block_hash,
            public_key,
            view,
        }
    }

    // Make this a getter to force the use of ::new
    pub fn signature(&self) -> BlsSignature {
        self.signature
    }

    pub fn verify(&self) -> Result<()> {
        let mut bytes = Vec::new();
        bytes.extend_from_slice(self.block_hash.as_bytes());
        bytes.extend_from_slice(&self.view.to_be_bytes());

        self.public_key.verify(&bytes, self.signature)
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NewView {
    /// A signature on the view, QC hash and validator index.
    pub signature: BlsSignature,
    pub qc: QuorumCertificate,
    pub view: u64,
    pub public_key: NodePublicKey,
}

impl NewView {
    pub fn new(
        secret_key: SecretKey,
        qc: QuorumCertificate,
        view: u64,
        public_key: NodePublicKey,
    ) -> Self {
        let mut bytes = Vec::new();
        bytes.extend_from_slice(qc.compute_hash().as_bytes());
        bytes.extend_from_slice(&public_key.as_bytes());
        bytes.extend_from_slice(&view.to_be_bytes());

        NewView {
            signature: secret_key.sign(&bytes),
            qc,
            view,
            public_key,
        }
    }

    pub fn verify(&self, public_key: NodePublicKey) -> Result<()> {
        let mut message = Vec::new();
        message.extend_from_slice(self.qc.compute_hash().as_bytes());
        message.extend_from_slice(&self.public_key.as_bytes());
        message.extend_from_slice(&self.view.to_be_bytes());

        public_key.verify(&message, self.signature)
    }
}

/// Each node advertises one or more block strategies. Each strategy signifies a willingness to maintain
/// some group of blocks; when we attempt to fetch a block or block range, we will try to pick a peer that
/// maintains the blocks we are interested in.
///
/// This allows us to compute the blocks a peer is likely to have in its cache before having to be told.
#[derive(Clone, Debug, Serialize, Deserialize)]
pub enum BlockStrategy {
    /// "I have these blocks at the moment and I won't drop them until view .."
    /// None == unlimited
    CachedViewRange(Range<u64>, Option<u64>),
    /// Latest N blocks.
    Latest(u64),
}

#[derive(Debug, Clone, Serialize, Deserialize, Default, PartialEq, Eq)]
pub struct BlockRequest {
    pub from_view: u64,
    pub to_view: u64,
}

#[derive(Clone, Serialize, Deserialize)]
pub struct BlockResponse {
    pub proposals: Vec<Proposal>,
    pub from_view: u64,
    /// When we send a block response, we may also send data on what blocks we are prepared
    /// to serve.
    pub availability: Option<Vec<BlockStrategy>>,
}

impl fmt::Debug for BlockResponse {
    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
        f.debug_struct("BlockResponse")
            .field("proposals", &self.proposals)
            .field("from_view", &self.from_view)
            .finish_non_exhaustive()
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RequestBlocksByHeight {
    pub request_at: SystemTime,
    pub from_height: u64,
    pub to_height: u64,
}

/// Used to convey proposal processing internally, to avoid blocking threads for too long.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InjectedProposal {
    // An encoded PeerId
    pub from: PeerId,
    pub block: Proposal,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct IntershardCall {
    pub source_address: Address,
    pub target_address: Option<Address>,
    pub source_chain_id: u64,
    pub bridge_nonce: u64,
    pub calldata: Vec<u8>,
    pub gas_price: u128,
    pub gas_limit: EvmGas,
}

/// A message intended to be sent over the network as part of p2p communication.
#[derive(Debug, Clone, Serialize, Deserialize)]
/// Keep this in-sync with the routing in P2pNode::start()
pub enum ExternalMessage {
    Proposal(Proposal),
    Vote(Box<Vote>),
    NewView(Box<NewView>),
    BlockRequest(BlockRequest),
    BlockResponse(BlockResponse),
    ProcessProposal,                   // deprecated since 0.7.0
    NewTransaction(SignedTransaction), // deprecated since 0.9.4
    /// An acknowledgement of the receipt of a message. Note this is only used as a response when the caller doesn't
    /// require any data in the response.
    Acknowledgement,
    /// The following are used for the new sync protocol
    InjectedProposal(InjectedProposal),
    /// 0.6.0
    MetaDataRequest(RequestBlocksByHeight),
    MetaDataResponse, // deprecated since 0.9.0
    MultiBlockRequest(Vec<Hash>),
    MultiBlockResponse(Vec<Proposal>),
    /// 0.7.0
    SyncBlockHeaders(Vec<SyncBlockHeader>),
    /// 0.8.0
    PassiveSyncRequest(RequestBlocksByHash),
    PassiveSyncResponse(Vec<BlockTransactionsReceipts>),
    PassiveSyncResponseLZ(Vec<u8>), // compressed block
    /// 0.9.4
    BatchedTransactions(Vec<SignedTransaction>),
}

impl ExternalMessage {
    pub fn into_proposal(self) -> Option<Proposal> {
        match self {
            ExternalMessage::Proposal(p) => Some(p),
            _ => None,
        }
    }
}

/// Returns a terse, human-readable summary of a message.
impl Display for ExternalMessage {
    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
        match self {
            ExternalMessage::PassiveSyncResponseLZ(r) => {
                write!(f, "PassiveSyncResponseLZ({})", r.len())
            }
            ExternalMessage::PassiveSyncResponse(r) => {
                write!(f, "PassiveSyncResponse({})", r.len())
            }
            ExternalMessage::PassiveSyncRequest(r) => {
                write!(f, "PassiveSyncRequest({})", r.hash)
            }
            ExternalMessage::SyncBlockHeaders(r) => {
                write!(f, "SyncBlockHeaders({})", r.len())
            }
            ExternalMessage::MultiBlockRequest(r) => {
                write!(f, "MultiBlockRequest({})", r.len())
            }
            ExternalMessage::MultiBlockResponse(r) => {
                write!(f, "MultiBlockResponse({})", r.len())
            }
            ExternalMessage::MetaDataRequest(r) => {
                write!(f, "MetaDataRequest({:?})", r.from_height..=r.to_height)
            }
            ExternalMessage::InjectedProposal(p) => {
                write!(f, "InjectedProposal({})", p.block.view())
            }
            ExternalMessage::Proposal(p) => write!(f, "Proposal({})", p.view()),
            ExternalMessage::Vote(v) => write!(f, "Vote({})", v.view),
            ExternalMessage::NewView(n) => write!(f, "NewView({})", n.view),
            ExternalMessage::BlockRequest(r) => {
                write!(f, "BlockRequest({}..={})", r.from_view, r.to_view)
            }
            ExternalMessage::BlockResponse(r) => {
                let mut views = r.proposals.iter().map(|p| p.view());
                let first = views.next();
                let last = views.next_back();
                match (first, last) {
                    (None, None) => write!(f, "BlockResponse([])"),
                    (Some(first), None) => {
                        write!(f, "BlockResponse([{first}])")
                    }
                    (Some(first), Some(last)) => {
                        write!(f, "BlockResponse([{first}, ..., {last}])")
                    }
                    (None, Some(_)) => unreachable!(),
                }
            }
            ExternalMessage::NewTransaction(txn) => match txn.clone().verify() {
                Ok(txn) => {
                    write!(
                        f,
                        "NewTransaction(Hash: {:?}, from: {:?}, nonce: {:?})",
                        txn.hash,
                        txn.signer,
                        txn.tx.nonce()
                    )
                }
                Err(err) => {
                    write!(f, "NewTransaction(Unable to verify txn due to: {:?})", err)
                }
            },
            ExternalMessage::BatchedTransactions(txns) => {
                write!(f, "BatchedTransactions(txns_count: {:?})", txns.len())
            }
            ExternalMessage::Acknowledgement => write!(f, "RequestResponse"),
            ExternalMessage::ProcessProposal | ExternalMessage::MetaDataResponse => {
                unimplemented!("deprecated")
            }
        }
    }
}

/// A message intended only for local communication between shard nodes and/or the parent p2p node,
/// but not sent over the network.
#[derive(Debug, Clone)]
pub enum InternalMessage {
    /// Notifies the coordinator process to spawn a node of the given shard
    LaunchShard(u64),
    /// Notifes the destination shard to start bridging from the given source shard
    LaunchLink(u64),
    /// Routes intershard call information between two locally running, bridged, shard processes
    IntershardCall(IntershardCall),
    /// Trigger a checkpoint export of the given block, including the state at its root hash as read
    /// from the given trie
    /// (checkpoint block, transactions, parent block, reference to our trie DB, output path)
    ExportBlockCheckpoint(
        Box<Block>,
        Vec<SignedTransaction>,
        Box<Block>,
        TrieStorage,
        Box<Path>,
    ),
    /// Notify p2p cordinator to subscribe to a particular gossipsub topic
    SubscribeToGossipSubTopic(GossipSubTopic),
    /// Notify p2p cordinator to unsubscribe from a particular gossipsub topic
    UnsubscribeFromGossipSubTopic(GossipSubTopic),
}

#[derive(Debug, Clone)]
pub enum GossipSubTopic {
    /// General topic for all nodes. Includes Proposal messages
    General(u64),
    /// Topic for Validators only. Includes NewView messages
    Validator(u64),
}

/// Returns a terse, human-readable summary of a message.
impl Display for InternalMessage {
    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
        match self {
            InternalMessage::LaunchShard(id) => write!(f, "LaunchShard({id})"),
            InternalMessage::LaunchLink(dest) => write!(f, "LaunchLink({dest})"),
            InternalMessage::IntershardCall(_) => write!(f, "IntershardCall"),
            InternalMessage::ExportBlockCheckpoint(block, ..) => {
                write!(f, "ExportCheckpoint({})", block.number())
            }
            InternalMessage::SubscribeToGossipSubTopic(topic) => {
                write!(f, "SubscribeToGossipSubTopic({:?})", topic)
            }
            InternalMessage::UnsubscribeFromGossipSubTopic(topic) => {
                write!(f, "UnsubscribeFromGossipSubTopic({:?})", topic)
            }
        }
    }
}

#[derive(Debug, Clone, Copy, Eq, PartialEq, Serialize, Deserialize)]
pub struct QuorumCertificate {
    /// An aggregated signature from `n - f` distinct replicas, built by signing a block hash in a specific view.
    pub signature: BlsSignature,
    pub cosigned: BitArray,
    pub block_hash: Hash,
    pub view: u64,
}

impl QuorumCertificate {
    pub fn genesis() -> Self {
        Self {
            signature: BlsSignature::identity(),
            cosigned: bitarr![u8, Msb0; 0; MAX_COMMITTEE_SIZE],
            block_hash: Hash::ZERO,
            view: 0,
        }
    }

    pub fn new_with_identity(block_hash: Hash, view: u64) -> Self {
        QuorumCertificate {
            signature: BlsSignature::identity(),
            cosigned: bitarr![u8, Msb0; 0; MAX_COMMITTEE_SIZE],
            block_hash,
            view,
        }
    }

    pub fn new(
        signatures: &[BlsSignature],
        cosigned: BitArray,
        block_hash: Hash,
        view: u64,
    ) -> Self {
        QuorumCertificate {
            signature: BlsSignature::aggregate(signatures).unwrap(),
            cosigned,
            block_hash,
            view,
        }
    }

    // Verifying an aggregated signature is a case of verifying the aggregated public key
    // against the aggregated signature
    pub fn verify(&self, public_keys: Vec<NodePublicKey>) -> bool {
        // Select which public keys have gone into creating the signature
        let public_keys = public_keys
            .into_iter()
            .zip(self.cosigned.iter())
            .filter_map(
                |(public_key, cosigned)| {
                    if *cosigned { Some(public_key) } else { None }
                },
            )
            .collect::<Vec<_>>();

        let mut bytes = Vec::new();
        bytes.extend_from_slice(self.block_hash.as_bytes());
        bytes.extend_from_slice(&self.view.to_be_bytes());

        BlsSignature::verify_aggregate(&self.signature, &bytes, public_keys).is_ok()
    }

    pub fn compute_hash(&self) -> Hash {
        Hash::builder()
            .with(self.signature.to_bytes())
            .with(self.cosigned.as_raw_slice()) // FIXME: What does this do when `self.cosigned.len() % 8 != 0`?
            .with(self.block_hash.as_bytes())
            .with(self.view.to_be_bytes())
            .finalize()
    }

    pub fn size(&self) -> usize {
        self.signature.to_bytes().len()
            + self.cosigned.as_raw_slice().len()
            + self.block_hash.as_bytes().len()
            + std::mem::size_of_val(&self.view)
    }
}

impl Display for QuorumCertificate {
    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
        write!(f, "QC hash: {}, ", self.compute_hash())?;
        write!(f, "QC signature: [..], ")?;
        write!(f, "QC cosigned: {:?}, ", self.cosigned)?;
        Ok(())
    }
}

/// A collection of `n - f` [QuorumCertificate]s.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct AggregateQc {
    pub signature: BlsSignature,
    pub cosigned: BitArray,
    pub view: u64,
    pub qcs: Vec<QuorumCertificate>,
}

impl AggregateQc {
    pub fn compute_hash(&self) -> Hash {
        let hashes: Vec<_> = self.qcs.iter().map(|qc| qc.compute_hash()).collect();

        Hash::builder()
            .with(self.signature.to_bytes())
            .with(self.cosigned.as_raw_slice())
            .with(self.view.to_be_bytes())
            .with_iter(hashes.iter().map(|hash| hash.as_bytes()))
            .finalize()
    }

    pub fn size(&self) -> usize {
        let mut size = 0;
        size += self.signature.to_bytes().len();
        size += self.cosigned.as_raw_slice().len();
        size += std::mem::size_of_val(&self.view);
        for qc in &self.qcs {
            size += qc.size();
        }
        size
    }
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub enum BlockRef {
    Hash(Hash),
    View(u64),
    Number(u64),
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub struct SyncBlockHeader {
    pub header: BlockHeader,
    pub size_estimate: usize,
}
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RequestBlocksByHash {
    pub hash: Hash,
    pub count: usize,
    pub request_at: SystemTime,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BlockTransactionsReceipts {
    pub block: Block,
    pub transaction_receipts: Vec<(SignedTransaction, TransactionReceipt)>,
}
/// The [Copy]-able subset of a block.
#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]
pub struct BlockHeader {
    pub view: u64, // only useful to consensus: the proposer can be derived from the block's view
    pub number: u64, // distinct from view, this is the normal incrementing block number
    pub hash: Hash,
    /// A block's quorum certificate (QC) is proof that more than `2n/3` nodes (out of `n`) have voted for this block.
    /// It also includes a pointer to the parent block.
    pub qc: QuorumCertificate,
    pub signature: BlsSignature,
    pub state_root_hash: Hash,
    pub transactions_root_hash: Hash,
    pub receipts_root_hash: Hash,
    /// The time this block was mined at.
    pub timestamp: SystemTime,
    pub gas_used: EvmGas,
    pub gas_limit: EvmGas,
}

impl BlockHeader {
    pub fn genesis_hash() -> Hash {
        Hash::builder()
            .with(0_u64.to_be_bytes())
            .with(Hash::ZERO.as_bytes())
            .finalize()
    }

    pub fn genesis(state_root_hash: Hash) -> Self {
        Self {
            view: 0,
            number: 0,
            hash: BlockHeader::genesis_hash(),
            qc: QuorumCertificate::genesis(),
            signature: BlsSignature::identity(),
            state_root_hash,
            transactions_root_hash: Hash::ZERO,
            receipts_root_hash: Hash::ZERO,
            timestamp: SystemTime::UNIX_EPOCH,
            gas_used: EvmGas(0),
            gas_limit: EvmGas(0),
        }
    }

    pub fn size(&self) -> usize {
        std::mem::size_of_val(&self.view)
            + std::mem::size_of_val(&self.number)
            + self.hash.as_bytes().len()
            + self.qc.size()
            + self.signature.to_bytes().len()
            + self.state_root_hash.as_bytes().len()
            + self.transactions_root_hash.as_bytes().len()
            + self.receipts_root_hash.as_bytes().len()
            + std::mem::size_of_val(&self.timestamp)
            + std::mem::size_of_val(&self.gas_used)
            + std::mem::size_of_val(&self.gas_limit)
    }
}

impl Default for BlockHeader {
    /// Not suitable for use as a real block header.
    fn default() -> Self {
        Self {
            view: 0,
            number: 0,
            hash: Hash::ZERO,
            qc: QuorumCertificate::genesis(),
            signature: BlsSignature::identity(),
            state_root_hash: Hash(Keccak256::digest([alloy::rlp::EMPTY_STRING_CODE]).into()),
            transactions_root_hash: Hash::ZERO,
            receipts_root_hash: Hash::ZERO,
            timestamp: SystemTime::UNIX_EPOCH,
            gas_used: EvmGas(0),
            gas_limit: EvmGas(0),
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct Block {
    pub header: BlockHeader,
    /// The block will include an [AggregateQc] if the previous leader failed, meaning we couldn't construct a QC. When
    /// this is not `None`, `qc` will contain a clone of the highest QC within this [AggregateQc];
    pub agg: Option<AggregateQc>,
    pub transactions: Vec<Hash>,
}

impl Block {
    pub fn genesis(state_root_hash: Hash) -> Block {
        Self::new(
            0u64,
            0u64,
            QuorumCertificate::genesis(),
            None,
            state_root_hash,
            Hash::ZERO,
            Hash::ZERO,
            vec![],
            SystemTime::UNIX_EPOCH,
            EvmGas(0),
            EvmGas(0),
            Either::Right(BlsSignature::identity()),
        )
    }

    #[allow(clippy::too_many_arguments)]
    pub fn from_qc(
        secret_key: SecretKey,
        view: u64,
        number: u64,
        qc: QuorumCertificate,
        agg: Option<AggregateQc>,
        state_root_hash: Hash,
        transactions_root_hash: Hash,
        receipts_root_hash: Hash,
        transactions: Vec<Hash>,
        timestamp: SystemTime,
        gas_used: EvmGas,
        gas_limit: EvmGas,
    ) -> Block {
        Self::new(
            view,
            number,
            qc,
            agg,
            state_root_hash,
            transactions_root_hash,
            receipts_root_hash,
            transactions,
            timestamp,
            gas_used,
            gas_limit,
            Either::Left(secret_key),
        )
    }

    #[allow(clippy::too_many_arguments)]
    fn new(
        view: u64,
        number: u64,
        qc: QuorumCertificate,
        agg: Option<AggregateQc>,
        state_root_hash: Hash,
        transactions_root_hash: Hash,
        receipts_root_hash: Hash,
        transactions: Vec<Hash>,
        timestamp: SystemTime,
        gas_used: EvmGas,
        gas_limit: EvmGas,
        secret_key_or_signature: Either<SecretKey, BlsSignature>,
    ) -> Self {
        let block = Block {
            header: BlockHeader {
                view,
                number,
                hash: Hash::ZERO,
                qc,
                signature: BlsSignature::identity(),
                state_root_hash,
                transactions_root_hash,
                receipts_root_hash,
                timestamp,
                gas_used,
                gas_limit,
            },
            agg,
            transactions,
        };

        let hash = block.compute_hash();
        let signature = secret_key_or_signature
            .map_left(|key| key.sign(hash.as_bytes()))
            .into_inner();

        Block {
            header: BlockHeader {
                hash,
                signature,
                ..block.header
            },
            ..block
        }
    }

    pub fn verify_hash(&self) -> Result<()> {
        if self.compute_hash() != self.hash() {
            return Err(anyhow!("invalid hash"));
        }

        Ok(())
    }

    pub fn verify(&self, public_key: NodePublicKey) -> Result<()> {
        public_key.verify(self.header.hash.as_bytes(), self.header.signature)
    }

    pub fn view(&self) -> u64 {
        self.header.view
    }

    pub fn number(&self) -> u64 {
        self.header.number
    }

    pub fn is_genesis(&self) -> bool {
        self.number() == 0
    }

    pub fn hash(&self) -> Hash {
        self.header.hash
    }

    pub fn parent_hash(&self) -> Hash {
        self.header.qc.block_hash
    }

    pub fn signature(&self) -> BlsSignature {
        self.header.signature
    }

    pub fn state_root_hash(&self) -> Hash {
        self.header.state_root_hash
    }

    pub fn transactions_root_hash(&self) -> Hash {
        self.header.transactions_root_hash
    }

    pub fn receipts_root_hash(&self) -> Hash {
        self.header.receipts_root_hash
    }
    pub fn timestamp(&self) -> SystemTime {
        self.header.timestamp
    }

    pub fn gas_used(&self) -> EvmGas {
        self.header.gas_used
    }
    pub fn gas_limit(&self) -> EvmGas {
        self.header.gas_limit
    }
    pub fn size(&self) -> usize {
        let mut size = 0;

        // Size of BlockHeader
        size += self.header.size();

        // Size of AggregateQc if present
        if let Some(agg) = &self.agg {
            size += agg.size();
        }

        // Size of transactions
        for tx in &self.transactions {
            size += tx.as_bytes().len();
        }

        size
    }
}

impl Block {
    pub fn compute_hash(&self) -> Hash {
        Hash::builder()
            .with(self.view().to_be_bytes())
            .with(self.number().to_be_bytes())
            .with(self.state_root_hash().as_bytes())
            .with(self.transactions_root_hash().as_bytes())
            .with(self.receipts_root_hash().as_bytes())
            .with(
                self.timestamp()
                    .duration_since(SystemTime::UNIX_EPOCH)
                    .unwrap()
                    .as_nanos()
                    .to_be_bytes(),
            )
            .with(self.gas_used().0.to_be_bytes())
            .with(self.gas_limit().0.to_be_bytes())
            .with(self.header.qc.compute_hash().as_bytes())
            .with_optional(
                self.agg
                    .as_ref()
                    .map(|agg| agg.compute_hash().as_bytes().to_vec()),
            )
            .with_iter(self.transactions.iter().map(|hash| hash.as_bytes()))
            .finalize()
    }
}

```

`zilliqa/src/node.rs`:

```rs
use std::{
    fmt::Debug,
    sync::{
        Arc,
        atomic::{AtomicPtr, AtomicUsize},
    },
    time::Duration,
};

use alloy::{
    eips::{BlockId, BlockNumberOrTag, RpcBlockHash},
    primitives::Address,
    rpc::types::{
        TransactionInfo,
        trace::{
            geth::{
                FourByteFrame, GethDebugBuiltInTracerType, GethDebugTracerType,
                GethDebugTracingOptions, GethTrace, NoopFrame, TraceResult,
            },
            parity::{TraceResults, TraceType},
        },
    },
};
use anyhow::{Result, anyhow};
use libp2p::{PeerId, request_response::OutboundFailure};
use rand::RngCore;
use revm::{Inspector, primitives::ExecutionResult};
use revm_inspectors::tracing::{
    FourByteInspector, MuxInspector, TracingInspector, TracingInspectorConfig, TransactionContext,
    js::JsInspector,
};
use tokio::sync::{broadcast, mpsc::UnboundedSender};
use tracing::*;

use crate::{
    api::types::filters::Filters,
    cfg::{ForkName, NodeConfig},
    consensus::Consensus,
    crypto::{Hash, SecretKey},
    db::Db,
    exec::{PendingState, TransactionApplyResult},
    inspector::{self, ScillaInspector},
    message::{
        Block, BlockHeader, BlockTransactionsReceipts, ExternalMessage, InjectedProposal,
        InternalMessage, IntershardCall, Proposal,
    },
    node_launcher::ResponseChannel,
    p2p_node::{LocalMessageTuple, OutboundMessageTuple},
    pool::TxAddResult,
    state::State,
    sync::SyncPeers,
    transaction::{
        EvmGas, SignedTransaction, TransactionReceipt, TxIntershard, VerifiedTransaction,
    },
};

#[derive(Debug, Copy, Clone, Eq, PartialEq, Hash, Default)]
pub struct RequestId(u64);

impl RequestId {
    pub fn random() -> Self {
        Self(rand::thread_rng().next_u64())
    }
}

#[derive(Debug)]
pub struct OutgoingMessageFailure {
    pub peer: PeerId,
    pub request_id: RequestId,
    pub error: OutboundFailure,
}

#[derive(Debug, Clone)]
pub struct MessageSender {
    pub our_shard: u64,
    pub our_peer_id: PeerId,
    pub outbound_channel: UnboundedSender<OutboundMessageTuple>,
    pub local_channel: UnboundedSender<LocalMessageTuple>,
    pub request_id: RequestId,
}

impl MessageSender {
    /// Send message to the p2p/coordinator thread
    pub fn send_message_to_coordinator(&self, message: InternalMessage) -> Result<()> {
        self.local_channel
            .send((self.our_shard, self.our_shard, message))?;
        Ok(())
    }

    /// Send a message to a locally running shard node
    pub fn send_message_to_shard(
        &self,
        destination_shard: u64,
        message: InternalMessage,
    ) -> Result<()> {
        self.local_channel
            .send((self.our_shard, destination_shard, message))?;
        Ok(())
    }

    pub fn next_request_id(&mut self) -> RequestId {
        let request_id = self.request_id;
        self.request_id.0 = self.request_id.0.wrapping_add(1);
        request_id
    }

    /// Send a message to a remote node of the same shard.
    /// Note that if this ever fails for individual messages (rather than because the channel is closed),
    /// you will need to adjust consensus.rs to attempt to retain as much of multiple block responses
    /// as possible.
    pub fn send_external_message(
        &mut self,
        peer: PeerId,
        message: ExternalMessage,
    ) -> Result<RequestId> {
        debug!("sending {message} from {} to {}", self.our_peer_id, peer);
        let request_id = self.next_request_id();
        self.outbound_channel
            .send((Some((peer, request_id)), self.our_shard, message))?;
        Ok(request_id)
    }

    /// Broadcast to the entire network of this shard
    pub fn broadcast_external_message(&self, message: ExternalMessage) -> Result<()> {
        self.outbound_channel
            .send((None, self.our_shard, message))?;
        Ok(())
    }

    /// Broadcast to the entire network of this shard
    // This is a duplicate of [MessageSender::broadcast_external_message] but it allows for
    // a separate treatment for proposals, if desired for debugging or future purposes.
    pub fn broadcast_proposal(&self, message: ExternalMessage) -> Result<()> {
        self.outbound_channel
            .send((None, self.our_shard, message))?;
        Ok(())
    }
}

/// Messages sent by [Consensus].
/// Tuple of (destination, message).
pub type NetworkMessage = (Option<PeerId>, ExternalMessage);

/// The central data structure for a blockchain node.
///
/// # Transaction Lifecycle
/// 1. New transactions are created with a call to [`Node::new_transaction()`].
///    The node gossips the transaction to the network and itself via a [`Message::NewTransaction`] message.
///    This initial node also stores the transaction hash in `new_transactions`.
///
/// 1. When a node recieves a [`NewTransaction`] via [`Node::handle_message()`], it stores it in `new_transactions`.
///    This contains all transactions which have been receieved, but not yet executed.
///
/// 2. When the initial node is a leader of a block, it adds all transaction hashes in `new_transactions` to the block.
///
/// 3. When a node recieves a block proposal, it looks up the transactions in `new_transactions` and executes them against its `state`.
///    Successfully executed transactions are added to `transactions` so they can be returned via APIs.
#[derive(Debug)]
pub struct Node {
    pub config: NodeConfig,
    pub db: Arc<Db>,
    peer_id: PeerId,
    message_sender: MessageSender,
    /// Send responses to requests down this channel. The `ResponseChannel` passed must correspond to a
    /// `ResponseChannel` received via `handle_request`.
    request_responses: UnboundedSender<(ResponseChannel, ExternalMessage)>,
    reset_timeout: UnboundedSender<Duration>,
    pub consensus: Consensus,
    peer_num: Arc<AtomicUsize>,
    pub chain_id: ChainId,
    pub filters: Filters,
    swarm_peers: Arc<AtomicPtr<Vec<PeerId>>>,
}

#[derive(Debug, Copy, Clone)]
pub struct ChainId {
    pub eth: u64,
}

impl ChainId {
    pub fn new(eth_chain_id: u64) -> Self {
        ChainId { eth: eth_chain_id }
    }
    pub fn zil(&self) -> u64 {
        self.eth - 0x8000
    }
}

impl Node {
    #[allow(clippy::too_many_arguments)]
    pub fn new(
        config: NodeConfig,
        secret_key: SecretKey,
        message_sender_channel: UnboundedSender<OutboundMessageTuple>,
        local_sender_channel: UnboundedSender<LocalMessageTuple>,
        request_responses: UnboundedSender<(ResponseChannel, ExternalMessage)>,
        reset_timeout: UnboundedSender<Duration>,
        peer_num: Arc<AtomicUsize>,
        sync_peers: Arc<SyncPeers>,
        swarm_peers: Arc<AtomicPtr<Vec<PeerId>>>,
    ) -> Result<Node> {
        config.validate()?;
        let peer_id = secret_key.to_libp2p_keypair().public().to_peer_id();
        let message_sender = MessageSender {
            our_shard: config.eth_chain_id,
            our_peer_id: peer_id,
            outbound_channel: message_sender_channel,
            local_channel: local_sender_channel,
            request_id: RequestId::default(),
        };
        let executable_blocks_height = config
            .consensus
            .get_forks()?
            .find_height_fork_first_activated(ForkName::ExecutableBlocks);
        let db = Arc::new(Db::new(
            config.data_dir.as_ref(),
            config.eth_chain_id,
            config.state_cache_size,
            executable_blocks_height,
        )?);
        let node = Node {
            config: config.clone(),
            peer_id,
            message_sender: message_sender.clone(),
            request_responses,
            reset_timeout: reset_timeout.clone(),
            db: db.clone(),
            chain_id: ChainId::new(config.eth_chain_id),
            consensus: Consensus::new(
                secret_key,
                config,
                message_sender,
                reset_timeout,
                db,
                sync_peers,
            )?,
            peer_num,
            filters: Filters::new(),
            swarm_peers,
        };
        Ok(node)
    }

    pub fn handle_broadcast(
        &mut self,
        from: PeerId,
        message: ExternalMessage,
        response_channel: ResponseChannel,
    ) -> Result<()> {
        debug!(%from, to = %self.peer_id, %message, "handling broadcast");
        match message {
            // Repeated `NewView`s might get broadcast.
            ExternalMessage::NewView(m) => {
                if let Some(network_message) = self.consensus.new_view(from, *m)? {
                    self.handle_network_message_response(network_message)?;
                }
            }
            // RFC-161 sync algorithm, phase 2.
            ExternalMessage::MultiBlockRequest(request) => {
                let message = self
                    .consensus
                    .sync
                    .handle_multiblock_request(from, request)?;
                self.request_responses.send((response_channel, message))?;
            }
            ExternalMessage::PassiveSyncRequest(request) => {
                let message = self.consensus.sync.handle_passive_request(from, request)?;
                self.request_responses.send((response_channel, message))?;
            }
            // RFC-161 sync algorithm, phase 1.
            ExternalMessage::MetaDataRequest(request) => {
                let message = self.consensus.sync.handle_active_request(from, request)?;
                self.request_responses.send((response_channel, message))?;
            }
            // Respond to block probe requests.
            ExternalMessage::BlockRequest(request) => {
                // respond with an invalid response
                let message = self.consensus.sync.handle_block_request(from, request)?;
                self.request_responses.send((response_channel, message))?;
            }
            // `Proposals` are re-routed to `handle_request()`
            msg => {
                warn!(%msg, "unexpected message type");
            }
        }
        Ok(())
    }

    pub fn handle_broadcast_transactions(
        &mut self,
        transactions: Vec<VerifiedTransaction>,
    ) -> Result<()> {
        let from_broadcast = true;
        self.consensus
            .handle_new_transactions(transactions, from_broadcast)?;
        Ok(())
    }

    pub fn try_to_apply_transactions(&mut self) -> Result<()> {
        self.consensus.try_early_proposal_after_txn_batch()
    }

    pub fn handle_request(
        &mut self,
        from: PeerId,
        id: &str,
        message: ExternalMessage,
        response_channel: ResponseChannel,
    ) -> Result<()> {
        debug!(%from, to = %self.peer_id, %id, %message, "handling request");
        match message {
            ExternalMessage::Vote(m) => {
                // Acknowledge this vote.
                self.request_responses
                    .send((response_channel, ExternalMessage::Acknowledgement))?;

                if let Some(network_message) = self.consensus.vote(from, *m)? {
                    self.handle_network_message_response(network_message)?;
                }
            }
            ExternalMessage::NewView(m) => {
                // Acknowledge this new view.
                self.request_responses
                    .send((response_channel, ExternalMessage::Acknowledgement))?;

                if let Some(network_message) = self.consensus.new_view(from, *m)? {
                    self.handle_network_message_response(network_message)?;
                }
            }
            // Handle requests which contain a block proposal. Initially sent as a broadcast, it is re-routed into
            // a Request by the underlying layer, with a faux request-id. This is to mitigate issues when there are
            // too many transactions in the broadcast queue.
            ExternalMessage::Proposal(m) => {
                if from != self.peer_id {
                    self.handle_proposal(from, m)?;

                    // Acknowledge the proposal.
                    self.request_responses
                        .send((response_channel, ExternalMessage::Acknowledgement))?;
                } else {
                    debug!("Ignoring own Proposal broadcast")
                }
            }
            // This just breaks down group block messages into individual messages to stop them blocking threads
            // for long periods.
            ExternalMessage::InjectedProposal(p) => {
                self.handle_injected_proposal(from, p)?;
            }
            msg => {
                warn!(%msg, "unexpected message type");
            }
        }

        Ok(())
    }

    pub fn handle_request_failure(
        &mut self,
        to: PeerId,
        failure: OutgoingMessageFailure,
    ) -> Result<()> {
        debug!(from = %self.peer_id, %to, ?failure, "handling message failure");
        self.consensus.sync.handle_request_failure(to, failure)?;
        Ok(())
    }

    pub fn handle_response(&mut self, from: PeerId, message: ExternalMessage) -> Result<()> {
        debug!(%from, to = %self.peer_id, %message, "handling response");
        match message {
            // 0.6.0
            ExternalMessage::MultiBlockResponse(response) => self
                .consensus
                .sync
                .handle_multiblock_response(from, Some(response))?,
            // 0.7.0
            ExternalMessage::SyncBlockHeaders(response) => self
                .consensus
                .sync
                .handle_active_response(from, Some(response))?,
            // 0.8.0 probe response
            ExternalMessage::BlockResponse(response) => {
                self.consensus.sync.handle_block_response(from, response)?
            }
            // 0.8.0 passive sync
            ExternalMessage::PassiveSyncResponse(response) => self
                .consensus
                .sync
                .handle_passive_response(from, Some(response))?,
            ExternalMessage::PassiveSyncResponseLZ(response) => {
                // decompress the block
                let mut decoder = lz4::Decoder::new(std::io::Cursor::new(response))?;
                let mut buf = Vec::new();
                std::io::Read::read_to_end(&mut decoder, &mut buf).unwrap();
                let response =
                    cbor4ii::serde::from_slice::<BlockTransactionsReceipts>(&buf).unwrap();
                self.consensus
                    .sync
                    .handle_passive_response(from, Some(vec![response]))?;
            }
            ExternalMessage::Acknowledgement => {} // do nothing
            msg => {
                warn!(%msg, "unexpected message type");
            }
        }

        Ok(())
    }

    pub fn handle_internal_message(&self, from: u64, message: InternalMessage) -> Result<()> {
        let to = self.chain_id.eth;
        tracing::debug!(%from, %to, %message, "handling message");
        match message {
            InternalMessage::IntershardCall(intershard_call) => {
                self.inject_intershard_transaction(intershard_call)?
            }
            InternalMessage::LaunchLink(source) => {
                self.message_sender
                    .send_message_to_coordinator(InternalMessage::LaunchShard(source))?;
            }
            _ => {
                warn!(
                    "{message} type messages should be handled by the coordinator, not forwarded to a node.",
                );
            }
        }
        Ok(())
    }

    fn inject_intershard_transaction(&self, intershard_call: IntershardCall) -> Result<()> {
        let tx = SignedTransaction::Intershard {
            tx: TxIntershard {
                chain_id: self.chain_id.eth,
                bridge_nonce: intershard_call.bridge_nonce,
                source_chain: intershard_call.source_chain_id,
                gas_price: intershard_call.gas_price,
                gas_limit: intershard_call.gas_limit,
                to_addr: intershard_call.target_address,
                payload: intershard_call.calldata,
            },
            from: intershard_call.source_address,
        };
        let verified_tx = tx.verify()?;
        trace!("Injecting intershard transaction {}", verified_tx.hash);
        self.consensus.new_transaction(
            verified_tx,
            true,
            &mut self.consensus.transaction_pool.write(),
        )?;
        Ok(())
    }

    fn broadcast_and_execute_proposal(&mut self, proposal: Proposal) -> Result<()> {
        self.message_sender
            .broadcast_proposal(ExternalMessage::Proposal(proposal.clone()))?;
        self.handle_proposal(self.peer_id, proposal)?;
        Ok(())
    }

    fn handle_network_message_response(&mut self, message: NetworkMessage) -> Result<()> {
        let (peer_id, response) = message;
        if let Some(peer_id) = peer_id {
            self.message_sender
                .send_external_message(peer_id, response)?;
        } else if let ExternalMessage::Proposal(new_proposal) = response {
            // Recursively process own Proposal
            self.broadcast_and_execute_proposal(new_proposal)?;
        } else {
            self.message_sender.broadcast_external_message(response)?;
        }
        Ok(())
    }

    // handle timeout - true if something happened
    pub fn handle_timeout(&mut self) -> Result<bool> {
        if let Some(network_message) = self.consensus.timeout()? {
            self.handle_network_message_response(network_message)?;
            return Ok(true);
        }

        Ok(false)
    }

    pub fn create_transaction(&self, txn: VerifiedTransaction) -> Result<(Hash, TxAddResult)> {
        let hash = txn.hash;

        let from_broadcast = false;
        let result = self
            .consensus
            .handle_new_transactions(vec![txn], from_broadcast)?;
        if !result[0].was_added() {
            debug!(?result, "Transaction cannot be added to mempool");
        }

        Ok((hash, result[0]))
    }

    pub fn process_transactions_to_broadcast(&mut self) -> Result<()> {
        let txns_to_broadcast = self
            .consensus
            .transaction_pool
            .write()
            .pull_txns_to_broadcast()?;
        if txns_to_broadcast.is_empty() {
            return Ok(());
        }
        self.message_sender
            .broadcast_external_message(ExternalMessage::BatchedTransactions(txns_to_broadcast))
    }

    pub fn number(&self) -> u64 {
        self.consensus.head_block().header.number
    }

    pub fn resolve_block_number(&self, block_number: BlockNumberOrTag) -> Result<Option<Block>> {
        match block_number {
            BlockNumberOrTag::Number(n) => self.consensus.get_canonical_block_by_number(n),

            BlockNumberOrTag::Earliest => self.consensus.get_canonical_block_by_number(0),
            BlockNumberOrTag::Latest => Ok(Some(self.consensus.head_block())),
            BlockNumberOrTag::Pending => self.consensus.get_pending_block(),
            BlockNumberOrTag::Finalized => {
                let Some(view) = self.db.get_finalized_view()? else {
                    return self.resolve_block_number(BlockNumberOrTag::Earliest);
                };
                let Some(block) = self.db.get_block_by_view(view)? else {
                    return self.resolve_block_number(BlockNumberOrTag::Earliest);
                };
                Ok(Some(block))
            }
            // Safe block tag in our consensus refers to the block that the node's highQC points to
            // (high_qc means it's the latest = high, and it's a QC where 2/3 validators voted for it).
            BlockNumberOrTag::Safe => {
                let block_hash = self.consensus.high_qc.block_hash;

                let Some(safe_block) = self.consensus.get_block(&block_hash)? else {
                    return self.resolve_block_number(BlockNumberOrTag::Earliest);
                };
                Ok(Some(safe_block))
            }
        }
    }

    pub fn get_finalized_block(&self) -> Result<Option<Block>> {
        self.resolve_block_number(BlockNumberOrTag::Finalized)
    }

    pub fn get_finalized_block_number(&self) -> Result<u64> {
        match self.resolve_block_number(BlockNumberOrTag::Finalized)? {
            Some(block) => Ok(block.number()),
            None => Ok(0),
        }
    }

    pub fn get_block(&self, block_id: impl Into<BlockId>) -> Result<Option<Block>> {
        match block_id.into() {
            BlockId::Hash(RpcBlockHash {
                block_hash,
                require_canonical,
            }) => {
                // See https://eips.ethereum.org/EIPS/eip-1898
                let Some(block) = self.consensus.get_block(&block_hash.into())? else {
                    return Ok(None);
                };
                // Get latest finalized block number
                let finalized_block = self
                    .resolve_block_number(BlockNumberOrTag::Finalized)?
                    .ok_or_else(|| anyhow!("Unable to retrieve finalized block!"))?;
                let require_canonical = require_canonical.unwrap_or(false);

                // If the caller requests canonical block then it must be finalized
                if require_canonical && block.number() > finalized_block.number() {
                    return Ok(None);
                }

                Ok(Some(block))
            }
            BlockId::Number(number) => self.resolve_block_number(number),
        }
    }

    pub fn get_state(&self, block: &Block) -> Result<State> {
        Ok(self
            .consensus
            .state()
            .at_root(block.state_root_hash().into()))
    }

    pub fn trace_evm_transaction(
        &self,
        txn_hash: Hash,
        trace_types: &revm::primitives::HashSet<TraceType>,
    ) -> Result<TraceResults> {
        let txn = self
            .get_transaction_by_hash(txn_hash)?
            .ok_or_else(|| anyhow!("transaction not found: {txn_hash}"))?;
        let receipt = self
            .get_transaction_receipt(txn_hash)?
            .ok_or_else(|| anyhow!("transaction not mined: {txn_hash}"))?;

        let block = self
            .get_block(receipt.block_hash)?
            .ok_or_else(|| anyhow!("missing block: {}", receipt.block_hash))?;
        let parent = self
            .get_block(block.parent_hash())?
            .ok_or_else(|| anyhow!("missing block: {}", block.parent_hash()))?;

        let mut state = self
            .consensus
            .state()
            .at_root(parent.state_root_hash().into());
        if state.is_empty() {
            return Err(anyhow!("State required to execute request does not exist"));
        }

        for other_txn_hash in block.transactions {
            if txn_hash != other_txn_hash {
                let other_txn = self
                    .get_transaction_by_hash(other_txn_hash)?
                    .ok_or_else(|| anyhow!("transaction not found: {other_txn_hash}"))?;
                state.apply_transaction(other_txn, block.header, inspector::noop(), false)?;
            } else {
                let config = TracingInspectorConfig::from_parity_config(trace_types);
                let mut inspector = TracingInspector::new(config);
                let pre_state = state.try_clone()?;

                let result = state.apply_transaction(txn, block.header, &mut inspector, true)?;

                let TransactionApplyResult::Evm(result, ..) = result else {
                    return Err(anyhow!("not an EVM transaction"));
                };

                let builder = inspector.into_parity_builder();
                let trace =
                    builder.into_trace_results_with_state(&result, trace_types, &pre_state)?;

                return Ok(trace);
            }
        }

        Err(anyhow!("transaction not found in block: {txn_hash}"))
    }

    pub fn replay_transaction<I: Inspector<PendingState> + ScillaInspector>(
        &self,
        txn_hash: Hash,
        inspector: I,
    ) -> Result<TransactionApplyResult> {
        let txn = self
            .get_transaction_by_hash(txn_hash)?
            .ok_or_else(|| anyhow!("transaction not found: {txn_hash}"))?;
        let receipt = self
            .get_transaction_receipt(txn_hash)?
            .ok_or_else(|| anyhow!("transaction not mined: {txn_hash}"))?;

        let block = self
            .get_block(receipt.block_hash)?
            .ok_or_else(|| anyhow!("missing block: {}", receipt.block_hash))?;
        let parent = self
            .get_block(block.parent_hash())?
            .ok_or_else(|| anyhow!("missing block: {}", block.parent_hash()))?;

        let mut state = self
            .consensus
            .state()
            .at_root(parent.state_root_hash().into());
        if state.is_empty() {
            return Err(anyhow!("State required to execute request does not exist"));
        }

        for other_txn_hash in block.transactions {
            if txn_hash != other_txn_hash {
                let other_txn = self
                    .get_transaction_by_hash(other_txn_hash)?
                    .ok_or_else(|| anyhow!("transaction not found: {other_txn_hash}"))?;
                state.apply_transaction(other_txn, parent.header, inspector::noop(), false)?;
            } else {
                let result = state.apply_transaction(txn, block.header, inspector, true)?;

                return Ok(result);
            }
        }

        Err(anyhow!("transaction not found in block: {txn_hash}"))
    }

    pub fn debug_trace_block(
        &self,
        block_number: BlockNumberOrTag,
        trace_opts: GethDebugTracingOptions,
    ) -> Result<Vec<TraceResult>> {
        let block = self
            .get_block(block_number)?
            .ok_or_else(|| anyhow!("missing block: {block_number}"))?;
        let parent = self
            .get_block(block.parent_hash())?
            .ok_or_else(|| anyhow!("missing block: {}", block.parent_hash()))?;
        let mut state = self
            .consensus
            .state()
            .at_root(parent.state_root_hash().into());
        if state.is_empty() {
            return Err(anyhow!("State required to execute request does not exist"));
        }

        let mut traces: Vec<TraceResult> = Vec::new();

        for (index, &txn_hash) in block.transactions.iter().enumerate() {
            if let Ok(Some(trace)) = self.debug_trace_transaction(
                &mut state,
                txn_hash,
                index,
                &block,
                trace_opts.clone(),
            ) {
                traces.push(trace);
            }
        }

        Ok(traces)
    }

    pub fn debug_trace_transaction(
        &self,
        state: &mut State,
        txn_hash: Hash,
        txn_index: usize,
        block: &Block,
        trace_opts: GethDebugTracingOptions,
    ) -> Result<Option<TraceResult>> {
        let GethDebugTracingOptions {
            config,
            tracer,
            tracer_config,
            ..
        } = trace_opts;

        let txn = self
            .get_transaction_by_hash(txn_hash)?
            .ok_or_else(|| anyhow!("transaction not found: {txn_hash}"))?;

        let Some(tracer) = tracer else {
            let inspector_config = TracingInspectorConfig::from_geth_config(&config);
            let mut inspector = TracingInspector::new(inspector_config);

            let result = state.apply_transaction(txn, block.header, &mut inspector, true)?;

            let TransactionApplyResult::Evm(result, ..) = result else {
                return Ok(None);
            };

            let builder = inspector.into_geth_builder();
            let trace = builder.geth_traces(
                result.result.gas_used(),
                result.result.into_output().unwrap_or_default(),
                config,
            );
            return Ok(Some(TraceResult::Success {
                result: trace.into(),
                tx_hash: Some(txn_hash.0.into()),
            }));
        };

        match tracer {
            GethDebugTracerType::BuiltInTracer(tracer) => match tracer {
                GethDebugBuiltInTracerType::CallTracer => {
                    let call_config = tracer_config.into_call_config()?;
                    let mut inspector = TracingInspector::new(
                        TracingInspectorConfig::from_geth_call_config(&call_config),
                    );

                    let result =
                        state.apply_transaction(txn, block.header, &mut inspector, true)?;

                    let TransactionApplyResult::Evm(result, ..) = result else {
                        return Ok(None);
                    };

                    let trace = inspector
                        .into_geth_builder()
                        .geth_call_traces(call_config, result.result.gas_used());

                    Ok(Some(TraceResult::Success {
                        result: trace.into(),
                        tx_hash: Some(txn_hash.0.into()),
                    }))
                }
                GethDebugBuiltInTracerType::FlatCallTracer => {
                    Err(anyhow!("`flatCallTracer` is not implemented"))
                }
                GethDebugBuiltInTracerType::FourByteTracer => {
                    let mut inspector = FourByteInspector::default();
                    let result =
                        state.apply_transaction(txn, block.header, &mut inspector, true)?;

                    let TransactionApplyResult::Evm(_, _) = result else {
                        return Ok(None);
                    };

                    Ok(Some(TraceResult::Success {
                        result: FourByteFrame::from(&inspector).into(),
                        tx_hash: Some(txn_hash.0.into()),
                    }))
                }
                GethDebugBuiltInTracerType::MuxTracer => {
                    let mux_config = tracer_config.into_mux_config()?;

                    let mut inspector = MuxInspector::try_from_config(mux_config)?;
                    let result =
                        state.apply_transaction(txn, block.header, &mut inspector, true)?;

                    let TransactionApplyResult::Evm(result, ..) = result else {
                        return Ok(None);
                    };
                    let state_ref = &(*state);
                    let tx_info = TransactionInfo {
                        hash: Some(txn_hash.into()),
                        index: Some(txn_index as u64),
                        block_hash: Some(block.hash().into()),
                        block_number: Some(block.number()),
                        base_fee: state.gas_price.try_into().ok(),
                    };
                    let trace = inspector.try_into_mux_frame(&result, &state_ref, tx_info)?;
                    Ok(Some(TraceResult::Success {
                        result: trace.into(),
                        tx_hash: Some(txn_hash.0.into()),
                    }))
                }
                GethDebugBuiltInTracerType::NoopTracer => Ok(Some(TraceResult::Success {
                    result: NoopFrame::default().into(),
                    tx_hash: Some(txn_hash.0.into()),
                })),
                GethDebugBuiltInTracerType::PreStateTracer => {
                    let prestate_config = tracer_config.into_pre_state_config()?;

                    let mut inspector = TracingInspector::new(
                        TracingInspectorConfig::from_geth_prestate_config(&prestate_config),
                    );
                    let result =
                        state.apply_transaction(txn, block.header, &mut inspector, true)?;

                    let TransactionApplyResult::Evm(result, ..) = result else {
                        return Ok(None);
                    };
                    let state_ref = &(*state);
                    let trace = inspector.into_geth_builder().geth_prestate_traces(
                        &result,
                        &prestate_config,
                        state_ref,
                    )?;

                    Ok(Some(TraceResult::Success {
                        result: trace.into(),
                        tx_hash: Some(txn_hash.0.into()),
                    }))
                }
            },
            GethDebugTracerType::JsTracer(js_code) => {
                let config = tracer_config.into_json();

                let transaction_context = TransactionContext {
                    block_hash: Some(block.hash().0.into()),
                    tx_hash: Some(txn_hash.0.into()),
                    tx_index: txn_index.into(),
                };
                let mut inspector =
                    JsInspector::with_transaction_context(js_code, config, transaction_context)
                        .map_err(|e| anyhow!("Unable to create js inspector: {e}"))?;

                let result = state.apply_transaction(txn, block.header, &mut inspector, true)?;

                let TransactionApplyResult::Evm(result, env) = result else {
                    return Ok(None);
                };
                let state_ref = &(*state);
                let result = inspector
                    .json_result(result, &env, &state_ref)
                    .map_err(|e| anyhow!("Unable to create json result: {e}"))?;

                Ok(Some(TraceResult::Success {
                    result: GethTrace::JS(result),
                    tx_hash: Some(txn_hash.0.into()),
                }))
            }
        }
    }

    pub fn call_contract(
        &self,
        block: &Block,
        from_addr: Address,
        to_addr: Option<Address>,
        data: Vec<u8>,
        amount: u128,
    ) -> Result<ExecutionResult> {
        trace!("call_contract: block={:?}", block);

        let state = self
            .consensus
            .state()
            .at_root(block.state_root_hash().into());
        if state.is_empty() {
            return Err(anyhow!("State required to execute request does not exist"));
        }

        state.call_contract(from_addr, to_addr, data, amount, block.header, true)
    }

    pub fn get_proposer_reward_address(&self, header: BlockHeader) -> Result<Option<Address>> {
        // Return the zero address for the genesis block. There was no reward for it.
        if header.view == 0 {
            return Ok(None);
        }

        let parent = self
            .get_block(header.qc.block_hash)?
            .ok_or_else(|| anyhow!("missing parent: {}", header.qc.block_hash))?;

        let Some(proposer) = self.consensus.leader_at_block(&parent, header.view) else {
            return Ok(None);
        };

        self.consensus
            .state()
            .get_reward_address(proposer.public_key)
    }

    pub fn get_touched_transactions(&self, address: Address) -> Result<Vec<Hash>> {
        self.consensus.get_touched_transactions(address)
    }

    pub fn get_gas_price(&self) -> u128 {
        *self.config.consensus.gas_price
    }

    #[allow(clippy::too_many_arguments)]
    pub fn estimate_gas(
        &self,
        block_number: BlockNumberOrTag,
        from_addr: Address,
        to_addr: Option<Address>,
        data: Vec<u8>,
        gas: Option<EvmGas>,
        gas_price: Option<u128>,
        value: u128,
    ) -> Result<u64> {
        let block = self
            .get_block(block_number)?
            .ok_or_else(|| anyhow!("missing block: {block_number}"))?;
        let state = self.get_state(&block)?;
        if state.is_empty() {
            return Err(anyhow!("State required to execute request does not exist"));
        }

        state.estimate_gas(
            from_addr,
            to_addr,
            data,
            block.header,
            gas,
            gas_price,
            value,
            true,
        )
    }

    pub fn subscribe_to_new_blocks(&self) -> broadcast::Receiver<BlockHeader> {
        self.consensus.new_blocks.subscribe()
    }

    /// Returns a stream of pairs of (receipt, index of transaction in block)
    pub fn subscribe_to_receipts(&self) -> broadcast::Receiver<(TransactionReceipt, usize)> {
        self.consensus.new_receipts.subscribe()
    }

    pub fn subscribe_to_new_transactions(&self) -> broadcast::Receiver<VerifiedTransaction> {
        self.consensus.new_transactions.subscribe()
    }

    pub fn subscribe_to_new_transaction_hashes(&self) -> broadcast::Receiver<Hash> {
        self.consensus.new_transaction_hashes.subscribe()
    }

    pub fn get_chain_tip(&self) -> u64 {
        self.consensus.head_block().header.number
    }

    pub fn get_transaction_receipts_in_block(
        &self,
        block_hash: Hash,
    ) -> Result<Vec<TransactionReceipt>> {
        self.db.get_transaction_receipts_in_block(&block_hash)
    }

    pub fn get_finalized_height(&self) -> Result<u64> {
        self.consensus.get_finalized_view()
    }

    pub fn get_current_view(&self) -> Result<u64> {
        self.consensus.get_view()
    }

    pub fn get_transaction_receipt(&self, tx_hash: Hash) -> Result<Option<TransactionReceipt>> {
        self.consensus.get_transaction_receipt(&tx_hash)
    }

    pub fn get_transaction_by_hash(&self, hash: Hash) -> Result<Option<VerifiedTransaction>> {
        self.consensus.get_transaction_by_hash(hash)
    }

    pub fn txpool_content(&mut self) -> crate::pool::TxPoolContent {
        self.consensus.txpool_content()
    }

    pub fn txpool_content_from(&mut self, address: &Address) -> crate::pool::TxPoolContentFrom {
        self.consensus.txpool_content_from(address)
    }

    pub fn txpool_status(&mut self) -> crate::pool::TxPoolStatus {
        self.consensus.txpool_status()
    }

    pub fn get_peer_num(&self) -> usize {
        self.peer_num.load(std::sync::atomic::Ordering::Relaxed)
    }

    fn handle_proposal(&mut self, from: PeerId, proposal: Proposal) -> Result<()> {
        if let Some(network_message) = self.consensus.proposal(from, proposal.clone(), false)? {
            self.reset_timeout
                .send(self.config.consensus.consensus_timeout)?;
            self.handle_network_message_response(network_message)?;
        }
        self.consensus.sync.sync_from_proposal(proposal)?;
        Ok(())
    }

    fn handle_injected_proposal(&mut self, from: PeerId, req: InjectedProposal) -> Result<()> {
        if from != self.consensus.peer_id() {
            warn!("Someone ({from}) sent me a InjectedProposal; illegal- ignoring");
            return Ok(());
        }
        trace!("Handling proposal for view {0}", req.block.header.view);
        let block_number = req.block.number();
        let proposal = self.consensus.receive_block(from, req.block)?;
        // decrement after - if there are issues in receive_block() it will stop syncing;
        self.consensus.sync.mark_received_proposal(block_number)?;
        if let Some(proposal) = proposal {
            trace!(
                " ... broadcasting proposal for view {0}",
                proposal.header.view
            );
            self.message_sender
                .broadcast_proposal(ExternalMessage::Proposal(proposal))?;
        }
        Ok(())
    }

    pub fn get_peer_ids(&self) -> Result<(Vec<PeerId>, Vec<PeerId>)> {
        let sync_peers = self.consensus.sync.peer_ids();
        let swarm_peers: Vec<PeerId>;
        unsafe {
            let swarm_ptr = self.swarm_peers.load(std::sync::atomic::Ordering::Relaxed);
            swarm_peers = (*swarm_ptr).clone();
        }
        Ok((swarm_peers, sync_peers))
    }
}

```

`zilliqa/src/node_launcher.rs`:

```rs
use std::{
    net::Ipv4Addr,
    sync::{
        Arc,
        atomic::{AtomicPtr, AtomicUsize},
    },
    time::{Duration, SystemTime},
};

use anyhow::{Result, anyhow};
use http::{Method, header};
use libp2p::{PeerId, futures::StreamExt};
use node::Node;
use opentelemetry::KeyValue;
use opentelemetry_semantic_conventions::{
    attribute::{
        ERROR_TYPE, MESSAGING_DESTINATION_NAME, MESSAGING_OPERATION_NAME, MESSAGING_SYSTEM,
    },
    metric::MESSAGING_PROCESS_DURATION,
};
use parking_lot::RwLock;
use tokio::{
    select,
    sync::mpsc::{self, UnboundedSender},
    time::{self, Instant},
};
use tokio_stream::wrappers::UnboundedReceiverStream;
use tower_http::cors::{Any, CorsLayer};
use tracing::*;

use crate::{
    api::{self, subscription_id_provider::EthIdProvider},
    cfg::NodeConfig,
    crypto::SecretKey,
    health::HealthLayer,
    message::{ExternalMessage, InternalMessage},
    node::{self, OutgoingMessageFailure},
    p2p_node::{LocalMessageTuple, OutboundMessageTuple},
    sync::SyncPeers,
};

pub struct NodeLauncher {
    pub node: Arc<RwLock<Node>>,
    pub config: NodeConfig,
    pub broadcasts: UnboundedReceiverStream<(PeerId, ExternalMessage, ResponseChannel)>,
    pub requests: UnboundedReceiverStream<(PeerId, String, ExternalMessage, ResponseChannel)>,
    pub request_failures: UnboundedReceiverStream<(PeerId, OutgoingMessageFailure)>,
    pub responses: UnboundedReceiverStream<(PeerId, ExternalMessage)>,
    pub local_messages: UnboundedReceiverStream<(u64, InternalMessage)>,
    /// Channel used to steer next sleep time
    pub reset_timeout_receiver: UnboundedReceiverStream<Duration>,
    node_launched: bool,
}

// If the `fake_response_channel` feature is enabled, swap out the libp2p ResponseChannel for a `u64`. In our
// integration tests we are not able to construct a ResponseChannel manually, so we need an alternative way of linking
// a request and a response.
#[cfg(not(feature = "fake_response_channel"))]
type ChannelType = libp2p::request_response::ResponseChannel<ExternalMessage>;
#[cfg(feature = "fake_response_channel")]
type ChannelType = u64;

/// A wrapper around [libp2p::request_response::ResponseChannel] which also handles the case where the node has sent a
/// request to itself. In this case, we don't require a response.
#[derive(Debug)]
#[cfg_attr(feature = "fake_response_channel", derive(Clone, Hash, PartialEq, Eq))]
pub enum ResponseChannel {
    Local,
    Remote(ChannelType),
}

impl ResponseChannel {
    pub fn into_inner(self) -> Option<ChannelType> {
        match self {
            ResponseChannel::Local => None,
            ResponseChannel::Remote(c) => Some(c),
        }
    }
}

/// The collection of channels used to send messages to a [NodeLauncher].
pub struct NodeInputChannels {
    /// Send broadcast messages (received via gossipsub) down this channel.
    pub broadcasts: UnboundedSender<(PeerId, ExternalMessage, ResponseChannel)>,
    /// Send direct requests down this channel. The `ResponseChannel` must be used by the receiver to respond to this
    /// request.
    pub requests: UnboundedSender<(PeerId, String, ExternalMessage, ResponseChannel)>,
    /// Send failed requests down this channel.
    pub request_failures: UnboundedSender<(PeerId, OutgoingMessageFailure)>,
    /// Send direct responses to direct requests down this channel.
    pub responses: UnboundedSender<(PeerId, ExternalMessage)>,
    /// Send local messages down this channel. This is used to forward cross-shard messages to the node.
    pub local_messages: UnboundedSender<(u64, InternalMessage)>,
}

impl NodeLauncher {
    pub async fn new(
        secret_key: SecretKey,
        config: NodeConfig,
        outbound_message_sender: UnboundedSender<OutboundMessageTuple>,
        local_outbound_message_sender: UnboundedSender<LocalMessageTuple>,
        request_responses_sender: UnboundedSender<(ResponseChannel, ExternalMessage)>,
        peer_num: Arc<AtomicUsize>,
        swarm_peers: Arc<AtomicPtr<Vec<PeerId>>>,
    ) -> Result<(Self, NodeInputChannels, Arc<SyncPeers>)> {
        /// Helper to create a (sender, receiver) pair for a channel.
        fn sender_receiver<T>() -> (UnboundedSender<T>, UnboundedReceiverStream<T>) {
            let (sender, receiver) = mpsc::unbounded_channel();
            (sender, UnboundedReceiverStream::new(receiver))
        }

        let (broadcasts_sender, broadcasts_receiver) = sender_receiver();
        let (requests_sender, requests_receiver) = sender_receiver();
        let (request_failures_sender, request_failures_receiver) = sender_receiver();
        let (responses_sender, responses_receiver) = sender_receiver();
        let (local_messages_sender, local_messages_receiver) = sender_receiver();
        let (reset_timeout_sender, reset_timeout_receiver) = sender_receiver();

        let peer_id = secret_key.to_libp2p_keypair().public().to_peer_id();
        let sync_peers = Arc::new(SyncPeers::new(peer_id));

        let node = Node::new(
            config.clone(),
            secret_key,
            outbound_message_sender,
            local_outbound_message_sender,
            request_responses_sender,
            reset_timeout_sender.clone(),
            peer_num,
            sync_peers.clone(),
            swarm_peers.clone(),
        )?;

        let node = Arc::new(RwLock::new(node));

        for api_server in &config.api_servers {
            let rpc_module = api::rpc_module(Arc::clone(&node), &api_server.enabled_apis);
            // Construct the JSON-RPC API server. We inject a [CorsLayer] to ensure web browsers can call our API directly.
            let cors = CorsLayer::new()
                .allow_methods(Method::POST)
                .allow_origin(Any)
                .allow_headers([header::CONTENT_TYPE]);
            let middleware = tower::ServiceBuilder::new().layer(HealthLayer).layer(cors);
            let server = jsonrpsee::server::ServerBuilder::new()
                .max_response_body_size(config.max_rpc_response_size)
                .set_http_middleware(middleware)
                .set_id_provider(EthIdProvider)
                .build((Ipv4Addr::UNSPECIFIED, api_server.port))
                .await;

            match server {
                Ok(server) => {
                    let port = server.local_addr()?.port();
                    info!("JSON-RPC server listening on port {}", port);
                    let handle = server.start(rpc_module);
                    tokio::spawn(handle.stopped());
                }
                Err(e) => {
                    error!("Failed to start JSON-RPC server: {}", e);
                }
            }
        }

        let launcher = NodeLauncher {
            node,
            broadcasts: broadcasts_receiver,
            requests: requests_receiver,
            request_failures: request_failures_receiver,
            responses: responses_receiver,
            local_messages: local_messages_receiver,
            reset_timeout_receiver,
            node_launched: false,
            config,
        };
        let input_channels = NodeInputChannels {
            broadcasts: broadcasts_sender,
            requests: requests_sender,
            request_failures: request_failures_sender,
            responses: responses_sender,
            local_messages: local_messages_sender,
        };

        Ok((launcher, input_channels, sync_peers))
    }

    pub async fn start_shard_node(&mut self) -> Result<()> {
        if self.node_launched {
            return Err(anyhow!("Node already running!"));
        }

        let consensus_sleep = time::sleep(Duration::from_millis(5));
        tokio::pin!(consensus_sleep);

        let mempool_sleep = time::sleep(Duration::from_millis(5));
        tokio::pin!(mempool_sleep);

        self.node_launched = true;

        let meter = opentelemetry::global::meter("zilliqa");
        let messaging_process_duration = meter
            .f64_histogram(MESSAGING_PROCESS_DURATION)
            .with_unit("s")
            .with_boundaries(vec![
                0.005, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1.0, 2.5, 5.0, 7.5, 10.0,
            ])
            .build();

        loop {
            select! {
                message = self.broadcasts.next() => {
                    let (source, message, response_channel) = message.expect("message stream should be infinite");
                    let mut attributes = vec![
                        KeyValue::new(MESSAGING_OPERATION_NAME, "handle"),
                        KeyValue::new(MESSAGING_SYSTEM, "tokio_channel"),
                        KeyValue::new(MESSAGING_DESTINATION_NAME, "broadcast"),
                    ];

                    let start = SystemTime::now();
                    if let ExternalMessage::BatchedTransactions(transactions) = message {
                        let my_peer_id = self.node.write().consensus.peer_id();

                        if source != my_peer_id {
                            let mut verified = Vec::with_capacity(transactions.len());
                            for txn in transactions {
                                match txn.verify() {
                                    Ok(txn) => verified.push(txn),
                                    Err(e) => error!("Skipping transaction {e}"),
                                }
                            }
                            if let Err(e)= self.node.write().handle_broadcast_transactions(verified) {
                                error!("Failed to handle broadcast transactions {e}");
                            }
                        }
                        // Try to assemble block even for the origin of this batch
                        // // For now, we don't add new transactions to the block after initial creation
                        // if let Err(e) = self.node.write().try_to_apply_transactions() {
                        //     error!("Failed to try to apply transactions {e}");
                        // }
                    }
                    else if let Err(e) = self.node.write().handle_broadcast(source, message, response_channel) {
                        attributes.push(KeyValue::new(ERROR_TYPE, "process-error"));
                        error!("Failed to process broadcast message: {e}");
                    }
                    messaging_process_duration.record(
                        start.elapsed().map_or(0.0, |d| d.as_secs_f64()),
                        &attributes,
                    );
                }
                message = self.requests.next() => {
                    let (source, id, message, response_channel) = message.expect("message stream should be infinite");
                    let mut attributes = vec![
                        KeyValue::new(MESSAGING_OPERATION_NAME, "handle"),
                        KeyValue::new(MESSAGING_SYSTEM, "tokio_channel"),
                        KeyValue::new(MESSAGING_DESTINATION_NAME, "request"),
                    ];

                    let start = SystemTime::now();
                    if let Err(e) = self.node.write().handle_request(source, &id, message, response_channel) {
                        attributes.push(KeyValue::new(ERROR_TYPE, "process-error"));
                        error!("Failed to process request message: {e}");
                    }
                    messaging_process_duration.record(
                        start.elapsed().map_or(0.0, |d| d.as_secs_f64()),
                        &attributes,
                    );
                }
                message = self.request_failures.next() => {
                    let (source, message) = message.expect("message stream should be infinite");
                    let mut attributes = vec![
                        KeyValue::new(MESSAGING_OPERATION_NAME, "handle"),
                        KeyValue::new(MESSAGING_SYSTEM, "tokio_channel"),
                        KeyValue::new(MESSAGING_DESTINATION_NAME, "request_failure"),
                    ];

                    let start = SystemTime::now();
                    if let Err(e) = self.node.write().handle_request_failure(source, message) {
                        attributes.push(KeyValue::new(ERROR_TYPE, "process-error"));
                        error!("Failed to process request failure message: {e}");
                    }
                    messaging_process_duration.record(
                        start.elapsed().map_or(0.0, |d| d.as_secs_f64()),
                        &attributes,
                    );
                }
                message = self.responses.next() => {
                    let (source, message) = message.expect("message stream should be infinite");
                    let mut attributes = vec![
                        KeyValue::new(MESSAGING_OPERATION_NAME, "handle"),
                        KeyValue::new(MESSAGING_SYSTEM, "tokio_channel"),
                        KeyValue::new(MESSAGING_DESTINATION_NAME, "response"),
                    ];

                    let start = SystemTime::now();
                    if let Err(e) = self.node.write().handle_response(source, message) {
                        attributes.push(KeyValue::new(ERROR_TYPE, "process-error"));
                        error!("Failed to process response message: {e}");
                    }
                    messaging_process_duration.record(
                        start.elapsed().map_or(0.0, |d| d.as_secs_f64()),
                        &attributes,
                    );
                }
                message = self.local_messages.next() => {
                    let (_source, _message) = message.expect("message stream should be infinite");
                    todo!("Local messages will need to be handled once cross-shard messaging is implemented");
                }
                () = &mut consensus_sleep => {
                    let attributes = vec![
                        KeyValue::new(MESSAGING_OPERATION_NAME, "handle"),
                        KeyValue::new(MESSAGING_SYSTEM, "tokio_channel"),
                        KeyValue::new(MESSAGING_DESTINATION_NAME, "timeout"),
                    ];

                    let start = SystemTime::now();
                    // No messages for a while, so check if consensus wants to timeout
                    if let Err(e) = self.node.write().handle_timeout() {
                        error!("Failed to handle timeout {e}");
                    }
                    consensus_sleep.as_mut().reset(Instant::now() + Duration::from_millis(500));
                    messaging_process_duration.record(
                        start.elapsed().map_or(0.0, |d| d.as_secs_f64()),
                        &attributes,
                    );
                },
                r = self.reset_timeout_receiver.next() => {
                    let sleep_time = r.expect("reset timeout stream should be infinite");
                    trace!(?sleep_time, "timeout reset");
                    consensus_sleep.as_mut().reset(Instant::now() + sleep_time);
                },

                () = &mut mempool_sleep => {
                    self.node.write().process_transactions_to_broadcast()?;
                    mempool_sleep.as_mut().reset(Instant::now() + Duration::from_millis(250));
                },
            }
        }
    }
}

```

`zilliqa/src/p2p_node.rs`:

```rs
//! A node in the Zilliqa P2P network. May coordinate multiple shard nodes.

use std::{
    collections::HashMap,
    sync::{
        Arc,
        atomic::{AtomicPtr, AtomicUsize},
    },
    time::Duration,
};

use anyhow::{Result, anyhow};
use cfg_if::cfg_if;
use itertools::Itertools;
use libp2p::{
    PeerId, StreamProtocol, Swarm, autonat,
    futures::StreamExt,
    gossipsub::{self, IdentTopic, MessageAcceptance, MessageAuthenticity, TopicHash},
    identify,
    kad::{self, store::MemoryStore},
    multiaddr::{Multiaddr, Protocol},
    noise,
    request_response::{self, OutboundFailure, ProtocolSupport},
    swarm::{NetworkBehaviour, SwarmEvent},
    tcp, yamux,
};
use tokio::{
    select,
    signal::{self, unix::SignalKind},
    sync::mpsc::{self, UnboundedSender, error::SendError},
    task::JoinSet,
};
use tokio_stream::wrappers::UnboundedReceiverStream;
use tracing::*;

use crate::{
    cfg::{Config, ConsensusConfig, NodeConfig},
    crypto::SecretKey,
    db,
    message::{ExternalMessage, GossipSubTopic, InternalMessage},
    node::{OutgoingMessageFailure, RequestId},
    node_launcher::{NodeInputChannels, NodeLauncher, ResponseChannel},
    sync::SyncPeers,
};

/// Validator topic is for broadcasts which only apply to validators.
///
/// - Broadcasts are so sent to the public topic (Proposal)
/// - Direct messages are not sent to any topic (Vote, NewView)
/// - Re-sending of NewView is sent to the Validator-only topic
static VALIDATOR_TOPIC_SUFFIX: &str = "-validator";

/// Messages are a tuple of the destination shard ID and the actual message.
type DirectMessage = (u64, ExternalMessage);

#[derive(NetworkBehaviour)]
struct Behaviour {
    request_response: request_response::cbor::Behaviour<DirectMessage, ExternalMessage>,
    gossipsub: gossipsub::Behaviour,
    autonat_client: autonat::v2::client::Behaviour,
    autonat_server: autonat::v2::server::Behaviour,
    identify: identify::Behaviour,
    kademlia: kad::Behaviour<MemoryStore>,
}

/// Messages circulating over the p2p network.
/// (destination, shard_id, message)
pub type OutboundMessageTuple = (Option<(PeerId, RequestId)>, u64, ExternalMessage);

/// Messages passed between local shard nodes.
/// (source_shard, destination_shard, message)
pub type LocalMessageTuple = (u64, u64, InternalMessage);

pub struct P2pNode {
    shard_peers: HashMap<u64, Arc<SyncPeers>>,
    shard_nodes: HashMap<u64, NodeInputChannels>,
    shard_threads: JoinSet<Result<()>>,
    task_threads: JoinSet<Result<()>>,
    secret_key: SecretKey,
    config: Config,
    peer_id: PeerId,
    swarm: Swarm<Behaviour>,
    /// Shard nodes get a copy of these senders to propagate messages.
    outbound_message_sender: UnboundedSender<OutboundMessageTuple>,
    local_message_sender: UnboundedSender<LocalMessageTuple>,
    request_responses_sender: UnboundedSender<(ResponseChannel, ExternalMessage)>,
    /// The p2p node keeps a handle to these receivers, to obtain messages from shards and propagate
    /// them as necessary.
    outbound_message_receiver: UnboundedReceiverStream<OutboundMessageTuple>,
    local_message_receiver: UnboundedReceiverStream<LocalMessageTuple>,
    request_responses_receiver: UnboundedReceiverStream<(ResponseChannel, ExternalMessage)>,
    /// Map of pending direct requests. Maps the libp2p request ID to our request ID.
    pending_requests: HashMap<request_response::OutboundRequestId, (u64, RequestId)>,
    // Count of current peers for API
    peer_num: Arc<AtomicUsize>,
    swarm_peers: Arc<AtomicPtr<Vec<PeerId>>>,
    kad_protocol: StreamProtocol,
    protocol_version: String,
}

impl P2pNode {
    pub fn new(secret_key: SecretKey, config: Config) -> Result<Self> {
        let (outbound_message_sender, outbound_message_receiver) = mpsc::unbounded_channel();
        let outbound_message_receiver = UnboundedReceiverStream::new(outbound_message_receiver);

        let (local_message_sender, local_message_receiver) = mpsc::unbounded_channel();
        let local_message_receiver = UnboundedReceiverStream::new(local_message_receiver);

        let (request_responses_sender, request_responses_receiver) = mpsc::unbounded_channel();
        let request_responses_receiver = UnboundedReceiverStream::new(request_responses_receiver);

        let key_pair = secret_key.to_libp2p_keypair();
        let peer_id = PeerId::from(key_pair.public());
        info!(%peer_id);

        let protocol_version = format!("{}/1.0.0", config.network);
        let kad_protocol =
            StreamProtocol::try_from_owned(format!("/{}/kad/1.0.0", config.network))?;

        let swarm = libp2p::SwarmBuilder::with_existing_identity(key_pair)
            .with_tokio()
            .with_tcp(
                tcp::Config::default(),
                noise::Config::new,
                yamux::Config::default,
            )?
            .with_dns()?
            .with_behaviour(|key_pair| {
                Ok(Behaviour {
                    request_response: request_response::cbor::Behaviour::new(
                        vec![(
                            StreamProtocol::try_from_owned(format!(
                                "/{}/req-resp/1.0.0",
                                config.network
                            ))?,
                            ProtocolSupport::Full,
                        )],
                        request_response::Config::default()
                            // This is a temporary patch to prevent long-running Scilla executions causing nodes to Timeout - https://github.com/Zilliqa/zq2/issues/2667
                            .with_request_timeout(Duration::from_secs(60)),
                    ),
                    gossipsub: gossipsub::Behaviour::new(
                        MessageAuthenticity::Signed(key_pair.clone()),
                        gossipsub::ConfigBuilder::default()
                            // 1MB is sufficient to accommodate proposal with 4000 simple transfers (block gas limit)
                            .max_transmit_size(1024 * 1024)
                            // Increase the duplicate cache time to reduce the likelihood of delayed messages being
                            // mistakenly re-propagated and flooding the network.
                            .duplicate_cache_time(Duration::from_secs(3600))
                            // Increase the queue duration to reduce the likelihood of dropped messages.
                            // https://github.com/Zilliqa/zq2/issues/2823
                            .publish_queue_duration(Duration::from_secs(60))
                            .forward_queue_duration(Duration::from_secs(30)) // might be helpful too
                            .validate_messages() // manual forwarding is required
                            .build()
                            .map_err(|e| anyhow!(e))?,
                    )
                    .map_err(|e| anyhow!(e))?,
                    autonat_client: autonat::v2::client::Behaviour::default(),
                    autonat_server: autonat::v2::server::Behaviour::default(),
                    kademlia: kad::Behaviour::with_config(
                        peer_id,
                        MemoryStore::new(peer_id),
                        kad::Config::new(kad_protocol.clone()),
                    ),
                    identify: identify::Behaviour::new(
                        identify::Config::new(protocol_version.clone(), key_pair.public())
                            .with_hide_listen_addrs(true)
                            .with_push_listen_addr_updates(true),
                    ),
                })
            })?
            // Set the idle connection timeout to 10 seconds. Some protocols (such as autonat) rely on using a
            // connection shortly after an event has been emitted from the `Swarm`, but don't use it immediately
            // meaning the connection is immediately closed before the protocol can use it. libp2p may change the
            // default in the future to 10 seconds too (https://github.com/libp2p/rust-libp2p/pull/4967).
            .with_swarm_config(|config| {
                config.with_idle_connection_timeout(Duration::from_secs(60))
            })
            .build();

        Ok(Self {
            shard_peers: HashMap::new(),
            shard_nodes: HashMap::new(),
            peer_id,
            secret_key,
            config,
            swarm,
            shard_threads: JoinSet::new(),
            task_threads: JoinSet::new(),
            outbound_message_sender,
            local_message_sender,
            request_responses_sender,
            outbound_message_receiver,
            local_message_receiver,
            request_responses_receiver,
            pending_requests: HashMap::new(),
            peer_num: Arc::new(AtomicUsize::new(0)),
            swarm_peers: Arc::new(AtomicPtr::new(Box::into_raw(Box::new(vec![])))),
            kad_protocol,
            protocol_version,
        })
    }

    pub fn shard_id_to_topic(shard_id: u64, message: Option<&ExternalMessage>) -> IdentTopic {
        match message {
            Some(ExternalMessage::NewView(_)) => Self::validator_topic(shard_id),
            _ => IdentTopic::new(shard_id.to_string()),
        }
    }

    pub fn shard_id_from_topic_hash(topic_hash: &TopicHash) -> Result<u64> {
        Ok(topic_hash
            .clone()
            .into_string()
            .split("-")
            .collect::<Vec<_>>()[0]
            .parse::<u64>()?)
    }

    pub fn validator_topic(shard_id: u64) -> IdentTopic {
        IdentTopic::new(shard_id.to_string() + VALIDATOR_TOPIC_SUFFIX)
    }

    /// Temporary method until light nodes are implemented, which will allow
    /// connecting to the other shard and obtaining consensus parameters.
    /// For now, we copy the (presumably main shard's) existing config and use it
    /// as a default to construct a child shard.
    fn generate_child_config(parent: &NodeConfig, shard_id: u64) -> NodeConfig {
        let parent = parent.clone();
        NodeConfig {
            api_servers: vec![],
            eth_chain_id: shard_id,
            consensus: ConsensusConfig {
                is_main: false,
                main_shard_id: Some(parent.eth_chain_id),
                ..parent.consensus
            },
            ..parent
        }
    }

    pub async fn add_shard_node(&mut self, config: NodeConfig) -> Result<()> {
        let shard_id = config.eth_chain_id;
        if self.shard_nodes.contains_key(&shard_id) {
            info!("LaunchShard message received for a shard we're already running. Ignoring...");
            return Ok(());
        }
        let (mut node, input_channels, peers) = NodeLauncher::new(
            self.secret_key,
            config,
            self.outbound_message_sender.clone(),
            self.local_message_sender.clone(),
            self.request_responses_sender.clone(),
            self.peer_num.clone(),
            self.swarm_peers.clone(),
        )
        .await?;
        self.shard_peers.insert(shard_id, peers);
        self.shard_nodes.insert(shard_id, input_channels);
        self.shard_threads
            .spawn(async move { node.start_shard_node().await });
        self.swarm
            .behaviour_mut()
            .gossipsub
            .subscribe(&Self::shard_id_to_topic(shard_id, None))?;
        // subscribe to validator topic by default. Unsubscribe later if we find that we are not in the committee
        self.swarm
            .behaviour_mut()
            .gossipsub
            .subscribe(&Self::validator_topic(shard_id))?;
        Ok(())
    }

    fn send_to<T: Send + Sync + 'static>(
        &self,
        topic_hash: &TopicHash,
        sender: impl FnOnce(&NodeInputChannels) -> Result<(), SendError<T>>,
    ) -> Result<()> {
        let Some(channels) = self
            .shard_nodes
            .get(&Self::shard_id_from_topic_hash(topic_hash)?)
        else {
            warn!(?topic_hash, "message received for unknown shard or topic");
            return Ok(());
        };
        Ok(sender(channels)?)
    }

    pub async fn start(&mut self) -> Result<()> {
        self.swarm.listen_on(
            Multiaddr::empty()
                .with(Protocol::Ip4(std::net::Ipv4Addr::UNSPECIFIED))
                .with(Protocol::Tcp(self.config.p2p_port)),
        )?;

        if let Some(external_address) = &self.config.external_address {
            self.swarm.add_external_address(external_address.clone());
        }

        // if we are a bootstrap, add our external address, which allows us to switch to kademlia SERVER mode.
        for (peer, address) in &self.config.bootstrap_address.0 {
            if self.swarm.local_peer_id() == peer {
                self.swarm.add_external_address(address.clone());
            }
        }

        let mut terminate = signal::unix::signal(SignalKind::terminate())?;

        loop {
            select! {
                event = self.swarm.next() => {
                    let event = event.expect("swarm stream should be infinite");
                    debug!(?event, "swarm event");
                    match event {
                        SwarmEvent::ConnectionClosed{..} |
                        SwarmEvent::ConnectionEstablished{..} => {
                            // update peers when new peer connects/disconnects
                            let new_peers = Box::into_raw(Box::new(self.swarm.connected_peers().cloned().collect_vec()));
                            let old_ptr = self.swarm_peers.swap(new_peers, std::sync::atomic::Ordering::Relaxed);
                            unsafe {
                                let _ = Box::from_raw(old_ptr); // previous vec will be dropped here
                            }
                        }
                        // only dial after we have a listen address, to reuse port
                        SwarmEvent::NewListenAddr { address, .. } => {
                            info!(%address, "P2P swarm listening on");
                            for (peer, address) in &self.config.bootstrap_address.0 {
                                if self.swarm.local_peer_id() != peer {
                                    self.swarm.dial(address.clone())?;
                                }
                            }
                        }
                        // this is necessary - https://docs.rs/libp2p-kad/latest/libp2p_kad/#important-discrepancies
                        SwarmEvent::Behaviour(BehaviourEvent::Identify(identify::Event::Received { peer_id, info, .. })) => {
                            // only add peer, if it is on the same application protocol
                            let is_match = info.protocol_version == self.protocol_version;
                            // will only be true if peer is publicly reachable i.e. SERVER mode.
                            let is_kad = info.protocols.iter().any(|p| *p == self.kad_protocol);

                            for addr in info.listen_addrs {
                                if is_match {
                                    self.swarm.add_peer_address(peer_id, addr.clone());
                                }
                                if is_kad {
                                    self.swarm.behaviour_mut().kademlia.add_address(&peer_id, addr.clone());
                                }
                            }
                        }
                        // Add/Remove peers to/from the shard peer list used in syncing.
                        SwarmEvent::Behaviour(BehaviourEvent::Gossipsub(gossipsub::Event::Subscribed { peer_id, topic })) => {
                            if let Some(peers) = self.shard_peers.get(&Self::shard_id_from_topic_hash(&topic)?) {
                                peers.add_peer(peer_id);
                            }
                        }
                        SwarmEvent::Behaviour(BehaviourEvent::Gossipsub(gossipsub::Event::Unsubscribed { peer_id, topic })) => {
                            if let Some(peers) = self.shard_peers.get(&Self::shard_id_from_topic_hash(&topic)?) {
                                peers.remove_peer(peer_id);
                            }
                        }
                        SwarmEvent::Behaviour(BehaviourEvent::Gossipsub(gossipsub::Event::Message{
                            message_id: msg_id,
                            message: gossipsub::Message {
                                source,
                                data,
                                topic: topic_hash, ..
                            }, ..
                        })) => {
                            let source = source.expect("message should have a source");
                            let external_message = match cbor4ii::serde::from_slice::<ExternalMessage>(&data) {
                                Ok(m) => m,
                                Err(e) => {
                                    let data = hex::encode(&data);
                                    error!(?e, data, "message parsing failed");
                                    continue;
                                }
                            };
                            let to = self.peer_id;
                            debug!(%source, %to, %external_message, %topic_hash, "broadcast received");

                            match external_message {
                                ExternalMessage::BatchedTransactions(_) | ExternalMessage::NewView(_) => {
                                    self.swarm.behaviour_mut().gossipsub.report_message_validation_result(&msg_id, &source, MessageAcceptance::Accept); // forward
                                    self.send_to(&topic_hash, |c| c.broadcasts.send((source, external_message, ResponseChannel::Local)))?;
                                },
                                // Route broadcasts to speed-up Proposal processing, with faux request-id
                                ExternalMessage::Proposal(_) => {
                                    self.swarm.behaviour_mut().gossipsub.report_message_validation_result(&msg_id, &source, MessageAcceptance::Accept); // forward
                                    self.send_to(&topic_hash, |c| c.requests.send((source, msg_id.to_string(), external_message, ResponseChannel::Local)))?;
                                },
                                // Drop invalid libp2p gossips
                                _ => {
                                    self.swarm.behaviour_mut().gossipsub.report_message_validation_result(&msg_id, &source, MessageAcceptance::Reject); // drop and punish
                                    error!(%source, %to, %external_message, %topic_hash, "unhandled libp2p broadcast");
                                }
                            }
                        }
                        SwarmEvent::Behaviour(BehaviourEvent::RequestResponse(request_response::Event::Message { message, peer: _source, .. })) => {
                            match message {
                                request_response::Message::Request { request, channel: _channel, request_id: _request_id, .. } => {
                                    let to = self.peer_id;
                                    let (shard_id, _external_message) = request;
                                    debug!(source = %_source, %to, external_message = %_external_message, request_id = %_request_id, "message received");
                                    let _topic = Self::shard_id_to_topic(shard_id, None);
                                    let _id = format!("{}", _request_id);
                                    cfg_if! {
                                        if #[cfg(not(feature = "fake_response_channel"))] {
                                            match _external_message {
                                                ExternalMessage::MetaDataRequest(_)
                                                | ExternalMessage::MultiBlockRequest(_)
                                                | ExternalMessage::BlockRequest(_)
                                                | ExternalMessage::PassiveSyncRequest(_) => self
                                                    .send_to(&_topic.hash(), |c| c.broadcasts.send((_source, _external_message, ResponseChannel::Remote(_channel))))?,
                                                ExternalMessage::Vote(_)
                                                | ExternalMessage::NewView(_) => self.send_to(&_topic.hash(), |c| c.requests.send((_source, _id, _external_message, ResponseChannel::Remote(_channel))))?,
                                                _ => error!(source = %_source, %to, external_message = %_external_message, request_id = %_request_id, "unhandled libp2p request"),
                                            }
                                        } else {
                                            panic!("fake_response_channel is enabled and you are trying to use a real libp2p network");
                                        }
                                    }
                                }
                                request_response::Message::Response { request_id, response } => {
                                    if let Some((shard_id, _)) = self.pending_requests.remove(&request_id) {
                                        self.send_to(&Self::shard_id_to_topic(shard_id, None).hash(), |c| c.responses.send((_source, response)))?;
                                    } else {
                                        return Err(anyhow!("response to request with no id"));
                                    }
                                }
                            }
                        }
                        SwarmEvent::Behaviour(BehaviourEvent::RequestResponse(request_response::Event::OutboundFailure { peer, request_id, error, .. })) => {
                            if let OutboundFailure::DialFailure = error {
                                // We failed to send a message to a peer. The likely reason is that we don't know their
                                // address. Someone else in the network must know it, because we learnt their peer ID.
                                // Therefore, we can attempt to learn their address by triggering a Kademlia bootstrap.
                                let _ = self.swarm.behaviour_mut().kademlia.bootstrap();
                            }

                            if let Some((shard_id, request_id)) = self.pending_requests.remove(&request_id) {
                                let error = OutgoingMessageFailure { peer, request_id, error };
                                self.send_to(&Self::shard_id_to_topic(shard_id, None).hash(), |c| c.request_failures.send((peer, error)))?;
                            } else {
                                return Err(anyhow!("request without id failed"));
                            }
                        }
                        _ => {},
                    }
                },
                message = self.local_message_receiver.next() => {
                    let (source, destination, message) = message.expect("message stream should be infinite");
                    match message {
                        InternalMessage::LaunchShard(shard_id) => {
                            let shard_config = self.config.nodes
                                .iter()
                                .find(|shard_config| shard_config.eth_chain_id == shard_id)
                                .cloned()
                                .unwrap_or_else(
                                    || Self::generate_child_config(self.config.nodes.first().unwrap(), shard_id));
                            self.add_shard_node(shard_config.clone()).await?;
                        },
                        InternalMessage::LaunchLink(_) | InternalMessage::IntershardCall(_) => {
                            self.send_to(&Self::shard_id_to_topic(destination, None).hash(), |c| c.local_messages.send((source, message)))?;
                        }
                        InternalMessage::ExportBlockCheckpoint(block, transactions, parent, trie_storage, path) => {
                            self.task_threads.spawn(async move { db::checkpoint_block_with_state(&block, &transactions, &parent, trie_storage, source, path) });
                        }
                        InternalMessage::SubscribeToGossipSubTopic(topic) => {
                            debug!("subscribing to topic {:?}", topic);
                            if let GossipSubTopic::Validator(shard_id) = topic {
                                self.swarm.behaviour_mut().gossipsub.subscribe(&Self::validator_topic(shard_id))?;
                            }
                        }
                        InternalMessage::UnsubscribeFromGossipSubTopic(topic) => {
                            debug!("unsubscribing from topic {:?}", topic);
                            if let GossipSubTopic::Validator(shard_id) = topic {
                                self.swarm.behaviour_mut().gossipsub.unsubscribe(&Self::validator_topic(shard_id));
                            }
                        }
                    }
                },
                message = self.request_responses_receiver.next() => {
                    let (ch, _rs) = message.expect("message stream should be infinite");
                    if let Some(_ch) = ch.into_inner() {
                        cfg_if! {
                            if #[cfg(not(feature = "fake_response_channel"))] {
                                let _ = self.swarm.behaviour_mut().request_response.send_response(_ch, _rs);
                            } else {
                                panic!("fake_response_channel is enabled and you are trying to use a real libp2p network");
                            }
                        }
                    }
                }
                message = self.outbound_message_receiver.next() => {
                    let (dest, shard_id, message) = message.expect("message stream should be infinite");
                    let data = cbor4ii::serde::to_vec(Vec::new(), &message).unwrap();
                    let from = self.peer_id;

                    let topic = Self::shard_id_to_topic(shard_id, Some(&message));

                    match dest {
                        Some((dest, request_id)) => {
                            debug!(%from, %dest, %message, ?request_id, "sending direct message");
                            let id = format!("{:?}", request_id);
                            if from == dest {
                                self.send_to(&topic.hash(), |c| c.requests.send((from, id, message, ResponseChannel::Local)))?;
                            } else {
                                let libp2p_request_id = self.swarm.behaviour_mut().request_response.send_request(&dest, (shard_id, message));
                                self.pending_requests.insert(libp2p_request_id, (shard_id, request_id));
                            }
                        },
                        None => {
                            debug!(%from, %message, %topic, "broadcasting");
                            if let Err(e) = self.swarm.behaviour_mut().gossipsub.publish(topic.hash(), data.clone()) {
                                trace!(%e, "failed to publish message")
                            }
                        },
                    }
                },
                Some(res) = self.task_threads.join_next() => {
                    if let Err(e) = res {
                        // One-shot task (i.e. checkpoint export) failed. Log it and carry on.
                        error!(%e);
                    }
                }
                Some(res) = self.shard_threads.join_next() => {
                    if let Err(e) = res {
                        // Currently, abort everything should a single shard fail.
                        error!(%e);
                        break;
                    }
                }
                _ = terminate.recv() => {
                    self.shard_threads.shutdown().await;
                    unsafe {
                        let _ = Box::from_raw(self.swarm_peers.load(std::sync::atomic::Ordering::Relaxed));
                        // previous vec will be dropped here
                    }
                    break;
                },
                _ = signal::ctrl_c() => {
                    self.shard_threads.shutdown().await;
                    unsafe {
                        let _ = Box::from_raw(self.swarm_peers.load(std::sync::atomic::Ordering::Relaxed));
                        // previous vec will be dropped here
                    }
                    break;
                },
            }
            self.peer_num.store(
                self.swarm.network_info().num_peers(),
                std::sync::atomic::Ordering::Relaxed,
            );
        }
        Ok(())
    }
}

```

`zilliqa/src/pool.rs`:

```rs
use std::{
    cmp::Ordering,
    collections::{BTreeMap, BTreeSet, HashMap, VecDeque},
};

use alloy::primitives::Address;
use anyhow::Result;
use itertools::Itertools;
use tracing::debug;

use crate::{
    crypto::Hash,
    state::{Account, State},
    transaction::{SignedTransaction, ValidationOutcome, VerifiedTransaction},
};

/// Transaction pool limits
const GLOBAL_TXN_POOL_SIZE_LIMIT: u64 = 1_000_000;
const TOTAL_SENDERS_COUNT_LIMIT: usize = 50_000;
const MAX_TXNS_PER_SENDER: u64 = 20000;

/// The result of trying to add a transaction to the mempool. The argument is
/// a human-readable string to be returned to the user.
#[derive(Debug, Copy, Clone)]
pub enum TxAddResult {
    /// Transaction was successfully added to the mempool
    AddedToMempool,
    /// Transaction was a duplicate
    Duplicate(Hash),
    /// Bad signature
    CannotVerifySignature,
    /// Transaction failed to validate
    ValidationFailed(ValidationOutcome),
    /// Nonce was too low at the point we tried to actually add the txn to the pool - (got, expected)
    NonceTooLow(u64, u64),
    /// This txn has same nonce, lower gas price as one already in the mempool
    SameNonceButLowerGasPrice,
}

/// For transaction status returns
pub enum PendingOrQueued {
    Pending,
    Queued,
}

impl TxAddResult {
    pub fn was_added(&self) -> bool {
        matches!(self, Self::AddedToMempool)
    }
}

#[derive(Copy, Clone, Debug, Eq, PartialEq, PartialOrd, Ord)]
struct PendingQueueKey {
    // Field order is crucial here since we need to sort by gas price first
    // When we derive Ord, the fields are used in order from top to bottom
    highest_gas_price: u128,
    address: Address,
}

#[derive(Copy, Clone, Debug, Eq, PartialEq, PartialOrd, Ord)]
struct NoncelessTransactionKey {
    // Field order is crucial here since we need to sort by gas price first
    // When we derive Ord, the fields are used in order from top to bottom
    highest_gas_price: u128,
    hash: Hash,
}

impl From<VerifiedTransaction> for NoncelessTransactionKey {
    fn from(txn: VerifiedTransaction) -> Self {
        NoncelessTransactionKey {
            highest_gas_price: txn.tx.gas_price_per_evm_gas(),
            hash: txn.hash,
        }
    }
}

impl From<&VerifiedTransaction> for NoncelessTransactionKey {
    fn from(txn: &VerifiedTransaction) -> Self {
        NoncelessTransactionKey {
            highest_gas_price: txn.tx.gas_price_per_evm_gas(),
            hash: txn.hash,
        }
    }
}

#[derive(Clone, Debug, Eq, PartialEq)]
struct TransactionsAccount {
    // Account address
    address: Address,
    // The actual account's balance
    balance_account: u128,
    // The account's remaining balance after all pending transactions
    balance_after_pending: i128,
    // The account's actual nonce
    nonce_account: u64,
    // All transactions with nonces, sorted by nonce
    nonced_transactions_pending: BTreeMap<u64, VerifiedTransaction>,
    nonced_transactions_queued: BTreeMap<u64, VerifiedTransaction>,
    // All transactions without nonces, sorted by gas price
    nonceless_transactions_pending: BTreeMap<NoncelessTransactionKey, VerifiedTransaction>,
    nonceless_transactions_queued: BTreeMap<NoncelessTransactionKey, VerifiedTransaction>,
}

impl TransactionsAccount {
    // state transition functions
    // these move transactions from pending to queued and vice versa
    // they should leave everything consistent
    fn queue_to_pending_nonced(&mut self) {
        let (_k, transaction) = self.nonced_transactions_queued.pop_first().unwrap();
        if let Some(highest_pending_nonce) = self
            .nonced_transactions_pending
            .last_key_value()
            .map(|(k, _v)| k)
        {
            debug_assert!(
                transaction.tx.nonce().unwrap() == highest_pending_nonce + 1,
                "Attempt to move nonced transaction to pending with non-sequential nonce"
            );
        }
        self.balance_after_pending -= transaction.tx.maximum_validation_cost().unwrap() as i128;
        let prev_value = self
            .nonced_transactions_pending
            .insert(transaction.tx.nonce().unwrap(), transaction);
        debug_assert!(prev_value.is_none());
    }
    fn pending_to_queue_nonced(&mut self) {
        let (_k, transaction) = self.nonced_transactions_pending.pop_last().unwrap();
        self.balance_after_pending += transaction.tx.maximum_validation_cost().unwrap() as i128;
        let prev_value = self
            .nonced_transactions_queued
            .insert(transaction.tx.nonce().unwrap(), transaction);
        debug_assert!(prev_value.is_none());
    }
    fn queue_to_pending_nonceless(&mut self, key: NoncelessTransactionKey) {
        let transaction = self.nonceless_transactions_queued.remove(&key).unwrap();
        self.balance_after_pending -= transaction.tx.maximum_validation_cost().unwrap() as i128;
        let prev_value = self.nonceless_transactions_pending.insert(key, transaction);
        debug_assert!(prev_value.is_none());
    }
    fn pending_to_queue_nonceless(&mut self, key: NoncelessTransactionKey) {
        let transaction = self.nonceless_transactions_pending.remove(&key).unwrap();
        self.balance_after_pending += transaction.tx.maximum_validation_cost().unwrap() as i128;
        let prev_value = self.nonceless_transactions_queued.insert(key, transaction);
        debug_assert!(prev_value.is_none());
    }
    fn get_first_queued_nonced(&self) -> Option<&VerifiedTransaction> {
        let next_queueable_nonce = match self
            .get_last_pending_nonced()
            .map(|tx| tx.tx.nonce().unwrap() + 1)
        {
            Some(nonce) => nonce,
            None => self.nonce_account,
        };
        self.nonced_transactions_queued
            .first_key_value()
            .filter(|(_k, v)| v.tx.nonce().unwrap() == next_queueable_nonce)
            .map(|(_k, v)| v)
    }
    fn get_last_pending_nonced(&self) -> Option<&VerifiedTransaction> {
        self.nonced_transactions_pending
            .last_key_value()
            .map(|(_k, v)| v)
    }
    fn get_highest_gas_queued_nonceless(&self) -> Option<&VerifiedTransaction> {
        self.nonceless_transactions_queued
            .last_key_value()
            .map(|(_k, v)| v)
    }
    fn get_lowest_gas_pending_nonceless(&self) -> Option<&VerifiedTransaction> {
        self.nonceless_transactions_pending
            .first_key_value()
            .map(|(_k, v)| v)
    }
    /// Update pending transactions after changes
    fn maintain(&mut self) {
        let dbg_total_txns_before = self.get_transaction_count();
        if self.balance_after_pending >= 0 {
            // Add transactions to pending queue if there's balance and they're valid
            loop {
                let balance_after_pending = self.balance_after_pending;
                let first_queued_nonced = self
                    .get_first_queued_nonced()
                    .filter(|x| x.tx.gas_price_per_evm_gas() as i128 <= balance_after_pending);
                let highest_gas_queued_nonceless = self
                    .get_highest_gas_queued_nonceless()
                    .filter(|x| x.tx.gas_price_per_evm_gas() as i128 <= balance_after_pending);
                match (first_queued_nonced, highest_gas_queued_nonceless) {
                    (None, None) => break,
                    (None, Some(y)) => self.queue_to_pending_nonceless(y.into()),
                    (Some(_), None) => self.queue_to_pending_nonced(),
                    (Some(x), Some(y)) => {
                        if x.tx.gas_price_per_evm_gas() >= y.tx.gas_price_per_evm_gas() {
                            self.queue_to_pending_nonced()
                        } else {
                            self.queue_to_pending_nonceless(y.into())
                        }
                    }
                }
            }
        } else {
            // Remove transactions from the pending queue if there's not enough balance
            while self.balance_after_pending < 0 {
                let last_pending_nonced = self.get_last_pending_nonced();
                let lowest_gas_pending_nonceless = self.get_lowest_gas_pending_nonceless();
                match (last_pending_nonced, lowest_gas_pending_nonceless) {
                    (None, None) => break,
                    (None, Some(y)) => self.pending_to_queue_nonceless(y.into()),
                    (Some(_), None) => self.pending_to_queue_nonced(),
                    (Some(x), Some(y)) => {
                        if x.tx.gas_price_per_evm_gas() < y.tx.gas_price_per_evm_gas() {
                            self.pending_to_queue_nonced()
                        } else {
                            self.pending_to_queue_nonceless(y.into())
                        }
                    }
                }
            }
        }
        debug_assert!(dbg_total_txns_before == self.get_transaction_count());
    }
    fn full_recalculate(&mut self) {
        self.nonced_transactions_queued
            .append(&mut self.nonced_transactions_pending);
        self.nonceless_transactions_queued
            .append(&mut self.nonceless_transactions_pending);
        self.balance_after_pending = self.balance_account as i128;
        self.maintain();
    }
    fn insert_nonced_txn(&mut self, txn: VerifiedTransaction) {
        debug_assert!(txn.tx.nonce().is_some());
        let nonce = txn.tx.nonce().unwrap();
        debug_assert!(!self.nonced_transactions_pending.contains_key(&nonce));
        let existing_txn = self.nonced_transactions_queued.insert(nonce, txn);
        debug_assert!(
            existing_txn.is_none(),
            "JCVH: Attempt to double insert a transaction"
        );
        self.maintain();
    }
    fn insert_unnonced_txn(&mut self, txn: VerifiedTransaction) {
        debug_assert!(txn.tx.nonce().is_none());
        let gas_price = txn.tx.maximum_validation_cost().unwrap() as i128;
        // Put it in pending and then pop it again if necessary
        let existing_txn = self
            .nonceless_transactions_pending
            .insert((&txn).into(), txn.clone());
        debug_assert!(
            existing_txn.is_none(),
            "BQHN: Attempt to double insert a transaction"
        );
        self.balance_after_pending -= gas_price;
        self.maintain();
    }
    fn insert_txn(&mut self, txn: VerifiedTransaction) {
        if txn.tx.nonce().is_some() {
            self.insert_nonced_txn(txn);
        } else {
            self.insert_unnonced_txn(txn);
        }
    }
    /// Returns hash of updated transaction
    fn update_txn(&mut self, new_txn: VerifiedTransaction) -> Option<Hash> {
        if let Some(nonce) = new_txn.tx.nonce() {
            if let std::collections::btree_map::Entry::Occupied(mut entry) =
                self.nonced_transactions_pending.entry(nonce)
            {
                let new_gas_price = new_txn.tx.maximum_validation_cost().unwrap() as i128;
                let old_txn = entry.insert(new_txn);
                self.balance_after_pending -=
                    new_gas_price - old_txn.tx.maximum_validation_cost().unwrap() as i128;
                self.maintain();
                return Some(old_txn.hash);
            }
            if let std::collections::btree_map::Entry::Occupied(mut entry) =
                self.nonced_transactions_queued.entry(nonce)
            {
                let old_txn = entry.insert(new_txn);
                self.maintain();
                return Some(old_txn.hash);
            }
            unreachable!("YMGL: Transaction not found")
        } else {
            unreachable!("Cannot update transaction without nonce")
        }
    }
    fn get_pending(&self) -> impl Iterator<Item = &VerifiedTransaction> {
        let nonceless_iterator = self
            .nonceless_transactions_pending
            .iter()
            .map(|x| x.1)
            .rev();
        let nonced_iterator = self.nonced_transactions_pending.iter().map(|x| x.1);

        nonceless_iterator.merge_by(nonced_iterator, |a, b| {
            a.tx.gas_price_per_evm_gas() > b.tx.gas_price_per_evm_gas()
        })
    }
    fn get_queued(&self) -> impl Iterator<Item = &VerifiedTransaction> {
        let nonceless_iterator = self.nonceless_transactions_queued.iter().rev().map(|x| x.1);
        let nonced_iterator = self.nonced_transactions_queued.iter().map(|x| x.1);

        nonceless_iterator.merge_by(nonced_iterator, |a, b| {
            a.tx.gas_price_per_evm_gas() > b.tx.gas_price_per_evm_gas()
        })
    }
    fn get_pending_transaction_count(&self) -> u64 {
        let nonced_pending_count = self.nonced_transactions_pending.len();
        let nonceless_pending_count = self.nonceless_transactions_pending.len();
        (nonced_pending_count + nonceless_pending_count) as u64
    }
    fn get_transaction_count(&self) -> usize {
        self.nonced_transactions_queued.len()
            + self.nonced_transactions_pending.len()
            + self.nonceless_transactions_queued.len()
            + self.nonceless_transactions_pending.len()
    }
    fn is_empty(&self) -> bool {
        self.nonced_transactions_queued.is_empty()
            && self.nonced_transactions_pending.is_empty()
            && self.nonceless_transactions_pending.is_empty()
            && self.nonceless_transactions_queued.is_empty()
    }
    fn peek_best_txn(&self) -> Option<&VerifiedTransaction> {
        self.get_pending().next()
    }
    fn pop_best_if(
        &mut self,
        predicate: impl Fn(&VerifiedTransaction) -> bool,
    ) -> Option<VerifiedTransaction> {
        let transaction = match self.peek_best_txn() {
            Some(txn) if predicate(txn) => txn.clone(),
            _ => return None,
        };
        if transaction.tx.nonce().is_some() {
            self.nonced_transactions_pending.pop_first().unwrap();
            self.balance_after_pending += transaction.tx.maximum_validation_cost().unwrap() as i128;
            self.nonce_account += 1;
        } else {
            self.nonceless_transactions_pending.pop_last().unwrap();
            self.balance_after_pending += transaction.tx.maximum_validation_cost().unwrap() as i128;
        }
        self.maintain();
        Some(transaction)
    }
    // Must be followed by maintain()
    fn update_balance(&mut self, new_balance: u128) {
        assert!(new_balance < i128::MAX as u128);
        let balance_delta = new_balance as i128 - self.balance_account as i128;
        self.balance_account = new_balance;
        self.balance_after_pending += balance_delta;
    }
    // Must be followed by maintain()
    fn update_nonce(&mut self, new_nonce: u64) -> Vec<Hash> {
        let old_nonce = self.nonce_account;
        let lowest_existing_nonce = self
            .nonced_transactions_pending
            .first_key_value()
            .or(self.nonced_transactions_queued.first_key_value())
            .and_then(|x| x.1.tx.nonce());
        match new_nonce.cmp(&old_nonce) {
            Ordering::Less => {
                self.nonce_account = new_nonce;
                if Some(old_nonce) == lowest_existing_nonce {
                    self.full_recalculate();
                }
            }
            Ordering::Equal => (),
            Ordering::Greater => {
                if let Some(lowest_existing_nonce) = lowest_existing_nonce {
                    match new_nonce.cmp(&lowest_existing_nonce) {
                        std::cmp::Ordering::Less => self.nonce_account = new_nonce,
                        std::cmp::Ordering::Equal => {
                            self.nonce_account = new_nonce;
                            self.full_recalculate();
                        }
                        std::cmp::Ordering::Greater => panic!(
                            "Nonce cannot be increased above lowest transaction nonce in pool"
                        ),
                    }
                }
            }
        }
        vec![]
    }
    fn update_with_account(&mut self, account: &Account) -> Vec<Hash> {
        self.update_balance(account.balance);
        let result = self.update_nonce(account.nonce);
        self.maintain();
        result
    }
    fn get_pending_or_queued(&self, txn: &VerifiedTransaction) -> Option<PendingOrQueued> {
        debug_assert!(txn.signer == self.address);
        if self
            .nonceless_transactions_pending
            .contains_key(&txn.into())
        {
            return Some(PendingOrQueued::Pending);
        }
        if self.nonceless_transactions_queued.contains_key(&txn.into()) {
            return Some(PendingOrQueued::Queued);
        }
        if let Some(nonce) = txn.tx.nonce() {
            if self.nonced_transactions_pending.contains_key(&nonce) {
                return Some(PendingOrQueued::Pending);
            }
            if self.nonced_transactions_queued.contains_key(&nonce) {
                return Some(PendingOrQueued::Queued);
            }
        }
        None
    }
    fn get_txn_by_nonce(&self, nonce: u64) -> Option<&VerifiedTransaction> {
        self.nonced_transactions_pending
            .get(&nonce)
            .or_else(|| self.nonced_transactions_queued.get(&nonce))
    }
    fn get_pending_queue_key(&self) -> Option<PendingQueueKey> {
        self.peek_best_txn()
            .map(|best_transaction| PendingQueueKey {
                highest_gas_price: best_transaction.tx.gas_price_per_evm_gas(),
                address: best_transaction.signer,
            })
    }

    fn mark_executed(&mut self, txn: &VerifiedTransaction) -> Vec<Hash> {
        if let std::collections::btree_map::Entry::Occupied(entry) =
            self.nonceless_transactions_pending.entry(txn.into())
        {
            let old_txn = entry.remove();
            let gas = old_txn.tx.gas_price_per_evm_gas();
            self.balance_after_pending += gas as i128;
            self.maintain();
            return vec![old_txn.hash];
        }
        if let std::collections::btree_map::Entry::Occupied(entry) =
            self.nonceless_transactions_queued.entry(txn.into())
        {
            let old_txn = entry.remove();
            self.maintain();
            return vec![old_txn.hash];
        }
        let Some(nonce_to_remove) = txn.tx.nonce() else {
            tracing::warn!(
                "Transaction could not be marked executed since it was not in pool: {:?}",
                txn
            );
            return vec![];
        };
        if let Some(lowest_nonce) = self
            .nonced_transactions_pending
            .first_key_value()
            .or(self.nonced_transactions_queued.first_key_value())
            .map(|x| x.1.tx.nonce().unwrap())
        {
            if let Some(txn) = self.nonced_transactions_pending.remove(&nonce_to_remove) {
                self.nonce_account = txn.tx.nonce().unwrap() + 1;
                if txn.tx.nonce().unwrap() == lowest_nonce {
                    self.nonce_account += 1;
                    self.balance_after_pending += txn.tx.maximum_validation_cost().unwrap() as i128;
                    self.maintain();
                } else {
                    self.full_recalculate();
                    tracing::warn!("Pending transaction remove was not lowest nonce")
                }
                vec![txn.hash]
            } else if let Some(txn) = self.nonced_transactions_queued.remove(&nonce_to_remove) {
                if txn.tx.nonce().unwrap() == lowest_nonce {
                    self.maintain();
                } else {
                    self.maintain();
                    tracing::warn!("Queued transaction removed was not lowest nonce")
                }
                vec![txn.hash]
            } else {
                tracing::warn!(
                    "Transaction could not be marked executed since it was not in pool: {:?}",
                    txn
                );
                return vec![];
            }
        } else {
            tracing::warn!("No nonced transactions in pool");
            vec![]
        }
    }
}

/// Private implementation of the transaction pool
/// The pool is a set of pools for individual accounts (all_transactions), each of which maintains
/// its own pending lists of nonced and nonceless transactions.
/// When pending transactions are queried they just need to be merged from the individual accounts.
#[derive(Clone, Debug, Default)]
struct TransactionPoolCore {
    all_transactions: HashMap<Address, TransactionsAccount>,
    pending_account_queue: BTreeSet<PendingQueueKey>,
    hash_to_txn_map: HashMap<Hash, VerifiedTransaction>,
    // Keeps track of the total number of transactions in the pool for speed
    total_transactions_counter: usize,
}

impl TransactionPoolCore {
    fn update_with_state(&mut self, state: &State) {
        // For now, we're polling for updates in all accounts
        // But in future we expect to receive account change notifications
        for (address, transactions_account) in self.all_transactions.iter_mut() {
            let old_nonce = transactions_account.nonce_account;
            let old_balance = transactions_account.balance_account;
            let new_account = state.get_account(*address).unwrap();
            let new_nonce = new_account.nonce;
            let new_balance = new_account.balance;
            if old_nonce != new_nonce || old_balance != new_balance {
                if let Some(pending_queue_key) = transactions_account.get_pending_queue_key() {
                    self.pending_account_queue.remove(&pending_queue_key);
                }
                let removed_txn_hashes = transactions_account.update_with_account(&new_account);
                self.total_transactions_counter -= removed_txn_hashes.len();
                for hash in removed_txn_hashes {
                    self.hash_to_txn_map.remove(&hash);
                }
                if let Some(pending_queue_key) = transactions_account.get_pending_queue_key() {
                    self.pending_account_queue.insert(pending_queue_key);
                }
            }
        }
        self.all_transactions.retain(|_k, v| !v.is_empty());
    }

    fn update_with_account(&mut self, account_address: &Address, account_data: &Account) {
        if let Some(transactions_account) = self.all_transactions.get_mut(account_address) {
            let old_nonce = transactions_account.nonce_account;
            let old_balance = transactions_account.balance_account;
            let new_account = account_data;
            let new_nonce = new_account.nonce;
            let new_balance = new_account.balance;
            if old_nonce != new_nonce || old_balance != new_balance {
                if let Some(pending_queue_key) = transactions_account.get_pending_queue_key() {
                    self.pending_account_queue.remove(&pending_queue_key);
                }
                let removed_txn_hashes = transactions_account.update_with_account(new_account);
                self.total_transactions_counter -= removed_txn_hashes.len();
                for hash in removed_txn_hashes {
                    self.hash_to_txn_map.remove(&hash);
                }
                if let Some(pending_queue_key) = transactions_account.get_pending_queue_key() {
                    self.pending_account_queue.insert(pending_queue_key);
                }
                if transactions_account.is_empty() {
                    self.all_transactions.remove(account_address);
                }
            }
        }
    }
    // Potentially slow, depending on merge behaviour
    fn pending_transactions_ordered(&self) -> impl Iterator<Item = &VerifiedTransaction> {
        self.all_transactions
            .values()
            .map(|x| x.get_pending())
            .kmerge_by(|a, b| a.tx.gas_price_per_evm_gas() > b.tx.gas_price_per_evm_gas())
    }

    // Potentially slow, depending on merge behaviour
    fn queued_transactions_ordered(&self) -> impl Iterator<Item = &VerifiedTransaction> {
        self.all_transactions
            .values()
            .map(|x| x.get_queued())
            .kmerge_by(|a, b| a.tx.gas_price_per_evm_gas() > b.tx.gas_price_per_evm_gas())
    }

    fn get_pending_or_queued(&self, txn: &VerifiedTransaction) -> Option<PendingOrQueued> {
        match self.all_transactions.get(&txn.signer) {
            Some(account) => account.get_pending_or_queued(txn),
            None => None,
        }
    }

    fn account_pending_transaction_count(&self, account_address: &Address) -> u64 {
        match self.all_transactions.get(account_address) {
            Some(account) => account.get_pending_transaction_count(),
            None => 0,
        }
    }

    fn account_transaction_count(&self, account_address: &Address) -> u64 {
        match self.all_transactions.get(account_address) {
            Some(account) => account.get_transaction_count() as u64,
            None => 0,
        }
    }

    fn pending_transaction_count(&self) -> u64 {
        self.all_transactions
            .values()
            .map(|x| x.get_pending_transaction_count())
            .sum()
    }

    fn transaction_count(&self) -> u64 {
        self.total_transactions_counter as u64
    }

    pub fn senders_count(&self) -> usize {
        self.all_transactions.len()
    }

    fn get_txn_by_address_and_nonce(
        &self,
        address: &Address,
        nonce: u64,
    ) -> Option<&VerifiedTransaction> {
        match self.all_transactions.get(address) {
            Some(account) => account.get_txn_by_nonce(nonce),
            None => None,
        }
    }

    fn get_transaction_by_hash(&self, hash: &Hash) -> Option<&VerifiedTransaction> {
        self.hash_to_txn_map.get(hash)
    }

    fn update_txn(&mut self, txn: VerifiedTransaction) {
        let transactions_account = self.all_transactions.get_mut(&txn.signer).unwrap();
        if let Some(pending_queue_key) = transactions_account.get_pending_queue_key() {
            self.pending_account_queue.remove(&pending_queue_key);
        }
        let old_hash = transactions_account.update_txn(txn.clone()).unwrap();
        self.hash_to_txn_map.remove(&old_hash);
        self.hash_to_txn_map.insert(txn.hash, txn);
        if let Some(pending_queue_key) = transactions_account.get_pending_queue_key() {
            self.pending_account_queue.insert(pending_queue_key);
        }
    }

    fn add_txn(&mut self, txn: VerifiedTransaction, account: &Account) {
        let transactions_account =
            self.all_transactions
                .entry(txn.signer)
                .or_insert_with(|| TransactionsAccount {
                    address: txn.signer,
                    balance_account: account.balance,
                    balance_after_pending: account.balance as i128,
                    nonce_account: account.nonce,
                    nonced_transactions_pending: BTreeMap::new(),
                    nonced_transactions_queued: BTreeMap::new(),
                    nonceless_transactions_pending: BTreeMap::new(),
                    nonceless_transactions_queued: BTreeMap::new(),
                });
        if let Some(pending_queue_key) = transactions_account.get_pending_queue_key() {
            self.pending_account_queue.remove(&pending_queue_key);
        }
        transactions_account.insert_txn(txn.clone());
        self.total_transactions_counter += 1;
        if let Some(pending_queue_key) = transactions_account.get_pending_queue_key() {
            self.pending_account_queue.insert(pending_queue_key);
        }
        self.hash_to_txn_map.insert(txn.hash, txn);
    }

    fn preview_content(&self) -> TxPoolContent {
        let pending_txns: HashMap<Address, Vec<VerifiedTransaction>> = self
            .all_transactions
            .iter()
            .map(|(address, transactions)| {
                (*address, transactions.get_pending().cloned().collect())
            })
            .collect();
        let queued_txns: HashMap<Address, Vec<VerifiedTransaction>> = self
            .all_transactions
            .iter()
            .map(|(address, transactions)| (*address, transactions.get_queued().cloned().collect()))
            .collect();
        TxPoolContent {
            pending: pending_txns,
            queued: queued_txns,
        }
    }

    fn preview_content_from(&self, address: &Address) -> TxPoolContentFrom {
        let pending_txns: Vec<VerifiedTransaction> = self
            .all_transactions
            .get(address)
            .map_or(Vec::new(), |x| x.get_pending().cloned().collect());
        let queued_txns: Vec<VerifiedTransaction> = self
            .all_transactions
            .get(address)
            .map_or(Vec::new(), |x| x.get_queued().cloned().collect());
        TxPoolContentFrom {
            pending: pending_txns,
            queued: queued_txns,
        }
    }

    fn any_pending(&self) -> bool {
        !self.pending_account_queue.is_empty()
    }

    fn clear(&mut self) {
        self.pending_account_queue.clear();
        self.all_transactions.clear();
        self.hash_to_txn_map.clear();
        self.total_transactions_counter = 0;
    }

    fn peek_best_txn(&self) -> Option<&VerifiedTransaction> {
        let best_account_key = self.pending_account_queue.last()?;

        let best_account = self
            .all_transactions
            .get(&best_account_key.address)
            .unwrap();

        best_account.peek_best_txn()
    }

    pub fn pop_best_if(
        &mut self,
        predicate: impl Fn(&VerifiedTransaction) -> bool,
    ) -> Option<VerifiedTransaction> {
        let best_account_key = self.pending_account_queue.last().cloned()?;

        let transactions_account = self
            .all_transactions
            .get_mut(&best_account_key.address.clone())
            .unwrap();

        let old_pending_queue_key = transactions_account.get_pending_queue_key();
        let result = transactions_account.pop_best_if(predicate);
        if let Some(ref txn) = result {
            self.total_transactions_counter -= 1;
            if let Some(pending_queue_key) = old_pending_queue_key {
                self.pending_account_queue.remove(&pending_queue_key);
            }
            if let Some(pending_queue_key) = transactions_account.get_pending_queue_key() {
                self.pending_account_queue.insert(pending_queue_key);
            }
            if transactions_account.is_empty() {
                self.all_transactions.remove(&best_account_key.address);
            }
            self.hash_to_txn_map.remove(&txn.hash).unwrap();
        }
        result
    }

    pub fn mark_executed(&mut self, txn: &VerifiedTransaction) {
        let address = txn.signer;
        if let Some(account) = self.all_transactions.get_mut(&address) {
            if let Some(pending_queue_key) = account.get_pending_queue_key() {
                self.pending_account_queue.remove(&pending_queue_key);
            }
            let removed_txn_hashes = account.mark_executed(txn);
            self.total_transactions_counter -= removed_txn_hashes.len();
            for hash in removed_txn_hashes {
                self.hash_to_txn_map.remove(&hash);
            }
            if let Some(key) = account.get_pending_queue_key() {
                self.pending_account_queue.insert(key);
            }
            if account.is_empty() {
                self.all_transactions.remove(&address);
            }
        }
    }
}

/// This struct wraps the transaction pool to separate the methods needed by the wider application
/// from the internal implementation details.
#[derive(Clone, Debug, Default)]
pub struct TransactionPool {
    core: TransactionPoolCore,
    /// Keeps transactions created at this node that will be broadcast
    transactions_to_broadcast: VecDeque<VerifiedTransaction>,
}

// Represents currently pending txns for inclusion in the next block(s), as well as the ones that are being scheduled for future execution.
#[derive(Clone)]
pub struct TxPoolContent {
    pub pending: HashMap<Address, Vec<VerifiedTransaction>>,
    pub queued: HashMap<Address, Vec<VerifiedTransaction>>,
}

#[derive(Clone)]
pub struct TxPoolContentFrom {
    pub pending: Vec<VerifiedTransaction>,
    pub queued: Vec<VerifiedTransaction>,
}

#[derive(Clone)]
pub struct TxPoolStatus {
    pub pending: u64,
    pub queued: u64,
}

impl TransactionPool {
    pub fn update_with_state(&mut self, state: &State) {
        self.core.update_with_state(state);
    }
    pub fn update_with_account(&mut self, account_address: &Address, account_data: &Account) {
        self.core.update_with_account(account_address, account_data);
    }
    pub fn best_transaction(&self) -> Option<&VerifiedTransaction> {
        self.core.peek_best_txn()
    }

    pub fn pending_transactions_ordered(&self) -> impl Iterator<Item = &VerifiedTransaction> {
        self.core.pending_transactions_ordered()
    }

    pub fn queued_transactions_ordered(&self) -> impl Iterator<Item = &VerifiedTransaction> {
        self.core.queued_transactions_ordered()
    }

    pub fn get_transaction(&self, hash: &Hash) -> Option<&VerifiedTransaction> {
        self.core.get_transaction_by_hash(hash)
    }

    /// Returns whether the transaction is pending or queued
    /// The result is not guaranteed to be in any particular order
    pub fn get_pending_or_queued(
        &self,
        txn: &VerifiedTransaction,
    ) -> Result<Option<PendingOrQueued>> {
        Ok(self.core.get_pending_or_queued(txn))
    }

    pub fn preview_content(&self) -> TxPoolContent {
        self.core.preview_content()
    }

    pub fn preview_content_from(&self, address: &Address) -> TxPoolContentFrom {
        self.core.preview_content_from(address)
    }

    pub fn preview_status(&self) -> TxPoolStatus {
        let pending_count = self.pending_transaction_count();
        let total_count = self.transaction_count();
        TxPoolStatus {
            pending: pending_count,
            queued: total_count - pending_count,
        }
    }

    pub fn account_pending_transaction_count(&self, account_address: &Address) -> u64 {
        self.core.account_pending_transaction_count(account_address)
    }

    pub fn account_total_transaction_count(&self, account_address: &Address) -> u64 {
        self.core.account_transaction_count(account_address)
    }

    pub fn pending_transaction_count(&self) -> u64 {
        self.core.pending_transaction_count()
    }

    pub fn transaction_count(&self) -> u64 {
        self.core.transaction_count()
    }

    pub fn mark_executed(&mut self, txn: &VerifiedTransaction) {
        self.core.mark_executed(txn);
    }

    /// Returns a pair (did_we_add_it, message).
    /// If we return false, it's safe to say that txn validation failed.
    pub fn insert_transaction(
        &mut self,
        txn: VerifiedTransaction,
        account: &Account,
        from_broadcast: bool,
    ) -> TxAddResult {
        // check for duplicates
        if self.core.hash_to_txn_map.contains_key(&txn.hash) {
            tracing::warn!(
                "Transaction with this hash is already in the pool. Txn hash: {:?}, from: {:?}, account nonce: {:?}",
                txn.hash,
                txn.signer,
                account.nonce,
            );
            self.update_with_account(&txn.signer, account);
            return TxAddResult::Duplicate(txn.hash);
        }

        if let Some(transaction_nonce) = txn.tx.nonce() {
            if transaction_nonce < account.nonce {
                debug!(
                    "Nonce is too low. Txn hash: {:?}, from: {:?}, nonce: {:?}, account nonce: {:?}",
                    txn.hash, txn.signer, transaction_nonce, account.nonce,
                );
                // This transaction is permanently invalid, so there is nothing to do.
                // unwrap() is safe because we checked above that it was some().
                self.update_with_account(&txn.signer, account);
                return TxAddResult::NonceTooLow(transaction_nonce, account.nonce);
            }
        }

        let existing_transaction = match txn.tx.nonce() {
            Some(nonce) => self.core.get_txn_by_address_and_nonce(&txn.signer, nonce),
            None => None,
        };
        if let Some(existing_txn) = existing_transaction {
            // Only proceed if the new transaction is better. Note that if they are
            // equally good, we prioritise the existing transaction to avoid the need
            // to broadcast a new transaction to the network.
            // N.B.: This will in theory never affect intershard/nonceless transactions - since
            // with the current bridge design it is not possible to broadcast a different one while
            // keeping the same nonce. So for those, it will always discard the new (identical)
            // one.
            if txn.signer == existing_txn.signer
                && txn.tx.nonce().unwrap() == existing_txn.tx.nonce().unwrap()
                && txn.tx.gas_price_per_evm_gas() < existing_txn.tx.gas_price_per_evm_gas()
            {
                debug!(
                    "Received txn with the same nonce but lower gas price. Txn hash: {:?}, from: {:?}, nonce: {:?}, gas_price: {:?}",
                    txn.hash,
                    txn.signer,
                    txn.tx.nonce(),
                    txn.tx.gas_price_per_evm_gas()
                );
                self.update_with_account(&txn.signer, account);
                return TxAddResult::SameNonceButLowerGasPrice;
            } else {
                debug!(
                    "Txn updated in mempool. Hash: {:?}, from: {:?}, nonce: {:?}, account nonce: {:?}",
                    txn.hash,
                    txn.signer,
                    txn.tx.nonce(),
                    account.nonce,
                );
                self.update_with_account(&txn.signer, account);
                self.core.update_txn(txn.clone());
            }
        } else {
            // Check global size
            if self.core.transaction_count() + 1 > GLOBAL_TXN_POOL_SIZE_LIMIT {
                return TxAddResult::ValidationFailed(
                    ValidationOutcome::GlobalTransactionCountExceeded,
                );
            }

            // Check total number of senders
            if self.core.senders_count() + 1 > TOTAL_SENDERS_COUNT_LIMIT {
                return TxAddResult::ValidationFailed(
                    ValidationOutcome::TotalNumberOfSlotsExceeded,
                );
            }

            // Check total number of slots for senders
            if self.account_total_transaction_count(&txn.signer) + 1 > MAX_TXNS_PER_SENDER {
                return TxAddResult::ValidationFailed(
                    ValidationOutcome::TransactionCountExceededForSender,
                );
            }

            debug!(
                "Txn added to mempool. Hash: {:?}, from: {:?}, nonce: {:?}, account nonce: {:?}",
                txn.hash,
                txn.signer,
                txn.tx.nonce(),
                account.nonce,
            );
            self.core.add_txn(txn.clone(), account);
            self.update_with_account(&txn.signer, account);
        }

        // If this is a transaction created at this node, add it to broadcast vector
        if !from_broadcast {
            self.store_broadcast_txn(&txn);
        }

        TxAddResult::AddedToMempool
    }

    // Like insert transaction, but if the transaction is already there, we always overwrite it
    pub fn insert_transaction_forced(
        &mut self,
        txn: VerifiedTransaction,
        account: &Account,
        from_broadcast: bool,
    ) -> TxAddResult {
        // check for duplicates
        if self.core.hash_to_txn_map.contains_key(&txn.hash) {
            tracing::warn!(
                "Transaction with this hash is already in the pool. Txn hash: {:?}, from: {:?}, account nonce: {:?}",
                txn.hash,
                txn.signer,
                account.nonce,
            );
            self.update_with_account(&txn.signer, account);
            return TxAddResult::Duplicate(txn.hash);
        }

        if let Some(transaction_nonce) = txn.tx.nonce() {
            if transaction_nonce < account.nonce {
                debug!(
                    "Nonce is too low. Txn hash: {:?}, from: {:?}, nonce: {:?}, account nonce: {:?}",
                    txn.hash, txn.signer, transaction_nonce, account.nonce,
                );
                // This transaction is permanently invalid, so there is nothing to do.
                // unwrap() is safe because we checked above that it was some().
                self.update_with_account(&txn.signer, account);
                return TxAddResult::NonceTooLow(transaction_nonce, account.nonce);
            }
        }

        let existing_transaction = match txn.tx.nonce() {
            Some(nonce) => self.core.get_txn_by_address_and_nonce(&txn.signer, nonce),
            None => None,
        };
        if let Some(_existing_txn) = existing_transaction {
            debug!(
                "Txn updated in mempool. Hash: {:?}, from: {:?}, nonce: {:?}, account nonce: {:?}",
                txn.hash,
                txn.signer,
                txn.tx.nonce(),
                account.nonce,
            );
            self.update_with_account(&txn.signer, account);
            self.core.update_txn(txn.clone());
        } else {
            debug!(
                "Txn added to mempool. Hash: {:?}, from: {:?}, nonce: {:?}, account nonce: {:?}",
                txn.hash,
                txn.signer,
                txn.tx.nonce(),
                account.nonce,
            );
            self.core.add_txn(txn.clone(), account);
            self.update_with_account(&txn.signer, account);
        }

        // If this is a transaction created at this node, add it to broadcast vector
        if !from_broadcast {
            self.store_broadcast_txn(&txn);
        }

        TxAddResult::AddedToMempool
    }

    fn store_broadcast_txn(&mut self, txn: &VerifiedTransaction) {
        self.transactions_to_broadcast.push_back(txn.clone());
    }

    pub fn pull_txns_to_broadcast(&mut self) -> Result<Vec<SignedTransaction>> {
        const MAX_BATCH_SIZE: usize = 1000;
        const BATCH_SIZE_THRESHOLD: usize = 972 * 1024; // 95% of max_transmit_size().

        if self.transactions_to_broadcast.is_empty() {
            return Ok(Vec::new());
        }

        let mut batch_count = 0usize;
        let mut batch_size = BATCH_SIZE_THRESHOLD;

        for tx in self.transactions_to_broadcast.iter() {
            // batch by number or size
            if let Some(balance_size) = batch_size.checked_sub(tx.encoded_size()) {
                batch_size = balance_size;
                batch_count += 1;
                if batch_count == MAX_BATCH_SIZE {
                    break;
                }
            } else {
                break;
            };
        }

        let selected = self
            .transactions_to_broadcast
            .drain(0..batch_count)
            .map(|tx| tx.tx)
            .collect();
        Ok(selected)
    }

    pub fn pop_best_if(
        &mut self,
        predicate: impl Fn(&VerifiedTransaction) -> bool,
    ) -> Option<VerifiedTransaction> {
        self.core.pop_best_if(predicate)
    }

    /// Check the ready transactions in arbitrary order, for one that is Ready
    pub fn has_txn_ready(&self) -> bool {
        self.core.any_pending()
    }

    pub fn clear(&mut self) {
        self.core.clear();
    }
}

#[cfg(test)]
mod tests {
    use std::{
        path::PathBuf,
        sync::Arc,
        time::{Duration, Instant},
    };

    use alloy::{
        consensus::TxLegacy,
        primitives::{Address, Bytes, PrimitiveSignature, TxKind, U256},
    };
    use anyhow::Result;
    use itertools::Itertools;
    use rand::{seq::SliceRandom, thread_rng};

    use super::TransactionPool;
    use crate::{
        cfg::NodeConfig,
        crypto::Hash,
        db::Db,
        pool::{PendingOrQueued, TxAddResult},
        state::State,
        transaction::{EvmGas, SignedTransaction, TxIntershard, VerifiedTransaction},
    };

    fn transaction(from_addr: Address, nonce: u64, gas_price: u128) -> VerifiedTransaction {
        let tx = SignedTransaction::Legacy {
            tx: TxLegacy {
                chain_id: Some(0),
                nonce,
                gas_price,
                gas_limit: 1,
                to: TxKind::Create,
                value: U256::ZERO,
                input: Bytes::new(),
            },
            sig: PrimitiveSignature::new(U256::from(1), U256::from(1), false),
        };
        let cbor_size = cbor4ii::serde::to_vec(Vec::with_capacity(4096), &tx)
            .map(|b| b.len())
            .unwrap_or_default();
        VerifiedTransaction {
            cbor_size,
            tx,
            signer: from_addr,
            hash: Hash::builder()
                .with(from_addr.as_slice())
                .with(nonce.to_le_bytes())
                .finalize(),
        }
    }

    fn intershard_transaction(
        from_shard: u8,
        shard_nonce: u8,
        gas_price: u128,
    ) -> VerifiedTransaction {
        let tx = SignedTransaction::Intershard {
            tx: TxIntershard {
                chain_id: 0,
                bridge_nonce: shard_nonce as u64,
                source_chain: from_shard as u64,
                gas_price,
                gas_limit: EvmGas(0),
                to_addr: None,
                payload: vec![],
            },
            from: Address::ZERO,
        };
        let cbor_size = cbor4ii::serde::to_vec(Vec::with_capacity(4096), &tx)
            .map(|b| b.len())
            .unwrap_or_default();
        VerifiedTransaction {
            cbor_size,
            tx,
            signer: Address::ZERO,
            hash: Hash::builder()
                .with([shard_nonce])
                .with([from_shard])
                .finalize(),
        }
    }

    fn get_in_memory_state() -> Result<State> {
        let node_config = NodeConfig::default();

        let db = Db::new::<PathBuf>(None, 0, 0, None)?;
        let db = Arc::new(db);

        State::new_with_genesis(db.state_trie()?, node_config, db.clone())
    }

    fn create_acc(
        state: &mut State,
        address: Address,
        balance: u128,
        nonce: u64,
    ) -> Result<crate::state::Account> {
        let mut acc = state.get_account(address)?;
        acc.balance = balance;
        acc.nonce = nonce;
        state.save_account(address, acc.clone())?;
        Ok(acc)
    }

    #[test]
    #[rustfmt::skip]
    fn test_internal_add_txns() -> Result<()> {
        let mut state = get_in_memory_state()?;

        let mut pool = TransactionPool::default();

        let acc1_addr = "0x0000000000000000000000000000000000000001".parse()?;
        let acc1_balance = 30;
        let acc1_nonce = 0;
        let acc1 = create_acc(&mut state, acc1_addr, acc1_balance, acc1_nonce)?;

        let txn1 = transaction(acc1_addr, 0, 10);
        let txn2 = transaction(acc1_addr, 1, 10);
        let txn3 = transaction(acc1_addr, 2, 10);
        let txn4 = transaction(acc1_addr, 3, 10);
        let txn5 = transaction(acc1_addr, 4, 10);
        let txn6 = transaction(acc1_addr, 5, 10);

        // Initially insert a bunch of transactions with nonces too high
        pool.insert_transaction(txn4.clone(), &acc1, false);
        pool.insert_transaction(txn2.clone(), &acc1, false);
        pool.insert_transaction(txn3.clone(), &acc1, false);
        pool.core.update_with_state(&state);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().balance_account, 30);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().nonce_account, 0);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().balance_after_pending, 30);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().nonced_transactions_pending.len(), 0);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().nonced_transactions_queued.len(), 3);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().get_pending_transaction_count(), 0);

        // Add the lowest transaction and now they should get added up to the balance
        pool.insert_transaction(txn1.clone(), &acc1, false);
        pool.core.update_with_state(&state);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().get_pending_transaction_count(), 3);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().balance_account, 30);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().nonce_account, 0);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().balance_after_pending, 0);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().get_pending().collect_vec(), vec![&txn1, &txn2, &txn3]);

        // Increase the balance by 5 and nothing else should change
        state.mutate_account(acc1_addr, |acc| {
            acc.balance += 5;
            Ok(())
        })?;
        assert_eq!(state.get_account(acc1_addr).unwrap().balance, 35);
        pool.core.update_with_state(&state);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().get_pending_transaction_count(), 3);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().balance_account, 35);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().nonce_account, 0);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().balance_after_pending, 5);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().get_pending().collect_vec(), vec![&txn1, &txn2, &txn3]);

        // increase the balance by another 5 and now they should all be pending
        state.mutate_account(acc1_addr, |acc| {
            acc.balance += 5;
            Ok(())
        })?;
        assert_eq!(state.get_account(acc1_addr).unwrap().balance, 40);
        pool.core.update_with_state(&state);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().balance_account, 40);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().nonce_account, 0);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().balance_after_pending, 0);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().get_pending_transaction_count(), 4);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().get_pending().collect_vec(), vec![&txn1, &txn2, &txn3, &txn4]);

        // add another two, and they shouldn't pend
        pool.insert_transaction(txn5.clone(), &acc1, false);
        pool.insert_transaction(txn6.clone(), &acc1, false);
        pool.core.update_with_state(&state);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().balance_account, 40);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().nonce_account, 0);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().balance_after_pending, 0);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().get_pending_transaction_count(), 4);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().get_pending().collect_vec(), vec![&txn1, &txn2, &txn3, &txn4]);

        // pop a transaction off the front and one of the next two should get added
        pool.pop_best_if(|txn| {
            assert_eq!(txn, &txn1);
            true
        });
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().balance_account, 40);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().nonce_account, 1);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().balance_after_pending, 0);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().get_pending_transaction_count(), 4);
        assert_eq!(pool.core.all_transactions.get(&acc1_addr).unwrap().get_pending().collect_vec(), vec![&txn2, &txn3, &txn4, &txn5]);

        Ok(())
    }

    #[test]
    fn nonces_returned_in_order() -> Result<()> {
        let mut pool = TransactionPool::default();
        let from = "0x0000000000000000000000000000000000001234".parse()?;

        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, from, 100, 0)?;

        pool.insert_transaction(transaction(from, 1, 1), &acc, false);

        pool.update_with_state(&state);
        let tx = pool.best_transaction();
        assert_eq!(tx, None);

        pool.insert_transaction(transaction(from, 2, 2), &acc, false);
        pool.insert_transaction(transaction(from, 0, 0), &acc, false);

        let tx = pool.best_transaction().unwrap().clone();
        assert_eq!(tx.tx.nonce().unwrap(), 0);
        pool.mark_executed(&tx);
        state.mutate_account(from, |acc| {
            acc.nonce += 1;
            Ok(())
        })?;
        pool.update_with_state(&state);

        let tx = pool.best_transaction().unwrap().clone();
        assert_eq!(tx.tx.nonce().unwrap(), 1);
        pool.mark_executed(&tx);
        state.mutate_account(from, |acc| {
            acc.nonce += 1;
            Ok(())
        })?;
        pool.update_with_state(&state);

        let tx = pool.best_transaction().unwrap().clone();
        assert_eq!(tx.tx.nonce().unwrap(), 2);
        pool.mark_executed(&tx);
        state.mutate_account(from, |acc| {
            acc.nonce += 1;
            Ok(())
        })?;
        pool.update_with_state(&state);

        Ok(())
    }

    #[test]
    fn nonces_returned_in_order_same_gas() -> Result<()> {
        let mut pool = TransactionPool::default();
        let from = "0x0000000000000000000000000000000000001234".parse()?;

        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, from, 100, 0)?;
        pool.update_with_state(&state);

        const COUNT: u64 = 100;

        let mut nonces = (0..COUNT).collect::<Vec<_>>();
        let mut rng = thread_rng();
        nonces.shuffle(&mut rng);

        for i in 0..COUNT {
            pool.insert_transaction(transaction(from, nonces[i as usize], 3), &acc, false);
        }

        for i in 0..COUNT {
            let tx = pool.best_transaction().unwrap().clone();
            assert_eq!(tx.tx.nonce().unwrap(), i);
            pool.mark_executed(&tx);
            state.mutate_account(from, |acc| {
                acc.nonce += 1;
                Ok(())
            })?;
            pool.update_with_state(&state);
        }
        Ok(())
    }

    #[test]
    fn ordered_by_gas_price() -> Result<()> {
        let mut pool = TransactionPool::default();
        let from0 = "0x0000000000000000000000000000000000000000".parse()?;
        let from1 = "0x0000000000000000000000000000000000000001".parse()?;
        let from2 = "0x0000000000000000000000000000000000000002".parse()?;
        let from3 = "0x0000000000000000000000000000000000000003".parse()?;

        let mut state = get_in_memory_state()?;
        let acc0 = create_acc(&mut state, from0, 100, 0)?;
        let acc1 = create_acc(&mut state, from1, 100, 0)?;
        let acc2 = create_acc(&mut state, from2, 100, 0)?;
        let acc3 = create_acc(&mut state, from3, 100, 0)?;
        pool.update_with_state(&state);

        pool.insert_transaction(intershard_transaction(0, 0, 1), &acc0, false);
        pool.insert_transaction(transaction(from1, 0, 2), &acc1, false);
        pool.insert_transaction(transaction(from2, 0, 3), &acc2, false);
        pool.insert_transaction(transaction(from3, 0, 0), &acc3, false);
        pool.insert_transaction(intershard_transaction(0, 1, 5), &acc0, false);
        assert_eq!(pool.transaction_count(), 5);

        let tx = pool.best_transaction().unwrap().clone();
        assert_eq!(tx.tx.gas_price_per_evm_gas(), 5);
        pool.mark_executed(&tx);
        let tx = pool.best_transaction().unwrap().clone();
        assert_eq!(tx.tx.gas_price_per_evm_gas(), 3);

        pool.mark_executed(&tx);
        let tx = pool.best_transaction().unwrap().clone();

        assert_eq!(tx.tx.gas_price_per_evm_gas(), 2);
        pool.mark_executed(&tx);
        let tx = pool.best_transaction().unwrap().clone();

        assert_eq!(tx.tx.gas_price_per_evm_gas(), 1);
        pool.mark_executed(&tx);
        let tx = pool.best_transaction().unwrap().clone();

        assert_eq!(tx.tx.gas_price_per_evm_gas(), 0);
        pool.mark_executed(&tx);

        assert_eq!(pool.transaction_count(), 0);
        Ok(())
    }

    #[test]
    fn update_nonce_discards_invalid_transaction() -> Result<()> {
        let mut pool = TransactionPool::default();
        let from = "0x0000000000000000000000000000000000001234".parse()?;

        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, from, 100, 0)?;
        pool.update_with_state(&state);

        pool.insert_transaction(transaction(from, 0, 0), &acc, false);
        pool.insert_transaction(transaction(from, 1, 0), &acc, false);

        pool.mark_executed(&transaction(from, 0, 0));
        state.mutate_account(from, |acc| {
            acc.nonce += 1;
            Ok(())
        })?;
        pool.update_with_state(&state);

        assert_eq!(pool.best_transaction().unwrap().tx.nonce().unwrap(), 1);
        Ok(())
    }

    #[test]
    fn too_expensive_tranactions_are_not_proposed() -> Result<()> {
        let mut pool = TransactionPool::default();
        let from = "0x0000000000000000000000000000000000001234".parse()?;

        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, from, 100, 0)?;
        pool.update_with_state(&state);

        pool.insert_transaction(transaction(from, 0, 1), &acc, false);
        pool.insert_transaction(transaction(from, 1, 200), &acc, false);

        assert_eq!(pool.best_transaction().unwrap().tx.nonce().unwrap(), 0);
        pool.mark_executed(&transaction(from, 0, 1));
        state.mutate_account(from, |acc| {
            acc.nonce += 1;
            Ok(())
        })?;
        pool.update_with_state(&state);

        // Sender has insufficient funds at this point
        assert_eq!(pool.best_transaction(), None);

        // Increase funds of sender to satisfy txn fee
        let mut acc = state.must_get_account(from);
        acc.balance = 500;
        state.save_account(from, acc)?;
        pool.update_with_state(&state);

        assert_eq!(pool.best_transaction().unwrap().tx.nonce().unwrap(), 1);
        Ok(())
    }

    #[test]
    fn pending_queued_test() -> Result<()> {
        let mut pool = TransactionPool::default();
        let from = "0x0000000000000000000000000000000000001234".parse()?;

        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, from, 100, 0)?;
        pool.update_with_state(&state);

        let txn0 = intershard_transaction(0, 0, 100);
        let txn1 = transaction(from, 0, 1);
        let txn2 = transaction(from, 1, 1);
        let txn3 = transaction(from, 2, 1);
        let txn4 = transaction(from, 3, 200);
        let txn5 = transaction(from, 10, 1);

        pool.insert_transaction(txn0.clone(), &acc, false);
        pool.insert_transaction(txn1.clone(), &acc, false);
        pool.insert_transaction(txn2.clone(), &acc, false);
        pool.insert_transaction(txn3.clone(), &acc, false);
        pool.insert_transaction(txn4.clone(), &acc, false);
        pool.insert_transaction(txn5.clone(), &acc, false);

        let pending: Vec<_> = pool.pending_transactions_ordered().cloned().collect();
        let queued: Vec<_> = pool.queued_transactions_ordered().cloned().collect();

        assert_eq!(pending.len(), 4);
        assert_eq!(pending[0], txn0);
        assert_eq!(pending[1], txn1);
        assert_eq!(pending[2], txn2);
        assert_eq!(pending[3], txn3);

        assert_eq!(queued.len(), 2);
        assert_eq!(queued[0], txn4);
        assert_eq!(queued[1], txn5);

        Ok(())
    }

    #[test]
    fn benchmark_pending_transactions() -> Result<()> {
        let mut pool = TransactionPool::default();
        let from = "0x0000000000000000000000000000000000001234".parse()?;

        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, from, 1_000_000, 0)?;
        pool.update_with_state(&state);

        // Insert 100 pending transactions
        for nonce in 0u64..100u64 {
            pool.insert_transaction(transaction(from, nonce, 1), &acc, false);
        }

        // Insert 100 queued transactions
        for nonce in 101u64..201u64 {
            pool.insert_transaction(transaction(from, nonce, 1), &acc, false);
        }

        // Benchmark the preview_content method
        let start = std::time::Instant::now();
        let _result: Vec<_> = pool.pending_transactions_ordered().collect();
        let duration = start.elapsed();

        println!(
            "Benchmark completed: pending_transactions took {:?} to execute.",
            duration
        );
        Ok(())
    }

    // Helper function to create a transaction with custom hash
    fn transaction_with_hash(
        from_addr: Address,
        nonce: u8,
        gas_price: u128,
        hash_suffix: u8,
    ) -> VerifiedTransaction {
        VerifiedTransaction {
            tx: SignedTransaction::Legacy {
                tx: TxLegacy {
                    chain_id: Some(0),
                    nonce: nonce as u64,
                    gas_price,
                    gas_limit: 1,
                    to: TxKind::Create,
                    value: U256::ZERO,
                    input: Bytes::new(),
                },
                sig: PrimitiveSignature::new(U256::from(1), U256::from(1), false),
            },
            signer: from_addr,
            hash: Hash::builder()
                .with(from_addr.as_slice())
                .with([nonce, hash_suffix])
                .finalize(),
            cbor_size: 0,
        }
    }

    #[test]
    fn test_duplicate_transaction_handling() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr = "0x0000000000000000000000000000000000000001".parse()?;
        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, addr, 100, 0)?;

        let txn = transaction(addr, 0, 10);

        // First insertion should succeed
        let result1 = pool.insert_transaction(txn.clone(), &acc, false);
        assert!(matches!(result1, TxAddResult::AddedToMempool));

        // Second insertion of same transaction should be handled gracefully
        let result2 = pool.insert_transaction(txn.clone(), &acc, false);
        assert!(matches!(result2, TxAddResult::Duplicate(_))); // Same txn, no change

        assert_eq!(pool.transaction_count(), 1);
        Ok(())
    }

    #[test]
    fn test_nonce_too_low_rejection() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr = "0x0000000000000000000000000000000000000001".parse()?;
        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, addr, 100, 5)?; // Account nonce is 5

        let txn = transaction(addr, 3, 10); // Transaction nonce is 3 (too low)

        let result = pool.insert_transaction(txn, &acc, false);
        assert!(matches!(result, TxAddResult::NonceTooLow(3, 5)));
        assert_eq!(pool.transaction_count(), 0);
        Ok(())
    }

    #[test]
    fn test_gas_price_replacement() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr = "0x0000000000000000000000000000000000000001".parse()?;
        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, addr, 100, 0)?;

        let txn_low = transaction_with_hash(addr, 0, 10, 1);
        let txn_high = transaction_with_hash(addr, 0, 20, 2);
        let txn_same = transaction_with_hash(addr, 0, 10, 3);

        // Insert low gas price transaction
        let result1 = pool.insert_transaction(txn_low.clone(), &acc, false);
        assert!(matches!(result1, TxAddResult::AddedToMempool));

        // Insert higher gas price transaction with same nonce - should replace
        let result2 = pool.insert_transaction(txn_high.clone(), &acc, false);
        assert!(matches!(result2, TxAddResult::AddedToMempool));

        // Insert same gas price transaction - should be rejected
        let result3 = pool.insert_transaction(txn_same, &acc, false);
        assert!(matches!(result3, TxAddResult::SameNonceButLowerGasPrice));

        // Pool should contain only the high gas price transaction
        assert_eq!(pool.transaction_count(), 1);
        assert_eq!(pool.best_transaction().unwrap().hash, txn_high.hash);
        Ok(())
    }

    #[test]
    fn test_insufficient_balance_queuing() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr = "0x0000000000000000000000000000000000000001".parse()?;
        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, addr, 25, 0)?; // Balance only covers 2.5 transactions at gas price 10

        let txn1 = transaction(addr, 0, 10);
        let txn2 = transaction(addr, 1, 10);
        let txn3 = transaction(addr, 2, 10);
        let txn4 = transaction(addr, 3, 10);

        pool.insert_transaction(txn1.clone(), &acc, false);
        pool.insert_transaction(txn2.clone(), &acc, false);
        pool.insert_transaction(txn3.clone(), &acc, false);
        pool.insert_transaction(txn4.clone(), &acc, false);

        // Only first 2 transactions should be pending due to balance constraint
        let pending: Vec<_> = pool.pending_transactions_ordered().cloned().collect();
        let queued: Vec<_> = pool.queued_transactions_ordered().cloned().collect();

        assert_eq!(pending.len(), 2);
        assert_eq!(queued.len(), 2);
        assert_eq!(pending[0], txn1);
        assert_eq!(pending[1], txn2);
        Ok(())
    }

    #[test]
    fn test_nonceless_transaction_ordering() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr = "0x0000000000000000000000000000000000000001".parse()?;
        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, addr, 1000, 0)?;

        // Create nonceless transactions with different gas prices
        let txn1 = intershard_transaction(1, 1, 5);
        let txn2 = intershard_transaction(2, 2, 15);
        let txn3 = intershard_transaction(3, 3, 10);

        pool.insert_transaction(txn1.clone(), &acc, false);
        pool.insert_transaction(txn2.clone(), &acc, false);
        pool.insert_transaction(txn3.clone(), &acc, false);

        // Should be ordered by gas price (highest first)
        let pending: Vec<_> = pool.pending_transactions_ordered().cloned().collect();
        assert_eq!(pending.len(), 3);
        assert_eq!(pending[0], txn2); // gas price 15
        assert_eq!(pending[1], txn3); // gas price 10
        assert_eq!(pending[2], txn1); // gas price 5
        Ok(())
    }

    #[test]
    fn test_mixed_nonce_nonceless_ordering() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr = "0x0000000000000000000000000000000000000001".parse()?;
        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, addr, 1000, 0)?;

        let txn_nonce = transaction(addr, 0, 12);
        let txn_nonceless_high = intershard_transaction(1, 1, 15);
        let txn_nonceless_low = intershard_transaction(2, 2, 8);

        pool.insert_transaction(txn_nonce.clone(), &acc, false);
        pool.insert_transaction(txn_nonceless_high.clone(), &acc, false);
        pool.insert_transaction(txn_nonceless_low.clone(), &acc, false);

        let pending: Vec<_> = pool.pending_transactions_ordered().cloned().collect();
        assert_eq!(pending.len(), 3);
        assert_eq!(pending[0], txn_nonceless_high); // gas price 15
        assert_eq!(pending[1], txn_nonce); // gas price 12
        assert_eq!(pending[2], txn_nonceless_low); // gas price 8
        Ok(())
    }

    #[test]
    fn test_account_balance_updates() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr = "0x0000000000000000000000000000000000000001".parse()?;
        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, addr, 15, 0)?;

        let txn1 = transaction(addr, 0, 10);
        let txn2 = transaction(addr, 1, 10);

        pool.insert_transaction(txn1.clone(), &acc, false);
        pool.insert_transaction(txn2.clone(), &acc, false);

        // Initially, only first transaction should be pending due to balance
        assert_eq!(pool.pending_transaction_count(), 1);

        // Increase balance
        let new_acc = create_acc(&mut state, addr, 25, 0)?;
        pool.update_with_account(&addr, &new_acc);

        // Now both should be pending
        assert_eq!(pool.pending_transaction_count(), 2);
        Ok(())
    }

    #[test]
    fn test_pop_best_with_predicate() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr = "0x0000000000000000000000000000000000000001".parse()?;
        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, addr, 100, 0)?;

        let txn1 = transaction(addr, 0, 10);
        let txn2 = transaction(addr, 1, 20);

        pool.insert_transaction(txn1.clone(), &acc, false);
        pool.insert_transaction(txn2.clone(), &acc, false);

        // Pop best transaction only if gas price > 15
        let popped = pool.pop_best_if(|tx| tx.tx.gas_price_per_evm_gas() > 15);
        assert!(popped.is_none()); // Should be None because best tx has gas price 10

        // Pop best transaction only if gas price > 5
        let popped = pool.pop_best_if(|tx| tx.tx.gas_price_per_evm_gas() > 5);
        assert!(popped.is_some());
        assert_eq!(popped.unwrap().hash, txn1.hash);

        dbg!(&pool);
        assert_eq!(pool.transaction_count(), 1);
        assert_eq!(pool.best_transaction().unwrap().hash, txn2.hash);
        Ok(())
    }

    #[test]
    fn test_mark_executed_removes_transaction() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr = "0x0000000000000000000000000000000000000001".parse()?;
        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, addr, 100, 0)?;

        let txn1 = transaction(addr, 0, 10);
        let txn2 = intershard_transaction(1, 1, 15);

        pool.insert_transaction(txn1.clone(), &acc, false);
        pool.insert_transaction(txn2.clone(), &acc, false);

        assert_eq!(pool.transaction_count(), 2);

        // Mark nonceless transaction as executed
        pool.mark_executed(&txn2);
        assert_eq!(pool.transaction_count(), 1);

        // Mark nonced transaction as executed
        pool.mark_executed(&txn1);
        assert_eq!(pool.transaction_count(), 0);
        Ok(())
    }

    #[test]
    fn test_transaction_broadcast_queue() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr = "0x0000000000000000000000000000000000000001".parse()?;
        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, addr, 100, 0)?;

        let txn1 = transaction(addr, 0, 10);
        let txn2 = transaction(addr, 1, 20);

        // Insert without broadcast flag
        pool.insert_transaction(txn1.clone(), &acc, false);

        // Insert with broadcast flag (from network)
        pool.insert_transaction(txn2.clone(), &acc, true);

        let to_broadcast = pool.pull_txns_to_broadcast()?;
        assert_eq!(to_broadcast.len(), 1); // Only txn1 should be in broadcast queue
        assert_eq!(to_broadcast[0], txn1.tx);

        // Second call should return empty
        let to_broadcast2 = pool.pull_txns_to_broadcast()?;
        assert_eq!(to_broadcast2.len(), 0);
        Ok(())
    }

    #[test]
    fn test_get_pending_or_queued_status() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr = "0x0000000000000000000000000000000000000001".parse()?;
        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, addr, 15, 0)?; // Limited balance

        let txn1 = transaction(addr, 0, 10);
        let txn2 = transaction(addr, 1, 10);
        let txn3 = intershard_transaction(1, 1, 5);

        pool.insert_transaction(txn1.clone(), &acc, false);
        pool.insert_transaction(txn2.clone(), &acc, false);
        pool.insert_transaction(txn3.clone(), &acc, false);

        // txn1 should be pending (enough balance)
        let status1 = pool.get_pending_or_queued(&txn1)?;
        assert!(matches!(status1, Some(PendingOrQueued::Pending)));

        // txn2 should be queued (insufficient balance)
        let status2 = pool.get_pending_or_queued(&txn2)?;
        assert!(matches!(status2, Some(PendingOrQueued::Queued)));

        // txn3 (nonceless) should be pending
        let status3 = pool.get_pending_or_queued(&txn3)?;
        assert!(matches!(status3, Some(PendingOrQueued::Pending)));
        Ok(())
    }

    #[test]
    fn test_pool_content_preview() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr1 = "0x0000000000000000000000000000000000000001".parse()?;
        let addr2 = "0x0000000000000000000000000000000000000002".parse()?;
        let mut state = get_in_memory_state()?;
        let acc1 = create_acc(&mut state, addr1, 50, 0)?;
        let acc2 = create_acc(&mut state, addr2, 50, 0)?;

        let txn1 = transaction(addr1, 0, 10);
        let txn2 = transaction(addr1, 1, 50); // Will be queued due to balance
        let txn3 = transaction(addr2, 0, 20);

        pool.insert_transaction(txn1.clone(), &acc1, false);
        pool.insert_transaction(txn2.clone(), &acc1, false);
        pool.insert_transaction(txn3.clone(), &acc2, false);

        let content = pool.preview_content();

        // Check pending transactions
        assert_eq!(content.pending.get(&addr1).unwrap().len(), 1);
        assert_eq!(content.pending.get(&addr2).unwrap().len(), 1);

        // Check queued transactions
        assert_eq!(content.queued.get(&addr1).unwrap().len(), 1);
        assert_eq!(content.queued.get(&addr2).unwrap().len(), 0);

        let content_from = pool.preview_content_from(&addr1);
        assert_eq!(content_from.pending.len(), 1);
        assert_eq!(content_from.queued.len(), 1);
        Ok(())
    }

    #[test]
    fn test_pool_clear() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr = "0x0000000000000000000000000000000000000001".parse()?;
        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, addr, 100, 0)?;

        let txn1 = transaction(addr, 0, 10);
        let txn2 = intershard_transaction(1, 1, 15);

        pool.insert_transaction(txn1, &acc, false);
        pool.insert_transaction(txn2, &acc, false);

        assert_eq!(pool.transaction_count(), 2);
        assert!(pool.has_txn_ready());

        pool.clear();

        assert_eq!(pool.transaction_count(), 0);
        assert!(!pool.has_txn_ready());
        assert!(pool.best_transaction().is_none());
        Ok(())
    }

    #[test]
    fn test_account_counts() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr1 = "0x0000000000000000000000000000000000000001".parse()?;
        let addr2 = "0x0000000000000000000000000000000000000002".parse()?;
        let mut state = get_in_memory_state()?;
        let acc1 = create_acc(&mut state, addr1, 100, 0)?;
        let acc2 = create_acc(&mut state, addr2, 20, 0)?;

        let txn1 = transaction(addr1, 0, 10);
        let txn2 = transaction(addr1, 1, 10);
        let txn3 = transaction(addr2, 0, 30); // Will be queued due to insufficient balance

        pool.insert_transaction(txn1, &acc1, false);
        pool.insert_transaction(txn2, &acc1, false);
        pool.insert_transaction(txn3, &acc2, false);

        assert_eq!(pool.account_total_transaction_count(&addr1), 2);
        assert_eq!(pool.account_pending_transaction_count(&addr1), 2);

        assert_eq!(pool.account_total_transaction_count(&addr2), 1);
        assert_eq!(pool.account_pending_transaction_count(&addr2), 0);

        let status = pool.preview_status();
        assert_eq!(status.pending, 2);
        assert_eq!(status.queued, 1);
        Ok(())
    }

    #[test]
    fn test_get_transaction_by_hash_basic() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr = "0x0000000000000000000000000000000000000001".parse()?;
        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, addr, 100, 0)?;

        let txn1 = transaction(addr, 0, 10);
        let txn2 = intershard_transaction(1, 1, 15);
        let non_existent_hash = Hash::builder().with([99, 99, 99]).finalize();

        // Initially, no transactions should be found
        assert!(pool.get_transaction(&txn1.hash).is_none());
        assert!(pool.get_transaction(&txn2.hash).is_none());
        assert!(pool.get_transaction(&non_existent_hash).is_none());

        // Add transactions
        pool.insert_transaction(txn1.clone(), &acc, false);
        pool.insert_transaction(txn2.clone(), &acc, false);

        // Now they should be retrievable by hash
        let retrieved_txn1 = pool.get_transaction(&txn1.hash);
        let retrieved_txn2 = pool.get_transaction(&txn2.hash);

        assert!(retrieved_txn1.is_some());
        assert!(retrieved_txn2.is_some());
        assert_eq!(retrieved_txn1.unwrap().hash, txn1.hash);
        assert_eq!(retrieved_txn2.unwrap().hash, txn2.hash);
        assert_eq!(retrieved_txn1.unwrap().signer, txn1.signer);
        assert_eq!(retrieved_txn2.unwrap().signer, txn2.signer);

        // Non-existent hash should still return None
        assert!(pool.get_transaction(&non_existent_hash).is_none());

        Ok(())
    }

    #[test]
    fn test_get_transaction_by_hash_after_execution() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr = "0x0000000000000000000000000000000000000001".parse()?;
        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, addr, 100, 0)?;

        let txn1 = transaction(addr, 0, 10);
        let txn2 = transaction(addr, 1, 20);
        let txn3 = intershard_transaction(1, 1, 15);

        pool.insert_transaction(txn1.clone(), &acc, false);
        pool.insert_transaction(txn2.clone(), &acc, false);
        pool.insert_transaction(txn3.clone(), &acc, false);

        // All should be retrievable initially
        assert!(pool.get_transaction(&txn1.hash).is_some());
        assert!(pool.get_transaction(&txn2.hash).is_some());
        assert!(pool.get_transaction(&txn3.hash).is_some());

        // Mark txn1 as executed
        pool.mark_executed(&txn1);

        // txn1 should no longer be retrievable, others should still be
        assert!(pool.get_transaction(&txn1.hash).is_none());
        assert!(pool.get_transaction(&txn2.hash).is_some());
        assert!(pool.get_transaction(&txn3.hash).is_some());

        // Mark txn3 (nonceless) as executed
        pool.mark_executed(&txn3);

        // txn3 should no longer be retrievable
        assert!(pool.get_transaction(&txn1.hash).is_none());
        assert!(pool.get_transaction(&txn2.hash).is_some());
        assert!(pool.get_transaction(&txn3.hash).is_none());

        Ok(())
    }

    #[test]
    fn test_get_transaction_by_hash_after_pop() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr = "0x0000000000000000000000000000000000000001".parse()?;
        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, addr, 100, 0)?;

        let txn1 = transaction(addr, 0, 30);
        let txn2 = transaction(addr, 1, 20);
        let txn3 = transaction(addr, 2, 10);

        pool.insert_transaction(txn1.clone(), &acc, false);
        pool.insert_transaction(txn2.clone(), &acc, false);
        pool.insert_transaction(txn3.clone(), &acc, false);

        // All should be retrievable initially
        assert!(pool.get_transaction(&txn1.hash).is_some());
        assert!(pool.get_transaction(&txn2.hash).is_some());
        assert!(pool.get_transaction(&txn3.hash).is_some());

        // Pop best transaction (should be txn1 with highest gas price)
        let popped = pool.pop_best_if(|_| true);
        assert!(popped.is_some());
        assert_eq!(popped.unwrap().hash, txn1.hash);

        // txn1 should no longer be retrievable after popping
        assert!(pool.get_transaction(&txn1.hash).is_none());
        assert!(pool.get_transaction(&txn2.hash).is_some());
        assert!(pool.get_transaction(&txn3.hash).is_some());

        // Pop with a predicate that should reject the next best
        let popped2 = pool.pop_best_if(|tx| tx.tx.gas_price_per_evm_gas() > 25);
        assert!(popped2.is_none()); // Should be None because txn2 has gas price 20

        // txn2 should still be retrievable since it wasn't popped
        assert!(pool.get_transaction(&txn2.hash).is_some());

        Ok(())
    }

    #[test]
    fn test_get_transaction_by_hash_after_replacement() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr = "0x0000000000000000000000000000000000000001".parse()?;
        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, addr, 100, 0)?;

        let txn_low = transaction_with_hash(addr, 0, 10, 1);
        let txn_high = transaction_with_hash(addr, 0, 20, 2);

        // Insert low gas price transaction
        pool.insert_transaction(txn_low.clone(), &acc, false);

        // Should be retrievable by its hash
        assert!(pool.get_transaction(&txn_low.hash).is_some());
        assert!(pool.get_transaction(&txn_high.hash).is_none());

        // Insert higher gas price transaction with same nonce (should replace)
        pool.insert_transaction(txn_high.clone(), &acc, false);

        // Old transaction should no longer be retrievable, new one should be
        assert!(pool.get_transaction(&txn_low.hash).is_none());
        assert!(pool.get_transaction(&txn_high.hash).is_some());

        // Verify the retrieved transaction is correct
        let retrieved = pool.get_transaction(&txn_high.hash).unwrap();
        assert_eq!(retrieved.hash, txn_high.hash);
        assert_eq!(retrieved.tx.gas_price_per_evm_gas(), 20);

        Ok(())
    }

    #[test]
    fn test_get_transaction_by_hash_after_clear() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr = "0x0000000000000000000000000000000000000001".parse()?;
        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, addr, 100, 0)?;

        let txn1 = transaction(addr, 0, 10);
        let txn2 = intershard_transaction(1, 1, 15);

        pool.insert_transaction(txn1.clone(), &acc, false);
        pool.insert_transaction(txn2.clone(), &acc, false);

        // Both should be retrievable initially
        assert!(pool.get_transaction(&txn1.hash).is_some());
        assert!(pool.get_transaction(&txn2.hash).is_some());

        // Clear the pool
        pool.clear();

        // No transactions should be retrievable after clearing
        assert!(pool.get_transaction(&txn1.hash).is_none());
        assert!(pool.get_transaction(&txn2.hash).is_none());
        assert_eq!(pool.transaction_count(), 0);

        Ok(())
    }

    #[test]
    fn test_get_transaction_by_hash_consistency_during_state_updates() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr = "0x0000000000000000000000000000000000000001".parse()?;
        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, addr, 15, 0)?; // Limited balance

        let txn1 = transaction(addr, 0, 10);
        let txn2 = transaction(addr, 1, 10); // Will be queued due to balance
        let txn3 = intershard_transaction(1, 1, 5);

        pool.insert_transaction(txn1.clone(), &acc, false);
        pool.insert_transaction(txn2.clone(), &acc, false);
        pool.insert_transaction(txn3.clone(), &acc, false);

        // All should be retrievable regardless of pending/queued status
        assert!(pool.get_transaction(&txn1.hash).is_some());
        assert!(pool.get_transaction(&txn2.hash).is_some());
        assert!(pool.get_transaction(&txn3.hash).is_some());

        // Update balance to allow all transactions to be pending
        let new_acc = create_acc(&mut state, addr, 100, 0)?;
        pool.update_with_account(&addr, &new_acc);

        // All should still be retrievable after balance update
        assert!(pool.get_transaction(&txn1.hash).is_some());
        assert!(pool.get_transaction(&txn2.hash).is_some());
        assert!(pool.get_transaction(&txn3.hash).is_some());

        // Reduce balance again
        let limited_acc = create_acc(&mut state, addr, 12, 0)?;
        pool.update_with_account(&addr, &limited_acc);

        // All should still be retrievable even if some are queued again
        assert!(pool.get_transaction(&txn1.hash).is_some());
        assert!(pool.get_transaction(&txn2.hash).is_some());
        assert!(pool.get_transaction(&txn3.hash).is_some());

        Ok(())
    }

    #[test]
    fn test_get_transaction_by_hash_multiple_accounts() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr1 = "0x0000000000000000000000000000000000000001".parse()?;
        let addr2 = "0x0000000000000000000000000000000000000002".parse()?;
        let mut state = get_in_memory_state()?;
        let acc1 = create_acc(&mut state, addr1, 100, 0)?;
        let acc2 = create_acc(&mut state, addr2, 100, 0)?;

        let txn1_acc1 = transaction(addr1, 0, 10);
        let txn2_acc1 = transaction(addr1, 1, 20);
        let txn1_acc2 = transaction(addr2, 1, 15);
        let txn2_acc2 = intershard_transaction(1, 1, 5);

        assert!(matches!(
            pool.insert_transaction(txn1_acc1.clone(), &acc1, false),
            TxAddResult::AddedToMempool
        ));
        assert!(matches!(
            pool.insert_transaction(txn2_acc1.clone(), &acc1, false),
            TxAddResult::AddedToMempool
        ));
        assert!(matches!(
            pool.insert_transaction(txn1_acc2.clone(), &acc2, false),
            TxAddResult::AddedToMempool
        ));
        assert!(matches!(
            pool.insert_transaction(txn2_acc2.clone(), &acc2, false),
            TxAddResult::AddedToMempool
        ));

        // All transactions from both accounts should be retrievable
        assert!(pool.get_transaction(&txn1_acc1.hash).is_some());
        assert!(pool.get_transaction(&txn2_acc1.hash).is_some());
        assert!(pool.get_transaction(&txn1_acc2.hash).is_some());
        assert!(pool.get_transaction(&txn2_acc2.hash).is_some());

        // Execute a transaction from account 1
        pool.mark_executed(&txn1_acc1);

        // Only that specific transaction should be removed
        assert!(pool.get_transaction(&txn1_acc1.hash).is_none());
        assert!(pool.get_transaction(&txn2_acc1.hash).is_some());
        assert!(pool.get_transaction(&txn1_acc2.hash).is_some());
        assert!(pool.get_transaction(&txn2_acc2.hash).is_some());

        // Remove first transaction from account 2
        let new_acc2 = create_acc(&mut state, addr2, 100, 1)?;
        pool.update_with_account(&addr2, &new_acc2);
        pool.mark_executed(&txn1_acc2);

        // Account 2's first transaction should be removed, others should remain
        assert!(pool.get_transaction(&txn1_acc1.hash).is_none());
        assert!(pool.get_transaction(&txn2_acc1.hash).is_some());
        assert!(
            pool.core
                .get_txn_by_address_and_nonce(&txn1_acc2.signer, txn1_acc2.tx.nonce().unwrap())
                .is_none()
        );
        assert!(pool.get_transaction(&txn1_acc2.hash).is_none());
        assert!(pool.get_transaction(&txn2_acc2.hash).is_some());

        Ok(())
    }

    #[test]
    fn pool_benchmark_insert_ascending_nonces() -> Result<()> {
        let mut pool = TransactionPool::default();
        let mut state = get_in_memory_state()?;

        // Create 1000 accounts
        let mut accounts = Vec::new();
        for i in 0..1000 {
            let addr: Address = format!("0x{:040x}", i).parse()?;
            let acc = create_acc(&mut state, addr, 1_000_000, 0)?;
            accounts.push((addr, acc));
        }

        let start = Instant::now();
        let target_duration = Duration::from_secs(1);
        let mut transaction_count = 0;
        let mut account_idx = 0;
        let mut nonce = 0;

        // Insert transactions for 1 second in ascending nonce order
        while start.elapsed() < target_duration {
            let (addr, acc) = &accounts[account_idx % accounts.len()];
            let txn = transaction(*addr, nonce, 10);
            pool.insert_transaction(txn, acc, false);

            transaction_count += 1;
            nonce += 1;

            // Move to next account after every 1000 transactions to simulate realistic usage
            if nonce % 1000 == 0 {
                account_idx += 1;
                nonce = 0;
            }
        }

        let duration = start.elapsed();
        let time_per_op = duration.as_nanos() / transaction_count as u128;

        println!(
            "Timing: Insert transactions (ascending nonces) - {} ops in {:?} = {} ns/op",
            transaction_count, duration, time_per_op
        );

        Ok(())
    }

    #[test]
    fn pool_benchmark_insert_descending_nonces() -> Result<()> {
        let mut pool = TransactionPool::default();
        let mut state = get_in_memory_state()?;

        // Create 1000 accounts
        let mut accounts = Vec::new();
        for i in 0..1000 {
            let addr: Address = format!("0x{:040x}", i).parse()?;
            let acc = create_acc(&mut state, addr, 1_000_000, 0)?;
            accounts.push((addr, acc));
        }

        let start = Instant::now();
        let target_duration = Duration::from_secs(1);
        let mut transaction_count = 0;
        let mut account_idx = 0;
        let mut nonce = 999; // Start from high nonce and go down

        // Insert transactions for 1 second in descending nonce order
        while start.elapsed() < target_duration {
            let (addr, acc) = &accounts[account_idx % accounts.len()];
            let txn = transaction(*addr, nonce, 10);
            pool.insert_transaction(txn, acc, false);

            transaction_count += 1;

            if nonce > 0 {
                nonce -= 1;
            } else {
                // Move to next account and reset nonce
                account_idx += 1;
                nonce = 999;
            }
        }

        let duration = start.elapsed();
        let time_per_op = duration.as_nanos() / transaction_count as u128;

        println!(
            "Timing: Insert transactions (descending nonces) - {} ops in {:?} = {} ns/op",
            transaction_count, duration, time_per_op
        );

        Ok(())
    }

    #[test]
    fn pool_benchmark_operations_on_large_pool() -> Result<()> {
        let mut pool = TransactionPool::default();
        let mut state = get_in_memory_state()?;

        // Create 100 accounts with 100 transactions each
        let mut accounts = Vec::new();
        for i in 0..100 {
            let addr: Address = format!("0x{:040x}", i).parse()?;
            let acc = create_acc(&mut state, addr, 1_000_000, 0)?;
            accounts.push((addr, acc));
        }

        // Insert transactions
        for (addr, acc) in &accounts {
            for nonce in 0..100 {
                let txn = transaction(*addr, nonce, 10);
                pool.insert_transaction(txn, acc, false);
            }
        }

        let target_duration = Duration::from_secs(1);

        // Benchmark getting all pending transactions for 1 second
        let start = Instant::now();
        let mut operations = 0;
        while start.elapsed() < target_duration {
            let _pending: Vec<_> = pool.pending_transactions_ordered().collect();
            operations += 1;
        }
        let duration = start.elapsed();
        let time_per_op = duration.as_nanos() / operations as u128;
        println!(
            "Timing: Get all pending transactions - {} ops in {:?} = {} ns/op",
            operations, duration, time_per_op
        );

        // Benchmark getting pending transaction count for 1 second
        let start = Instant::now();
        let mut operations = 0;
        while start.elapsed() < target_duration {
            let _count = pool.pending_transaction_count();
            operations += 1;
        }
        let duration = start.elapsed();
        let time_per_op = duration.as_nanos() / operations as u128;
        println!(
            "Timing: Get pending transaction count - {} ops in {:?} = {} ns/op",
            operations, duration, time_per_op
        );

        // Benchmark getting best transaction for 1 second
        let start = Instant::now();
        let mut operations = 0;
        while start.elapsed() < target_duration {
            let _best = pool.best_transaction();
            operations += 1;
        }
        let duration = start.elapsed();
        let time_per_op = duration.as_nanos() / operations as u128;
        println!(
            "Timing: Get best transaction - {} ops in {:?} = {} ns/op",
            operations, duration, time_per_op
        );

        // Benchmark popping transactions for 1 second
        let mut test_pool = pool.clone();
        let start = Instant::now();
        let mut operations = 0;
        let mut transactions = Vec::new();
        while start.elapsed() < target_duration {
            let best = test_pool.pop_best_if(|_| true);
            operations += 1;
            if let Some(tx) = best {
                transactions.push(tx);
            } else {
                break;
            }
        }
        let duration = start.elapsed();
        let time_per_op = duration.as_nanos() / operations as u128;
        println!(
            "Timing: Popping best transaction - {} ops in {:?} = {} ns/op",
            operations, duration, time_per_op
        );

        Ok(())
    }

    #[test]
    fn test_state_update_during_fork_handling() -> Result<()> {
        let mut pool = TransactionPool::default();
        let addr = "0x0000000000000000000000000000000000000001".parse()?;
        let mut state = get_in_memory_state()?;
        let acc = create_acc(&mut state, addr, 100, 0)?;

        // Insert some transactions
        pool.insert_transaction(transaction(addr, 0, 10), &acc, false);
        pool.insert_transaction(transaction(addr, 1, 10), &acc, false);
        pool.insert_transaction(transaction(addr, 2, 10), &acc, false);

        // Simulate what happens during fork handling:
        // 1. remove some transactions (simulating block execution)
        pool.pop_best_if(|_| true);
        pool.pop_best_if(|_| true);

        // 2. Immediately re-insert transactions (simulating fork revert)
        // But use the OLD account state for insertion
        let old_acc = create_acc(&mut state, addr, 100, 0)?;
        let txn0 = transaction(addr, 0, 10);
        let txn1 = transaction(addr, 1, 10);

        // This pattern might cause counting issues
        pool.insert_transaction(txn0, &old_acc, true);
        pool.insert_transaction(txn1, &old_acc, true);

        Ok(())
    }
}

```

`zilliqa/src/precompiles/bls_verify.rs`:

```rs
use blsful::Bls12381G2Impl;
use ethabi::{ParamType, Token, decode, encode, short_signature};
use revm::{
    ContextStatefulPrecompile, InnerEvmContext,
    precompile::PrecompileError,
    primitives::{
        Bytes, PrecompileErrors, PrecompileOutput, PrecompileResult,
        alloy_primitives::private::alloy_rlp::Encodable,
    },
};

use crate::exec::PendingState;

pub struct BlsVerify;

// keep in-sync with zilliqa/src/contracts/deposit_v3.sol
impl BlsVerify {
    /// We charge gas as if we were using Ethereum precompile gas prices for each operation:
    ///     - Message to hash: SHA256 over 76 byte message: 60 + 12 * 3 = 96
    ///     - Hash to point: Rough estimate                             = 100_000
    ///     - Single pairing check on BLS12-381 (ref: EIP-1108)         = 79_000
    ///                                                                 = 180_000
    const BLS_VERIFY_GAS_PRICE: u64 = 180_000u64;
    fn bls_verify(
        input: &[u8],
        gas_limit: u64,
        _context: &mut InnerEvmContext<PendingState>,
    ) -> PrecompileResult {
        if gas_limit < Self::BLS_VERIFY_GAS_PRICE {
            return Err(PrecompileErrors::Error(PrecompileError::OutOfGas));
        }

        let Ok(decoded) = decode(
            &[ParamType::Bytes, ParamType::Bytes, ParamType::Bytes],
            input,
        ) else {
            return Err(PrecompileError::Other("ABI input decoding error!".into()).into());
        };
        if decoded.len() != 3 {
            // expected 3 arguments
            return Err(PrecompileError::Other("ABI inputs missing".into()).into());
        };

        let message = decoded[0].to_owned().into_bytes().unwrap();

        let Ok(signature) = <blsful::Bls12381G2Impl as blsful::Pairing>::Signature::try_from(
            decoded[1].to_owned().into_bytes().unwrap(),
        ) else {
            return Err(PrecompileError::Other("ABI signature invalid".into()).into());
        };

        let Ok(pk) = blsful::PublicKey::<Bls12381G2Impl>::try_from(
            decoded[2].to_owned().into_bytes().unwrap(),
        ) else {
            return Err(PrecompileError::Other("ABI pubkey invalid".into()).into());
        };

        let result = blsful::Signature::Basic(signature)
            .verify(&pk, message)
            .is_ok();

        // FIXME: Gas?
        let output = encode(&[Token::Bool(result)]);
        Ok(PrecompileOutput::new(
            Self::BLS_VERIFY_GAS_PRICE,
            output.into(),
        ))
    }
}

impl ContextStatefulPrecompile<PendingState> for BlsVerify {
    fn call(
        &self,
        input: &Bytes,
        gas_price: u64,
        context: &mut InnerEvmContext<PendingState>,
    ) -> PrecompileResult {
        if input.length() < 4 {
            return Err(PrecompileError::Other(
                "Provided input must be at least 4-byte long".into(),
            )
            .into());
        }

        let dispatch_table: [([u8; 4], _); 1] = [(
            short_signature(
                "blsVerify",
                &[ParamType::Bytes, ParamType::Bytes, ParamType::Bytes],
            ),
            Self::bls_verify,
        )];

        let Some(handler) = dispatch_table
            .iter()
            .find(|&predicate| predicate.0 == input[..4])
        else {
            return Err(PrecompileError::Other(
                "Unable to find handler with given selector".to_string(),
            )
            .into());
        };

        handler.1(&input[4..], gas_price, context)
    }
}

```

`zilliqa/src/precompiles/mod.rs`:

```rs
mod bls_verify;
mod pop_verify;
mod scilla;

use std::sync::Arc;

use alloy::primitives::Address;
use bls_verify::BlsVerify;
use pop_verify::PopVerify;
use revm::ContextPrecompile;
use scilla::ScillaRead;
pub use scilla::scilla_call_handle_register;

use crate::exec::PendingState;

pub fn get_custom_precompiles() -> Vec<(Address, ContextPrecompile<PendingState>)> {
    vec![
        (
            Address::from(*b"\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0ZIL\x80"),
            ContextPrecompile::ContextStateful(Arc::new(PopVerify)),
        ),
        (
            Address::from(*b"\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0ZIL\x81"),
            ContextPrecompile::ContextStateful(Arc::new(BlsVerify)),
        ),
        (
            Address::from(*b"\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0ZIL\x92"),
            ContextPrecompile::ContextStateful(Arc::new(ScillaRead)),
        ),
        // The "Scilla call" precompile also exists at address `0x5a494c53`. However, it is implemented by overwriting
        // the `revm` call handler, rather than using a conventional precompile. This is because it requires extra
        // information which isn't provided by the precompile interface, such as the external context (where the
        // inspector is kept), the `msg.sender` and the `msg.value`.
    ]
}

```

`zilliqa/src/precompiles/pop_verify.rs`:

```rs
use blsful::Bls12381G2Impl;
use ethabi::{ParamType, Token, decode, encode, short_signature};
use revm::{
    ContextStatefulPrecompile, InnerEvmContext,
    precompile::PrecompileError,
    primitives::{
        Bytes, PrecompileErrors, PrecompileOutput, PrecompileResult,
        alloy_primitives::private::alloy_rlp::Encodable,
    },
};

use crate::exec::PendingState;

pub struct PopVerify;

// keep in-sync with zilliqa/src/contracts/deposit_v2.sol
impl PopVerify {
    const POP_VERIFY_GAS_PRICE: u64 = 1_000_000u64; // FIXME: Gas Price?
    fn pop_verify(
        input: &[u8],
        gas_limit: u64,
        _context: &mut InnerEvmContext<PendingState>,
    ) -> PrecompileResult {
        if gas_limit < Self::POP_VERIFY_GAS_PRICE {
            return Err(PrecompileErrors::Error(PrecompileError::OutOfGas));
        }

        let Ok(decoded) = decode(&[ParamType::Bytes, ParamType::Bytes], input) else {
            return Err(PrecompileError::Other("ABI input decoding error!".into()).into());
        };
        if decoded.len() != 2 {
            // expected 2 arguments
            return Err(PrecompileError::Other("ABI inputs missing".into()).into());
        };

        let Ok(pop) = blsful::ProofOfPossession::<Bls12381G2Impl>::try_from(
            decoded[0].to_owned().into_bytes().unwrap(),
        ) else {
            return Err(PrecompileError::Other("ABI signature invalid".into()).into());
        };

        let Ok(pk) = blsful::PublicKey::<Bls12381G2Impl>::try_from(
            decoded[1].to_owned().into_bytes().unwrap(),
        ) else {
            return Err(PrecompileError::Other("ABI pubkey invalid".into()).into());
        };

        let result = pop.verify(pk).is_ok();

        // FIXME: Gas?
        let output = encode(&[Token::Bool(result)]);
        Ok(PrecompileOutput::new(
            Self::POP_VERIFY_GAS_PRICE,
            output.into(),
        ))
    }
}

impl ContextStatefulPrecompile<PendingState> for PopVerify {
    fn call(
        &self,
        input: &Bytes,
        gas_price: u64,
        context: &mut InnerEvmContext<PendingState>,
    ) -> PrecompileResult {
        if input.length() < 4 {
            return Err(PrecompileError::Other(
                "Provided input must be at least 4-byte long".into(),
            )
            .into());
        }

        let dispatch_table: [([u8; 4], _); 1] = [(
            short_signature("popVerify", &[ParamType::Bytes, ParamType::Bytes]),
            Self::pop_verify,
        )];

        let Some(handler) = dispatch_table
            .iter()
            .find(|&predicate| predicate.0 == input[..4])
        else {
            return Err(PrecompileError::Other(
                "Unable to find handler with given selector".to_string(),
            )
            .into());
        };

        handler.1(&input[4..], gas_price, context)
    }
}

```

`zilliqa/src/precompiles/scilla.rs`:

```rs
use std::sync::Arc;

use alloy::{
    primitives::{I256, U256},
    sol_types::{SolValue, abi::Decoder},
};
use anyhow::{Result, anyhow};
use revm::{
    ContextStatefulPrecompile, FrameOrResult, InnerEvmContext,
    handler::register::EvmHandler,
    interpreter::{CallInputs, Gas, InstructionResult, InterpreterResult},
    precompile::PrecompileError,
    primitives::{
        Address, Bytes, EVMError, LogData, PrecompileErrors, PrecompileOutput, PrecompileResult,
    },
};
use scilla_parser::{
    ast::nodes::{
        NodeAddressType, NodeByteStr, NodeMetaIdentifier, NodeScillaType, NodeTypeMapKey,
        NodeTypeMapValue, NodeTypeMapValueAllowingTypeArguments, NodeTypeNameIdentifier,
    },
    parser::{lexer::Lexer, parser::ScillaTypeParser},
};
use tracing::trace;

use crate::{
    cfg::scilla_ext_libs_path_default,
    constants::SCILLA_INVOKE_RUNNER,
    exec::{ExternalContext, PendingState, ScillaError, scilla_call},
    inspector::ScillaInspector,
    state::Code,
    transaction::{EvmGas, ZilAmount},
};

/// Internal representation of Scilla types. This is a greatly simplified version of [NodeScillaType] (which comes
/// directly from the Scilla parser) and only supports the types we currently care about. Raw parsed types can be
/// converted to a [ScillaType] with a [ToScillaType::to_scilla_type] implementation.
#[derive(Clone, Debug)]
enum ScillaType {
    Map(Box<ScillaType>, Box<ScillaType>),
    ByStr20,
    Int32,
    Int64,
    Int128,
    Int256,
    Uint32,
    Uint64,
    Uint128,
    Uint256,
    String,
}

impl ScillaType {
    /// Returns the Scilla representation of this type, assuming it is a transition parameter. Note this may not be
    /// exactly the same as the type in the contract (e.g. `ByStr20 with contract end` types are truncated to just
    /// `ByStr20`).
    fn param_type(&self) -> Option<&'static str> {
        match self {
            ScillaType::ByStr20 => Some("ByStr20"),
            ScillaType::Int32 => Some("Int32"),
            ScillaType::Int64 => Some("Int64"),
            ScillaType::Int128 => Some("Int128"),
            ScillaType::Int256 => Some("Int256"),
            ScillaType::Uint32 => Some("Uint32"),
            ScillaType::Uint64 => Some("Uint64"),
            ScillaType::Uint128 => Some("Uint128"),
            ScillaType::Uint256 => Some("Uint256"),
            ScillaType::String => Some("String"),
            ScillaType::Map(_, _) => None,
        }
    }
}

trait ToScillaType {
    fn to_scilla_type(self) -> Option<ScillaType>;
}

impl ToScillaType for NodeScillaType {
    fn to_scilla_type(self) -> Option<ScillaType> {
        match self {
            NodeScillaType::MapType(k, v) => (k.node, v.node).to_scilla_type(),
            NodeScillaType::GenericTypeWithArgs(ident, args) if args.is_empty() => {
                ident.node.to_scilla_type()
            }
            NodeScillaType::EnclosedType(ty) => ty.node.to_scilla_type(),
            NodeScillaType::ScillaAddresseType(ty) => ty.node.to_scilla_type(),
            _ => None,
        }
    }
}

impl ToScillaType for (NodeTypeMapKey, NodeTypeMapValue) {
    fn to_scilla_type(self) -> Option<ScillaType> {
        let (k, v) = self;
        let k = match k {
            NodeTypeMapKey::GenericMapKey(ident) | NodeTypeMapKey::EnclosedGenericId(ident) => {
                ident.node.to_scilla_type()
            }
            NodeTypeMapKey::AddressMapKeyType(_) | NodeTypeMapKey::EnclosedAddressMapKeyType(_) => {
                None
            }
        }?;
        let v = match v {
            NodeTypeMapValue::MapValueTypeOrEnumLikeIdentifier(ident) => {
                ident.node.to_scilla_type()
            }
            NodeTypeMapValue::MapValueParenthesizedType(ident) => match ident.node {
                NodeTypeMapValueAllowingTypeArguments::TypeMapValueNoArgs(ident) => {
                    match ident.node {
                        NodeTypeMapValue::MapValueTypeOrEnumLikeIdentifier(ident) => {
                            ident.node.to_scilla_type()
                        }
                        NodeTypeMapValue::MapKeyValue(ident) => {
                            (ident.node.key.node, ident.node.value.node).to_scilla_type()
                        }
                        _ => None,
                    }
                }
                _ => None,
            },
            _ => None,
        }?;

        Some(ScillaType::Map(k.into(), v.into()))
    }
}

impl ToScillaType for NodeMetaIdentifier {
    fn to_scilla_type(self) -> Option<ScillaType> {
        match self {
            NodeMetaIdentifier::MetaName(ty) => ty.node.to_scilla_type(),
            _ => None,
        }
    }
}

impl ToScillaType for NodeTypeNameIdentifier {
    fn to_scilla_type(self) -> Option<ScillaType> {
        match self {
            NodeTypeNameIdentifier::ByteStringType(NodeByteStr::Type(s)) => match s.node.as_str() {
                "ByStr20" => Some(ScillaType::ByStr20),
                _ => None,
            },
            NodeTypeNameIdentifier::TypeOrEnumLikeIdentifier(ident) => match ident.node.as_str() {
                "Int32" => Some(ScillaType::Int32),
                "Int64" => Some(ScillaType::Int64),
                "Int128" => Some(ScillaType::Int128),
                "Int256" => Some(ScillaType::Int256),
                "Uint32" => Some(ScillaType::Uint32),
                "Uint64" => Some(ScillaType::Uint64),
                "Uint128" => Some(ScillaType::Uint128),
                "Uint256" => Some(ScillaType::Uint256),
                "String" => Some(ScillaType::String),
                _ => None,
            },
            _ => None,
        }
    }
}

impl ToScillaType for NodeAddressType {
    fn to_scilla_type(self) -> Option<ScillaType> {
        self.identifier.node.to_scilla_type()
    }
}

/// Given a Scilla value of type `ty`, read a Solidity value of this type from the [Decoder] and return the
/// equivalent Scilla value which could be used to look up this key in a map.
fn read_index(ty: ScillaType, d: &mut Decoder) -> Result<Vec<u8>> {
    let index = match ty {
        // Note we use the `Debug` impl of `Address`, rather than `Display` because we don't want to include the EIP-55
        // checksum.
        ScillaType::ByStr20 => {
            serde_json::to_vec(&format!("{:?}", Address::detokenize(d.decode()?)))?
        }
        ScillaType::Int32 => serde_json::to_vec(&i32::detokenize(d.decode()?).to_string())?,
        ScillaType::Int64 => serde_json::to_vec(&i64::detokenize(d.decode()?).to_string())?,
        ScillaType::Int128 => serde_json::to_vec(&i128::detokenize(d.decode()?).to_string())?,
        ScillaType::Int256 => serde_json::to_vec(&I256::detokenize(d.decode()?).to_string())?,
        ScillaType::Uint32 => serde_json::to_vec(&u32::detokenize(d.decode()?).to_string())?,
        ScillaType::Uint64 => serde_json::to_vec(&u64::detokenize(d.decode()?).to_string())?,
        ScillaType::Uint128 => serde_json::to_vec(&u128::detokenize(d.decode()?).to_string())?,
        ScillaType::Uint256 => serde_json::to_vec(&U256::detokenize(d.decode()?).to_string())?,
        ScillaType::String => String::detokenize(d.decode()?).into_bytes(),
        ScillaType::Map(_, _) => {
            return Err(anyhow!("a map cannot be the key of another map"));
        }
    };
    Ok(index)
}

/// Given a scilla type and an EVM ABI decoder, converts the scilla type to a non-map type. The types of map keys will
/// be read from the decoder and the values of those types will be added to `indices`.
///
/// For example, passing `ScillaType::Map(ScillaType::Int32, ScillaType::String)` will read an `int32` from the
/// decoder, add its value to `indices` and return `ScillaType::String`.
fn get_indices(
    ty: ScillaType,
    decoder: &mut Decoder,
    indices: &mut Vec<Vec<u8>>,
) -> Result<ScillaType> {
    match ty {
        ScillaType::Map(k, v) => {
            let index = read_index(*k, decoder)?;
            indices.push(index);
            get_indices(*v, decoder, indices)
        }
        _ => Ok(ty),
    }
}

pub(crate) struct ScillaRead;

#[track_caller]
fn oog<T>() -> Result<T, PrecompileErrors> {
    let location = std::panic::Location::caller();
    trace!(%location, "scilla_call out of gas");
    Err(PrecompileErrors::Error(PrecompileError::OutOfGas))
}

#[track_caller]
fn err<T>(message: impl Into<String>) -> Result<T, PrecompileErrors> {
    let location = std::panic::Location::caller();
    let message = message.into();
    trace!(%location, message, "scilla_call failed");
    Err(err_inner(message))
}

#[track_caller]
fn err_inner(message: impl Into<String>) -> PrecompileErrors {
    let location = std::panic::Location::caller();
    let message = message.into();
    trace!(%location, message, "scilla_call failed");
    PrecompileErrors::Error(PrecompileError::other(message))
}

#[track_caller]
fn fatal<T>(message: &'static str) -> Result<T, PrecompileErrors> {
    let location = std::panic::Location::caller();
    trace!(%location, message, "scilla_call failed");
    Err(PrecompileErrors::Fatal {
        msg: message.to_owned(),
    })
}

// ZQ1 suggests revisiting these costs in the future.
const BASE_COST: u64 = 15;
const PER_BYTE_COST: u64 = 3;

impl ContextStatefulPrecompile<PendingState> for ScillaRead {
    fn call(
        &self,
        input: &Bytes,
        gas_limit: u64,
        context: &mut InnerEvmContext<PendingState>,
    ) -> PrecompileResult {
        let Ok(input_len) = u64::try_from(input.len()) else {
            return err("input too long");
        };
        let required_gas = input_len * PER_BYTE_COST + BASE_COST;
        if gas_limit < required_gas {
            return oog();
        }

        let mut decoder = Decoder::new(input, false);

        let address =
            Address::detokenize(decoder.decode().map_err(|_| err_inner("invalid address"))?);
        let field = String::detokenize(decoder.decode().map_err(|_| err_inner("invalid field"))?);

        let account = match context.db.load_account(address) {
            Ok(account) => account,
            Err(e) => {
                tracing::error!(?e, "state access failed");
                return fatal("state access failed");
            }
        };
        let Code::Scilla {
            ref types,
            ref init_data,
            ..
        } = account.account.code
        else {
            return err(format!("{address} is not a scilla contract"));
        };

        let (ty, init_data_value) = match (
            init_data.iter().find(|p| p.name == field),
            types.get(&field),
        ) {
            // Note that if a field exists in both the `init_data` and mutable fields, we ignore the `init_data` and
            // read from the field. This behaviour matches the semantics of Scilla and specification in ZIP-21.
            (_, Some((ty, _))) => (ty, None),
            (Some(v), None) => (&v.ty, Some(v.value.clone())),
            (None, None) => {
                return err(format!("variable {field} does not exist in contract"));
            }
        };

        let mut errors = vec![];
        let Ok(parsed) = ScillaTypeParser::new().parse(&mut errors, Lexer::new(ty)) else {
            return fatal("failed to parse scilla type");
        };

        let Some(ty) = parsed.node.to_scilla_type() else {
            return err(format!("unsupported scilla type: {ty}"));
        };

        let mut indices = vec![];
        let Ok(ty) = get_indices(ty, &mut decoder, &mut indices) else {
            return err("failed to read indices");
        };

        macro_rules! encoder {
            ($ty:ty) => {{
                if let Some(value) = init_data_value {
                    let Ok(value) = serde_json::from_value::<String>(value) else {
                        return fatal("failed to parse raw value");
                    };
                    let Ok(value) = value.parse::<$ty>() else {
                        return fatal("failed to parse value");
                    };
                    value.abi_encode()
                } else {
                    let Ok(value) = context.db.load_storage(address, &field, &indices) else {
                        return fatal("failed to read value");
                    };
                    if let Some(value) = value {
                        let Ok(value) = serde_json::from_slice::<String>(&value) else {
                            return fatal("failed to parse raw value");
                        };
                        let Ok(value) = value.parse::<$ty>() else {
                            return fatal("failed to parse value");
                        };
                        value.abi_encode()
                    } else {
                        vec![]
                    }
                }
            }};
        }

        let value = match ty {
            ScillaType::ByStr20 => encoder!(Address),
            ScillaType::Int32 => encoder!(i32),
            ScillaType::Int64 => encoder!(i64),
            ScillaType::Int128 => encoder!(i128),
            ScillaType::Int256 => encoder!(I256),
            ScillaType::Uint32 => encoder!(u32),
            ScillaType::Uint64 => encoder!(u64),
            ScillaType::Uint128 => encoder!(u128),
            ScillaType::Uint256 => encoder!(U256),
            ScillaType::String => {
                if let Some(value) = init_data_value {
                    let Ok(value) = serde_json::from_value::<String>(value) else {
                        return fatal("failed to parse raw value");
                    };
                    value.abi_encode()
                } else {
                    let Ok(value) = context.db.load_storage(address, &field, &indices) else {
                        return fatal("failed to read value");
                    };
                    if let Some(value) = value {
                        let Ok(value) = serde_json::from_slice::<String>(value) else {
                            return fatal("failed to parse raw value");
                        };
                        value.abi_encode()
                    } else {
                        vec![]
                    }
                }
            }
            ScillaType::Map(_, _) => unreachable!("map will not be returned from `get_indices`"),
        };

        Ok(PrecompileOutput::new(required_gas, value.into()))
    }
}

pub fn scilla_call_handle_register<I: ScillaInspector>(
    handler: &mut EvmHandler<'_, ExternalContext<I>, PendingState>,
) {
    // Create handler
    let prev_handle = handler.execution.create.clone();
    handler.execution.create = Arc::new(move |ctx, inputs| {
        // Reserve enough space to store the caller.
        ctx.external.callers.reserve(
            (ctx.evm.journaled_state.depth + 1).saturating_sub(ctx.external.callers.len()),
        );
        for _ in ctx.external.callers.len()..(ctx.evm.journaled_state.depth + 1) {
            ctx.external.callers.push(Address::ZERO);
        }
        ctx.external.callers[ctx.evm.journaled_state.depth] = inputs.caller;

        prev_handle(ctx, inputs)
    });

    // Create result handler
    let prev_handle = handler.execution.insert_create_outcome.clone();
    handler.execution.insert_create_outcome = Arc::new(move |ctx, frame, outcome| {
        if outcome.result.is_error() || outcome.result.is_revert() {
            ctx.external.has_evm_failed = true;
        }
        prev_handle(ctx, frame, outcome)
    });

    // EOF create handler
    let prev_handle = handler.execution.eofcreate.clone();
    handler.execution.eofcreate = Arc::new(move |ctx, inputs| {
        // Reserve enough space to store the caller.
        ctx.external.callers.reserve(
            (ctx.evm.journaled_state.depth + 1).saturating_sub(ctx.external.callers.len()),
        );
        for _ in ctx.external.callers.len()..(ctx.evm.journaled_state.depth + 1) {
            ctx.external.callers.push(Address::ZERO);
        }
        ctx.external.callers[ctx.evm.journaled_state.depth] = inputs.caller;

        prev_handle(ctx, inputs)
    });

    // EOF result handler
    let prev_handle = handler.execution.insert_eofcreate_outcome.clone();
    handler.execution.insert_eofcreate_outcome = Arc::new(move |ctx, frame, outcome| {
        if outcome.result.is_error() || outcome.result.is_revert() {
            ctx.external.has_evm_failed = true;
        }
        prev_handle(ctx, frame, outcome)
    });

    // Call handler
    let prev_handle = handler.execution.call.clone();
    handler.execution.call = Arc::new(move |ctx, inputs| {
        // Reserve enough space to store the caller.
        ctx.external.callers.reserve(
            (ctx.evm.journaled_state.depth + 1).saturating_sub(ctx.external.callers.len()),
        );
        for _ in ctx.external.callers.len()..(ctx.evm.journaled_state.depth + 1) {
            ctx.external.callers.push(Address::ZERO);
        }
        ctx.external.callers[ctx.evm.journaled_state.depth] = inputs.caller;

        if inputs.bytecode_address != Address::from(*b"\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0ZIL\x53") {
            return prev_handle(ctx, inputs);
        }

        let gas = Gas::new(inputs.gas_limit);
        let gas_exempt = ctx
            .external
            .fork
            .scilla_call_gas_exempt_addrs
            .contains(&inputs.caller);

        // Record access of whitelisted contract by precompile
        if gas_exempt {
            ctx.external.has_touched_whitelisted_addresses = true;
        }

        // The behaviour is different for contracts having 21k gas and/or deployed with zq1
        // 1. If gas == 21k and gas_exempt -> allow it to run with gas_left()
        // 2. if precompile failed and gas_exempt -> mark entire txn as failed (not only the current precompile)
        // 3. Otherwise, let it run with what it's given and let the caller decide

        let outcome = scilla_call_precompile(
            &inputs,
            gas.limit(),
            &mut ctx.evm.inner,
            &mut ctx.external,
            gas_exempt,
        );

        // Copied from `EvmContext::call_precompile`
        let mut result = InterpreterResult {
            result: InstructionResult::Return,
            gas,
            output: Bytes::new(),
        };

        match outcome {
            Ok(output) => {
                if result.gas.record_cost(output.gas_used) {
                    result.result = InstructionResult::Return;
                    result.output = output.bytes;
                } else {
                    result.result = InstructionResult::PrecompileOOG;
                }
            }
            Err(PrecompileErrors::Error(e)) => {
                result.result = if e.is_oog() {
                    InstructionResult::PrecompileOOG
                } else {
                    InstructionResult::PrecompileError
                };
            }
            Err(PrecompileErrors::Fatal { msg }) => return Err(EVMError::Precompile(msg)),
        }

        if ctx
            .external
            .fork
            .failed_scilla_call_from_gas_exempt_caller_causes_revert
        {
            // If precompile failed and this is whitelisted contract -> mark entire transaction as failed
            match result.result {
                InstructionResult::Return => {}
                _ => {
                    if gas_exempt {
                        ctx.external.enforce_transaction_failure = true;
                    }
                }
            }
        }

        Ok(FrameOrResult::new_call_result(
            result,
            inputs.return_memory_offset.clone(),
        ))
    });

    // Call result handler
    let prev_handle = handler.execution.insert_call_outcome.clone();
    handler.execution.insert_call_outcome = Arc::new(move |ctx, frame, memory, outcome| {
        if outcome.result.is_error() || outcome.result.is_revert() {
            ctx.external.has_evm_failed = true;
        }
        prev_handle(ctx, frame, memory, outcome)
    });
}

fn scilla_call_precompile<I: ScillaInspector>(
    input: &CallInputs,
    gas_limit: u64,
    evmctx: &mut InnerEvmContext<PendingState>,
    external_context: &mut ExternalContext<I>,
    gas_exempt: bool,
) -> PrecompileResult {
    let Ok(input_len) = u64::try_from(input.input.len()) else {
        return err("input too long");
    };

    let required_gas = input_len * PER_BYTE_COST + BASE_COST + EvmGas::from(SCILLA_INVOKE_RUNNER).0;

    if !gas_exempt && gas_limit < required_gas {
        return oog();
    }

    let mut decoder = Decoder::new(&input.input, false);

    let address = Address::detokenize(decoder.decode().map_err(|_| err_inner("invalid address"))?);
    let transition = String::detokenize(
        decoder
            .decode()
            .map_err(|_| err_inner("invalid transition"))?,
    );
    let keep_origin = U256::detokenize(
        decoder
            .decode()
            .map_err(|_| err_inner("invalid keep_origin"))?,
    );

    let keep_origin = if keep_origin == U256::from(0) {
        false
    } else if keep_origin == U256::from(1) {
        true
    } else {
        return err("call mode should be either 0 or 1");
    };
    trace!(%address, transition, %keep_origin, "scilla_call");

    let account = match evmctx.db.pre_state.get_account(address) {
        Ok(account) => account,
        Err(e) => {
            tracing::error!(?e, "state access failed");
            return fatal("state access failed");
        }
    };
    let Code::Scilla { transitions, .. } = account.code else {
        return err(format!("{address} is not a scilla contract"));
    };
    let Some(transition) = transitions.into_iter().find(|t| t.name == transition) else {
        return err(format!(
            "transition {transition} does not exist in contract"
        ));
    };

    let params: Vec<_> = transition
        .params
        .into_iter()
        .map(|param| {
            let mut errors = vec![];
            let Ok(parsed) = ScillaTypeParser::new().parse(&mut errors, Lexer::new(&param.ty))
            else {
                return fatal("failed to parse parameter type");
            };

            let Some(ty) = parsed.node.to_scilla_type() else {
                return err(format!("unsupported scilla type: {}", param.ty));
            };
            let Some(param_type) = ty.param_type() else {
                return err(format!("unexpected scilla type as a parameter: {ty:?}"));
            };

            let Ok(value) = read_index(ty, &mut decoder) else {
                return fatal("failed to get value");
            };
            let Ok(value) = serde_json::from_slice::<serde_json::Value>(&value) else {
                return fatal("failed to parse value");
            };
            let param =
                serde_json::json!({"vname": param.name, "type": param_type, "value": value});

            Ok(param)
        })
        .collect::<Result<_, _>>()?;

    let message = serde_json::json!({"_tag": transition.name, "params": params });

    let empty_state = PendingState::new(evmctx.db.pre_state.clone());
    // Temporarily move the `PendingState` out of `evmctx`, replacing it with an empty state.
    let mut state = std::mem::replace(&mut evmctx.db, empty_state);
    let depth = evmctx.journaled_state.depth;
    if external_context.fork.scilla_call_respects_evm_state_changes {
        state.evm_state = Some(evmctx.journaled_state.clone());
    }

    // 1. if evm_exec_failure_causes_scilla_whitelisted_addr_to_fail == true then we take converted value
    // 2. if evm_exec_failure_causes_scilla_whitelisted_addr_to_fail == false and evm_to_scilla_value_transfer_zero == true -> we return 0
    // 3. else we take converted value
    let effective_value = {
        match (
            external_context
                .fork
                .evm_exec_failure_causes_scilla_whitelisted_addr_to_fail,
            external_context.fork.evm_to_scilla_value_transfer_zero,
        ) {
            (true, _) => ZilAmount::from_amount(input.transfer_value().unwrap_or_default().to()),
            (false, true) => ZilAmount::from_amount(0),
            _ => ZilAmount::from_amount(input.transfer_value().unwrap_or_default().to()),
        }
    };

    let scilla = evmctx.db.pre_state.scilla();
    let Ok((result, mut state)) = scilla_call(
        state,
        scilla,
        evmctx.env.tx.caller,
        if keep_origin {
            if external_context
                .fork
                .call_mode_1_sets_caller_to_parent_caller
            {
                // Use the caller of the parent call-stack.
                external_context.callers[depth - 1]
            } else {
                // Use the original transaction signer.
                evmctx.env.tx.caller
            }
        } else {
            input.caller
        },
        // If this call is gas exempt the gas limit likely is not enough to invoke the Scilla call, therefore we lie
        // and pass a large number instead.
        if gas_exempt {
            EvmGas(u64::MAX).into()
        } else {
            EvmGas(gas_limit - required_gas).into()
        },
        address,
        effective_value,
        serde_json::to_string(&message).unwrap(),
        &mut external_context.inspector,
        &scilla_ext_libs_path_default(),
        external_context.fork,
        evmctx.env.block.number.to(),
    ) else {
        return fatal("scilla call failed");
    };
    trace!(?result, "scilla_call complete");
    if !&result.success {
        evmctx.db = state;
        if result.errors.values().any(|errs| {
            errs.iter()
                .any(|err| matches!(err, ScillaError::GasNotSufficient))
        }) {
            return oog();
        } else {
            return err("scilla call failed");
        }
    }
    state.new_state.retain(|address, account| {
        if !account.touched {
            return true;
        }
        if !account.from_evm {
            return true;
        }

        // Apply changes made to EVM accounts back to the EVM `JournaledState`.
        let before = evmctx.journaled_state.state.get_mut(address).unwrap();

        // The only thing that Scilla is able to update is the balance.
        if before.info.balance.to::<u128>() != account.account.balance {
            before.info.balance = account.account.balance.try_into().unwrap();
            before.mark_touch();
        }

        false
    });
    evmctx.db = state;

    for log in result.logs {
        let log = log.into_evm();
        evmctx.journaled_state.log(alloy::primitives::Log {
            address: log.address,
            data: LogData::new_unchecked(log.topics, log.data.into()),
        });
    }

    // TODO(#767): Handle transfer to Scilla contract if `result.accepted`.

    Ok(PrecompileOutput::new(
        if gas_exempt {
            u64::min(required_gas, gas_limit)
        } else {
            required_gas + result.gas_used.0
        },
        Bytes::new(),
    ))
}

```

`zilliqa/src/range_map.rs`:

```rs
use std::{
    cmp::{Ordering, max, min},
    default::Default,
    fmt,
    fmt::Display,
    ops::Range,
};

use serde::{Deserialize, Serialize};

/// A block map - a reasonably efficient, easily implementable representation of a collection of ranges.
/// Feel free to make this generic - we only ever need the u64 variant so I didn't bother.
/// I did look at crates to implement this, but they were all either overcomplicated, unmaintained, or both;
/// if you can find a good one, please do!
/// (but watch out for the semantics of int_diff() which are quite specialised).
#[derive(Debug, Clone, PartialEq, Eq, Default, Serialize, Deserialize)]
pub struct RangeMap {
    /// ranges in this rangemap. These are held as non-overlapping non-empty ranges sorted in ascending order of start
    /// (and thus ascending order of end).
    pub ranges: Vec<Range<u64>>,
}

impl Display for RangeMap {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        let mut got_one = false;
        for r in &self.ranges {
            if got_one {
                write!(f, ",")?;
            }
            if r.start < r.end + 1 {
                write!(f, "{}-{}", r.start, r.end - 1)?;
            } else {
                write!(f, "{}", r.start)?;
            }
            got_one = true;
        }
        Ok(())
    }
}

/// Merge two ranges, returning the combined range if you can and None if you can't
/// (which would mean that the ranges are disjoint).
fn merge_ranges(r1: &Range<u64>, r2: &Range<u64>) -> Option<Range<u64>> {
    // < and > because the ranges are half-open.
    if r1.end < r2.start || r1.start > r2.end {
        // Ranges are disjoint
        None
    } else {
        // We can merge them.
        Some(Range {
            start: std::cmp::min(r1.start, r2.start),
            end: std::cmp::max(r1.end, r2.end),
        })
    }
}

/// Iterates over all the values in a range_map() by stepping through
/// each range and value in turn.
pub struct ItemIterator<'a> {
    map: &'a RangeMap,
    index: usize,
    value: u64,
}

impl<'a> ItemIterator<'a> {
    pub fn new(map: &'a RangeMap) -> Self {
        let value = if !map.ranges.is_empty() {
            map.ranges[0].start
        } else {
            0
        };
        Self {
            map,
            index: 0,
            value,
        }
    }
}

impl Iterator for ItemIterator<'_> {
    type Item = u64;

    /// Just count up through the ranges and values one by one until
    /// you get to the end.
    fn next(&mut self) -> Option<u64> {
        if self.index < self.map.ranges.len() {
            let range = &self.map.ranges[self.index];
            if self.value < range.end {
                let result = self.value;
                self.value += 1;
                return Some(result);
            } else {
                self.index += 1;
                if self.index < self.map.ranges.len() {
                    // All our ranges are at least 1 long
                    let result = &self.map.ranges[self.index].start;
                    self.value = result + 1;
                    return Some(*result);
                }
            }
        }
        None
    }
}

impl RangeMap {
    /// Create a new, empty RangeMap
    pub fn new() -> Self {
        Self::default()
    }

    /// Iterate over all the values in this RangeMap
    pub fn iter_values(&self) -> ItemIterator {
        ItemIterator::new(self)
    }

    /// From a single interval
    pub fn from_closed_interval(start: u64, end: u64) -> Self {
        Self {
            ranges: vec![Range {
                start,
                end: end + 1,
            }],
        }
    }

    /// Create a RangeMap from a (half-open) Range.
    pub fn from_range(range: &Range<u64>) -> Self {
        Self {
            ranges: vec![range.clone()],
        }
    }

    /// Does this RangeMap contain any items?
    pub fn is_empty(&self) -> bool {
        self.ranges.is_empty()
    }

    /// Mostly for testing - convert each Range to a pair of u64s (half-open) so that
    /// we can easily print it.
    pub fn to_tuple_vec(&self) -> Vec<(u64, u64)> {
        let mut result = Vec::new();
        for range in &self.ranges {
            result.push((range.start, range.end))
        }
        result
    }

    /// Again, mostly for testing - from a vector of (half-open!) range tuples.
    pub fn from_tuple_vec(vec: &Vec<(u64, u64)>) -> Self {
        let mut result = Self::new();
        for v in vec {
            result.with_range(&Range {
                start: v.0,
                end: v.1,
            });
        }
        result
    }

    /// Add a range from a (closed!) tuple.
    pub fn with_closed_tuple(&mut self, tuple: (u64, u64)) -> &mut Self {
        self.with_range(&Range {
            start: tuple.0,
            end: tuple.1 + 1,
        })
    }

    /// Add a single element
    pub fn with_elem(&mut self, val: u64) -> &mut Self {
        self.with_range(&Range {
            start: val,
            end: val + 1,
        })
    }

    /// Add a range to this RangeMap, returning a reference to self.
    pub fn with_range(&mut self, range: &Range<u64>) -> &mut Self {
        if range.is_empty() {
            return self;
        }

        if self.is_empty() {
            self.ranges.push(range.clone());
            return self;
        }

        let last = self.ranges.last_mut().unwrap();
        // Optimise the common case where the new range overlaps with the current greatest range. Note that `end`
        // is exclusive, since `Range`s are half-open, but we still check `range.start <= last.end`. In the case
        // where `range.start == last.end`, the ranges are not overlapping, but adjacent and we can still merge
        // them immediately.
        if last.start <= range.start && range.start <= last.end {
            // If `range` is completely covered by `last`, there is nothing to do
            if range.end <= last.end {
                return self;
            }

            // Otherwise, expand `last` to cover `range`.
            last.end = range.end;
            return self;
        }
        // Optimise the common case where the new range is greater than all current ranges.
        if range.start > last.end {
            self.ranges.push(range.clone());
            return self;
        }

        // General case
        let mut inserted = false;
        for (idx, r) in self.ranges.iter().enumerate() {
            if r.start > range.start {
                self.ranges.insert(idx, range.clone());
                inserted = true;
                break;
            }
        }
        if !inserted {
            self.ranges.push(range.clone());
        }
        self.canonicalise();

        self
    }

    /// Canonicalise this RangeMap - go through the RangeMap merging
    /// adjacent ranges.
    /// Note: this function doesn't remove empty ranges.
    fn canonicalise(&mut self) -> &mut Self {
        // Counts through the source list.
        let mut src = 1;
        // Counts through the target list.
        let mut dst = 0;
        while src < self.ranges.len() {
            let (first, second) = (&self.ranges[dst], &self.ranges[src]);
            if let Some(merged) = merge_ranges(first, second) {
                self.ranges[dst] = merged.clone();
            } else {
                // We can't merge.
                dst += 1;
                self.ranges[dst] = second.clone();
            }
            src += 1;
        }
        // If the merge_offset is 1, we didn't merge anything.
        self.ranges.truncate(dst + 1);
        self
    }

    /// Non-destructively merge this range map with `ranges`, and
    /// return the result.
    pub fn with_range_map(&mut self, ranges: &Self) -> &mut Self {
        for r in ranges.ranges.iter() {
            self.with_range(r);
        }
        self
    }

    /// Return the max value in this range map
    pub fn max(&self) -> Option<u64> {
        self.ranges.last().map(|x| x.end - 1)
    }

    /// Remove any values in this RangeMap greater than limit
    /// (this is used to delete elements of "not here" ranges that we think
    /// might actually exist)
    pub fn with_closed_upper_limit(&mut self, limit: u64) -> &mut Self {
        let mut new_ranges: Vec<Range<u64>> = Vec::new();
        for r in self.ranges.iter() {
            if r.end > limit {
                if r.start < limit {
                    new_ranges.push(Range {
                        start: r.start,
                        end: limit + 1,
                    });
                }
                // Otherwise we start after the limit; nothing to do.
            } else {
                // Below the limit
                new_ranges.push(r.clone());
            }
        }
        self.ranges = new_ranges;
        self
    }

    /// Make an unlimited diff_inter() call - equivalent to diff_inter_limited(to_remove, None).
    pub fn diff_inter(&self, to_remove: &Self) -> (Self, Self) {
        self.diff_inter_limited(to_remove, None)
    }

    /// Set difference
    ///
    /// Returns `(intersection, diff)` where:
    ///  * `intersection` is the set of things in both `self` and `to_remove`.
    ///  * `diff` is the set of things in self with the set of things in `to-remove` removed.
    ///
    /// We will never put more than `limit` ranges in intersection -
    /// the rest will be returned in diff.
    ///
    /// This is used to limit the number of requests to a node. None
    /// == unlimited.  We also don't guarantee to find the "best"
    /// `limit` ranges - just no more than `limit`.
    pub fn diff_inter_limited(&self, to_remove: &Self, limit: Option<usize>) -> (Self, Self) {
        //  We proceed in lock-step between the sets.
        let mut intersection = RangeMap::new();
        let mut diff = RangeMap::new();
        let mut self_iter = self.ranges.iter();
        let mut current_self_iter: Option<Range<u64>> = self_iter.next().cloned();
        let mut remove_iter = to_remove.ranges.iter();
        let mut current_remove_iter: Option<Range<u64>> = remove_iter.next().cloned();
        // Termination: the outer loop terminates when we're through self.
        // Every step of the inner loop either
        //  - breaks, or
        //  - advances remain by one, or
        //  - breaks remain into a smaller range than it was before.
        while let Some(next_self) = &current_self_iter {
            if let Some(val) = limit {
                if intersection.ranges.len() >= val {
                    // Too many things in diff now - we're done. Append the rest of self and return.
                    while let Some(n) = &current_self_iter {
                        diff.with_range(n);
                        current_self_iter = self_iter.next().cloned();
                    }
                    break;
                }
            }
            if let Some(current_remove) = &current_remove_iter {
                // Things in self which are too small to remove - these will always
                // be too small to remove, because current_remove is nondecreasing.
                let early = Range {
                    start: next_self.start,
                    end: min(next_self.end, current_remove.start),
                };

                // Things in both self and to_remove - these will always be removed.
                let mid = Range {
                    start: max(next_self.start, current_remove.start),
                    end: min(next_self.end, current_remove.end),
                };

                if !early.is_empty() {
                    // This means that there is a space between next_self.start (what we have) and
                    // current_remove.start (what we want to remove). Once remove is removed, it will
                    // therefore still be here.
                    diff.with_range(&early);
                }

                if !mid.is_empty() {
                    intersection.with_range(&mid);
                }

                // now, either there are still things in self that too large for to_remove
                match next_self.end.cmp(&current_remove.end) {
                    Ordering::Greater => {
                        current_self_iter = Some(Range {
                            start: max(next_self.start, current_remove.end),
                            end: next_self.end,
                        });
                        // But next_self starts after current_remove.end, so we know that nothing in
                        // current_remove can possibly overlap this, so
                        current_remove_iter = remove_iter.next().cloned();
                    }
                    Ordering::Less => {
                        // or there are things still in to_remove that are not in self
                        current_remove_iter = Some(Range {
                            start: max(current_remove.start, next_self.end),
                            end: current_remove.end,
                        });
                        // But current_remove now starts after next_self, so we can advance self
                        current_self_iter = self_iter.next().cloned();
                    }
                    _ => {
                        // If we get here, then the two ended precisely at the same place. Advance both iterators.
                        current_self_iter = self_iter.next().cloned();
                        current_remove_iter = remove_iter.next().cloned();
                    }
                }
            } else {
                // We've run out of things to remove. Everything else must therefore remain.
                diff.with_range(next_self);
                current_self_iter = self_iter.next().cloned();
            }
        }
        // We've run out of things; anything left to remove will therefore not be removed and we're done.
        (intersection, diff)
    }

    // This is a very strange function. It limits the storage size of a RangeMap at the high end.
    // it's used when trimming the "no blocks for this view" cache to prevent memory exhaustion in large
    // networks.
    pub fn truncate(&mut self, max_ranges: usize) {
        self.ranges.truncate(max_ranges);
    }
}

#[cfg(test)]
mod tests {
    use std::ops::Range;

    use crate::range_map::RangeMap;

    #[test]
    fn simple() {
        let map1 = RangeMap::from_closed_interval(0, 10);
        let mut map2 = RangeMap::from_closed_interval(2, 15);
        map2.with_range(&Range { start: 8, end: 23 });

        assert_eq!(map1.max(), Some(10));
        assert_eq!(map2.max(), Some(22));
    }

    #[test]
    fn canonical() {
        let mut map = RangeMap::new();
        map.with_elem(1).with_elem(2).with_elem(3);
        assert_eq!(map.to_tuple_vec(), vec![(1, 4)]);
    }

    #[test]
    fn merge() {
        let mut map1 = RangeMap::new();
        map1.with_range(&Range { start: 5, end: 8 });
        map1.with_range(&Range { start: 13, end: 20 });
        map1.with_range(&Range { start: 3, end: 10 });
        map1.with_range(&Range { start: 20, end: 22 });
        map1.with_range(&Range { start: 30, end: 32 });
        map1.with_range(&Range { start: 19, end: 33 });

        // this should end up as...
        assert_eq!(map1.ranges.len(), 2);
        assert_eq!(map1.to_tuple_vec(), vec![(3, 10), (13, 33)]);
    }

    #[test]
    fn int_diff() {
        let available = RangeMap::from_tuple_vec(&vec![(1, 8), (10, 12), (14, 33)]);
        let wanted = RangeMap::from_tuple_vec(&vec![(2, 3), (11, 14), (14, 20)]);

        println!("----------------------");
        let (can_get, still_need) = wanted.diff_inter(&available);

        // Things we want that we have also got.
        assert_eq!(
            can_get,
            RangeMap::from_tuple_vec(&vec![(2, 3), (11, 12), (14, 20)])
        );

        // Things we still want.
        assert_eq!(still_need, RangeMap::from_tuple_vec(&vec![(12, 14)]));
    }

    #[test]
    fn int_diff_2() {
        let have = RangeMap::from_tuple_vec(&vec![
            (0, 5),
            (6, 9),
            (10, 13),
            (15, 18),
            (19, 20),
            (22, 45),
            (46, 47),
        ]);
        let want = RangeMap::from_tuple_vec(&vec![(6, 47)]);
        let (get, still_want) = want.diff_inter(&have);

        assert_eq!(
            get,
            RangeMap::from_tuple_vec(&vec![
                (6, 9),
                (10, 13),
                (15, 18),
                (19, 20),
                (22, 45),
                (46, 47)
            ])
        );
        assert_eq!(
            still_want,
            RangeMap::from_tuple_vec(&vec![(9, 10), (13, 15), (18, 19), (20, 22), (45, 46)])
        );
    }

    #[test]
    fn int_diff_3() {
        let have = RangeMap::from_tuple_vec(&vec![(208, 8000)]);
        let to_remove = RangeMap::from_tuple_vec(&vec![(7820, 7827), (7889, 7903)]);
        println!("have = {:?} to_remove = {:?}", have, to_remove);
        let (get, still_want) = have.diff_inter(&to_remove);
        println!("get = {:?} still_want = {:?}", get, still_want);
        assert_eq!(
            get,
            RangeMap::from_tuple_vec(&vec![(7820, 7827), (7889, 7903)])
        );
        assert_eq!(
            still_want,
            RangeMap::from_tuple_vec(&vec![(208, 7820), (7827, 7889), (7903, 8000)])
        );
    }

    #[test]
    fn int_diff_4() {
        let have = RangeMap::from_tuple_vec(&vec![(0, 660), (661, 753), (1935, 1945)]);
        let to_remove = RangeMap::from_tuple_vec(&vec![(1871, 1872)]);
        println!("have = {:?} to_remove = {:?}", have, to_remove);
        let (get, still_want) = have.diff_inter(&to_remove);
        println!("get = {:?} still_want = {:?}", get, still_want);
        assert_eq!(get, RangeMap::from_tuple_vec(&vec![]));
        assert_eq!(
            still_want,
            RangeMap::from_tuple_vec(&vec![(0, 660), (661, 753), (1935, 1945)])
        );
    }

    #[test]
    fn iterator() {
        let map3 = RangeMap::from_tuple_vec(&vec![(1, 4), (6, 8), (9, 10)]);
        assert_eq!(
            map3.iter_values().collect::<Vec<u64>>(),
            vec![1, 2, 3, 6, 7, 9]
        );
    }

    #[test]
    fn limit() {
        let the_map = RangeMap::from_tuple_vec(&vec![
            (1, 5),
            (6, 9),
            (10, 13),
            (15, 18),
            (19, 20),
            (22, 45),
            (46, 47),
        ]);
        assert_eq!(
            the_map.clone().with_closed_upper_limit(20),
            &RangeMap::from_tuple_vec(&vec![(1, 5), (6, 9), (10, 13), (15, 18), (19, 20)])
        );
        assert_eq!(
            the_map.clone().with_closed_upper_limit(23),
            &RangeMap::from_tuple_vec(&vec![
                (1, 5),
                (6, 9),
                (10, 13),
                (15, 18),
                (19, 20),
                (22, 24)
            ])
        );
        assert_eq!(
            the_map.clone().with_closed_upper_limit(1),
            &RangeMap::from_tuple_vec(&vec![])
        );
        assert_eq!(the_map.clone().with_closed_upper_limit(9999), &the_map);
    }
}

```

`zilliqa/src/schnorr.rs`:

```rs
use k256::{
    AffinePoint, Scalar, U256,
    elliptic_curve::{Group, ops::Reduce, sec1::ToEncodedPoint},
};
pub use k256::{PublicKey, SecretKey, ecdsa::Signature};
use sha2::{Digest, Sha256};

#[allow(unused)]
pub fn sign(message: &[u8], secret_key: &SecretKey) -> Signature {
    loop {
        let k = Scalar::generate_vartime(&mut rand::thread_rng());

        if let Some(signature) = sign_inner(k, message, secret_key) {
            return signature;
        }
    }
}

fn sign_inner(k: Scalar, message: &[u8], secret_key: &SecretKey) -> Option<Signature> {
    let public_key = secret_key.public_key();

    // 2. Compute the commitment Q = kG, where G is the base point.
    let q = AffinePoint::GENERATOR * k;

    // 3. Compute the challenge r = H(Q, kpub, m)
    let mut hasher = Sha256::new();
    hasher.update(q.to_encoded_point(true).to_bytes());
    hasher.update(public_key.to_encoded_point(true).to_bytes());
    hasher.update(message);
    let r = <Scalar as Reduce<U256>>::reduce_bytes(&hasher.finalize());

    // 4. If r = 0 mod(order), goto 1
    if r.is_zero().into() {
        return None;
    }

    // 5. Compute s = k - r*kpriv mod(order)
    let s: Scalar = k - r.mul(&secret_key.as_scalar_primitive().into());

    // 6. If s = 0 goto 1.
    if s.is_zero().into() {
        return None;
    }

    // 7. Signature on m is (r, s)
    Signature::from_scalars(r.to_bytes(), s.to_bytes()).ok()
}

pub fn verify(message: &[u8], public_key: PublicKey, signature: Signature) -> Option<()> {
    let (r, s) = signature.split_scalars();

    // 2. Compute Q = sG + r*kpub
    let q = (AffinePoint::GENERATOR * *s) + (*public_key.as_affine() * *r);

    // 3. If Q = 0 (the neutral point), return 0;
    if q.is_identity().into() {
        return None;
    }

    // 4. r' = H(Q, kpub, m)
    let mut hasher = Sha256::new();
    hasher.update(q.to_encoded_point(true).to_bytes());
    hasher.update(public_key.to_encoded_point(true).to_bytes());
    hasher.update(message);
    let r_dash = <Scalar as Reduce<U256>>::reduce_bytes(&hasher.finalize());

    // 5. Return r' == r
    if r_dash != *r {
        return None;
    }

    Some(())
}

#[cfg(test)]
mod tests {
    use k256::{FieldBytes, PublicKey, Scalar, SecretKey, elliptic_curve::PrimeField};

    use super::{sign_inner, verify};

    #[test]
    fn signing() {
        // From https://github.com/Zilliqa/zilliqa-js/blob/226b371eaac78ed80e7b40b93189b6a97086bdf5/packages/zilliqa-js-crypto/test/schnorr.spec.ts#L23.
        let cases = [
            (
                "A7F1D92A82C8D8FE434D98558CE2B347171198542F112D0558F56BD68807999248336241F30D23E55F30D1C8ED610C4B0235398184B814A29CB45A672ACAE548E9C5F1B0C4158AE59B4D39F6F7E8A105D3FEEDA5D5F3D9E45BFA6CC351E220AE0CE106986D61FF34A11E19FD3650E9B7818FC33A1E0FC02C44557AC8AB50C9B2DEB2F6B5E24C4FDD9F8867BDCE1FF261008E7897970E346207D75E47A158298E5BA2F56246869CC42E362A02731264E60687EF5309D108534F51F8658FB4F080B7CB19EE9AEBD718CC4FA27C8C37DFC1ADA5D133D13ABE03F021E9B1B78CCBD82F7FF2B38C6D48D01E481B2D4FAF7171805FD7F2D39EF4C4F19B9496E81DAB8193B3737E1B27D9C43957166441B93515E8F03C95D8E8CE1E1864FAAD68DDFC5932130109390B0F1FE5CA716805F8362E98DCCAADC86ADBED25801A9A9DCFA6264319DDAFE83A89C51F3C6D199D38DE10E660C37BE872C3F2B31660DE8BC95902B9103262CDB941F77376F5D3DBB7A3D5A387797FC4819A035ECA704CEDB37110EE7F206B0C8805AAEBF4963E7C4708CE8D4E092366E71792A8A3B2BBCDEE321B3E15380C541EF0930888969F7457AFE18588826A419D58311C1784B5484EECDB393F6A0ACA11B91DF0866B500B8DEE501FD7EB9BCE09A17D74124B4605ADFC0777BED9816D8D7E8488544A18D8045CB3283B0A752B881B5F500FADB59010E63D",
                "039E43C9810E6CC09F46AAD38E716DAE3191629534967DC457D3A687D2E2CDDC6A",
                "0F494B8312E8D257E51730C78F8FE3B47B6840C59AAAEC7C2EBE404A2DE8B25A",
                "532B2267C4A3054F380B3357339BDFB379E88366FE61B42ACA05F69BC3F6F54E",
                "3AF3D288E830E96FF8ED0769F45ABDA774CD989E2AE32EF9E985C8505F14FF98",
                "E191EB14A70B5B53ADA45AFFF4A04578F5D8BB2B1C8A22985EA159B53826CDE7",
            ),
            (
                "1B664F8BDA2DBF33CB6BE21C8EB3ECA9D9D5BF144C08E9577ED0D1E5E560875109B340980580473DBC2E689A3BE838E77A0A3348FE960EC9BF81DA36F1868CA5D24788FA4C0C778BF0D12314285495636516CF40861B3D737FD35DBB591C5B5D25916EB1D86176B14E0E67D2D03957F0CF6C87834BF328540588360BA7C7C5F88541634FB7BADE5F94FF671D1FEBDCBDA116D2DA779038ED7679896C29198B2657B58C50EA054F644F4129C8BA8D8D544B727633DD40754398046796E038626FEF9237CE5B615BC08677EE5ABFBD85F73F7F8868CB1B5FBA4C1309F16061AA133821FBE2A758D2BBE6AA040A940D41B7D3B869CEE945150AA4A40E6FF719EEC24B2681CD5CE06B50273436584066046656D5EFED7315759189D68815DDB9E5F8D7FD53B6EC096616A773B9421F6704CED36EF4E484BA0C6C5A4855C71C33A54AC82BE803E5CFD175779FC444B7E6AA9001EEFABEBC0CF99754887C7B0A27AFDDC415F8A02C5AF1EFEA26AD1E5D92B1E29A8FAF5B2186C3094F4A137BCFAA65D7B274214DB64C86F3085B24938E1832FB310A6F064181E298D23062ABC817BA173023C8C04C5C3A1ECBF4AF72372B381FF69865C8F0E3C70B931C45A7419B3C441842EBFACC3D070AC3B433CD120B6E85B72DADCF40B23B173C34F6BE1B1901F6621F1497B085CF8E999D986EF8FF3A889A0238979983A8686F69E10EF9249A87",
                "0245DC2911EDC02F2774E0A40FBEB0112EA60BF513F9EC50889D59FC94C97EC18F",
                "8D566BB87EF69FFDA622E0A59FBAAFE57F486CE65844343A5D9B97DE9C4F619A",
                "948AFFFF6E068CA2F2757BFD6085D6E4C3084B038E5533C5927ECB19EA0D329C",
                "DFEE66E2C4799E73F0F778126A23032608408C27C2E7B3FA45A626BB9BDEB53C",
                "75445CC9DBFE4E7BC64E020FA22CACFA4C40D5AA84DD6AEF661564FCA9746C40",
            ),
            (
                "3444C8501F19A8A78670F748FA401C4020AE086D7157A3837EC721DEF0D6E095928C5B78ED9B95560CE33D5B22778BE66DCEF2D21878D481DFF41A4DEDCAFDCAEAB4BD78629D7EC40FD26F1DD954CA84A3B53B84E9903056E840837A1390F37BB8ADE799DAC1E465D811916547EB4B6A163082E9833634A1224C54F681B8DC70A792C0CB4671D4970CCC80E2168CE920CC8FA07B1F90E9898D16019913ED5B8EE8A8DE7AB6F7895601FD20E49FD73E6F5D24C0D97E67871539F0E4E32CCB6677AFF03356D1F3790945E94039E51A63B3C840B74E3053D95CA71C0D3AC20A9065828D30AB5BFB6188A8F291FB1EB4E1EED03E2F5F558C00D8E3084120DEEB8BFE908429B36A896A45D624E79372CC18DF37DB2D20C9726D4FEF7BECF220138B53BC54C2DA461A9955AFF33F2F93DD96464BF3E883FC5750BDBE79BC2F82427F41DE42659AC4B111D7CEF8085003469DF8C9D3541480C6841707CE4C8F3D003AF982AD35C2733D0FA3B1EE52A6DAB36203D99AEC179A565B5050F480235C3BC560AA28EF5DD5525BFA254E584A86FDBD4BCC5B56551BAD00255CB72F806D7F3C533321B0864007AFBA4E0FF9638517FA8D788F52766F3A28C57C428BFDD4234AA760CE8044DF1E1FBA58E8B1D9C5A79D2AC4592FC31702F7E83351D2160C09C5CEA554F2C93A61C040E225612DF2B550900B097E18638350E3BA15C9AD53CE1861",
                "02237627FE7374061FBD80AEA842DCE76D9206F0DDC7B319F3B30FA75DBD4F009A",
                "009755F442D66585A10B80A49850C77764AD029D1BEA73F4DA45AB331306E6E5",
                "2D78C77B736AD0A00FDF60695C01E96520656C13DC890A5B864672C6CED1C49A",
                "4B73D4D919D7B4DEF330391899EA02023851CABE044E34E18EAE3E10588CECCD",
                "D5DE85C4BDEA5910DC36AEF5660774D65291322C1E87FDA0D00C864E8C5FED29",
            ),
        ];
        for (message, public_key, secret_key, k, r, s) in cases {
            let k =
                Scalar::from_repr(FieldBytes::clone_from_slice(&hex::decode(k).unwrap())).unwrap();
            let message = hex::decode(message).unwrap();
            let secret_key = SecretKey::from_slice(&hex::decode(secret_key).unwrap()).unwrap();
            let public_key = PublicKey::from_sec1_bytes(&hex::decode(public_key).unwrap()).unwrap();

            let signature = sign_inner(k, &message, &secret_key).unwrap();

            assert_eq!(signature.r().to_string(), r);
            assert_eq!(signature.s().to_string(), s);

            assert!(verify(&message, public_key, signature).is_some());
        }
    }
}

```

`zilliqa/src/scilla.rs`:

```rs
//! Interface to the Scilla intepreter

use std::{
    collections::BTreeMap,
    fs,
    path::Path,
    str,
    sync::{
        Arc, Mutex,
        mpsc::{Receiver, Sender, channel},
    },
    thread,
    time::Duration,
};

use alloy::{hex::ToHexExt, primitives::Address};
use anyhow::{Result, anyhow};
use base64::Engine;
use bytes::{BufMut, Bytes, BytesMut};
use jsonrpsee::{
    IntoResponse, MethodCallback, MethodResponse, RpcModule,
    core::{ClientError, RegisterMethodError, client::ClientT, params::ObjectParams},
    http_client::HttpClientBuilder,
    server::ServerHandle,
    types::{ErrorObject, Params, error::CALL_EXECUTION_FAILED_CODE},
};
use prost::Message as _;
use rand::{Rng, distributions::Alphanumeric};
use revm::primitives::BLOCK_HASH_HISTORY;
use serde::{
    Deserialize, Deserializer, Serialize,
    de::{self, Unexpected},
};
use serde_json::Value;
use sha2::Sha256;
use sha3::{Digest, digest::DynDigest};
use tokio::runtime;
use tracing::trace;

use crate::{
    cfg::{Fork, ScillaExtLibsPathInScilla},
    crypto::Hash,
    exec::{PendingState, StorageValue},
    scilla_proto::{self, ProtoScillaQuery, ProtoScillaVal, ValType},
    serde_util::{bool_as_str, num_as_str},
    state::{Code, ContractInit},
    time::SystemTime,
    transaction::{ScillaGas, ZilAmount},
};

#[derive(PartialEq, Debug)]
enum ScillaServerRequestType {
    Check,
    Run,
}

#[derive(Debug)]
struct ScillaServerRequestBuilder {
    request_type: ScillaServerRequestType,
    init: Option<String>,
    message: Option<String>,
    lib_dirs: Option<Vec<String>>,
    code: Option<String>,
    gas_limit: Option<String>,
    ipc_address: Option<String>,
    balance: Option<String>,
    is_library: bool,
    contract_info: bool,
    json_errors: bool,
    pplit: bool,
}

impl ScillaServerRequestBuilder {
    fn new(request_type: ScillaServerRequestType) -> Self {
        Self {
            request_type,
            init: None,
            lib_dirs: None,
            code: None,
            message: None,
            gas_limit: None,
            balance: None,
            ipc_address: None,
            is_library: false,
            contract_info: false,
            json_errors: false,
            pplit: false,
        }
    }

    fn init(mut self, init: String) -> Self {
        self.init = Some(init);
        self
    }

    fn message(mut self, msg: &Value) -> Result<Self> {
        self.message = Some(serde_json::to_string(&msg)?);
        Ok(self)
    }

    fn lib_dirs(mut self, lib_dirs: Vec<String>) -> Self {
        self.lib_dirs = Some(lib_dirs);
        self
    }

    fn code(mut self, code: String) -> Self {
        self.code = Some(code);
        self
    }

    fn ipc_address(mut self, ipc_address: String) -> Self {
        self.ipc_address = Some(ipc_address);
        self
    }

    fn gas_limit(mut self, gas_limit: ScillaGas) -> Self {
        self.gas_limit = Some(gas_limit.to_string());
        self
    }

    fn balance(mut self, balance: ZilAmount) -> Self {
        self.balance = Some(balance.to_string());
        self
    }

    fn pplit(mut self, pplit: bool) -> Self {
        self.pplit = pplit;
        self
    }

    #[allow(clippy::wrong_self_convention)]
    fn is_library(mut self, is_library: bool) -> Self {
        self.is_library = is_library;
        self
    }

    fn contract_info(mut self, contract_info: bool) -> Self {
        self.contract_info = contract_info;
        self
    }

    fn json_errors(mut self, json_errors: bool) -> Self {
        self.json_errors = json_errors;
        self
    }

    fn build(self) -> Result<(&'static str, ObjectParams)> {
        let mut args = vec![];

        if let Some(init) = self.init {
            args.extend(["-init".to_owned(), init]);
        }

        if let Some(lib_dirs) = self.lib_dirs {
            args.extend(["-libdir".to_owned(), lib_dirs.join(":")]);
        }

        if let Some(ipc_address) = self.ipc_address {
            args.extend(["-ipcaddress".to_owned(), ipc_address])
        }

        if let Some(balance) = self.balance {
            args.extend(["-balance".to_owned(), balance]);
        }

        if let Some(message) = self.message {
            args.extend(["-imessage".to_owned(), message]);
        }

        if let Some(code) = self.code {
            // Check request doesn't need `-i` for input code.
            if self.request_type == ScillaServerRequestType::Run {
                args.push("-i".to_owned());
            }
            args.push(code);
        }

        if let Some(gas_limit) = self.gas_limit {
            args.extend(vec!["-gaslimit".to_owned(), gas_limit.to_string()]);
        }

        if self.contract_info {
            args.push("-contractinfo".to_owned());
        }

        if self.json_errors {
            args.push("-jsonerrors".to_owned());
        }

        if self.is_library {
            args.push("-islibrary".to_owned());
            if self.request_type == ScillaServerRequestType::Run {
                // Check request doesn't need `true` if -islibrary is specified.
                args.push("true".to_owned());
            }
        }
        if self.pplit {
            args.extend(vec!["-pplit".to_owned(), "true".to_owned()]);
        }

        let request_type = match self.request_type {
            ScillaServerRequestType::Check => "check",
            ScillaServerRequestType::Run => "run",
        };

        let mut params = ObjectParams::new();
        params.insert("argv", args)?;

        Ok((request_type, params))
    }
}

/// The interface to the Scilla interpreter.
#[derive(Debug)]
pub struct Scilla {
    request_tx: Sender<(&'static str, ObjectParams)>,
    response_rx: Mutex<Receiver<Result<Value, ClientError>>>,
    state_server: Arc<Mutex<StateServer>>,
    scilla_stdlib_dir: String,
}

impl Scilla {
    const MAX_ATTEMPTS: u8 = 3; // effective time is up to MAX_ATTEMPTS * REQ_TIMEOUT.
    const REQ_TIMEOUT: Duration = Duration::from_secs(120); // effective time should be kept below gossip/request timeouts.

    /// Create a new Scilla interpreter. This involves spawning two threads:
    /// 1. The client thread, responsible for communicating with the server.
    /// 2. The state IPC thread, responsible for serving state requests from the running Scilla server.
    ///
    /// # Client thread
    ///
    /// This thread starts an event loop which waits for JSON-RPC requests, forwards them to the server and sends the
    /// response back. Communication with the main thread is performed via two MPSC channels (one for requests and one
    /// for responses).
    ///
    /// If the other half of either channel is dropped by the main thread, we terminate.
    ///
    /// # State IPC thread
    ///
    /// This runs a JSON-RPC server at a random port. The address of this server is communicated to the Scilla server
    /// in each request (in the `-ipcaddress` argument). The server is implemented by [StateServer].
    ///
    /// After creating the [StateServer], we wrap it in an `Arc<Mutex<T>>` and send a clone back to the main thread,
    /// to enable shared access to the server.
    pub fn new(address: String, socket_dir: String, scilla_stdlib_dir: String) -> Scilla {
        let (request_tx, request_rx) = channel();
        let (response_tx, response_rx) = channel();

        thread::spawn(move || {
            let runtime = runtime::Builder::new_current_thread()
                .enable_all()
                .build()
                .unwrap();
            let client = HttpClientBuilder::default()
                .request_timeout(Self::REQ_TIMEOUT)
                .build(format!("{address}/run"))
                .unwrap();

            loop {
                let Ok((method, params)) = request_rx.recv() else {
                    break;
                };
                let response = runtime.block_on(client.request(method, params));
                let Ok(()) = response_tx.send(response) else {
                    break;
                };
            }
        });

        let (tx, rx) = channel();
        thread::spawn(move || {
            let runtime = runtime::Builder::new_current_thread()
                .enable_all()
                .build()
                .unwrap();

            runtime.block_on(async {
                let server = StateServer::new(&socket_dir).await.unwrap();
                let handle = server.handle.clone();
                let server = Arc::new(Mutex::new(server));
                tx.send(Arc::clone(&server)).unwrap();
                handle.stopped().await
            });
        });
        let state_server = rx.recv().unwrap();

        Scilla {
            request_tx,
            response_rx: Mutex::new(response_rx),
            state_server,
            scilla_stdlib_dir,
        }
    }

    fn state_server_addr(&self) -> String {
        self.state_server.lock().unwrap().endpoint.clone()
    }

    pub fn check_contract(
        &self,
        code: &str,
        gas_limit: ScillaGas,
        init: &ContractInit,
        ext_libs_dir: &ScillaExtLibsPathInScilla,
    ) -> Result<Result<CheckOutput, ErrorResponse>> {
        let mut attempt = 1;
        let response = loop {
            let request = ScillaServerRequestBuilder::new(ScillaServerRequestType::Check)
                .init(init.to_string())
                .lib_dirs(vec![self.scilla_stdlib_dir.clone(), ext_libs_dir.0.clone()])
                .code(code.to_owned())
                .gas_limit(gas_limit)
                .contract_info(true)
                .json_errors(true)
                .is_library(init.is_library()?)
                .build()?;

            tracing::debug!(%attempt,"Check attempt");
            self.request_tx.send(request)?;
            let response = self.response_rx.lock().unwrap().recv()?;

            match response {
                Ok(r) => break r,
                Err(ClientError::Call(e)) => break serde_json::from_str(e.message())?,
                Err(ClientError::RequestTimeout) if attempt < Self::MAX_ATTEMPTS => {
                    tracing::warn!(%attempt, "Check retry");
                    attempt += 1;
                }
                Err(e) => {
                    return Err(anyhow!("{e:?}"));
                }
            };
        };

        trace!(?response, "Check response");

        // Sometimes Scilla returns a JSON object within a JSON string. Sometimes it doesn't...
        let response = if let Some(response) = response.as_str() {
            serde_json::from_str(response)?
        } else {
            response
        };

        #[derive(Deserialize)]
        #[serde(untagged)]
        enum OutputOrError {
            Err(ErrorResponse),
            Output(CheckOutput),
        }

        match serde_json::from_value(response)? {
            OutputOrError::Err(e) => Ok(Err(e)),
            OutputOrError::Output(response) => Ok(Ok(response)),
        }
    }

    #[allow(clippy::too_many_arguments)]
    pub fn create_contract(
        &self,
        state: PendingState,
        sender: Address,
        code: &str,
        gas_limit: ScillaGas,
        value: ZilAmount,
        init: &ContractInit,
        ext_libs_dir: &ScillaExtLibsPathInScilla,
        fork: &Fork,
        current_block: u64,
    ) -> Result<(Result<CreateOutput, ErrorResponse>, PendingState)> {
        let mut attempt = 1;
        let (response, state) = loop {
            let pending_state = state.clone();

            let request = ScillaServerRequestBuilder::new(ScillaServerRequestType::Run)
                .ipc_address(self.state_server_addr())
                .init(init.to_string())
                .lib_dirs(vec![self.scilla_stdlib_dir.clone(), ext_libs_dir.0.clone()])
                .code(code.to_owned())
                .gas_limit(gas_limit)
                .balance(value)
                .json_errors(true)
                .is_library(init.is_library()?)
                .build()?;

            tracing::debug!(%attempt,"Create attempt");
            let (response, state) = self.state_server.lock().unwrap().active_call(
                sender,
                pending_state,
                current_block,
                fork,
                || {
                    self.request_tx.send(request)?;
                    Ok(self.response_rx.lock().unwrap().recv()?)
                },
            )?;

            match response {
                Ok(r) => break (r, state),
                Err(ClientError::Call(e)) => break (serde_json::from_str(e.message())?, state),
                Err(ClientError::RequestTimeout) if attempt < Self::MAX_ATTEMPTS => {
                    tracing::warn!(%attempt, "Create retry");
                    attempt += 1;
                }
                Err(e) => {
                    return Err(anyhow!("{e:?}"));
                }
            };
        };

        trace!(?response, "Create response");

        // Sometimes Scilla returns a JSON object within a JSON string. Sometimes it doesn't...
        let response = if let Some(response) = response.as_str() {
            serde_json::from_str(response)?
        } else {
            response
        };

        #[derive(Deserialize)]
        #[serde(untagged)]
        enum OutputOrError {
            Err(ErrorResponse),
            Output(CreateOutput),
        }

        match serde_json::from_value(response)? {
            OutputOrError::Err(e) => Ok((Err(e), state)),
            OutputOrError::Output(response) => Ok((Ok(response), state)),
        }
    }

    #[allow(clippy::too_many_arguments)]
    pub fn invoke_contract(
        &self,
        state: PendingState,
        contract: Address,
        code: &str,
        gas_limit: ScillaGas,
        contract_balance: ZilAmount,
        init: &ContractInit,
        msg: &Value,
        ext_libs_dir: &ScillaExtLibsPathInScilla,
        fork: &Fork,
        current_block: u64,
    ) -> Result<(Result<InvokeOutput, ErrorResponse>, PendingState)> {
        let mut attempt = 1;
        let (response, state) = loop {
            let pending_state = state.clone();

            let request = ScillaServerRequestBuilder::new(ScillaServerRequestType::Run)
                .init(init.to_string())
                .ipc_address(self.state_server_addr())
                .lib_dirs(vec![self.scilla_stdlib_dir.clone(), ext_libs_dir.0.clone()])
                .code(code.to_owned())
                .message(msg)?
                .balance(contract_balance)
                .gas_limit(gas_limit)
                .json_errors(true)
                .pplit(true)
                .build()?;

            tracing::debug!(%attempt,"Invoke attempt");
            let (response, state) = self.state_server.lock().unwrap().active_call(
                contract,
                pending_state,
                current_block,
                fork,
                || {
                    self.request_tx.send(request)?;
                    Ok(self.response_rx.lock().unwrap().recv()?)
                },
            )?;

            match response {
                Ok(r) => break (r, state),
                Err(ClientError::Call(e)) => break (serde_json::from_str(e.message())?, state),
                Err(ClientError::RequestTimeout) if attempt < Self::MAX_ATTEMPTS => {
                    tracing::warn!(%attempt, "Invoke retry");
                    attempt += 1;
                }
                Err(e) => return Err(anyhow!("{e:?}")),
            };
        };

        trace!(?response, "Invoke response");

        // Sometimes Scilla returns a JSON object within a JSON string. Sometimes it doesn't...
        let mut response: Value = if let Some(response) = response.as_str() {
            serde_json::from_str(response)?
        } else {
            serde_json::from_value(response)?
        };
        if !fork.scilla_json_preserve_order {
            response.sort_all_objects();
        }

        #[derive(Deserialize)]
        #[serde(untagged)]
        enum OutputOrError {
            Err(ErrorResponse),
            Output(InvokeOutput),
        }

        match serde_json::from_value(response)? {
            OutputOrError::Err(e) => Ok((Err(e), state)),
            OutputOrError::Output(response) => Ok((Ok(response), state)),
        }
    }
}

#[derive(Debug, Deserialize)]
pub struct CheckOutput {
    #[serde(with = "num_as_str")]
    pub gas_remaining: ScillaGas,
    pub contract_info: Option<ContractInfo>, // It's not included in the response for scilla libraries.
}

#[derive(Debug, Deserialize)]
pub struct Error {
    pub start_location: Location,
    pub error_message: String,
}

#[derive(Debug, Deserialize)]
pub struct Location {
    pub line: u64,
}

#[derive(Debug, Deserialize, Default)]
pub struct ContractInfo {
    pub scilla_major_version: String,
    pub fields: Vec<Param>,
    pub transitions: Vec<Transition>,
}

#[derive(Clone, Debug, Deserialize, Serialize, Default)]
pub struct Transition {
    #[serde(rename = "vname")]
    pub name: String,
    pub params: Vec<TransitionParam>,
}

#[derive(Clone, Debug, Deserialize, Serialize, Default)]
pub struct TransitionParam {
    #[serde(rename = "vname")]
    pub name: String,
    #[serde(rename = "type")]
    pub ty: String,
}

#[derive(Clone, Debug, Deserialize, Serialize)]
pub struct Param {
    #[serde(rename = "vname")]
    pub name: String,
    pub depth: u64,
    #[serde(rename = "type")]
    pub ty: String,
}

#[derive(Debug, Deserialize)]
pub struct CreateOutput {
    #[serde(with = "num_as_str")]
    pub gas_remaining: ScillaGas,
}

#[derive(Debug, Deserialize)]
pub struct ErrorResponse {
    pub errors: Vec<Error>,
    #[serde(with = "num_as_str")]
    pub gas_remaining: ScillaGas,
}

#[derive(Debug, Deserialize)]
pub struct InvokeOutput {
    #[serde(rename = "_accepted", with = "bool_as_str")]
    pub accepted: bool,
    #[serde(default)]
    pub messages: Vec<Message>,
    #[serde(default)]
    pub events: Vec<ScillaEvent>,
    #[serde(with = "num_as_str")]
    pub gas_remaining: ScillaGas,
}

#[derive(Debug, Deserialize)]
pub struct ScillaEvent {
    #[serde(rename = "_eventname")]
    pub event_name: String,
    pub params: Vec<ParamValue>,
}

#[derive(Clone, Debug, PartialEq, Eq, Deserialize, Serialize)]
pub struct ParamValue {
    #[serde(rename = "vname")]
    pub name: String,
    pub value: Value,
    #[serde(rename = "type")]
    pub ty: String,
}

impl ParamValue {
    pub fn compute_hash(&self) -> Hash {
        Hash::builder()
            .with(self.ty.as_bytes())
            .with(self.value.to_string().as_bytes())
            .with(self.name.as_bytes())
            .finalize()
    }
}

#[derive(Debug, Deserialize)]
pub struct Message {
    #[serde(rename = "_tag")]
    pub tag: String,
    #[serde(rename = "_amount", with = "num_as_str")]
    pub amount: ZilAmount,
    #[serde(rename = "_recipient")]
    pub recipient: Address,
    pub params: Value,
}

#[derive(Debug)]
struct StateServer {
    endpoint: String,
    handle: ServerHandle,
    /// This should be `Some` when a call is being made to the Scilla server. It stores the current contract address
    /// and state.
    active_call: Arc<Mutex<Option<ActiveCall>>>,
}

impl StateServer {
    async fn new(socket_dir: &str) -> Result<StateServer> {
        fs::create_dir_all(socket_dir)?;
        let mut path = "scilla-state-server-".to_owned();
        let suffix: String = rand::thread_rng()
            .sample_iter(Alphanumeric)
            .take(6)
            .map(char::from)
            .collect();
        path.push_str(&suffix);
        let endpoint = Path::new(socket_dir)
            .join(path)
            .to_str()
            .unwrap()
            .to_owned();

        let server = reth_ipc::server::Builder::default()
            .max_response_body_size(1024 * 1024 * 1024) // 1 GiB
            .build(endpoint.clone());

        let mut module = RpcModule::new(());

        fn de_b64<'de, D: Deserializer<'de>>(d: D) -> Result<Vec<u8>, D::Error> {
            let b64 = base64::engine::general_purpose::STANDARD;

            let s = String::deserialize(d)?;
            b64.decode(&s)
                .map_err(|_| de::Error::invalid_value(Unexpected::Str(&s), &"a base64 string"))
        }

        fn err(e: impl ToString) -> ErrorObject<'static> {
            ErrorObject::owned(CALL_EXECUTION_FAILED_CODE, e.to_string(), None::<()>)
        }

        let active_call: Arc<Mutex<Option<ActiveCall>>> = Arc::new(Mutex::new(None));

        fn register_method<F>(
            module: &mut RpcModule<()>,
            active_call: Arc<Mutex<Option<ActiveCall>>>,
            method_name: &'static str,
            callback: F,
        ) -> Result<(), RegisterMethodError>
        where
            F: Fn(Params<'_>, &mut ActiveCall) -> Result<Value, ErrorObject<'static>>
                + Send
                + Sync
                + 'static,
        {
            // Copied from `RpcModule::register_method`. This custom version overrides the response size limit when the
            // fork tells us to.
            module.verify_and_insert(
                method_name,
                MethodCallback::Sync(Arc::new(
                    move |id, params, max_response_size, extensions| {
                        let mut active_call = active_call.lock().unwrap();

                        let Some(active_call) = active_call.as_mut() else {
                            return MethodResponse::response::<()>(
                                id,
                                Err(err("no active call")).into_response(),
                                max_response_size,
                            )
                            .with_extensions(extensions);
                        };

                        // If the unlimited response size fork is NOT activated, override the configured response size with a
                        // smaller one of 10 MiB.
                        let max_response_size = if active_call.scilla_server_unlimited_response_size
                        {
                            max_response_size
                        } else {
                            10 * 1024 * 1024 // 10 MiB
                        };

                        let rp = callback(params, active_call).into_response();
                        MethodResponse::response(id, rp, max_response_size)
                            .with_extensions(extensions)
                    },
                )),
            )?;
            Ok(())
        }

        register_method(
            &mut module,
            Arc::clone(&active_call),
            "fetchStateValueB64",
            |params, active_call| {
                let b64 = base64::engine::general_purpose::STANDARD;
                #[derive(Deserialize)]
                struct Params {
                    #[serde(deserialize_with = "de_b64")]
                    query: Vec<u8>,
                }

                let Params { query } = params.parse()?;
                let ProtoScillaQuery { name, indices, .. } =
                    ProtoScillaQuery::decode(query.as_slice()).map_err(err)?;

                let value = active_call.fetch_state_value(name, indices).map_err(err)?;

                let result = match value {
                    Some(v) => vec![true.into(), b64.encode(v.encode_to_vec()).into()],
                    None => vec![false.into(), String::new().into()],
                };

                Ok(Value::Array(result))
            },
        )?;

        register_method(
            &mut module,
            Arc::clone(&active_call),
            "fetchExternalStateValueB64",
            |params, active_call| {
                let b64 = base64::engine::general_purpose::STANDARD;
                #[derive(Deserialize)]
                struct Params {
                    addr: Address,
                    #[serde(deserialize_with = "de_b64")]
                    query: Vec<u8>,
                }

                let Params { addr, query } = params.parse()?;
                let ProtoScillaQuery { name, indices, .. } =
                    ProtoScillaQuery::decode(query.as_slice()).map_err(err)?;

                let value = active_call
                    .fetch_external_state_value(addr, name, indices)
                    .map_err(err)?;

                let result = match value {
                    Some((v, ty)) => {
                        vec![true.into(), b64.encode(v.encode_to_vec()).into(), ty.into()]
                    }
                    None => vec![false.into(), String::new().into(), String::new().into()],
                };

                Ok(Value::Array(result))
            },
        )?;
        register_method(
            &mut module,
            Arc::clone(&active_call),
            "updateStateValueB64",
            |params, active_call| {
                #[derive(Deserialize)]
                struct Params {
                    #[serde(deserialize_with = "de_b64")]
                    query: Vec<u8>,
                    #[serde(deserialize_with = "de_b64")]
                    value: Vec<u8>,
                }

                let Params { query, value } = params.parse()?;
                let ProtoScillaQuery {
                    name,
                    mapdepth: _,
                    indices,
                    ignoreval,
                } = ProtoScillaQuery::decode(query.as_slice()).map_err(err)?;
                let value = ProtoScillaVal::decode(value.as_slice()).map_err(err)?;

                match active_call.update_state_value(name, indices, ignoreval, value) {
                    Ok(()) => Ok(Value::Null),
                    Err(e) => Err(err(e)),
                }
            },
        )?;
        register_method(
            &mut module,
            Arc::clone(&active_call),
            "fetchBlockchainInfo",
            |params, active_call| {
                #[derive(Deserialize)]
                struct Params {
                    query_name: String,
                    query_args: String,
                }

                let Params {
                    query_name,
                    query_args,
                } = params.parse()?;

                match active_call.fetch_blockchain_info(query_name, query_args) {
                    Ok((present, value)) => Ok(Value::Array(vec![present.into(), value.into()])),
                    Err(e) => Err(err(e)),
                }
            },
        )?;

        let handle = server.start(module).await?;

        Ok(StateServer {
            endpoint,
            handle,
            active_call,
        })
    }

    fn active_call<R>(
        &mut self,
        sender: Address, // TODO: rename
        state: PendingState,
        current_block: u64,
        fork: &Fork,
        f: impl FnOnce() -> Result<R>,
    ) -> Result<(R, PendingState)> {
        {
            let mut active_call = self.active_call.lock().unwrap();
            *active_call = Some(ActiveCall {
                sender,
                state,
                current_block,
                scilla_block_number_returns_current_block: fork
                    .scilla_block_number_returns_current_block,
                scilla_maps_are_encoded_correctly: fork.scilla_maps_are_encoded_correctly,
                scilla_server_unlimited_response_size: fork.scilla_server_unlimited_response_size,
            });
        }

        let response = f()?;

        let mut active_call = self.active_call.lock().unwrap();
        let ActiveCall { state, .. } = active_call.take().unwrap();
        Ok((response, state))
    }
}

// Scilla values are stored on disk in a flattened structure. We concatenate the indices that locate a given value.
// Each index is separated by a `0x1F` (ASCII unit separator) byte. This is currently safe, because this byte cannot
// occur in Scilla values, but we include an assertion to make sure this remains true.

// Separate each index with the ASCII unit separator byte.
const SEPARATOR: u8 = 0x1F;

pub fn storage_key(var_name: &str, indices: &[Vec<u8>]) -> Bytes {
    let len = var_name.len() + indices.len() + indices.iter().map(|v| v.len()).sum::<usize>();
    let mut bytes = BytesMut::with_capacity(len);
    bytes.extend_from_slice(var_name.as_bytes());
    for index in indices {
        assert!(!index.contains(&SEPARATOR));
        bytes.put_u8(SEPARATOR);
        bytes.extend_from_slice(index.as_slice());
    }
    bytes.freeze()
}

pub fn split_storage_key(key: impl AsRef<[u8]>) -> Result<(String, Vec<Vec<u8>>)> {
    let mut parts = key.as_ref().split(|b| *b == SEPARATOR);
    let var_name = parts.next().expect("split always returns one element");
    let var_name = String::from_utf8(var_name.to_vec())?;
    let indices = parts.map(|s| s.to_vec()).collect();

    Ok((var_name, indices))
}

#[derive(Debug)]
struct ActiveCall {
    sender: Address,
    state: PendingState,
    current_block: u64,
    scilla_block_number_returns_current_block: bool,
    scilla_maps_are_encoded_correctly: bool,
    scilla_server_unlimited_response_size: bool,
}

impl ActiveCall {
    fn fetch_value_inner(
        &mut self,
        addr: Address,
        name: String,
        indices: Vec<Vec<u8>>,
    ) -> Result<Option<(ProtoScillaVal, String)>> {
        let (ty, depth) = self.state.load_var_info(addr, &name)?;
        let ty = ty.to_owned();

        if indices.len() > depth as usize {
            return Err(anyhow!("too many indices"));
        }

        let value = if depth as usize == indices.len() {
            let value = self.state.load_storage(addr, &name, &indices)?.clone();
            let Some(value) = value else {
                return Ok(None);
            };
            ProtoScillaVal {
                val_type: Some(ValType::Bval(value.to_vec())),
            }
        } else {
            let mut value = self.state.load_storage_by_prefix(addr, &name, &indices)?;

            fn convert(
                scilla_maps_are_encoded_correctly: bool,
                value: BTreeMap<Vec<u8>, StorageValue>,
            ) -> ProtoScillaVal {
                ProtoScillaVal::map(
                    value
                        .into_iter()
                        .filter_map(|(k, v)| {
                            let k = if scilla_maps_are_encoded_correctly {
                                String::from_utf8(k).unwrap()
                            } else {
                                serde_json::from_slice(&k).ok()?
                            };
                            Some((
                                k,
                                match v {
                                    StorageValue::Map { map, complete } => {
                                        assert!(complete);
                                        convert(scilla_maps_are_encoded_correctly, map)
                                    }
                                    StorageValue::Value(Some(value)) => {
                                        ProtoScillaVal::bytes(value.into())
                                    }
                                    StorageValue::Value(None) => {
                                        return None;
                                    }
                                },
                            ))
                        })
                        .collect(),
                )
            }

            if self.scilla_maps_are_encoded_correctly {
                for index in &indices {
                    if let Some(StorageValue::Map { map: inner_map, .. }) = value.remove(index) {
                        value = inner_map;
                    } else {
                        break;
                    }
                }
            }

            convert(self.scilla_maps_are_encoded_correctly, value)
        };

        Ok(Some((value, ty)))
    }

    fn fetch_state_value(
        &mut self,
        name: String,
        indices: Vec<Vec<u8>>,
    ) -> Result<Option<ProtoScillaVal>> {
        let result = self
            .fetch_value_inner(self.sender, name, indices)?
            .map(|(v, _)| v);
        Ok(result)
    }

    fn fetch_external_state_value(
        &mut self,
        addr: Address,
        name: String,
        indices: Vec<Vec<u8>>,
    ) -> Result<Option<(ProtoScillaVal, String)>> {
        fn scilla_val(b: Vec<u8>) -> ProtoScillaVal {
            ProtoScillaVal {
                val_type: Some(ValType::Bval(b)),
            }
        }

        let account = self.state.load_account(addr)?;
        let result = match name.as_str() {
            "_balance" => {
                let balance = ZilAmount::from_amount(account.account.balance);
                let val = scilla_val(format!("\"{balance}\"").into_bytes());
                Ok(Some((val, "Uint128".to_owned())))
            }
            "_nonce" => {
                let val = scilla_val(format!("\"{}\"", account.account.nonce + 1).into_bytes());
                Ok(Some((val, "Uint64".to_owned())))
            }
            "_this_address" => {
                let val = scilla_val(format!("\"0x{:#x}\"", addr).into_bytes());
                Ok(Some((val, "ByStr20".to_owned())))
            }
            "_codehash" => {
                let code_bytes = match &account.account.code {
                    Code::Evm(bytes) => bytes.clone(),
                    Code::Scilla { code, .. } => code.clone().into_bytes(),
                };

                let mut hasher = Sha256::new();
                DynDigest::update(&mut hasher, &code_bytes);

                let mut hash = [0u8; 32];
                DynDigest::finalize_into(hasher, &mut hash[..]).unwrap();

                let val = scilla_val(format!("\"0x{}\"", hash.encode_hex()).into_bytes());
                Ok(Some((val, "ByStr32".to_owned())))
            }
            _ => self.fetch_value_inner(addr, name.clone(), indices.clone()),
        }?;

        Ok(result)
    }

    fn update_state_value(
        &mut self,
        name: String,
        indices: Vec<Vec<u8>>,
        ignore_value: bool,
        value: ProtoScillaVal,
    ) -> Result<()> {
        let (_, depth) = self.state.load_var_info(self.sender, &name)?;
        let depth = depth as usize;

        if indices.len() > depth {
            return Err(anyhow!("too many indices"));
        }

        if ignore_value {
            assert!(indices.len() <= depth);
            // Remove single element
            if indices.len() == depth {
                let storage_slot = self.state.load_storage(self.sender, &name, &indices)?;
                *storage_slot = None;
            } else {
                // Remove multiple elements from storage having the same prefix specified by `indices`

                self.state.set_storage(
                    self.sender,
                    &name,
                    &indices,
                    StorageValue::complete_map(),
                )?;
            }
        } else if indices.len() == depth {
            let Some(ValType::Bval(value)) = value.val_type else {
                return Err(anyhow!("invalid value"));
            };
            let storage_slot = self.state.load_storage(self.sender, &name, &indices)?;
            *storage_slot = Some(value.into());
        } else {
            fn convert(value: ProtoScillaVal) -> Result<StorageValue> {
                let Some(value) = value.val_type else {
                    return Err(anyhow!("missing val_type"));
                };
                match value {
                    ValType::Bval(bytes) => Ok(StorageValue::Value(Some(bytes.into()))),
                    ValType::Mval(scilla_proto::Map { m }) => {
                        let map = m
                            .into_iter()
                            .map(|(k, v)| Ok((k.into_bytes(), convert(v)?)))
                            .collect::<Result<_>>()?;
                        Ok(StorageValue::Map {
                            map,
                            // Note that we mark the map as complete here. The field has been fully overridden and any
                            // existing values should be deleted.
                            complete: true,
                        })
                    }
                }
            }

            self.state
                .set_storage(self.sender, &name, &indices, convert(value)?)?;
        }
        self.state.touch(self.sender);

        Ok(())
    }

    fn fetch_blockchain_info(&self, name: String, args: String) -> Result<(bool, String)> {
        let (exists, value) = match name.as_str() {
            "CHAINID" => Ok((true, self.state.zil_chain_id().to_string())),
            "BLOCKNUMBER" => {
                if self.scilla_block_number_returns_current_block {
                    Ok((true, self.current_block.to_string()))
                } else {
                    Ok((true, self.current_block.saturating_sub(1).to_string()))
                }
            }
            "BLOCKHASH" => {
                let block_number = args.parse()?;
                let Some(diff) = self.current_block.checked_sub(block_number) else {
                    return Ok((false, "".to_string()));
                };
                // We should return nothing if requested number is the same as the current number.
                if diff == 0 {
                    return Ok((false, "".to_string()));
                }
                if diff <= BLOCK_HASH_HISTORY {
                    return Ok((false, "".to_string()));
                }
                match self.state.get_canonical_block_by_number(block_number)? {
                    Some(block) => Ok((true, block.hash().to_string())),
                    None => Ok((false, "".to_string())),
                }
            }
            "TIMESTAMP" => {
                let block_number = args.parse()?;
                let Some(diff) = self.current_block.checked_sub(block_number) else {
                    return Ok((false, "".to_string()));
                };
                // We should return nothing if requested number is the same as the current number.
                if diff == 0 {
                    return Ok((false, "".to_string()));
                }
                if diff > BLOCK_HASH_HISTORY {
                    return Ok((false, "".to_string()));
                }
                match self.state.get_canonical_block_by_number(block_number)? {
                    Some(block) => Ok((
                        true,
                        block
                            .timestamp()
                            .duration_since(SystemTime::UNIX_EPOCH)?
                            .as_micros()
                            .to_string(),
                    )),
                    None => Ok((false, "".to_string())),
                }
            }
            _ => Err(anyhow!(
                "fetch_blockchain_info: `{name}` not implemented yet."
            )),
        }?;
        Ok((exists, value))
    }
}

```

`zilliqa/src/scilla_proto.rs`:

```rs
use std::collections::HashMap;

use prost::{Message, Oneof};

#[derive(Clone, PartialEq, Eq, Message)]
pub struct ProtoScillaQuery {
    #[prost(string, tag = "1")]
    pub name: String,
    #[prost(uint32, tag = "2")]
    pub mapdepth: u32,
    #[prost(bytes = "vec", repeated, tag = "3")]
    pub indices: Vec<Vec<u8>>,
    #[prost(bool, tag = "4")]
    pub ignoreval: bool,
}

#[derive(Clone, PartialEq, Eq, Message)]
pub struct ProtoScillaVal {
    #[prost(oneof = "ValType", tags = "1, 2")]
    pub val_type: Option<ValType>,
}

impl ProtoScillaVal {
    pub fn map(m: HashMap<String, ProtoScillaVal>) -> ProtoScillaVal {
        ProtoScillaVal {
            val_type: Some(ValType::Mval(Map { m })),
        }
    }

    pub fn bytes(b: Vec<u8>) -> ProtoScillaVal {
        ProtoScillaVal {
            val_type: Some(ValType::Bval(b)),
        }
    }
}

#[derive(Clone, PartialEq, Eq, Oneof)]
pub enum ValType {
    #[prost(bytes, tag = "1")]
    Bval(Vec<u8>),
    #[prost(message, tag = "2")]
    Mval(Map),
}

#[derive(Clone, PartialEq, Eq, Message)]
pub struct Map {
    #[prost(map = "string, message", tag = "1")]
    pub m: HashMap<String, ProtoScillaVal>,
}

```

`zilliqa/src/serde_util.rs`:

```rs
pub mod num_as_str {
    use std::{fmt::Display, str::FromStr};

    use serde::{Deserialize, Deserializer, Serialize, Serializer, de};

    pub fn serialize<T, S>(value: &T, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
        T: ToString,
    {
        value.to_string().serialize(serializer)
    }

    pub fn deserialize<'de, T, D>(deserializer: D) -> Result<T, D::Error>
    where
        T: FromStr,
        T::Err: Display,
        D: Deserializer<'de>,
    {
        String::deserialize(deserializer)?
            .parse()
            .map_err(de::Error::custom)
    }
}

pub mod bool_as_str {
    use serde::{
        Deserialize, Deserializer,
        de::{self, Unexpected},
    };

    pub fn deserialize<'de, D: Deserializer<'de>>(d: D) -> Result<bool, D::Error> {
        let s = String::deserialize(d)?;
        let b = s
            .parse()
            .map_err(|_| de::Error::invalid_value(Unexpected::Str(&s), &"a boolean"))?;
        Ok(b)
    }
}

pub mod json_value_as_str {
    use serde::{Deserialize, Deserializer, Serialize, Serializer, de};
    use serde_json::Value;

    pub fn serialize<S>(value: &Value, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        value.to_string().serialize(serializer)
    }

    pub fn deserialize<'de, D>(deserializer: D) -> Result<Value, D::Error>
    where
        D: Deserializer<'de>,
    {
        serde_json::from_str(&String::deserialize(deserializer)?).map_err(de::Error::custom)
    }
}

/// Custom (de)serializer for `Vec<ParamValue>` which doesn't rely on `deserialize_any` by serializing the inner
/// `serde_json::Value` as a string. This means bincode is able to handle it.
pub mod vec_param_value {
    use serde::{Deserialize, Deserializer, Serialize, Serializer, ser::SerializeSeq};

    use crate::scilla::ParamValue;

    pub fn serialize<S>(values: &Vec<ParamValue>, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        #[derive(Serialize)]
        struct ParamValueEncoded<'s> {
            #[serde(rename = "vname")]
            pub name: &'s str,
            pub value: String,
            #[serde(rename = "type")]
            pub ty: &'s str,
        }

        let mut serializer = serializer.serialize_seq(Some(values.len()))?;
        for value in values {
            let encoded = ParamValueEncoded {
                name: &value.name,
                value: serde_json::to_string(&value.value).unwrap(),
                ty: &value.ty,
            };
            serializer.serialize_element(&encoded)?;
        }
        serializer.end()
    }

    pub fn deserialize<'de, D>(deserializer: D) -> Result<Vec<ParamValue>, D::Error>
    where
        D: Deserializer<'de>,
    {
        #[derive(Deserialize)]
        struct ParamValueEncoded {
            #[serde(rename = "vname")]
            pub name: String,
            pub value: String,
            #[serde(rename = "type")]
            pub ty: String,
        }

        let values = <Vec<ParamValueEncoded>>::deserialize(deserializer)?
            .into_iter()
            .map(|value| ParamValue {
                name: value.name,
                value: serde_json::from_str(&value.value).unwrap(),
                ty: value.ty,
            })
            .collect();

        Ok(values)
    }
}

```

`zilliqa/src/state.rs`:

```rs
use std::{
    collections::BTreeMap,
    fmt::Display,
    sync::{Arc, Mutex, MutexGuard, OnceLock},
};

use alloy::{
    consensus::EMPTY_ROOT_HASH,
    primitives::{Address, B256},
};
use anyhow::{Result, anyhow};
use eth_trie::{EthTrie as PatriciaTrie, Trie};
use ethabi::Token;
use once_cell::sync::Lazy;
use serde::{Deserialize, Serialize};
use sha3::{Digest, Keccak256};
use tracing::{debug, info};

use crate::{
    cfg::{Amount, ConsensusConfig, Forks, NodeConfig, ReinitialiseParams, ScillaExtLibsPath},
    contracts::{self, Contract},
    crypto::{self, Hash},
    db::{Db, TrieStorage},
    error::ensure_success,
    message::{Block, BlockHeader, MAX_COMMITTEE_SIZE},
    node::ChainId,
    scilla::{ParamValue, Scilla, Transition},
    serde_util::vec_param_value,
    transaction::EvmGas,
};

#[derive(Clone, Debug)]
/// The state of the blockchain, consisting of:
/// -  state - a database of Map<Address, Map<key,value>>
/// -  accounts, Map<Address, Account>
///
/// where an address is a 20-byte array representing a user.
/// where Account is (nonce, code, storage_root)
/// the storage root is used to index into the state
/// all the keys are hashed and stored in the same sled tree
pub struct State {
    sql: Arc<Db>,
    db: Arc<TrieStorage>,
    accounts: Arc<Mutex<PatriciaTrie<TrieStorage>>>,
    /// The Scilla interpreter interface. Note that it is lazily initialized - This is a bit of a hack to ensure that
    /// tests which don't invoke Scilla, don't spawn the Scilla communication threads or TCP listeners.
    scilla: Arc<OnceLock<Mutex<Scilla>>>,
    scilla_address: String,
    socket_dir: String,
    scilla_lib_dir: String,
    pub scilla_ext_libs_path: ScillaExtLibsPath,
    pub block_gas_limit: EvmGas,
    pub gas_price: u128,
    pub chain_id: ChainId,
    pub forks: Forks,
}

impl State {
    pub fn new(trie: TrieStorage, config: &NodeConfig, sql: Arc<Db>) -> Result<State> {
        let db = Arc::new(trie);
        let consensus_config = &config.consensus;
        Ok(Self {
            db: db.clone(),
            accounts: Arc::new(Mutex::new(PatriciaTrie::new(db))),
            scilla: Arc::new(OnceLock::new()),
            scilla_address: consensus_config.scilla_address.clone(),
            socket_dir: consensus_config.scilla_server_socket_directory.clone(),
            scilla_lib_dir: consensus_config.scilla_stdlib_dir.clone(),
            scilla_ext_libs_path: consensus_config.scilla_ext_libs_path.clone(),
            block_gas_limit: consensus_config.eth_block_gas_limit,
            gas_price: *consensus_config.gas_price,
            chain_id: ChainId::new(config.eth_chain_id),
            forks: consensus_config.get_forks()?,
            sql,
        })
    }

    pub fn scilla(&self) -> MutexGuard<'_, Scilla> {
        self.scilla
            .get_or_init(|| {
                Mutex::new(Scilla::new(
                    self.scilla_address.clone(),
                    self.socket_dir.clone(),
                    self.scilla_lib_dir.clone(),
                ))
            })
            .lock()
            .unwrap()
    }

    pub fn new_at_root(
        trie: TrieStorage,
        root_hash: B256,
        config: NodeConfig,
        sql: Arc<Db>,
    ) -> Result<Self> {
        Ok(Self::new(trie, &config, sql)?.at_root(root_hash))
    }

    pub fn new_with_genesis(trie: TrieStorage, config: NodeConfig, sql: Arc<Db>) -> Result<State> {
        let mut state = State::new(trie, &config, sql)?;

        if config.consensus.is_main {
            let shard_data = contracts::shard_registry::CONSTRUCTOR.encode_input(
                contracts::shard_registry::BYTECODE.to_vec(),
                &[Token::Uint(
                    config.consensus.consensus_timeout.as_millis().into(),
                )],
            )?;
            state.force_deploy_contract_evm(shard_data, Some(contract_addr::SHARD_REGISTRY), 0)?;
        };

        let intershard_bridge_data = contracts::intershard_bridge::BYTECODE.to_vec();
        state.force_deploy_contract_evm(
            intershard_bridge_data,
            Some(contract_addr::INTERSHARD_BRIDGE),
            0,
        )?;

        let zero_account_balance = config
            .consensus
            .total_native_token_supply
            .0
            .checked_sub(
                config
                    .consensus
                    .genesis_accounts
                    .iter()
                    .fold(0, |acc, item: &(Address, Amount)| acc + item.1.0),
            )
            .expect("Genesis accounts sum to more than total native token supply")
            .checked_sub(
                config
                    .consensus
                    .genesis_deposits
                    .iter()
                    .fold(0, |acc, item| acc + item.stake.0),
            )
            .expect(
                "Genesis accounts + genesis deposits sum to more than total native token supply",
            );

        // Set ZERO account to total available balance
        state.mutate_account(Address::ZERO, |a| {
            a.balance = zero_account_balance;
            Ok(())
        })?;

        // Set GENESIS account starting balances
        for (address, balance) in config.consensus.genesis_accounts.clone() {
            state.mutate_account(address, |a| {
                a.balance = *balance;
                Ok(())
            })?;
        }

        state.deploy_initial_deposit_contract(&config)?;

        let deposit_contract = Lazy::<contracts::Contract>::force(&contracts::deposit::CONTRACT);
        let block_header = BlockHeader::genesis(Hash::ZERO);
        state.upgrade_deposit_contract(block_header, deposit_contract, None)?;

        // Check if any contracts are to be upgraded from genesis
        state.contract_upgrade_apply_state_change(&config.consensus, block_header)?;

        Ok(state)
    }

    /// If there are any contract updates to be performed then apply them to self
    pub fn contract_upgrade_apply_state_change(
        &mut self,
        config: &ConsensusConfig,
        block_header: BlockHeader,
    ) -> Result<()> {
        if let Some(deposit_v3_deploy_config) = &config.contract_upgrades.deposit_v3 {
            if deposit_v3_deploy_config.height == block_header.number {
                let deposit_v3_contract =
                    Lazy::<contracts::Contract>::force(&contracts::deposit_v3::CONTRACT);
                self.upgrade_deposit_contract(block_header, deposit_v3_contract, None)?;
            }
        }
        if let Some(deposit_v4_deploy_config) = &config.contract_upgrades.deposit_v4 {
            if deposit_v4_deploy_config.height == block_header.number {
                // The below account mutation fixes the Zero account's nonce in prototestnet and protomainnet.
                // Issue #2254 explains how the nonce was incorrect due to a bug in the ZQ1 persistence converter.
                // This code should run once for these networks in order for the deposit_v4 contract to be deployed, then this code can be removed.
                if self.chain_id.eth == 33103 || self.chain_id.eth == 32770 {
                    self.mutate_account(Address::ZERO, |a| {
                        // Nonce 5 is the next address to not have any code deployed
                        a.nonce = 5;
                        Ok(())
                    })?;
                }
                let deposit_v4_contract =
                    Lazy::<contracts::Contract>::force(&contracts::deposit_v4::CONTRACT);
                self.upgrade_deposit_contract(block_header, deposit_v4_contract, None)?;
            }
        }
        if let Some(deposit_v5_deploy_config) = &config.contract_upgrades.deposit_v5 {
            if deposit_v5_deploy_config.height == block_header.number {
                let deposit_v5_contract =
                    Lazy::<contracts::Contract>::force(&contracts::deposit_v5::CONTRACT);
                let reinitialise_params = deposit_v5_deploy_config
                    .reinitialise_params
                    .clone()
                    .unwrap_or(ReinitialiseParams::default());
                let deposit_v5_reinitialise_data = contracts::deposit_v5::REINITIALIZE
                    .encode_input(&[Token::Uint(reinitialise_params.withdrawal_period.into())])?;
                self.upgrade_deposit_contract(
                    block_header,
                    deposit_v5_contract,
                    Some(deposit_v5_reinitialise_data),
                )?;
            }
        }
        Ok(())
    }

    /// Deploy DepositInit contract (deposit_v1.sol)
    /// Warning: staking will not work with this contact deployment alone. self.upgrade_deposit_contract() must be called in order to deploy a full Deposit implementation.
    fn deploy_initial_deposit_contract(&mut self, config: &NodeConfig) -> Result<Address> {
        // Deploy DepositInit
        let deposit_addr =
            self.force_deploy_contract_evm(contracts::deposit_init::BYTECODE.to_vec(), None, 0)?;

        let initial_stakers: Vec<_> = config
            .consensus
            .genesis_deposits
            .clone()
            .into_iter()
            .map(|deposit| {
                Token::Tuple(vec![
                    Token::Bytes(deposit.public_key.as_bytes()),
                    Token::Bytes(deposit.peer_id.to_bytes()),
                    Token::Address(ethabi::Address::from(deposit.reward_address.into_array())),
                    Token::Address(ethabi::Address::from(deposit.control_address.into_array())),
                    Token::Uint((*deposit.stake).into()),
                ])
            })
            .collect();
        let deposit_initialize_data = contracts::deposit_init::INITIALIZE.encode_input(&[
            Token::Uint((*config.consensus.minimum_stake).into()),
            Token::Uint(MAX_COMMITTEE_SIZE.into()),
            Token::Uint(config.consensus.blocks_per_epoch.into()),
            Token::Array(initial_stakers),
        ])?;
        let eip1967_constructor_data = contracts::eip1967_proxy::CONSTRUCTOR.encode_input(
            contracts::eip1967_proxy::BYTECODE.to_vec(),
            &[
                Token::Address(ethabi::Address::from(deposit_addr.into_array())),
                Token::Bytes(deposit_initialize_data),
            ],
        )?;

        let total_genesis_deposits = config
            .consensus
            .genesis_deposits
            .iter()
            .fold(0, |acc, item| acc + item.stake.0);

        // Deploy Eip1967 proxy pointing to DepositInit
        let eip1967_addr = self.force_deploy_contract_evm(
            eip1967_constructor_data,
            Some(contract_addr::DEPOSIT_PROXY),
            total_genesis_deposits,
        )?;
        debug!(
            "Deployed initial deposit contract version to {} and EIP 1967 deposit contract to {}",
            deposit_addr, eip1967_addr
        );

        Ok(deposit_addr)
    }

    /// Uses an Eip1967 proxy to update the deposit contract.
    /// Return new deposit implementation address
    pub fn upgrade_deposit_contract(
        &mut self,
        current_block: BlockHeader,
        contract: &Contract,
        reinitialise_data: Option<Vec<u8>>,
    ) -> Result<Address> {
        let current_version = self.deposit_contract_version(current_block)?;

        // Deploy latest deposit implementation
        let new_deposit_impl_addr =
            self.force_deploy_contract_evm(contract.bytecode.to_vec(), None, 0)?;
        let deposit_upgrade_to_and_call_data =
            contract.abi.function("upgradeToAndCall")?.encode_input(&[
                Token::Address(ethabi::Address::from(new_deposit_impl_addr.into_array())),
                Token::Bytes(
                    reinitialise_data
                        .unwrap_or(contracts::deposit::REINITIALIZE.encode_input(&[])?),
                ),
            ])?;

        // Apply update to eip 1967 proxy
        let result = self.call_contract_apply(
            Address::ZERO,
            Some(contract_addr::DEPOSIT_PROXY),
            deposit_upgrade_to_and_call_data,
            0,
            current_block,
        )?;
        ensure_success(result)?;

        let new_version = self.deposit_contract_version(current_block)?;
        info!(
            "EIP 1967 deposit contract proxy {} updated from version {} to new version {} with contract addr {}",
            contract_addr::DEPOSIT_PROXY,
            current_version,
            new_version,
            new_deposit_impl_addr
        );

        Ok(new_deposit_impl_addr)
    }

    pub fn at_root(&self, root_hash: B256) -> Self {
        Self {
            db: self.db.clone(),
            accounts: Arc::new(Mutex::new(self.accounts.lock().unwrap().at_root(root_hash))),
            scilla: self.scilla.clone(),
            scilla_address: self.scilla_address.clone(),
            socket_dir: self.socket_dir.clone(),
            scilla_lib_dir: self.scilla_lib_dir.clone(),
            scilla_ext_libs_path: self.scilla_ext_libs_path.clone(),
            block_gas_limit: self.block_gas_limit,
            gas_price: self.gas_price,
            chain_id: self.chain_id,
            forks: self.forks.clone(),
            sql: self.sql.clone(),
        }
    }

    pub fn set_to_root(&mut self, root_hash: B256) {
        let at_root = self.accounts.lock().unwrap().at_root(root_hash);
        self.accounts = Arc::new(Mutex::new(at_root));
    }

    pub fn try_clone(&mut self) -> Result<Self> {
        let root_hash = self.accounts.lock().unwrap().root_hash()?;
        Ok(self.at_root(root_hash))
    }

    pub fn root_hash(&mut self) -> Result<crypto::Hash> {
        let hash = self.accounts.lock().unwrap().root_hash()?;
        Ok(crypto::Hash(hash.into()))
    }

    /// Canonical method to obtain trie key for an account node
    pub fn account_key(address: Address) -> B256 {
        <[u8; 32]>::from(Keccak256::digest(address)).into()
    }

    /// Canonical method to obtain trie key for an account's storage trie's storage node
    pub fn account_storage_key(address: Address, index: B256) -> B256 {
        let mut h = Keccak256::new();
        h.update(address);
        h.update(index);
        <[u8; 32]>::from(h.finalize()).into()
    }

    /// Fetch an Account struct.
    /// Note: use get_account_storage to obtain a specific storage value.
    /// If modifying a raw account, ensure you call save_account afterwards.
    /// Returns an error on failures to access the state tree, or decode the account; or an empty
    /// account if one didn't exist yet
    pub fn get_account(&self, address: Address) -> Result<Account> {
        Ok(self
            .accounts
            .lock()
            .unwrap()
            .get(&Self::account_key(address).0)?
            .map(|bytes| bincode::deserialize::<Account>(&bytes))
            .unwrap_or(Ok(Account::default()))?)
    }

    /// As get_account, but panics if account cannot be read.
    pub fn must_get_account(&self, address: Address) -> Account {
        self.get_account(address).unwrap_or_else(|e| {
            panic!("Failed to read account {address:?} from state storage: {e:?}")
        })
    }

    pub fn mutate_account<F: FnOnce(&mut Account) -> Result<R>, R>(
        &mut self,
        address: Address,
        mutation: F,
    ) -> Result<R> {
        let mut account = self.get_account(address)?;
        let result = mutation(&mut account)?;
        self.save_account(address, account)?;
        Ok(result)
    }

    /// If using this to modify the account, ensure save_account gets called
    pub fn get_account_trie(&self, address: Address) -> Result<PatriciaTrie<TrieStorage>> {
        let account = self.get_account(address)?;
        Ok(PatriciaTrie::new(self.db.clone()).at_root(account.storage_root))
    }

    /// Returns an error if there are any issues fetching the account from the state trie
    pub fn get_account_storage(&self, address: Address, index: B256) -> Result<B256> {
        match self
            .get_account_trie(address)?
            .get(&Self::account_storage_key(address, index).0)
        {
            // from_slice will only panic if vec.len != B256::len_bytes, i.e. 32
            Ok(Some(vec)) if vec.len() == 32 => Ok(B256::from_slice(&vec)),
            // empty storage location
            Ok(None) => Ok(B256::ZERO),
            // invalid value in storage
            Ok(Some(vec)) => Err(anyhow!(
                "Invalid storage for account {address:?} at index {index}: expected 32 bytes, got value {vec:?}"
            )),
            // any other error fetching
            Err(e) => Err(anyhow!(
                "Failed to fetch storage for account {address:?} at index {index}: {e}",
            )),
        }
    }

    /// Returns an error if there are any issues accessing the storage trie
    pub fn has_account(&self, address: Address) -> Result<bool> {
        Ok(self
            .accounts
            .lock()
            .unwrap()
            .contains(&Self::account_key(address).0)?)
    }

    pub fn save_account(&mut self, address: Address, account: Account) -> Result<()> {
        Ok(self.accounts.lock().unwrap().insert(
            &Self::account_key(address).0,
            &bincode::serialize(&account)?,
        )?)
    }

    pub fn get_canonical_block_by_number(&self, number: u64) -> Result<Option<Block>> {
        self.sql.get_canonical_block_by_number(number)
    }

    pub fn get_highest_canonical_block_number(&self) -> Result<Option<u64>> {
        self.sql.get_highest_canonical_block_number()
    }

    pub fn is_empty(&self) -> bool {
        self.accounts.lock().unwrap().iter().next().is_none()
    }
}

pub mod contract_addr {
    use alloy::primitives::Address;

    /// For intershard transactions, call this address
    pub const INTERSHARD_BRIDGE: Address = Address::new(*b"\0\0\0\0\0\0\0\0ZQINTERSHARD");
    /// Address of the shard registry - only present on the root shard.
    pub const SHARD_REGISTRY: Address = Address::new(*b"\0\0\0\0\0\0\0\0\0\0\0\0\0ZQSHARD");
    /// Address of EIP 1967 proxy for Deposit contract
    pub const DEPOSIT_PROXY: Address = Address::new(*b"\0\0\0\0\0ZILDEPOSITPROXY");
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Account {
    pub nonce: u64,
    pub balance: u128,
    pub code: Code,
    pub storage_root: B256,
}

impl Default for Account {
    fn default() -> Self {
        Self {
            nonce: 0,
            balance: 0,
            code: Code::default(),
            storage_root: EMPTY_ROOT_HASH,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExternalLibrary {
    pub name: String,
    pub address: Address,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ContractInit(Vec<ParamValue>);

impl ContractInit {
    pub fn new(init: Vec<ParamValue>) -> Self {
        Self(init)
    }

    pub fn scilla_version(&self) -> Result<String> {
        for entry in &self.0 {
            if entry.name == "_scilla_version" {
                return Ok(entry.value.to_string());
            }
        }
        Ok(String::new())
    }

    pub fn is_library(&self) -> Result<bool> {
        for entry in &self.0 {
            if entry.name == "_library" {
                return Ok(entry.value["constructor"].as_str() == Some("True"));
            }
        }
        Ok(false)
    }

    pub fn external_libraries(&self) -> Result<Vec<ExternalLibrary>> {
        let mut external_libraries = Vec::new();
        for entry in &self.0 {
            if entry.name == "_extlibs" {
                if let Some(ext_libs) = entry.value.as_array() {
                    for ext_lib in ext_libs {
                        if let Some(lib) = ext_lib["arguments"].as_array() {
                            if lib.len() != 2 {
                                return Err(anyhow!("Invalid init."));
                            }
                            let lib_name = lib[0].as_str().ok_or_else(|| {
                                anyhow!("Invalid init. Library name is not an string")
                            })?;
                            let lib_address = lib[1].as_str().ok_or_else(|| {
                                anyhow!("Invalid init. Library address is not an string")
                            })?;
                            external_libraries.push(ExternalLibrary {
                                name: lib_name.to_string(),
                                address: lib_address.parse::<Address>()?,
                            });
                        } else {
                            return Err(anyhow!("Invalid init."));
                        }
                    }
                }
            }
        }
        Ok(external_libraries)
    }

    pub fn into_inner(self) -> Vec<ParamValue> {
        self.0
    }
}

impl Display for ContractInit {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let json = serde_json::to_string(&self.0).map_err(|_| std::fmt::Error)?;
        write!(f, "{}", json)
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum Code {
    Evm(#[serde(with = "serde_bytes")] Vec<u8>),
    Scilla {
        code: String,
        #[serde(with = "vec_param_value")]
        init_data: Vec<ParamValue>,
        types: BTreeMap<String, (String, u8)>,
        transitions: Vec<Transition>,
    },
}

impl Default for Code {
    fn default() -> Self {
        Code::Evm(Vec::new())
    }
}

impl Code {
    pub fn is_eoa(&self) -> bool {
        matches!(self, Code::Evm(c) if c.is_empty())
    }

    pub fn evm_code_ref(&self) -> Option<&[u8]> {
        match self {
            Code::Evm(code) => Some(code.as_slice()),
            _ => None,
        }
    }

    pub fn evm_code(self) -> Option<Vec<u8>> {
        match self {
            Code::Evm(code) => Some(code),
            _ => None,
        }
    }

    pub fn scilla_code_and_init_data(&self) -> Option<(&str, &[ParamValue])> {
        match self {
            Code::Scilla {
                code, init_data, ..
            } => Some((code, init_data)),
            _ => None,
        }
    }

    pub fn is_scilla(&self) -> bool {
        matches!(self, Code::Scilla { .. })
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub enum ScillaValue {
    Bytes(Vec<u8>),
    Map(BTreeMap<String, ScillaValue>),
}

impl ScillaValue {
    pub fn map() -> Self {
        ScillaValue::Map(BTreeMap::new())
    }

    pub fn as_bytes(&self) -> Option<&[u8]> {
        match self {
            ScillaValue::Bytes(b) => Some(b),
            ScillaValue::Map(_) => None,
        }
    }

    pub fn as_map(&self) -> Option<&BTreeMap<String, ScillaValue>> {
        match self {
            ScillaValue::Map(m) => Some(m),
            ScillaValue::Bytes(_) => None,
        }
    }

    pub fn as_map_mut(&mut self) -> Option<&mut BTreeMap<String, ScillaValue>> {
        match self {
            ScillaValue::Map(m) => Some(m),
            ScillaValue::Bytes(_) => None,
        }
    }
}

#[cfg(test)]
mod tests {
    use std::{path::PathBuf, sync::Arc};

    use crypto::Hash;
    use revm::primitives::FixedBytes;

    use super::*;
    use crate::{api::to_hex::ToHex, cfg::NodeConfig, db::Db, message::BlockHeader};

    #[test]
    fn deposit_contract_updateability() {
        let db = Db::new::<PathBuf>(None, 0, 0, None).unwrap();
        let db = Arc::new(db);
        let config = NodeConfig::default();

        let mut state = State::new(db.state_trie().unwrap(), &config, db).unwrap();

        let deposit_init_addr = state.deploy_initial_deposit_contract(&config).unwrap();

        // Check initial deployment of DEPOSIT_V0
        let genesis_block_header = BlockHeader::genesis(Hash::ZERO);
        let stakers = state.get_stakers(genesis_block_header);
        // deposit init does not support getStakers()
        assert!(stakers.is_err());

        let version = state
            .deposit_contract_version(genesis_block_header)
            .unwrap();
        assert_eq!(version, 1);

        let proxy_storage_at = state
            .get_account_storage(
                contract_addr::DEPOSIT_PROXY,
                B256::from(
                    FixedBytes::try_from(
                        hex::decode(
                            "360894a13ba1a3210667c828492db98dca3e2076cc3735a920a3ca505d382bbc",
                        )
                        .unwrap()
                        .as_slice(),
                    )
                    .unwrap(),
                ),
            )
            .unwrap();
        // this is the eip 1967 contract's _implementation storage spot for the proxy address. It should point to deposit init address.
        assert!(
            proxy_storage_at
                .to_hex()
                .contains(&deposit_init_addr.0.to_string().split_off(2))
        );

        // Update to deposit v2
        let deposit_v2 = Lazy::<contracts::Contract>::force(&contracts::deposit_v2::CONTRACT);
        let deposit_v2_addr = state
            .upgrade_deposit_contract(BlockHeader::genesis(Hash::ZERO), deposit_v2, None)
            .unwrap();

        let proxy_storage_at = state
            .get_account_storage(
                contract_addr::DEPOSIT_PROXY,
                B256::from(
                    FixedBytes::try_from(
                        hex::decode(
                            "360894a13ba1a3210667c828492db98dca3e2076cc3735a920a3ca505d382bbc",
                        )
                        .unwrap()
                        .as_slice(),
                    )
                    .unwrap(),
                ),
            )
            .unwrap();
        // this is the eip 1967 contract's _implementation storage spot for the proxy address. It should now point to deposit v2 address.
        assert!(
            proxy_storage_at
                .to_hex()
                .contains(&deposit_v2_addr.0.to_string().split_off(2))
        );

        let version = state
            .deposit_contract_version(genesis_block_header)
            .unwrap();
        assert_eq!(version, 2);

        let stakers = state.get_stakers(genesis_block_header).unwrap();
        assert_eq!(stakers.len(), config.consensus.genesis_deposits.len());
    }
}

```

`zilliqa/src/sync.rs`:

```rs
use std::{
    cmp::{Ordering, Reverse},
    collections::{BTreeMap, BinaryHeap, HashMap, VecDeque},
    ops::RangeInclusive,
    sync::{Arc, Mutex},
    time::{Duration, Instant},
};

use anyhow::Result;
use itertools::Itertools;
use libp2p::PeerId;
use rand::Rng;
use rusqlite::types::{FromSql, FromSqlResult, ToSql, ToSqlOutput, ValueRef};
use tracing::{debug, error, info, trace, warn};

use crate::{
    api::types::eth::{SyncingMeta, SyncingStruct},
    cfg::NodeConfig,
    crypto::Hash,
    db::Db,
    message::{
        Block, BlockHeader, BlockRequest, BlockResponse, BlockTransactionsReceipts,
        ExternalMessage, InjectedProposal, Proposal, RequestBlocksByHash, RequestBlocksByHeight,
        SyncBlockHeader,
    },
    node::{MessageSender, OutgoingMessageFailure, RequestId},
    time::SystemTime,
};

// Syncing Algorithm
//
// When a Proposal is received by Consensus, we check if the parent exists in our DB.
// If not, then it triggers the active-syncing algorithm; else the passive-syncing algorithm.
/*
                                     +----------------------------+
                                     | PHASE-0: IDLE              |
+------------------------------------>                            <----------------------------------+
|                                    |                            |                                  |
|                                    +-++-------------------------+                                  |
|      Receives a normal proposal.     ||                                                            |
|     +--------------------------------+| Start syncing e.g. missing parent, or due to probe.        |
|     |                                 |                                                            |
|  +--v-------------------------+    +--v-------------------------+                                  |
|  | PHASE-4: PASSIVE BLOCKS    |    | PHASE-1: ACTIVE HEADERS    |                                  |
|  |                            |    |                            <----------------+                 |
|  | Request missing blocks.    |    | Request missing headers.   |                |                 |
|  +-+--------------------------+    +--+-------------------------+                |                 |
|    |                                  |                                          |                 |
|    | Receive & store blocks.          | Received headers hits our history.       |                 |
|    |                                  |                                          |                 |
+----+                               +--v-------------------------+             +--+--------------+  |
                                     | PHASE-2: ACTIVE BLOCKS     |             | RETRY-1: RETRY  |  |
                                     |                            |  on errors  |                 |  |
                                     | Request missing blocks.    +-------------> Retry 1-segment |  |
                                     +--+-------------------------+             +-----------------+  |
                                        |                                                            |
                                        | Receive all requested blocks.                              |
                                        |                                                            |
                                     +--v-------------------------+                                  |
                                     | PHASE-3: FINISH            |                                  |
                                     |                            +----------------------------------+
                                     | Inject cached segment.     |
                                     +----------------------------+
 */
//
// PHASE 1: Request missing chain headers.
// The entire chain of headers is stored in-memory, and is used to construct a chain of headers.
// 1. We start with the latest Proposal and request a segment of headers from a peer.
// 2. We construct the chain of headers, based on the response received.
// 3. If all headers are missing from our history, we request for more.
// 4. If any headers exist, we have hit our history, we move to Phase 2.
//
// PHASE 2: Request missing blocks.
// Once the chain of headers is constructed, we fill in the missing blocks to replay the history.
// 1. We construct a set of hashes, from the in-memory chain of headers.
// 2. We request these blocks from the same Peer that sent the headers.
// 3. We inject the received Proposals into the pipeline.
// 4. If there are still missing blocks, we ask for more.
// 5. If there are no more missing blocks, we move to Phase 3.
//
// PHASE 3: Zip it up.
// Phase 1&2 may run several times and bring up 99% of the chain, but it will never catch up.
// This closes the final gap.
// 1. We queue all recently received Proposals, while Phase 1 & 2 were in progress.
// 2. We extract a chain of Proposals from this queue.
// 3. If it does not link up to our history, we run Phase 1 again.
// 4. If it does, we inject the entire queue into the pipeline.
// 5. We are synced.
//
// PHASE4: Request blocks
// Request as many archival blocks as possible.
// 1. We start with the lowest block in our chain, and request blocks from down to `base_height`
// 2. We store the blocks from the received response.
// 3. We unconditionally move to Phase 0, to wait for the next Proposal.

#[derive(Debug)]
pub struct Sync {
    // database
    db: Arc<Db>,
    // message bus
    message_sender: MessageSender,
    // internal peers
    peers: Arc<SyncPeers>,
    last_probe_at: Instant,
    cache_probe_response: Option<Proposal>, // cache the probe response
    // peers handling in-flight requests
    in_flight: VecDeque<(PeerInfo, RequestId)>,
    p1_response: BTreeMap<PeerId, Option<Vec<SyncBlockHeader>>>,
    // how many blocks to request/prune at once
    max_batch_size: usize,
    prune_interval: u64,
    // how many blocks to inject into the queue
    max_blocks_in_flight: usize,
    // count of proposals pending in the pipeline
    in_pipeline: usize,
    // our peer id
    peer_id: PeerId,
    // internal sync state
    state: SyncState,
    // fixed-size queue of the most recent proposals
    recent_proposals: VecDeque<Proposal>,
    // for statistics only
    inject_at: Option<(std::time::Instant, usize, u64)>,
    // record data for eth_syncing() RPC call.
    started_at: u64,
    highest_block_seen: u64,
    retry_count: usize,
    error_count: usize,
    empty_count: usize,
    headers_downloaded: usize,
    blocks_downloaded: usize,
    active_sync_count: usize,
    // internal structure for syncing
    segments: SyncSegments,
    size_cache: HashMap<Hash, usize>,
    // passive sync
    sync_base_height: u64,
    zq2_floor_height: u64,
    ignore_passive: bool,
}

impl Sync {
    // Speed up by fetching multiple segments in Phase 1.
    const MAX_CONCURRENT_PEERS: usize = 10;
    // Mitigate DoS
    const MAX_BATCH_SIZE: usize = 100;
    // Cache recent block sizes
    const MAX_CACHE_SIZE: usize = 100_000;
    // Timeout for passive-sync/prune
    const PRUNE_TIMEOUT_MS: u128 = 1000;
    // Do not overflow libp2p::request-response::cbor::codec::RESPONSE_SIZE_MAXIMUM = 10MB (default)
    const RESPONSE_SIZE_THRESHOLD: usize = 9 * 1024 * 1024;

    pub fn new(
        config: &NodeConfig,
        db: Arc<Db>,
        latest_block: &Option<Block>,
        message_sender: MessageSender,
        peers: Arc<SyncPeers>,
    ) -> Result<Self> {
        let peer_id = message_sender.our_peer_id;
        let max_batch_size = config
            .sync
            .block_request_batch_size
            .clamp(10, Self::MAX_BATCH_SIZE); // reduce the max batch size - 100 is more than sufficient; less may work too.
        let max_blocks_in_flight = config.sync.max_blocks_in_flight.clamp(
            max_batch_size,
            Self::MAX_BATCH_SIZE * Self::MAX_CONCURRENT_PEERS, // phase 2 buffering - 1000 is more than sufficient; more may work too.
        );
        let sync_base_height = config.sync.base_height;
        let prune_interval = config.sync.prune_interval;
        // Start from reset, or continue sync
        let latest_block_number = latest_block
            .as_ref()
            .map_or_else(|| u64::MIN, |b| b.number());

        // If set, sync_base_height must be sane
        if sync_base_height != u64::MAX && latest_block_number < sync_base_height {
            return Err(anyhow::anyhow!("sync_base_height > highest_block"));
        }

        let zq2_floor_height = config
            .consensus
            .get_forks()?
            .find_height_fork_first_activated(crate::cfg::ForkName::ExecutableBlocks)
            .unwrap_or_default();

        let ignore_passive = config.sync.ignore_passive; // defaults to servicing passive-sync requests

        if latest_block_number < zq2_floor_height {
            return Err(anyhow::anyhow!("Please restore from a checkpoint"));
        }

        Ok(Self {
            db,
            message_sender,
            peer_id,
            peers,
            max_batch_size,
            max_blocks_in_flight,
            in_flight: VecDeque::with_capacity(Self::MAX_CONCURRENT_PEERS),
            in_pipeline: usize::MIN,
            state: SyncState::Phase0,
            recent_proposals: VecDeque::with_capacity(max_batch_size),
            inject_at: None,
            started_at: latest_block_number,
            highest_block_seen: latest_block_number,
            retry_count: 0,
            error_count: 0,
            empty_count: 0,
            headers_downloaded: 0,
            blocks_downloaded: 0,
            active_sync_count: 0,
            p1_response: BTreeMap::new(),
            segments: SyncSegments::default(),
            cache_probe_response: None,
            last_probe_at: Instant::now().checked_sub(Duration::from_secs(60)).unwrap(), // allow immediate sync at startup
            sync_base_height,
            prune_interval,
            size_cache: HashMap::with_capacity(Self::MAX_CACHE_SIZE),
            zq2_floor_height,
            ignore_passive,
        })
    }

    /// P2P Failure
    ///
    /// This gets called for any libp2p request failure - treated as a network failure
    pub fn handle_request_failure(
        &mut self,
        from: PeerId, // only to determine if self-triggered
        failure: OutgoingMessageFailure,
    ) -> Result<()> {
        self.error_count = self.error_count.saturating_add(1);
        if self
            .in_flight
            .iter()
            .any(|(p, r)| p.peer_id == failure.peer && *r == failure.request_id)
        {
            warn!(peer = %failure.peer, err=%failure.error, "sync::RequestFailure : failed");
            match &self.state {
                SyncState::Phase1(_) => self.handle_active_response(failure.peer, None)?,
                SyncState::Phase2(_) => self.handle_multiblock_response(failure.peer, None)?,
                SyncState::Phase4(_) => self.handle_passive_response(failure.peer, None)?,
                state => error!(%state, %from, "sync::RequestFailure : invalid"),
            }
        }
        Ok(())
    }

    /// Phase 0: Sync a block proposal.
    ///
    /// This is the main entry point for active-syncing a block proposal.
    /// We start by enqueuing all proposals, and then check if the parent block exists in history.
    /// If the parent block exists, we do nothing. Otherwise, we check the least recent one.
    /// If we find its parent in history, we inject the entire queue. Otherwise, we start syncing.
    ///
    /// We do not perform checks on the Proposal here. This is done in the consensus layer.
    pub fn sync_from_proposal(&mut self, proposal: Proposal) -> Result<()> {
        // just stuff the latest proposal into the fixed-size queue.
        while self.recent_proposals.len() >= self.max_batch_size {
            self.recent_proposals.pop_front();
        }
        self.highest_block_seen = self.highest_block_seen.max(proposal.number());
        self.recent_proposals.push_back(proposal);
        self.do_sync()
    }

    /// Phase 0: Sync from a probe.
    ///
    /// When invoked via NewView/manually, will trigger a probe to a peer to retrieve its latest block.
    /// The result is checked in `handle_block_response()`, and decision made to start syncing or not.
    pub fn sync_from_probe(&mut self) -> Result<()> {
        if self.am_syncing()? {
            // do not sync if we are already syncing
            debug!("sync::SyncFromProbe : syncing");
            return Ok(());
        }
        // avoid spamming the network
        let elapsed = self.last_probe_at.elapsed().as_secs();
        if elapsed < 60 {
            debug!(?elapsed, "sync::SyncFromProbe : skipping");
            return Ok(());
        } else {
            self.last_probe_at = Instant::now();
        }
        // inevitably picks a bootstrap node
        if let Some(peer_info) = self.peers.get_next_peer() {
            let peer = peer_info.peer_id;
            self.peers.append_peer(peer_info);
            info!(%peer, "sync::SyncFromProbe : probing");
            self.probe_peer(peer);
        } else {
            warn!("sync::SyncFromProbe: insufficient peers");
        }
        Ok(())
    }

    /// Drive the sync state-machine.
    fn do_sync(&mut self) -> Result<()> {
        if self.recent_proposals.is_empty() {
            // Do nothing if there's no recent proposals.
            debug!("sync::DoSync : missing recent proposals");
            return Ok(());
        }

        // check in-flights; manually failing one stale request at a time
        if let Some((
            PeerInfo {
                peer_id, last_used, ..
            },
            request_id,
        )) = self.in_flight.front()
        {
            if last_used.elapsed().as_secs() > 90 {
                warn!(%peer_id, ?request_id, "sync::DoSync : stale");
                self.handle_request_failure(
                    self.peer_id, // self-triggered
                    OutgoingMessageFailure {
                        peer: *peer_id,
                        request_id: *request_id,
                        error: libp2p::autonat::OutboundFailure::Timeout,
                    },
                )?;
            }
            return Ok(());
        }

        trace!(state = %self.state, "sync::DoSync");

        match self.state {
            // Check if we are out of sync
            SyncState::Phase0 if self.in_pipeline == 0 => {
                let meta = &self.recent_proposals.back().unwrap().header;
                if self.db.contains_canonical_block(&meta.hash)? {
                    // We have the latest block, trigger passive-sync
                    self.start_passive_sync()?;
                } else if !self.db.contains_canonical_block(&meta.qc.block_hash)? {
                    // We don't have the parent block, trigger active-sync
                    self.start_active_sync(*meta)?;
                }
                // could be a fork, wait for another proposal
            }
            // Continue phase 1, until we hit history/genesis.
            SyncState::Phase1(_) if self.in_pipeline < self.max_batch_size => {
                self.request_missing_headers()?;
            }
            // Continue phase 2, until we have all segments.
            SyncState::Phase2(_) if self.in_pipeline < self.max_blocks_in_flight => {
                self.request_missing_blocks()?;
            }
            // Wait till 99% synced, zip it up!
            SyncState::Phase3 if self.in_pipeline == 0 => {
                self.inject_recent_blocks()?;
            }
            // Retry to fix sync issues e.g. peers that are now offline
            SyncState::Retry1(_) if self.in_pipeline == 0 => {
                self.retry_phase1()?;
            }
            SyncState::Phase4(_) => self.request_passive_sync()?,
            _ => {
                debug!(in_pipeline = %self.in_pipeline, "sync::DoSync : syncing");
            }
        }
        Ok(())
    }

    /// Phase 0: Start Active Sync
    ///
    /// Given a block header, start the active sync process from that point going backwards.
    fn start_active_sync(&mut self, meta: BlockHeader) -> Result<()> {
        if !matches!(self.state, SyncState::Phase0) {
            unimplemented!("sync::StartActiveSync : invalid state");
        }
        // No parent block, trigger active-sync
        self.active_sync_count = self.active_sync_count.saturating_add(1);
        debug!(from_hash = %meta.qc.block_hash, "sync::StartActiveSync : syncing",);
        // Ensure started_at_block_number is set before running this.
        // https://github.com/Zilliqa/zq2/issues/2252#issuecomment-2636036676
        self.update_started_at()?;
        self.state = SyncState::Phase1(meta);
        self.request_missing_headers()?;
        Ok(())
    }

    /// Phase 0: Start Passive Sync
    ///
    /// Starts passive sync from the lowest block in the DB, back to the sync-base-height.
    /// It also prunes any blocks lower than sync-base-height.
    fn start_passive_sync(&mut self) -> Result<()> {
        if !matches!(self.state, SyncState::Phase0) {
            unimplemented!("sync::StartPassiveSync : invalid state");
        }

        if self.sync_base_height == u64::MAX && self.prune_interval == u64::MAX {
            return Ok(());
        }

        let range = self.db.available_range()?;

        match (*range.start()).cmp(&self.sync_base_height) {
            // done, turn off passive-sync
            Ordering::Equal => {
                self.sync_base_height = u64::MAX;
            }
            // passive-sync above sync-base-height
            Ordering::Greater => {
                debug!(?range, "sync::StartPassiveSync : syncing",);

                let last = range.start().saturating_sub(1);
                let hash = self
                    .db
                    .get_canonical_block_by_number(*range.start())?
                    .expect("must exist")
                    .header
                    .qc
                    .block_hash;

                self.state = SyncState::Phase4((last, hash));
                self.request_passive_sync()?;
            }
            Ordering::Less => {
                self.prune_range(range)?;
            }
        }
        Ok(())
    }

    /// Utility: Prune blocks
    ///
    /// Deletes both canonical and non-canonical blocks from the DB, given a range.
    pub fn prune_range(&mut self, range: RangeInclusive<u64>) -> Result<()> {
        let prune_ceil = if self.prune_interval != u64::MAX {
            // prune prune-interval
            range
                .end()
                .saturating_sub(self.prune_interval.saturating_sub(1))
        } else if self.sync_base_height != u64::MAX {
            // prune below sync-base-height
            range
                .end()
                .saturating_sub(MIN_PRUNE_INTERVAL.saturating_sub(1))
                .min(self.sync_base_height)
        } else {
            return Ok(());
        };

        // Prune canonical, and non-canonical blocks.
        debug!(?range, "sync::Prune",);
        let start_now = Instant::now();
        for number in *range.start()..prune_ceil {
            // check if we have time to prune
            if start_now.elapsed().as_millis() > Self::PRUNE_TIMEOUT_MS {
                break;
            }
            // remove canonical block and transactions
            if let Some(block) = self.db.get_canonical_block_by_number(number)? {
                trace!(number = %block.number(), hash=%block.hash(), "sync::Prune");
                self.db.prune_block(&block, true)?;
            }
            // remove any other non-canonical blocks; typically none
            for block in self.db.get_blocks_by_height(number)? {
                trace!(number = %block.number(), hash=%block.hash(), "sync::Prune");
                self.db.prune_block(&block, false)?;
            }
        }
        Ok(())
    }

    /// Injects the recent proposals
    ///
    /// The recent proposals have been buffering while active-sync is in process to 99%.
    /// This injects the last 1% to finish it up.
    fn inject_recent_blocks(&mut self) -> Result<()> {
        if !matches!(self.state, SyncState::Phase3) {
            unimplemented!("sync::RecentBlocks : invalid state");
        }
        // Only inject recent proposals - https://github.com/Zilliqa/zq2/issues/2520
        let highest_block = self
            .db
            .get_highest_recorded_block()?
            .expect("db is not empty");

        // drain, filter and sort cached-blocks.
        let proposals = self
            .recent_proposals
            .drain(..)
            .filter(|b| b.number() > highest_block.number()) // newer blocks
            .sorted_by(|a, b| match b.number().cmp(&a.number()) {
                Ordering::Equal => b.header.timestamp.cmp(&a.header.timestamp),
                o => o,
            }) // descending sort
            .collect_vec();

        if !proposals.is_empty() {
            // extract chain segment, ascending order
            let mut hash = proposals.first().expect("contains newer blocks").hash();
            let mut proposals = proposals
                .into_iter()
                .filter(|b| {
                    if b.hash() == hash {
                        hash = b.header.qc.block_hash; // find the parent
                        true
                    } else {
                        false
                    }
                })
                .collect_vec();
            proposals.reverse();

            // inject if it links up
            let ancestor_hash = proposals.first().expect(">= 1 block").header.qc.block_hash;
            let range = proposals.first().as_ref().unwrap().number()
                ..=proposals.last().as_ref().unwrap().number();
            if self.db.contains_canonical_block(&ancestor_hash)? {
                info!(?range, "sync::InjectRecent : received");
                self.inject_proposals(proposals)?;
            } else {
                debug!(?range, "sync::InjectRecent: skipped");
            }
        }
        self.segments.empty_sync_metadata();
        self.state = SyncState::Phase0;
        Ok(())
    }

    /// Update the startingBlock value.
    ///
    /// Must be called before starting/re-starting Phase 1.
    fn update_started_at(&mut self) -> Result<()> {
        self.started_at = self
            .db
            .get_highest_canonical_block_number()?
            .expect("no highest canonical block");
        if self.started_at < self.zq2_floor_height {
            error!(
                "Starting block {} is below ZQ2 height {}",
                self.started_at, self.zq2_floor_height
            );
        }
        Ok(())
    }

    /// Convenience function to convert a block to a proposal (add full txs)
    /// Should only be used for syncing history, not for consensus messages regarding new blocks.
    fn block_to_proposal(&self, block: Block) -> Proposal {
        // since block must be valid, unwrap(s) are safe
        let txs = block
            .transactions
            .iter()
            .map(|hash| self.db.get_transaction(hash).unwrap().unwrap())
            // handle verification on the client-side
            .map(|tx| (tx.tx, tx.hash))
            .collect_vec();
        Proposal::from_parts_with_hashes(block, txs)
    }

    /// Phase 2: Retry Phase 1
    ///
    /// If something went wrong in Phase 2, Phase 1 may need to be retried for the recently used segment.
    /// Things that could go wrong e.g. the peer went offline, the peer pruned history, etc.
    ///
    /// Pop the most recently used segment from the segment marker, and retry phase 1.
    /// This will rebuild history from the previous marker, with another peer.
    /// If this function is called many times, it will eventually restart from Phase 0.
    fn retry_phase1(&mut self) -> Result<()> {
        let SyncState::Retry1((range, marker)) = &self.state else {
            unimplemented!("sync::RetryPhase1 : invalid state");
        };

        self.retry_count = self.retry_count.saturating_add(1);
        debug!(?range, "sync::Retry1");

        // Insert faux metadata - we only need the number, parent_hash
        let mut faux_header = BlockHeader::genesis(Hash::ZERO);
        faux_header.number = marker.number.saturating_add(1);
        faux_header.qc.block_hash = marker.hash;

        self.state = SyncState::Phase1(faux_header);
        self.inject_at = None;

        // Ensure started is updated - https://github.com/Zilliqa/zq2/issues/2306
        self.update_started_at()?;
        self.do_sync()
    }

    /// Handle Passive Sync Request
    pub fn handle_passive_request(
        &mut self,
        from: PeerId,
        request: RequestBlocksByHash,
    ) -> Result<ExternalMessage> {
        debug!(hash = %request.hash, count = %request.count, %from,
            "sync::PassiveRequest : received",
        );

        // Check if we should service this request - https://github.com/Zilliqa/zq2/issues/1878
        if self.ignore_passive {
            warn!("sync::PassiveRequest : ignored");
            return Ok(ExternalMessage::PassiveSyncResponse(vec![]));
        }

        // Do not respond to stale requests as the client has probably timed-out
        if request.request_at.elapsed()?.as_secs() > 20 {
            warn!("sync::PassiveRequest : stale");
            return Ok(ExternalMessage::PassiveSyncResponse(vec![]));
        }

        if !self.db.contains_canonical_block(&request.hash)? {
            warn!("sync::PassiveRequest : missing");
            return Ok(ExternalMessage::PassiveSyncResponse(vec![]));
        };

        let started_at = Instant::now();
        let mut metas = Vec::new();
        let mut hash = request.hash;
        let mut size = 0;
        // return as much as possible
        while started_at.elapsed().as_millis() < Self::PRUNE_TIMEOUT_MS {
            // grab the block
            let Some(block) = self.db.get_block_by_hash(&hash)? else {
                break; // that's all we have!
            };
            let number = block.number();
            // and the receipts
            let receipts = self.db.get_transaction_receipts_in_block(&hash)?;
            let transaction_receipts = receipts
                .into_iter()
                .map(|r| {
                    let txn = self.db.get_transaction(&r.tx_hash).unwrap().unwrap();
                    (txn.tx, r)
                })
                .collect_vec();
            hash = block.parent_hash();

            // create the response
            let response = BlockTransactionsReceipts {
                block,
                transaction_receipts,
            };

            // compute the size
            let encoded = cbor4ii::serde::to_vec(Vec::new(), &response)?;
            size += encoded.len();
            if size > Self::RESPONSE_SIZE_THRESHOLD {
                // if the block is big, we will skip it for the current set of responses; and
                // it will go into the next response as a compressed block
                if !metas.is_empty() {
                    break; // return whatever fits
                }

                warn!(%number, %size, "sync::PassiveRequest : exceeded");
                // compress the single block; and respond
                let mut encoder = lz4::EncoderBuilder::new().build(Vec::new())?;
                std::io::Write::write_all(&mut encoder, &encoded)?;
                let (lzblock, result) = encoder.finish();
                result.expect("sync::PassiveRequest : lz4");
                return Ok(ExternalMessage::PassiveSyncResponseLZ(lzblock));
            }

            // add to the response
            metas.push(response);
            if metas.len() >= request.count {
                break; // we have enough
            }
        }

        let message = ExternalMessage::PassiveSyncResponse(metas);
        Ok(message)
    }

    /// Phase 4: Handle Passive Header Response
    ///
    pub fn handle_passive_response(
        &mut self,
        from: PeerId,
        response: Option<Vec<BlockTransactionsReceipts>>,
    ) -> Result<()> {
        let SyncState::Phase4(_) = self.state else {
            warn!(%from, "sync::PassiveResponse : dropped");
            return Ok(());
        };
        if self.in_flight.is_empty() || self.in_flight.front().unwrap().0.peer_id != from {
            warn!(%from, "sync::PassiveResponse : spurious");
            return Ok(());
        }

        if let Some(response) = response {
            if !response.is_empty() {
                info!(length = response.len(), %from,
                    "sync::PassiveResponse : received",
                );
                // self.blocks_downloaded = self.blocks_downloaded.saturating_add(response.len());
                self.peers
                    .done_with_peer(self.in_flight.pop_front(), DownGrade::None);

                // store the blocks in the DB
                self.store_proposals(response)?;
            } else {
                warn!(%from, "sync::PassiveResponse : empty",);
                self.peers
                    .done_with_peer(self.in_flight.pop_front(), DownGrade::Empty);
            }
        } else {
            warn!(%from, "sync::PassiveResponse : error",);
            self.peers
                .done_with_peer(self.in_flight.pop_front(), DownGrade::Error);
        }
        // fall-thru in all cases
        self.state = SyncState::Phase0;
        self.do_sync()
    }

    /// Phase 4: Request Passive Sync
    ///
    /// Request for as much as possible, but will only receive partial response.
    fn request_passive_sync(&mut self) -> Result<()> {
        let SyncState::Phase4((last, hash)) = self.state else {
            unimplemented!("sync::PassiveSync : invalid state");
        };

        // Early exit if there's a request in-flight; and if it has not expired.
        if !self.in_flight.is_empty() {
            debug!("sync::PassiveSync : syncing");
            return Ok(());
        }

        if let Some(peer_info) = self.peers.get_next_peer() {
            let range = self.sync_base_height..=last;
            info!(?range, from = %peer_info.peer_id, "sync::PassiveSync : requesting");
            let message = ExternalMessage::PassiveSyncRequest(RequestBlocksByHash {
                request_at: SystemTime::now(),
                count: range.count(),
                hash,
            });
            let request_id = self
                .message_sender
                .send_external_message(peer_info.peer_id, message)?;
            self.add_in_flight(peer_info, request_id);
        } else {
            warn!("sync::PassiveSync : insufficient peers");
        }
        Ok(())
    }

    /// Phase 2: Handle a multi-block response.
    ///
    /// This is Phase 2 in the syncing algorithm, where we receive a set of blocks and inject them into the pipeline.
    /// We also remove the blocks from the chain metadata, because they are now in the pipeline.
    pub fn handle_multiblock_response(
        &mut self,
        from: PeerId,
        response: Option<Vec<Proposal>>,
    ) -> Result<()> {
        let SyncState::Phase2((_, range, _)) = &self.state else {
            warn!(%from, "sync::MultiBlockResponse : dropped");
            return Ok(());
        };
        if self.in_flight.is_empty() || self.in_flight.front().unwrap().0.peer_id != from {
            warn!(%from, "sync::MultiBlockResponse : spurious");
            return Ok(());
        }

        // Only process a full response
        if let Some(response) = response {
            if !response.is_empty() {
                info!(?range, %from,
                    "sync::MultiBlockResponse : received",
                );
                self.blocks_downloaded = self.blocks_downloaded.saturating_add(response.len());
                self.peers
                    .done_with_peer(self.in_flight.pop_front(), DownGrade::None);
                if self.do_multiblock_response(from, response)? {
                    return Ok(()); // successful
                };
            } else {
                // Empty response, downgrade peer and retry phase 1.
                warn!(%from, "sync::MultiBlockResponse : empty",);
                self.peers
                    .done_with_peer(self.in_flight.pop_front(), DownGrade::Empty);
            }
        } else {
            // Network failure, downgrade peer and retry phase 1.
            warn!(%from, "sync::MultiBlockResponse : error",);
            self.peers
                .done_with_peer(self.in_flight.pop_front(), DownGrade::Error);
        }
        // failure fall-thru
        if let SyncState::Phase2((_, range, marker)) = &self.state {
            self.state = SyncState::Retry1((range.clone(), *marker));
        };
        self.do_sync()
    }

    fn do_multiblock_response(&mut self, from: PeerId, response: Vec<Proposal>) -> Result<bool> {
        let check_sum = match &self.state {
            SyncState::Phase2(x) => x.0,
            _ => unimplemented!("sync::MultiBlockResponse : invalid state"),
        };

        // If the checksum does not match, fail.
        let computed_sum = response
            .iter()
            .fold(Hash::builder().with(Hash::ZERO.as_bytes()), |sum, p| {
                sum.with(p.hash().as_bytes())
            })
            .finalize();

        if check_sum != computed_sum {
            error!(
                "sync::MultiBlockResponse : unexpected checksum={check_sum} != {computed_sum} from {from}"
            );
            return Ok(false);
        }

        // Response seems sane.
        let proposals = response
            .into_iter()
            .sorted_by_key(|p| p.number())
            .collect_vec();

        // Process the proposals
        if !self.inject_proposals(proposals)? {
            // phase-2 is stuck, cancel sync and restart
            self.state = SyncState::Phase3;
        };

        // if we're done
        if self.segments.count_sync_segments() == 0 {
            self.state = SyncState::Phase3;
        }

        Ok(true)
    }

    /// Returns a list of Proposals
    ///
    /// Given a set of block hashes, retrieve the list of proposals from its history.
    /// Returns this list of proposals to the requestor.
    pub fn handle_multiblock_request(
        &mut self,
        from: PeerId,
        request: Vec<Hash>,
    ) -> Result<ExternalMessage> {
        debug!(length = %request.len(), %from,
            "sync::MultiBlockRequest : received",
        );

        // TODO: Any additional checks
        // Validators should not respond to this, unless they are free e.g. stuck in an exponential backoff.

        let batch_size: usize = Self::MAX_BATCH_SIZE.min(request.len()); // mitigate DOS by limiting the number of blocks we return
        let mut proposals = Vec::with_capacity(batch_size);
        let mut cbor_size = 0;
        for hash in request {
            if cbor_size > Self::RESPONSE_SIZE_THRESHOLD {
                break; // response size limit reached
            }
            let Some(block) = self.db.get_block_by_hash(&hash)? else {
                break; // that's all we have!
            };
            if block.number() < self.zq2_floor_height {
                // do not active sync ZQ1 blocks
                warn!("sync::MultiBlockRequest : skipping ZQ1");
                break;
            }
            let proposal = self.block_to_proposal(block);
            let encoded_size = self.size_cache.get(&hash).cloned().unwrap_or_else(|| {
                cbor4ii::serde::to_vec(Vec::with_capacity(1024 * 1024), &proposal)
                    .unwrap()
                    .len()
            });
            cbor_size = cbor_size.saturating_add(encoded_size);
            proposals.push(proposal);
        }

        let message = ExternalMessage::MultiBlockResponse(proposals);
        Ok(message)
    }

    /// Phase 2: Request missing blocks from the chain.
    ///
    /// It constructs a set of hashes, which constitute the series of blocks that are missing.
    /// These hashes are then sent to a Peer for retrieval.
    /// This is phase 2 of the syncing algorithm.
    /// ** MAKE ONLY ONE REQUEST AT A TIME **
    fn request_missing_blocks(&mut self) -> Result<()> {
        if !matches!(self.state, SyncState::Phase2(_)) {
            unimplemented!("sync::MissingBlocks : invalid state");
        }
        // Early exit if there's a request in-flight; and if it has not expired.
        if !self.in_flight.is_empty() || self.in_pipeline > self.max_blocks_in_flight {
            debug!(
                "sync::MissingBlocks : syncing {}/{} blocks",
                self.in_pipeline, self.max_blocks_in_flight
            );
            return Ok(());
        }

        // will be re-inserted below
        if let Some(peer) = self.peers.get_next_peer() {
            // reinsert peer, as we will use a faux peer below, to force the request to go to the original responder
            self.peers.reinsert_peer(peer);

            // If we have no chain_segments, we have nothing to do
            if let Some((request_hashes, peer_info, block, range)) =
                self.segments.pop_last_sync_segment()
            {
                // Checksum of the request hashes
                let checksum = request_hashes
                    .iter()
                    .fold(Hash::builder().with(Hash::ZERO.as_bytes()), |sum, h| {
                        sum.with(h.as_bytes())
                    })
                    .finalize();

                // Fire request, to the original peer that sent the segment metadata
                info!(?range, from = %peer_info.peer_id,
                    "sync::MissingBlocks : requesting",
                );

                self.state = SyncState::Phase2((checksum, range, block));

                let message = ExternalMessage::MultiBlockRequest(request_hashes);
                let request_id = self
                    .message_sender
                    .send_external_message(peer_info.peer_id, message)?;
                self.add_in_flight(peer_info, request_id);
            } else {
                warn!("sync::MissingBlocks : no segments");
                self.state = SyncState::Phase3;
            }
        } else {
            warn!("sync::MissingBlocks : insufficient peers");
        }
        Ok(())
    }

    /// Phase 0: Handle a probe response
    ///
    /// Handle probe response:
    /// - Starts the sync-from-probe process.
    pub fn handle_block_response(
        &mut self,
        from: PeerId,
        mut response: BlockResponse,
    ) -> Result<()> {
        match self.state {
            // Start sync-from-probe
            SyncState::Phase0
                if response.availability.is_none() && !response.proposals.is_empty() =>
            {
                let proposal = response.proposals.pop().unwrap();
                if proposal.number() > self.started_at {
                    // inevitably from one of the bootstrap nodes
                    debug!(self = %self.started_at, block = %proposal.number(), %from,
                        "sync::BlockResponse : syncing",
                    );
                    self.sync_from_proposal(proposal)?;
                } else {
                    debug!(self = %self.started_at, block = %proposal.number(), %from,
                        "sync::BlockResponse : skipped",
                    );
                }
                Ok(())
            }
            _ => Ok(()),
        }
    }

    /// Handle probe request
    ///
    /// This is the first step in the syncing algorithm, where we receive a probe request and respond with the highest block we have.
    pub fn handle_block_request(
        &mut self,
        from: PeerId,
        request: BlockRequest,
    ) -> Result<ExternalMessage> {
        // probe message is BlockRequest::default()
        if request != BlockRequest::default() || from == self.peer_id {
            return Ok(ExternalMessage::Acknowledgement);
        }

        // Must have at least 1 block, genesis/checkpoint
        let block = self.db.get_highest_canonical_block()?.unwrap();

        info!(%from, number = %block.number(), "sync::BlockRequest : received");

        // send cached response
        if let Some(prop) = self.cache_probe_response.as_ref() {
            if prop.hash() == block.hash() {
                return Ok(ExternalMessage::BlockResponse(BlockResponse {
                    proposals: vec![prop.clone()],
                    from_view: u64::MAX,
                    availability: None,
                }));
            }
        };

        // Construct the proposal
        let prop = self.block_to_proposal(block);
        self.cache_probe_response = Some(prop.clone());
        let message = ExternalMessage::BlockResponse(BlockResponse {
            proposals: vec![prop],
            from_view: u64::MAX,
            availability: None,
        });
        Ok(message)
    }

    /// Phase 1: Handle a response to a metadata request.
    ///
    /// This is the first step in the syncing algorithm, where we receive a set of metadata and use it to
    /// construct a chain history. We check that the metadata does indeed constitute a segment of a chain.
    /// If it does, we record its segment marker and store the entire chain in-memory.
    pub fn handle_active_response(
        &mut self,
        from: PeerId,
        response: Option<Vec<SyncBlockHeader>>,
    ) -> Result<()> {
        if !matches!(self.state, SyncState::Phase1(_)) {
            warn!(%from, "sync::ActiveResponse : dropped");
            return Ok(());
        };
        if self.in_flight.is_empty() {
            warn!(%from, "sync::ActiveResponse : spurious");
            return Ok(());
        }

        // buffer response for processing
        self.p1_response.insert(from, response);

        // process responses, in-order
        while let Some((peer, _)) = self.in_flight.front() {
            if self.p1_response.contains_key(&peer.peer_id) {
                let peer_id = peer.peer_id;
                let response = self.p1_response.remove(&peer_id).unwrap();
                if let Some(response) = response {
                    // Only process a full response
                    if response.is_empty() || response.len() > self.max_batch_size {
                        warn!(from = %peer_id, "sync::ActiveResponse : invalid");
                        self.peers
                            .done_with_peer(self.in_flight.pop_front(), DownGrade::Empty);
                    } else {
                        self.headers_downloaded =
                            self.headers_downloaded.saturating_add(response.len());

                        let range = response.last().unwrap().header.number
                            ..=response.first().unwrap().header.number;

                        // full/last segment
                        if response.len() == self.max_batch_size
                            || *range.start() <= self.started_at
                        {
                            info!(?range, from = %peer_id,
                                "sync::ActiveResponse : received",
                            );
                            let peer = peer.clone();

                            self.peers
                                .done_with_peer(self.in_flight.pop_front(), DownGrade::None);

                            self.do_metadata_response(peer, response)?;
                            continue;
                        } else {
                            // retry partial
                            warn!(from = %peer_id, "sync::ActiveResponse : partial");
                            self.peers
                                .done_with_peer(self.in_flight.pop_front(), DownGrade::Empty);
                        }
                    }
                } else {
                    // Network failure, downgrade peer and retry.
                    warn!(from = %peer_id, "sync::ActiveResponse : error");
                    self.peers
                        .done_with_peer(self.in_flight.pop_front(), DownGrade::Error);
                }
                // failure fall-thru - fire one retry
                self.do_missing_metadata(1)?;
                if !self.in_flight.is_empty() {
                    self.in_flight.rotate_right(1); // adjust request order, do_missing_metadata() pushes peer to the back.
                }
            } else {
                break;
            }
        }

        // Stop potential recursion issues - https://github.com/Zilliqa/zq2/issues/3006
        // Only progress the state machine when all the pending requests are completed, either way.
        if !self.in_flight.is_empty() {
            return Ok(());
        }
        self.do_sync()
    }

    fn do_metadata_response(
        &mut self,
        segment_peer: PeerInfo,
        response: Vec<SyncBlockHeader>,
    ) -> Result<()> {
        let meta = match &self.state {
            SyncState::Phase1(meta) => meta,
            _ => unimplemented!("sync::DoMetadataResponse : invalid state"),
        };

        // Check the linkage of the returned chain
        let mut block_hash = meta.qc.block_hash;
        let mut block_num = meta.number;
        for SyncBlockHeader { header: meta, .. } in response.iter() {
            // check that the block hash and number is as expected.
            if meta.hash != Hash::ZERO && block_hash == meta.hash && block_num == meta.number + 1 {
                block_hash = meta.qc.block_hash;
                block_num = meta.number;
            } else {
                // If something does not match, restart from the last known segment.
                // This is a safety mechanism to prevent a peer from sending us garbage.
                error!(
                    "sync::DoMetadataResponse : unexpected metadata hash={block_hash} != {}, num={block_num} != {}",
                    meta.hash, meta.number,
                );
                // Unless, it is the first segment, where it will restart the entire sync.
                // https://github.com/Zilliqa/zq2/issues/2416
                if self.segments.count_sync_segments() <= 1 {
                    self.state = SyncState::Phase3; // flush, drop all segments, and restart
                    self.p1_response.clear();
                    for p in self.in_flight.drain(..) {
                        self.peers.done_with_peer(Some(p), DownGrade::None);
                    }
                }
                return Ok(());
            }
            if meta.hash == response.last().unwrap().header.hash {
                break; // done, we do not check the last parent, because that's outside this segment
            }
        }

        // Chain segment is sane, drop redundant blocks already in the DB.
        let mut drop = false;
        let segment = response
            .into_iter()
            .filter(|b| {
                trace!(size = %b.size_estimate, number = %b.header.number, "sync::DoMetadataResponse : block");
                drop |= self
                    .db
                    .contains_canonical_block(&b.header.hash)
                    .unwrap_or_default();
                !drop
            })
            .collect_vec();

        // Record non-empty segment
        if !segment.is_empty() {
            // Record segment landmark/marker
            self.segments
                .push_sync_segment(&segment_peer, segment.first().unwrap().header.hash);
            let segment_last = segment.last().cloned().unwrap().header;

            // Dynamic sub-segments - https://github.com/Zilliqa/zq2/issues/2312
            let mut block_size: usize = 0;
            let mut sub_segments = segment
                .into_iter()
                .rev() // Computed in ascending order, so that landmarks always top the segment.
                .filter(|&sb| {
                    self.segments.insert_sync_metadata(&sb.header); // record all metadata
                    block_size = block_size.saturating_add(sb.size_estimate);
                    trace!(total=%block_size, "sync::DoMetadataResponse : response");
                    if block_size > Self::RESPONSE_SIZE_THRESHOLD {
                        block_size = 0;
                        true
                    } else {
                        false
                    }
                })
                .collect_vec();
            while let Some(SyncBlockHeader { header, .. }) = sub_segments.pop() {
                // segment markers are inserted in descending order, which is the order in the stack.
                self.segments.push_sync_segment(&segment_peer, header.hash);
            }

            // Record the oldest block in the segment
            self.state = SyncState::Phase1(segment_last);
        }

        if drop {
            // turnaround to Phase 2.
            self.state = SyncState::Phase2((Hash::ZERO, 0..=0, BlockHeader::genesis(Hash::ZERO)));
            // drop all pending requests & responses
            self.p1_response.clear();
            for p in self.in_flight.drain(..) {
                self.peers.done_with_peer(Some(p), DownGrade::None);
            }
        }
        Ok(())
    }

    /// Returns the metadata of the chain from a given hash.
    ///
    /// This constructs a historical chain going backwards from a hash, by following the parent_hash.
    /// It collects N blocks and returns the metadata of that particular chain.
    /// This is mainly used in Phase 1 of the syncing algorithm, to construct a chain history.
    pub fn handle_active_request(
        &mut self,
        from: PeerId,
        request: RequestBlocksByHeight,
    ) -> Result<ExternalMessage> {
        let range = request.from_height..=request.to_height;
        debug!(?range, %from,
            "sync::MetadataRequest : received",
        );

        if self.zq2_floor_height > request.to_height {
            warn!("sync::MetadataRequest : skipping ZQ1");
            return Ok(ExternalMessage::SyncBlockHeaders(vec![]));
        }

        // Do not respond to stale requests as the client has probably timed-out
        if request.request_at.elapsed()?.as_secs() > 20 {
            warn!("sync::MetadataRequest : stale");
            return Ok(ExternalMessage::SyncBlockHeaders(vec![]));
        }

        let batch_size = Self::MAX_BATCH_SIZE
            .min(request.to_height.saturating_sub(request.from_height) as usize);
        let mut metas = Vec::with_capacity(batch_size);
        let Some(block) = self.db.get_canonical_block_by_number(request.to_height)? else {
            warn!("sync::MetadataRequest : missing");
            return Ok(ExternalMessage::SyncBlockHeaders(vec![]));
        };

        let mut hash = block.hash();
        while metas.len() <= batch_size {
            let Some(block) = self.db.get_block_by_hash(&hash)? else {
                break; // that's all we have!
            };

            let encoded_size = self.size_cache.get(&hash).cloned().unwrap_or_else(|| {
                // pseudo-LRU approximation
                if self.size_cache.len() > Self::MAX_CACHE_SIZE {
                    let mut rng = rand::thread_rng();
                    self.size_cache.retain(|_, _| rng.gen_bool(0.99));
                }
                // A large block can cause a node to get stuck syncing since no node can respond to the request in time.
                let proposal = self.block_to_proposal(block.clone());
                let encoded_size =
                    cbor4ii::serde::to_vec(Vec::with_capacity(1024 * 1024), &proposal)
                        .unwrap()
                        .len();
                self.size_cache.insert(hash, encoded_size);
                encoded_size
            });

            // insert the sync size
            metas.push(SyncBlockHeader {
                header: block.header,
                size_estimate: encoded_size,
            });
            hash = block.parent_hash();

            if block.number().saturating_sub(1) < self.zq2_floor_height {
                warn!("sync::MetadataRequest : skipping ZQ1");
                break;
            }
        }

        let message = ExternalMessage::SyncBlockHeaders(metas);
        Ok(message)
    }

    /// Phase 1: Request chain metadata from a peer.
    ///
    /// This constructs a chain history by requesting blocks from a peer, going backwards from a given block.
    /// If Phase 1 is in progress, it continues requesting blocks from the last known Phase 1 block.
    /// Otherwise, it requests blocks from the given starting metadata.
    pub fn request_missing_headers(&mut self) -> Result<()> {
        if !matches!(self.state, SyncState::Phase1(_)) {
            unimplemented!("sync::RequestMissingHeaders : invalid state");
        }
        // Early exit if there's a request in-flight; and if it has not expired.
        if !self.in_flight.is_empty() || self.in_pipeline > self.max_batch_size {
            // anything more than this and we cannot be sure whether the segment hits history
            debug!(
                "sync::RequestMissingHeaders : syncing {}/{} blocks",
                self.in_pipeline, self.max_batch_size
            );
            return Ok(());
        }

        let good_count = self.peers.count_good_peers();
        let peer_count = self.peers.count();
        let peer_set = if good_count > Self::MAX_CONCURRENT_PEERS {
            Self::MAX_CONCURRENT_PEERS // ideal case, more than enough good peers
        } else if good_count > 1 {
            good_count.saturating_sub(1) // leave one spare, for handling issues; eventually degenerates to 1-peer
        } else if peer_count > Self::MAX_CONCURRENT_PEERS {
            Self::MAX_CONCURRENT_PEERS // then, retry with non-good ones too; trying to bump up peers
        } else if peer_count > 1 {
            peer_count.saturating_sub(1) // leave one spare, for handling issues.
        } else {
            peer_count // last ditch effort, with only 1-peer (or none)
        };

        if peer_set == 0 {
            warn!("sync::RequestMissingHeaders : insufficient peers");
            return Ok(());
        }

        self.do_missing_metadata(peer_set)
    }

    /// Phase 1: Request chain metadata from a peer.
    ///
    /// This fires concurrent requests to N peers, to fetch different segments of chain metadata.
    /// The number of requests is limited by:
    /// - the number of good peers
    /// - hitting the starting point
    /// - encountering a V1 peer
    fn do_missing_metadata(&mut self, num_peers: usize) -> Result<()> {
        if !matches!(self.state, SyncState::Phase1(_)) {
            unimplemented!("sync::DoMissingMetadata : invalid state");
        }
        let mut offset = u64::MIN;
        for num in 1..=num_peers {
            if let Some(peer_info) = self.peers.get_next_peer() {
                let (message, done, range) = match &self.state {
                    SyncState::Phase1(BlockHeader {
                        number: block_number,
                        ..
                    }) => {
                        let range = block_number
                            .saturating_sub(offset)
                            .saturating_sub(self.max_batch_size as u64)
                            ..=block_number.saturating_sub(offset).saturating_sub(1);
                        let message = ExternalMessage::MetaDataRequest(RequestBlocksByHeight {
                            request_at: SystemTime::now(),
                            to_height: *range.end(),
                            from_height: *range.start(),
                        });
                        (message, *range.start() < self.started_at, range)
                    }
                    _ => unreachable!(),
                };

                debug!(?range, from = %peer_info.peer_id,
                    "sync::DoMissingMetadata : requesting ({num}/{num_peers})",
                );
                let count = range.count();
                offset = offset.saturating_add(count as u64);

                let request_id = self
                    .message_sender
                    .send_external_message(peer_info.peer_id, message)?;
                self.add_in_flight(peer_info, request_id);

                if done {
                    break;
                }
            } else {
                warn!("sync::DoMissingMetadata : insufficient peers");
                break;
            }
        }
        Ok(())
    }

    /// Phase 5: Store Proposals
    ///
    /// These need only be stored, not executed - IN DESCENDING ORDER.
    fn store_proposals(&mut self, response: Vec<BlockTransactionsReceipts>) -> Result<()> {
        let SyncState::Phase4((mut number, mut hash)) = self.state else {
            unimplemented!("sync::StoreProposals : invalid state");
        };
        let response = response
            .into_iter()
            .sorted_by_key(|p| Reverse(p.block.number()))
            .collect_vec();

        // Store it from high to low
        for BlockTransactionsReceipts {
            block,
            transaction_receipts,
        } in response
        {
            // Check for correct order
            if number == block.number() && hash == block.hash() {
                number = number.saturating_sub(1);
                hash = block.header.qc.block_hash;
            } else {
                error!(
                    "sync::StoreProposals : unexpected proposal number={number} != {}; hash={hash} != {}",
                    block.number(),
                    block.hash(),
                );
                return Ok(());
            }

            // Verify ZQ2 blocks only - ZQ1 blocks have faux block hashes, to maintain history.
            if block.verify_hash().is_err() && block.number() >= self.zq2_floor_height {
                return Err(anyhow::anyhow!(
                    "sync::StoreProposals : unverified {}",
                    block.number()
                ));
            }
            trace!(
                number = %block.number(), hash = %block.hash(),
                "sync::StoreProposals : applying",
            );

            // Store it
            self.db.with_sqlite_tx(|sqlite_tx| {
                    // Insert block
                    self.db.insert_block_with_db_tx(sqlite_tx, &block)?;
                    // Insert transactions/receipts
                    for (st, rt) in transaction_receipts {
                        // Verify transaction
                        if let Ok(vt) = st.clone().verify() {
                            self.db
                                .insert_transaction_with_db_tx(sqlite_tx, &vt.hash, &vt)?;
                        } else if block.number() < self.zq2_floor_height {
                            // FIXME: ZQ1 bypass
                            error!(number = %block.number(), index = %rt.index, hash = %rt.tx_hash, "sync::StoreProposals : unverifiable");
                            self.db
                                .insert_transaction_with_db_tx(sqlite_tx, &rt.tx_hash, &st.verify_bypass()?)?;
                        } else {
                            anyhow::bail!(
                                "sync::StoreProposal : unverifiable transaction {}/{}/{}",
                                block.number(),
                                rt.index,
                                rt.tx_hash
                            )
                        }
                        self.db
                            .insert_transaction_receipt_with_db_tx(sqlite_tx, rt)?;
                    }
                    Ok(())
                })?;
        }
        Ok(())
    }

    /// Phase 2 / 3: Inject the proposals into the chain.
    ///
    /// It adds the list of proposals into the pipeline for execution.
    /// It also outputs some syncing statistics.
    fn inject_proposals(&mut self, proposals: Vec<Proposal>) -> Result<bool> {
        if proposals.is_empty() {
            return Ok(true);
        }

        let highest_number = self
            .db
            .get_highest_canonical_block_number()?
            .unwrap_or_default();

        // Output some stats
        if let Some((when, injected, prev_highest)) = self.inject_at {
            let diff = injected - self.in_pipeline;
            let rate = diff as f32 / when.elapsed().as_secs_f32();
            debug!(%rate, "sync::InjectProposals : injected");
            // Detect if node is stuck i.e. active-sync is not making progress
            if highest_number == prev_highest
                && proposals
                    .first()
                    .unwrap()
                    .number()
                    .saturating_sub(self.max_blocks_in_flight as u64)
                    .saturating_sub(self.in_pipeline as u64)
                    .gt(&highest_number)
            {
                warn!(number = %prev_highest, "sync::InjectProposals : stuck");
                return Ok(false);
            }
        }

        // Increment proposals injected
        self.in_pipeline = self.in_pipeline.saturating_add(proposals.len());
        debug!(
            "sync::InjectProposals : injecting {}/{}",
            proposals.len(),
            self.in_pipeline
        );

        // Just pump the Proposals back to ourselves.
        for p in proposals {
            trace!(
                number = %p.number(), hash = %p.hash(),
                "sync::InjectProposals : applying",
            );
            self.message_sender.send_external_message(
                self.peer_id,
                ExternalMessage::InjectedProposal(InjectedProposal {
                    from: self.peer_id,
                    block: p,
                }),
            )?;
        }

        self.inject_at = Some((std::time::Instant::now(), self.in_pipeline, highest_number));
        Ok(true)
    }

    /// Mark a received proposal
    ///
    /// Mark a proposal as received, and remove it from the chain.
    pub fn mark_received_proposal(&mut self, number: u64) -> Result<()> {
        trace!(%number, "sync::MarkReceivedProposal : received");
        self.in_pipeline = self.in_pipeline.saturating_sub(1);
        // perform next block transfers, where possible
        self.do_sync()
    }

    /// Returns (am_syncing, current_highest_block)
    pub fn am_syncing(&self) -> Result<bool> {
        let sync_phases = matches!(
            self.state,
            SyncState::Phase1(_) | SyncState::Phase2(_) | SyncState::Phase3 | SyncState::Retry1(_)
        );
        Ok(sync_phases || self.in_pipeline != 0)
    }

    // Returns (starting_block, current_block,  highest_block) if we're syncing,
    // None if we're not.
    pub fn get_sync_data(&self) -> Result<Option<SyncingStruct>> {
        if !self.am_syncing()? {
            return Ok(None);
        }

        let current_block = self
            .db
            .get_highest_canonical_block_number()?
            .expect("no highest block");

        let peer_count = self.peers.count() + self.in_flight.len();

        Ok(Some(SyncingStruct {
            starting_block: self.started_at,
            current_block,
            highest_block: self.highest_block_seen,
            stats: SyncingMeta {
                peer_count,
                current_phase: self.state.to_string(),
                retry_count: self.retry_count,
                error_count: self.error_count,
                empty_count: self.empty_count,
                header_downloads: self.headers_downloaded,
                block_downloads: self.blocks_downloaded,
                buffered_blocks: self.in_pipeline,
                active_sync_count: self.active_sync_count,
            },
        }))
    }

    // Add an in-flight request
    fn add_in_flight(&mut self, peer_info: PeerInfo, request_id: RequestId) {
        self.in_flight.push_back((peer_info, request_id));
    }

    // Fired from both [Self::sync_from_probe(); and [Consensus::sync_from_probe()] test.
    pub fn probe_peer(&mut self, peer: PeerId) {
        self.message_sender
            .send_external_message(peer, ExternalMessage::BlockRequest(BlockRequest::default()))
            .ok(); // ignore errors, retry with subsequent peer(s).
    }

    pub fn peer_ids(&self) -> Vec<PeerId> {
        self.peers
            .peer_ids()
            .into_iter()
            .chain(self.in_flight.iter().map(|(p, _)| p.peer_id))
            .collect()
    }
}

#[derive(Debug)]
pub struct SyncPeers {
    peer_id: PeerId,
    peers: Arc<Mutex<BinaryHeap<PeerInfo>>>,
}

impl SyncPeers {
    pub fn new(peer_id: PeerId) -> Self {
        Self {
            peer_id,
            peers: Arc::new(Mutex::new(BinaryHeap::<PeerInfo>::new())),
        }
    }

    /// Count the number of good peers
    pub fn count_good_peers(&self) -> usize {
        let peers = self.peers.lock().unwrap();
        if peers.is_empty() {
            return 0;
        }
        let best_score = peers.iter().map(|p| p.score).min().unwrap();
        let best_count = peers.iter().filter(|p| p.score == best_score).count();

        best_count // optimistic, use as many peers as possible
    }

    fn count(&self) -> usize {
        self.peers.lock().unwrap().len()
    }

    fn peer_ids(&self) -> Vec<PeerId> {
        self.peers
            .lock()
            .unwrap()
            .iter()
            .map(|peer| peer.peer_id)
            .collect::<Vec<_>>()
    }

    /// Downgrade a peer based on the response received.
    ///
    /// This algorithm favours good peers that respond quickly (i.e. no timeout).
    /// In most cases, it eventually degenerates into 2 sources - avoid a single source of truth.
    fn done_with_peer(&self, in_flight: Option<(PeerInfo, RequestId)>, downgrade: DownGrade) {
        if in_flight.is_none() {
            return;
        }
        let (mut peer, _) = in_flight.unwrap();
        trace!("sync::DoneWithPeer {} {:?}", peer.peer_id, downgrade);
        // Reinsert peers that are good
        if peer.score < u32::MAX {
            peer.score = peer.score.saturating_add(downgrade as u32);
            self.append_peer(peer);
        }
    }

    /// Add bulk peers
    pub fn add_peers(&self, peers: Vec<PeerId>) {
        debug!("sync::AddPeers {:?}", peers);
        peers
            .into_iter()
            .filter(|p| *p != self.peer_id)
            .for_each(|p| self.add_peer(p));
    }

    /// Add a peer to the list of peers.
    pub fn add_peer(&self, peer: PeerId) {
        let mut peers = self.peers.lock().unwrap();
        // if the new peer is not synced, it will get downgraded to the back of heap.
        // but by placing them at the back of the 'best' pack, we get to try them out soon.
        let new_peer = PeerInfo {
            version: PeerVer::V2, // default to V2 since >= 0.7.0
            score: peers.iter().map(|p| p.score).min().unwrap_or_default(),
            peer_id: peer,
            last_used: Instant::now(),
        };
        // ensure that it is unique
        peers.retain(|p| p.peer_id != peer);
        peers.push(new_peer);
        trace!("sync::AddPeer {peer}/{}", peers.len());
    }

    /// Remove a peer from the list of peers.
    pub fn remove_peer(&self, peer: PeerId) {
        let mut peers = self.peers.lock().unwrap();
        peers.retain(|p: &PeerInfo| p.peer_id != peer);
        trace!("sync::RemovePeer {peer}/{}", peers.len());
    }

    /// Get the next best peer to use
    fn get_next_peer(&self) -> Option<PeerInfo> {
        if let Some(mut peer) = self.peers.lock().unwrap().pop() {
            peer.last_used = std::time::Instant::now();
            trace!(peer = % peer.peer_id, score= %peer.score, "sync::GetNextPeer");
            return Some(peer);
        }
        None
    }

    /// Reinserts the peer such that it is at the back of the good queue.
    fn append_peer(&self, mut peer: PeerInfo) {
        if peer.score == u32::MAX {
            return;
        }
        let mut peers = self.peers.lock().unwrap();
        if !peers.is_empty() {
            // Ensure that the next peer is equal or better
            peer.score = peer.score.max(peers.peek().unwrap().score);
        }
        peers.retain(|p| p.peer_id != peer.peer_id);
        peers.push(peer);
    }

    /// Reinserts the peer such that it is at the front of the good queue.
    fn reinsert_peer(&self, mut peer: PeerInfo) {
        if peer.score == u32::MAX {
            return;
        }
        let mut peers = self.peers.lock().unwrap();
        if !peers.is_empty() {
            // Ensure that it gets to the head of the line
            peer.last_used = peers
                .peek()
                .expect("peers.len() > 1")
                .last_used
                .checked_sub(Duration::from_secs(1))
                .expect("time is ordinal");
        }
        // ensure that it is unique
        peers.retain(|p| p.peer_id != peer.peer_id);
        peers.push(peer);
    }
}

#[derive(Debug, Clone, Eq, PartialEq)]
pub struct PeerInfo {
    pub score: u32,
    pub peer_id: PeerId,
    pub last_used: Instant,
    pub version: PeerVer,
}

impl Ord for PeerInfo {
    fn cmp(&self, other: &Self) -> Ordering {
        other
            .score
            .cmp(&self.score)
            .then_with(|| other.last_used.cmp(&self.last_used))
    }
}

impl PartialOrd for PeerInfo {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

/// For downgrading a peer from being selected in get_next_peer().
/// Ordered by degree of offence i.e. None is good, Timeout is worst
#[derive(Debug, Clone, Eq, PartialEq)]
enum DownGrade {
    None,
    Empty,
    Error,
}

impl Ord for DownGrade {
    fn cmp(&self, other: &Self) -> Ordering {
        (self.clone() as u32).cmp(&(other.clone() as u32))
    }
}

impl PartialOrd for DownGrade {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

/// Sync state
#[allow(clippy::large_enum_variant)]
#[derive(Debug, Clone)]
enum SyncState {
    Phase0,
    Phase1(BlockHeader),
    Phase2((Hash, RangeInclusive<u64>, BlockHeader)),
    Phase3,
    Retry1((RangeInclusive<u64>, BlockHeader)),
    Phase4((u64, Hash)),
}

impl std::fmt::Display for SyncState {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            SyncState::Phase0 => write!(f, "phase0"),
            SyncState::Phase1(_) => write!(f, "phase1"),
            SyncState::Phase2(_) => write!(f, "phase2"),
            SyncState::Phase3 => write!(f, "phase3"),
            SyncState::Retry1(_) => write!(f, "retry1"),
            SyncState::Phase4(_) => write!(f, "phase4"),
        }
    }
}

/// Peer Version
///
/// It identifies the form of sync algorithm that is supported by a peer. We assume that all peers are V1 at first.
/// At the first encounter with a peer, it is probed and its response determines if it is treated as a V1/V2 peer.
/// We have deprecated support for V1 peers. So, V1 now really means 'unknown' peer version.
///
/// V1 - peers that support original sync algorithm in `block_store.rs`
/// V2 - peers that support new sync algorithm in `sync.rs`
#[derive(Debug, Clone, Eq, PartialEq)]
pub enum PeerVer {
    V1 = 1, // deprecated
    V2 = 2,
}

impl FromSql for PeerVer {
    fn column_result(value: ValueRef) -> FromSqlResult<Self> {
        u32::column_result(value).map(|i| match i {
            1 => PeerVer::V1,
            2 => PeerVer::V2,
            _ => todo!("invalid version"),
        })
    }
}

impl ToSql for PeerVer {
    fn to_sql(&self) -> Result<ToSqlOutput, rusqlite::Error> {
        Ok((self.clone() as u32).into())
    }
}

#[derive(Debug, Default)]
struct SyncSegments {
    headers: HashMap<Hash, BlockHeader>,
    markers: Vec<(Hash, PeerInfo)>,
}

impl SyncSegments {
    /// Returns the number of stored sync segments
    fn count_sync_segments(&self) -> usize {
        self.markers.len()
    }

    /// Pop the stack, for active-sync from marker (inclusive)
    fn pop_last_sync_segment(
        &mut self,
    ) -> Option<(Vec<Hash>, PeerInfo, BlockHeader, RangeInclusive<u64>)> {
        let (mut hash, mut peer) = self.markers.pop()?;
        let mut hashes = vec![];
        let high_at = self.headers.get(&hash)?.number;
        let high_hash = self.headers.get(&hash)?.hash;
        let mut low_at = 0;
        while let Some(header) = self.headers.remove(&hash) {
            low_at = header.number;
            hashes.push(header.hash);
            hash = header.qc.block_hash;
        }
        peer.last_used = Instant::now();
        peer.score = u32::MAX;

        let mut faux_marker = BlockHeader::genesis(Hash::ZERO);
        faux_marker.number = high_at;
        faux_marker.hash = high_hash;

        Some((hashes, peer, faux_marker, low_at..=high_at))
    }

    /// Pushes a particular segment into the stack/queue.
    fn push_sync_segment(&mut self, peer: &PeerInfo, hash: Hash) {
        // do not double-push
        let last = self.markers.last().map_or_else(|| Hash::ZERO, |(h, _)| *h);
        if hash != last {
            self.markers.push((hash, peer.clone()));
        }
    }

    /// Bulk inserts a bunch of metadata.
    fn insert_sync_metadata(&mut self, meta: &BlockHeader) {
        self.headers.insert(meta.hash, *meta);
    }

    /// Empty the metadata table.
    fn empty_sync_metadata(&mut self) {
        self.markers.clear();
        self.headers.clear();
    }
}

// FIXME: Find a better way to do this, other than checking for debug/release build.
// For the purpose of testing, we need a smaller prune interval to ensure that the test cases run faster.
#[cfg(debug_assertions)]
pub const MIN_PRUNE_INTERVAL: u64 = 10;
#[cfg(not(debug_assertions))]
pub const MIN_PRUNE_INTERVAL: u64 = 300;

```

`zilliqa/src/test_util.rs`:

```rs
use std::{
    collections::HashMap,
    fs::DirBuilder,
    net::{IpAddr, SocketAddr},
    os::unix::fs::DirBuilderExt,
    path::PathBuf,
    process::{Child, Command, Stdio},
};

use alloy::{json_abi::JsonAbi, primitives::Bytes};
use foundry_compilers::{
    artifacts::{EvmVersion, Optimizer, Settings, SolcInput, Source},
    solc::{Solc, SolcLanguage},
};
use rand::{Rng, SeedableRng, distributions::Alphanumeric, rngs::SmallRng};
use serde::Deserialize;

pub fn compile_contract(path: &str, contract: &str) -> (JsonAbi, Bytes) {
    let path: PathBuf = format!("{}/{}", env!("CARGO_MANIFEST_DIR"), path).into();

    let solc_input = SolcInput::new(
        SolcLanguage::Solidity,
        Source::read_all_files(vec![path.clone()]).unwrap(),
        Settings {
            remappings: vec![
                format!(
                    "@openzeppelin/contracts={}/../vendor/openzeppelin-contracts/contracts",
                    env!("CARGO_MANIFEST_DIR")
                )
                .parse()
                .unwrap(),
            ],
            optimizer: Optimizer {
                enabled: Some(true),
                runs: Some(2usize.pow(32) - 1),
                details: None,
            },
            ..Default::default()
        },
    )
    .evm_version(EvmVersion::Shanghai); // ensure compatible with EVM version in exec.rs

    let mut solc = Solc::find_or_install(&semver::Version::new(0, 8, 28)).unwrap();
    solc.allow_paths
        .insert(PathBuf::from("../vendor/openzeppelin-contracts"));
    let mut output = solc.compile_exact(&solc_input).unwrap();

    if output.has_error() {
        for error in output.errors {
            eprintln!("{error}");
        }
        panic!("failed to compile contract");
    }

    let contract = output
        .contracts
        .remove(&path)
        .unwrap()
        .remove(contract)
        .unwrap();
    let evm = contract.evm.unwrap();

    (
        contract.abi.unwrap(),
        evm.bytecode.unwrap().into_bytes().unwrap(),
    )
}

pub struct ScillaServer {
    pub addr: String,
    pub temp_dir: String,
    container_name: String,
    child: Child,
}

impl Default for ScillaServer {
    fn default() -> ScillaServer {
        let mut container_name = "scilla-server-".to_owned();
        let rng = SmallRng::from_entropy();
        container_name.extend(rng.sample_iter(&Alphanumeric).map(char::from).take(8));

        let temp_dir = std::env::var_os("ZQ_TEST_TEMP_DIR")
            .map(|s| s.into_string())
            .transpose()
            .unwrap()
            .unwrap_or_else(|| "/tmp".to_owned());

        DirBuilder::new()
            .recursive(true)
            .mode(0o777)
            .create(format!("{temp_dir}/scilla_ext_libs"))
            .unwrap();
        DirBuilder::new()
            .recursive(true)
            .mode(0o777)
            .create(format!("{temp_dir}/scilla-sockets"))
            .unwrap();

        let child = Command::new("docker")
            .arg("run")
            .arg("--platform")
            .arg("linux/amd64")
            .arg("--name")
            .arg(&container_name)
            // Let Docker auto-assign a free port on the host. The scilla-server listens on port 3000.
            .arg("--publish")
            .arg("3000")
            .arg("--init")
            .arg("--rm")
            .arg("-v")
            .arg(format!("{temp_dir}:{temp_dir}"))
            .arg(
                "asia-docker.pkg.dev/prj-p-devops-services-tvwmrf63/zilliqa-public/scilla:abdb24b1",
            )
            .arg("/scilla/0/bin/scilla-server-http")
            .spawn()
            .unwrap();

        // Wait for the container to be running.
        for i in 0.. {
            let status_output = Command::new("docker")
                .arg("inspect")
                .arg("-f")
                .arg("{{.State.Status}}")
                .arg(&container_name)
                .output()
                .unwrap();
            let status = String::from_utf8(status_output.stdout).unwrap();
            if status.trim() == "running" {
                break;
            }
            if i >= 1200 {
                panic!("container is still not running");
            }
            std::thread::sleep(std::time::Duration::from_millis(100));
        }

        // Find the port that Docker selected on the host.
        let inspect = Command::new("docker")
            .arg("inspect")
            .arg("--format")
            .arg("{{json .NetworkSettings.Ports}}")
            .arg(&container_name)
            .output()
            .unwrap();
        #[derive(Deserialize, Copy, Clone)]
        struct Addr {
            #[serde(rename = "HostIp")]
            ip: IpAddr,
            #[serde(rename = "HostPort", with = "crate::serde_util::num_as_str")]
            port: u16,
        }
        let inspect: HashMap<String, Vec<Addr>> = serde_json::from_slice(&inspect.stdout).unwrap();
        let addrs: Vec<SocketAddr> = inspect["3000/tcp"]
            .iter()
            .copied()
            .map(|a| (a.ip, a.port).into())
            .collect();
        let addr = *addrs.iter().find(|a| a.is_ipv4()).unwrap();

        ScillaServer {
            addr: format!("http://{addr}"),
            temp_dir,
            container_name,
            child,
        }
    }
}

impl Drop for ScillaServer {
    fn drop(&mut self) {
        let mut stop_child = Command::new("docker")
            .arg("stop")
            .arg("--signal")
            .arg("SIGKILL")
            .arg(&self.container_name)
            .stdout(Stdio::null())
            .stderr(Stdio::null())
            .spawn()
            .unwrap();
        let _ = self.child.wait();
        let _ = stop_child.wait();
    }
}

```

`zilliqa/src/time.rs`:

```rs
//! When the `fake_time` feature is disabled, this module just re-exports [std::time::SystemTime].
//!
//! When the `fake_time` feature is enabled, an alternative fake [SystemTime] is exported, which can be controlled by
//! the `pause_at_epoch` and `advance` methods. This allows tests to run the system in a fully deterministic way.

#[cfg(not(feature = "fake_time"))]
pub type SystemTime = std::time::SystemTime;

#[cfg(feature = "fake_time")]
pub use time_impl::*;

#[cfg(feature = "fake_time")]
mod time_impl {
    use std::{error::Error, fmt, ops::Add, sync::Mutex, time::Duration};

    use futures::Future;
    use k256::pkcs8::der::DateTime;
    use serde::{Deserialize, Serialize};

    /// A fake implementation of [std::time::SystemTime]. The value of `SystemTime::now` can be controlled with [advance_time].
    #[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Serialize, Deserialize)]
    pub struct SystemTime(std::time::SystemTime);

    impl SystemTime {
        pub const UNIX_EPOCH: SystemTime = SystemTime(std::time::SystemTime::UNIX_EPOCH);

        pub fn now() -> Self {
            CURRENT_TIME
                .try_with(|current_time| {
                    let current_time = *current_time.lock().unwrap();
                    SystemTime(std::time::SystemTime::UNIX_EPOCH + current_time)
                })
                .unwrap_or_else(|_| {
                    // We are not within the scope of `with_fake_time()`, so use the real time.
                    SystemTime(std::time::SystemTime::now())
                })
        }

        pub fn elapsed(&self) -> Result<Duration, SystemTimeError> {
            SystemTime::now().duration_since(*self)
        }

        pub fn duration_since(&self, other: SystemTime) -> Result<Duration, SystemTimeError> {
            self.0
                .duration_since(other.0)
                .map_err(|e| SystemTimeError(e.duration()))
        }

        pub fn checked_sub(&self, duration: Duration) -> Option<Self> {
            self.0.checked_sub(duration).map(Self)
        }
    }

    impl Add<Duration> for SystemTime {
        type Output = SystemTime;

        fn add(self, rhs: Duration) -> Self::Output {
            SystemTime(self.0 + rhs)
        }
    }

    impl From<DateTime> for SystemTime {
        fn from(datetime: DateTime) -> Self {
            SystemTime(datetime.to_system_time())
        }
    }

    #[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord)]
    pub struct SystemTimeError(Duration);

    impl SystemTimeError {
        pub fn duration(&self) -> Duration {
            self.0
        }
    }
    impl fmt::Display for SystemTimeError {
        fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
            write!(f, "second time provided was later than self")
        }
    }

    impl Error for SystemTimeError {
        fn description(&self) -> &str {
            "other time was not earlier than self"
        }
    }

    tokio::task_local! {
        /// Stores the duration between the currently set fake time time and the `UNIX_EPOCH`.
        static CURRENT_TIME: Mutex<Duration>;
    }

    pub fn with_fake_time<F: Future>(f: F) -> impl Future<Output = F::Output> {
        CURRENT_TIME.scope(Mutex::new(Duration::ZERO), f)
    }

    pub fn sync_with_fake_time<R>(f: impl FnOnce() -> R) -> R {
        CURRENT_TIME.sync_scope(Mutex::new(Duration::ZERO), f)
    }

    /// Advance the fake time by this duration. Panics if not called within the scope of `with_fake_time()` or
    /// `sync_with_fake_time()`.
    pub fn advance(delta: Duration) {
        CURRENT_TIME.with(|current_time| {
            let mut current_time = current_time.lock().unwrap();
            *current_time += delta;
        });
    }
}

```

`zilliqa/src/transaction.rs`:

```rs
use std::{
    cmp::{Ordering, PartialOrd, max},
    collections::BTreeMap,
    fmt::{self, Display, Formatter},
    ops::{Add, AddAssign, Sub},
    str::FromStr,
};

use alloy::{
    consensus::{
        SignableTransaction, TxEip1559, TxEip2930, TxLegacy, transaction::RlpEcdsaEncodableTx,
    },
    primitives::{Address, B256, PrimitiveSignature, TxKind, U256, keccak256},
    rlp::{EMPTY_STRING_CODE, Encodable, Header},
    sol_types::SolValue,
};
use anyhow::{Result, anyhow};
use bytes::{BufMut, BytesMut};
use itertools::Itertools;
use k256::elliptic_curve::sec1::ToEncodedPoint;
use serde::{Deserialize, Serialize};
use sha2::Sha256;
use sha3::{
    Digest, Keccak256,
    digest::generic_array::{
        GenericArray,
        sequence::Split,
        typenum::{U12, U20},
    },
};
use tracing::warn;

use crate::{
    constants::{
        EVM_MAX_INIT_CODE_SIZE, EVM_MAX_TX_INPUT_SIZE, EVM_MIN_GAS_UNITS, SCILLA_INVOKE_RUNNER,
        SCILLA_TRANSFER, ZIL_CONTRACT_CREATE_GAS, ZIL_CONTRACT_INVOKE_GAS, ZIL_MAX_CODE_SIZE,
        ZIL_NORMAL_TXN_GAS,
    },
    crypto::{self, Hash},
    exec::{ScillaError, ScillaException, ScillaTransition},
    schnorr,
    scilla::ParamValue,
    serde_util::vec_param_value,
    state::Account,
    zq1_proto::{Code, Data, Nonce, ProtoTransactionCoreInfo},
};

/// Represents a validation result.
/// This could be Result<String>, except that we would then return
/// Result<Result<String>>, which would be confusing.
/// The argument is a human-readable error message which can be returned to the
/// user to indicate the problem with the transaction.
#[derive(Debug, Copy, Clone, PartialEq)]
pub enum ValidationOutcome {
    Success,
    /// Transaction input size exceeds configured limit - (size, limit)
    TransactionInputSizeExceeded(usize, usize),
    /// Transaction initcode size exceeds configured limit - (size, limit)
    InitCodeSizeExceeded(usize, usize),
    /// Gas limit exceeds block gas limit - (gas_limit, block_gas_limit)
    BlockGasLimitExceeded(EvmGas, EvmGas),
    /// Insufficient gas for zil transaction - (given, required)
    InsufficientGasZil(ScillaGas, ScillaGas),
    /// Insufficient gas for EVM transaction
    InsufficientGasEvm(EvmGas, EvmGas),
    /// Chain id was incorrect - (received, expected)
    IncorrectChainId(u64, u64),
    /// Insufficient funds in account - (txn_cost, account_balance)
    InsufficientFunds(u128, u128),
    /// Nonce too low - arg is the nonce we were expecting - (nonce, expected_nonce)
    NonceTooLow(u64, u64),
    /// Unrecognised type - not invocation, creation or transfer
    UnknownTransactionType,
    /// Global transaction count exceeded
    GlobalTransactionCountExceeded,
    /// Transaction counter exceeded for a sender
    TransactionCountExceededForSender,
    /// Total nunber of sender slots exceeded
    TotalNumberOfSlotsExceeded,
}

impl ValidationOutcome {
    // I did try this with a vector, but sadly this involves too much
    // trait magic to be convenient.
    pub fn and_then<T>(&self, test: T) -> Result<ValidationOutcome>
    where
        T: FnOnce() -> Result<ValidationOutcome>,
    {
        if self.is_ok() { test() } else { Ok(*self) }
    }

    pub fn is_ok(&self) -> bool {
        matches!(self, Self::Success)
    }

    pub fn to_msg_string(&self) -> String {
        match self {
            Self::Success => "Txn accepted".to_string(),
            Self::TransactionInputSizeExceeded(size, limit) => {
                format!("Transaction input size ({size}) exceeds limit ({limit})")
            }
            Self::InitCodeSizeExceeded(size, limit) => {
                format!("Init code size ({size}) exceeds limit ({limit})")
            }
            Self::BlockGasLimitExceeded(gas, limit) => {
                format!("Txn gas limit ({gas}) exceeeds block gas limit ({limit})")
            }
            Self::InsufficientGasZil(gas, limit) => {
                format!("Insufficient Zilliqa txn gas supplied ({gas}) - required ({limit})")
            }
            Self::InsufficientGasEvm(gas, limit) => {
                format!("Insufficient EVM txn gas supplied ({gas}) - required ({limit})")
            }
            Self::IncorrectChainId(got, wanted) => {
                format!("Txn has chain id {got}, expected chain {wanted}")
            }
            Self::InsufficientFunds(txn_cost, bal) => {
                format!("Insufficient funds - txn cost {txn_cost} but account balance {bal}")
            }
            Self::NonceTooLow(txn_nonce, expected) => {
                format!("Txn nonce ({txn_nonce}) is too low for account ({expected})")
            }
            Self::UnknownTransactionType => {
                "Txn is not transfer, contract creation or contract invocation".to_string()
            }
            Self::GlobalTransactionCountExceeded => {
                "Global number of transactions stored in the mempool has been exceeded!".to_string()
            }
            Self::TransactionCountExceededForSender => {
                "Transactions count kept per user has been exceeded!".to_string()
            }
            Self::TotalNumberOfSlotsExceeded => {
                "Total number of slots for all senders has been exceeded".to_string()
            }
        }
    }
}

/// A [Transaction] plus its signature. The underlying transaction can be obtained with
/// [`SignedTransaction::into_transaction()`]. The transaction's signer and hash can be obtained by converting this to a
/// [VerifiedTransaction] with [`SignedTransaction::verify()`].
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub enum SignedTransaction {
    Legacy {
        #[serde(with = "ser_rlp")]
        tx: TxLegacy,
        sig: PrimitiveSignature,
    },
    Eip2930 {
        #[serde(with = "ser_rlp")]
        tx: TxEip2930,
        sig: PrimitiveSignature,
    },
    Eip1559 {
        #[serde(with = "ser_rlp")]
        tx: TxEip1559,
        sig: PrimitiveSignature,
    },
    Zilliqa {
        tx: TxZilliqa,
        key: schnorr::PublicKey,
        sig: schnorr::Signature,
    },
    Intershard {
        tx: TxIntershard,
        // no signature as the transaction can only originate from a local (trusted) process
        // instead use raw from-address
        from: Address,
    },
}

// alloy's transaction types contain annotations (such as `skip_serializing_if`) which cause issues when
// (de)serializing with serde. Therefore, we serialize these transactions in their RLP form instead.
mod ser_rlp {
    use std::marker::PhantomData;

    use alloy::rlp::{Decodable, Encodable};
    use serde::{Deserializer, Serializer, de};

    pub fn serialize<T, S>(value: &T, serializer: S) -> Result<S::Ok, S::Error>
    where
        T: Encodable,
        S: Serializer,
    {
        let mut buf = Vec::with_capacity(value.length());
        value.encode(&mut buf);
        serializer.serialize_bytes(&buf)
    }

    pub fn deserialize<'de, T, D>(deserializer: D) -> Result<T, D::Error>
    where
        T: Decodable,
        D: Deserializer<'de>,
    {
        struct Visitor<T>(PhantomData<T>);

        impl<'de, T: Decodable> serde::de::Visitor<'de> for Visitor<T> {
            type Value = T;

            fn expecting(&self, formatter: &mut std::fmt::Formatter) -> std::fmt::Result {
                write!(formatter, "a byte array")
            }

            fn visit_bytes<E>(self, mut v: &[u8]) -> Result<Self::Value, E>
            where
                E: de::Error,
            {
                T::decode(&mut v).map_err(de::Error::custom)
            }

            fn visit_seq<A>(self, mut seq: A) -> Result<Self::Value, A::Error>
            where
                A: de::SeqAccess<'de>,
            {
                // Limit the length we preallocate.
                let len = seq.size_hint().unwrap_or(0).min(4096);
                let mut bytes = Vec::with_capacity(len);

                while let Some(byte) = seq.next_element()? {
                    bytes.push(byte);
                }

                T::decode(&mut bytes.as_slice()).map_err(de::Error::custom)
            }
        }

        deserializer.deserialize_bytes(Visitor(PhantomData))
    }
}

impl SignedTransaction {
    pub fn into_transaction(self) -> Transaction {
        match self {
            SignedTransaction::Legacy { tx, .. } => tx.into(),
            SignedTransaction::Eip2930 { tx, .. } => tx.into(),
            SignedTransaction::Eip1559 { tx, .. } => tx.into(),
            SignedTransaction::Zilliqa { tx, .. } => tx.into(),
            SignedTransaction::Intershard { tx, .. } => tx.into(),
        }
    }

    pub fn sig_r(&self) -> U256 {
        match self {
            SignedTransaction::Legacy { sig, .. } => sig.r(),
            SignedTransaction::Eip2930 { sig, .. } => sig.r(),
            SignedTransaction::Eip1559 { sig, .. } => sig.r(),
            SignedTransaction::Zilliqa { sig, .. } => {
                U256::from_be_bytes(sig.r().to_bytes().into())
            }
            SignedTransaction::Intershard { .. } => U256::ZERO,
        }
    }

    pub fn sig_s(&self) -> U256 {
        match self {
            SignedTransaction::Legacy { sig, .. } => sig.s(),
            SignedTransaction::Eip2930 { sig, .. } => sig.s(),
            SignedTransaction::Eip1559 { sig, .. } => sig.s(),
            SignedTransaction::Zilliqa { sig, .. } => {
                U256::from_be_bytes(sig.s().to_bytes().into())
            }
            SignedTransaction::Intershard { .. } => U256::ZERO,
        }
    }

    pub fn sig_v(&self) -> u64 {
        match self {
            SignedTransaction::Legacy { sig, .. } => sig.v() as u64,
            SignedTransaction::Eip2930 { sig, .. } => sig.v() as u64,
            SignedTransaction::Eip1559 { sig, .. } => sig.v() as u64,
            SignedTransaction::Zilliqa { .. } => 0,
            SignedTransaction::Intershard { .. } => 0,
        }
    }

    pub fn chain_id(&self) -> Option<u64> {
        match self {
            SignedTransaction::Legacy { tx, .. } => tx.chain_id,
            SignedTransaction::Eip2930 { tx, .. } => Some(tx.chain_id),
            SignedTransaction::Eip1559 { tx, .. } => Some(tx.chain_id),
            SignedTransaction::Zilliqa { tx, .. } => Some(tx.chain_id as u64),
            SignedTransaction::Intershard { tx, .. } => Some(tx.chain_id),
        }
    }

    pub fn nonce(&self) -> Option<u64> {
        match self {
            SignedTransaction::Legacy { tx, .. } => Some(tx.nonce),
            SignedTransaction::Eip2930 { tx, .. } => Some(tx.nonce),
            SignedTransaction::Eip1559 { tx, .. } => Some(tx.nonce),
            // Zilliqa nonces are 1-indexed rather than zero indexed.
            SignedTransaction::Zilliqa { tx, .. } => Some(tx.nonce - 1),
            SignedTransaction::Intershard { .. } => None,
        }
    }

    pub fn gas_price_per_evm_gas(&self) -> u128 {
        match self {
            SignedTransaction::Legacy { tx, .. } => tx.gas_price,
            SignedTransaction::Eip2930 { tx, .. } => tx.gas_price,
            // We ignore the priority fee and just use the maximum fee.
            SignedTransaction::Eip1559 { tx, .. } => tx.max_fee_per_gas,
            SignedTransaction::Zilliqa { tx, .. } => {
                tx.gas_price.get() / (EVM_GAS_PER_SCILLA_GAS as u128)
            }
            SignedTransaction::Intershard { tx, .. } => tx.gas_price,
        }
    }

    // ZilAmount / EvmGas
    // EvmGas / ScillaGas

    pub fn gas_price_per_scilla_gas(&self) -> ZilAmount {
        /// Convert a gas price in (10^-18) ZILs per [EvmGas] to [ZilAmount] ((10^-12) ZILs) per [ScillaGas].
        fn convert(price: u128) -> ZilAmount {
            // Units of `price`: u128 / EvmGas
            let price = ZilAmount::from_amount(price);
            // Units of `price`: ZilAmount / EvmGas
            // Units of `EVM_GAS_PER_SCILLA_GAS`: EvmGas / ScillaGas
            ZilAmount::from_raw(price.0 * (EVM_GAS_PER_SCILLA_GAS as u128))
            // Units of returned value: ZilAmount / ScillaGas
        }
        match self {
            SignedTransaction::Legacy { tx, .. } => convert(tx.gas_price),
            SignedTransaction::Eip2930 { tx, .. } => convert(tx.gas_price),
            // We ignore the priority fee and just use the maximum fee.
            SignedTransaction::Eip1559 { tx, .. } => convert(tx.max_fee_per_gas),
            SignedTransaction::Zilliqa { tx, .. } => tx.gas_price,
            SignedTransaction::Intershard { tx, .. } => convert(tx.gas_price),
        }
    }

    pub fn gas_limit(&self) -> EvmGas {
        match self {
            SignedTransaction::Legacy { tx, .. } => EvmGas(tx.gas_limit),
            SignedTransaction::Eip2930 { tx, .. } => EvmGas(tx.gas_limit),
            SignedTransaction::Eip1559 { tx, .. } => EvmGas(tx.gas_limit),
            SignedTransaction::Zilliqa { tx, .. } => tx.gas_limit.into(),
            SignedTransaction::Intershard { tx, .. } => tx.gas_limit,
        }
    }

    pub fn gas_limit_scilla(&self) -> ScillaGas {
        match self {
            SignedTransaction::Legacy { tx, .. } => EvmGas(tx.gas_limit).into(),
            SignedTransaction::Eip2930 { tx, .. } => EvmGas(tx.gas_limit).into(),
            SignedTransaction::Eip1559 { tx, .. } => EvmGas(tx.gas_limit).into(),
            SignedTransaction::Zilliqa { tx, .. } => tx.gas_limit,
            SignedTransaction::Intershard { tx, .. } => tx.gas_limit.into(),
        }
    }

    pub fn zil_amount(&self) -> ZilAmount {
        match self {
            SignedTransaction::Legacy { tx, .. } => ZilAmount::from_amount(tx.value.to()),
            SignedTransaction::Eip2930 { tx, .. } => ZilAmount::from_amount(tx.value.to()),
            SignedTransaction::Eip1559 { tx, .. } => ZilAmount::from_amount(tx.value.to()),
            SignedTransaction::Zilliqa { tx, .. } => tx.amount,
            SignedTransaction::Intershard { .. } => ZilAmount::from_raw(0),
        }
    }

    // We don't validate Zilliqa txns against their maximum cost, but against
    // the deposit size.
    pub(crate) fn maximum_validation_cost(&self) -> Result<u128> {
        match self {
            SignedTransaction::Legacy { tx, .. } => {
                Ok(tx.gas_limit as u128 * tx.gas_price + u128::try_from(tx.value)?)
            }
            SignedTransaction::Eip2930 { tx, .. } => {
                Ok(tx.gas_limit as u128 * tx.gas_price + u128::try_from(tx.value)?)
            }
            SignedTransaction::Eip1559 { tx, .. } => {
                Ok(tx.gas_limit as u128 * tx.max_fee_per_gas + u128::try_from(tx.value)?)
            }
            SignedTransaction::Zilliqa { tx, .. } => {
                // This is a copy of Transaction.h::GetTransactionType()
                // We validate against slightly different thresholds since we don't have the
                // mainnet constants to hand in Rust in zq2.
                Ok(total_scilla_gas_price(
                    if !tx.to_addr.is_zero() && !tx.data.is_empty() && tx.code.is_empty() {
                        // It's a contract call (erm, probably)
                        SCILLA_INVOKE_RUNNER
                    } else if !tx.code.is_empty() && tx.to_addr.is_zero() {
                        // create
                        SCILLA_INVOKE_RUNNER
                    } else {
                        // Validate as an EOA
                        SCILLA_TRANSFER
                    },
                    tx.gas_price,
                )
                .0)
            }
            SignedTransaction::Intershard { tx, .. } => Ok(tx.gas_price * tx.gas_limit.0 as u128),
        }
    }

    pub fn verify(self) -> Result<VerifiedTransaction> {
        self.verify_inner(false)
    }

    pub fn verify_bypass(self) -> Result<VerifiedTransaction> {
        self.verify_inner(true)
    }

    fn verify_inner(self, force: bool) -> Result<VerifiedTransaction> {
        let (tx, signer, hash) = match self {
            SignedTransaction::Legacy { tx, sig } => {
                let signed = tx.into_signed(sig);
                let signer = signed.recover_signer()?;
                let (tx, _, hash) = signed.into_parts();
                (SignedTransaction::Legacy { tx, sig }, signer, hash.into())
            }
            SignedTransaction::Eip2930 { tx, sig } => {
                let signed = tx.into_signed(sig);
                let signer = signed.recover_signer()?;
                let (tx, _, hash) = signed.into_parts();
                (SignedTransaction::Eip2930 { tx, sig }, signer, hash.into())
            }
            SignedTransaction::Eip1559 { tx, sig } => {
                let signed = tx.into_signed(sig);
                let signer = signed.recover_signer()?;
                let (tx, _, hash) = signed.into_parts();
                (SignedTransaction::Eip1559 { tx, sig }, signer, hash.into())
            }
            SignedTransaction::Zilliqa { tx, key, sig } => {
                let txn_data = encode_zilliqa_transaction(&tx, key);

                if !force {
                    schnorr::verify(&txn_data, key, sig)
                        .ok_or_else(|| anyhow!("invalid signature"))?;
                }

                let hashed = Sha256::digest(key.to_encoded_point(true).as_bytes());
                let (_, bytes): (GenericArray<u8, U12>, GenericArray<u8, U20>) = hashed.split();
                let signer = Address::new(bytes.into());

                let tx = SignedTransaction::Zilliqa { tx, key, sig };
                let hash = tx.calculate_hash();
                (tx, signer, hash)
            }
            SignedTransaction::Intershard { tx, from } => {
                let tx = SignedTransaction::Intershard { tx, from };
                let hash = tx.calculate_hash();
                (tx, from, hash)
            }
        };

        let cbor_size = cbor4ii::serde::to_vec(Vec::with_capacity(4096), &tx)
            .map(|b| b.len())
            .unwrap_or_default();

        Ok(VerifiedTransaction {
            tx,
            signer,
            hash,
            cbor_size,
        })
    }

    /// Calculate the hash of this transaction. If you need to do this more than once, consider caching the result
    /// using [`Self::verify()`] and the `hash` field from [RecoveredTransaction].
    pub fn calculate_hash(&self) -> crypto::Hash {
        match self {
            SignedTransaction::Legacy { tx, sig } => tx.tx_hash(sig).into(),
            SignedTransaction::Eip2930 { tx, sig } => tx.tx_hash(sig).into(),
            SignedTransaction::Eip1559 { tx, sig } => tx.tx_hash(sig).into(),
            SignedTransaction::Zilliqa { tx, key, .. } => {
                let txn_data = encode_zilliqa_transaction(tx, *key);
                crypto::Hash(Sha256::digest(txn_data).into())
            }
            SignedTransaction::Intershard { tx, from } => {
                let mut buffer = BytesMut::with_capacity(1024);
                Header {
                    list: true,
                    payload_length: 7,
                }
                .encode(&mut buffer);
                tx.encode_fields(&mut buffer);
                from.encode(&mut buffer);
                crypto::Hash(Keccak256::digest(buffer).into())
            }
        }
    }

    pub fn validate(
        &self,
        account: &Account,
        block_gas_limit: EvmGas,
        eth_chain_id: u64,
    ) -> Result<ValidationOutcome> {
        let result = ValidationOutcome::Success
            .and_then(|| self.validate_input_size())?
            .and_then(|| self.validate_gas_limit(block_gas_limit))?
            .and_then(|| self.validate_chain_id(eth_chain_id))?
            .and_then(|| self.validate_sender_account(account))?;
        Ok(result)
    }

    fn validate_input_size(&self) -> Result<ValidationOutcome> {
        if let SignedTransaction::Zilliqa { tx, .. } = self {
            if tx.code.len() > ZIL_MAX_CODE_SIZE {
                warn!(
                    "Zil transaction input size: {} exceeds limit: {ZIL_MAX_CODE_SIZE}",
                    tx.code.len()
                );
                return Ok(ValidationOutcome::TransactionInputSizeExceeded(
                    tx.code.len(),
                    ZIL_MAX_CODE_SIZE,
                ));
            }
            return Ok(ValidationOutcome::Success);
        };

        let (input_size, tx_kind) = match self {
            SignedTransaction::Legacy { tx, .. } => (tx.input.len(), tx.to),
            SignedTransaction::Eip2930 { tx, .. } => (tx.input.len(), tx.to),
            SignedTransaction::Eip1559 { tx, .. } => (tx.input.len(), tx.to),
            _ => return Ok(ValidationOutcome::Success),
        };

        if input_size > EVM_MAX_TX_INPUT_SIZE {
            warn!(
                "Evm transaction input size: {input_size} exceeds limit: {EVM_MAX_TX_INPUT_SIZE}"
            );
            return Ok(ValidationOutcome::TransactionInputSizeExceeded(
                input_size,
                EVM_MAX_TX_INPUT_SIZE,
            ));
        }

        if tx_kind == TxKind::Create && input_size > EVM_MAX_INIT_CODE_SIZE {
            warn!(
                "Evm transaction initcode size: {input_size} exceeds limit: {EVM_MAX_INIT_CODE_SIZE}"
            );
            return Ok(ValidationOutcome::InitCodeSizeExceeded(
                input_size,
                EVM_MAX_INIT_CODE_SIZE,
            ));
        }

        Ok(ValidationOutcome::Success)
    }

    fn validate_gas_limit(&self, block_gas_limit: EvmGas) -> Result<ValidationOutcome> {
        if self.gas_limit() > block_gas_limit {
            warn!("Transaction gas limit exceeds block gas limit!");
            return Ok(ValidationOutcome::BlockGasLimitExceeded(
                self.gas_limit(),
                block_gas_limit,
            ));
        }

        // The following logic is taken from ZQ1
        if let SignedTransaction::Zilliqa { tx, .. } = self {
            let required_gas = tx.get_deposit_gas()?;
            if tx.gas_limit < required_gas {
                warn!(
                    "Insufficient gas give for zil transaction, given: {}, required: {required_gas}!",
                    tx.gas_limit
                );
                return Ok(ValidationOutcome::InsufficientGasZil(
                    tx.gas_limit,
                    required_gas,
                ));
            }
            return Ok(ValidationOutcome::Success);
        }

        let gas_limit = self.gas_limit();

        if gas_limit < EVM_MIN_GAS_UNITS {
            warn!(
                "Insufficient gas give for evm transaction, given: {gas_limit}, required: {EVM_MIN_GAS_UNITS}!"
            );
            return Ok(ValidationOutcome::InsufficientGasEvm(
                gas_limit,
                EVM_MIN_GAS_UNITS,
            ));
        }

        Ok(ValidationOutcome::Success)
    }

    fn validate_chain_id(&self, eth_chain_id: u64) -> Result<ValidationOutcome> {
        let node_chain_id = match &self {
            SignedTransaction::Zilliqa { .. } => eth_chain_id - 0x8000,
            _ => eth_chain_id,
        };

        if let Some(txn_chain_id) = self.chain_id() {
            if node_chain_id != txn_chain_id {
                warn!(
                    "Chain_id provided in transaction: {} is different than node chain_id: {}",
                    txn_chain_id, node_chain_id
                );
                return Ok(ValidationOutcome::IncorrectChainId(
                    txn_chain_id,
                    node_chain_id,
                ));
            }
        }
        Ok(ValidationOutcome::Success)
    }

    fn validate_sender_account(&self, account: &Account) -> Result<ValidationOutcome> {
        let txn_cost = self.maximum_validation_cost()?;
        if txn_cost > account.balance {
            warn!("Insufficient funds");
            return Ok(ValidationOutcome::InsufficientFunds(
                txn_cost,
                account.balance,
            ));
        }

        let Some(nonce) = self.nonce() else {
            return Ok(ValidationOutcome::Success);
        };
        if nonce < account.nonce {
            warn!(
                "Nonce is too low. Txn nonce is: {}, acc: {}",
                nonce, account.nonce
            );
            return Ok(ValidationOutcome::NonceTooLow(nonce, account.nonce));
        }
        Ok(ValidationOutcome::Success)
    }
}

#[derive(Debug, Clone, PartialEq, Eq)]
/// A [SignedTransaction] which has had the signature verified and the signer recovered. The transaction's hash is also
/// calculated and cached.
///
/// [Serialize] and [Deserialize] are deliberately not implemented for this type. [SignedTransaction]s should be sent
/// accross the network the signer should be verified and recovered independently.
pub struct VerifiedTransaction {
    pub tx: SignedTransaction,
    pub signer: Address,
    pub hash: crypto::Hash,
    pub cbor_size: usize,
}

impl VerifiedTransaction {
    #[inline]
    pub fn encoded_size(&self) -> usize {
        self.cbor_size
    }
}

/// The core information of a transaction.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub enum Transaction {
    Legacy(TxLegacy),
    Eip2930(TxEip2930),
    Eip1559(TxEip1559),
    Zilliqa(TxZilliqa),
    Intershard(TxIntershard),
}

impl Transaction {
    pub fn chain_id(&self) -> Option<u64> {
        match self {
            Transaction::Legacy(TxLegacy { chain_id, .. }) => *chain_id,
            Transaction::Eip2930(TxEip2930 { chain_id, .. }) => Some(*chain_id),
            Transaction::Eip1559(TxEip1559 { chain_id, .. }) => Some(*chain_id),
            Transaction::Zilliqa(TxZilliqa { chain_id, .. }) => Some(*chain_id as u64),
            Transaction::Intershard(TxIntershard { chain_id, .. }) => Some(*chain_id),
        }
    }

    pub fn nonce(&self) -> Option<u64> {
        match self {
            Transaction::Legacy(TxLegacy { nonce, .. }) => Some(*nonce),
            Transaction::Eip2930(TxEip2930 { nonce, .. }) => Some(*nonce),
            Transaction::Eip1559(TxEip1559 { nonce, .. }) => Some(*nonce),
            // Zilliqa nonces are 1-indexed rather than zero indexed.
            Transaction::Zilliqa(TxZilliqa { nonce, .. }) => Some(*nonce - 1),
            Transaction::Intershard(TxIntershard { .. }) => None,
        }
    }

    pub fn max_fee_per_gas(&self) -> u128 {
        match self {
            Transaction::Legacy(TxLegacy { gas_price, .. }) => *gas_price,
            Transaction::Eip2930(TxEip2930 { gas_price, .. }) => *gas_price,
            Transaction::Eip1559(TxEip1559 {
                max_fee_per_gas, ..
            }) => *max_fee_per_gas,
            Transaction::Zilliqa(t) => t.gas_price.get() / (EVM_GAS_PER_SCILLA_GAS as u128),
            Transaction::Intershard(TxIntershard { gas_price, .. }) => *gas_price,
        }
    }

    pub fn gas_limit(&self) -> EvmGas {
        match self {
            Transaction::Legacy(TxLegacy { gas_limit, .. }) => EvmGas(*gas_limit),
            Transaction::Eip2930(TxEip2930 { gas_limit, .. }) => EvmGas(*gas_limit),
            Transaction::Eip1559(TxEip1559 { gas_limit, .. }) => EvmGas(*gas_limit),
            Transaction::Zilliqa(TxZilliqa { gas_limit, .. }) => (*gas_limit).into(),
            Transaction::Intershard(TxIntershard { gas_limit, .. }) => *gas_limit,
        }
    }

    pub fn to_addr(&self) -> Option<Address> {
        match self {
            Transaction::Legacy(TxLegacy { to, .. }) => to.to().copied(),
            Transaction::Eip2930(TxEip2930 { to, .. }) => to.to().copied(),
            Transaction::Eip1559(TxEip1559 { to, .. }) => to.to().copied(),
            // Note: we map the zero address to 'None' here so it is consistent with eth txs (contract creation).
            Transaction::Zilliqa(TxZilliqa { to_addr, .. }) => {
                if !to_addr.is_zero() {
                    Some(*to_addr)
                } else {
                    None
                }
            }
            Transaction::Intershard(TxIntershard { to_addr, .. }) => *to_addr,
        }
    }

    pub fn amount(&self) -> u128 {
        match self {
            Transaction::Legacy(TxLegacy { value, .. }) => value.to(),
            Transaction::Eip2930(TxEip2930 { value, .. }) => value.to(),
            Transaction::Eip1559(TxEip1559 { value, .. }) => value.to(),
            Transaction::Zilliqa(t) => t.amount.get(),
            Transaction::Intershard(_) => 0,
        }
    }

    pub fn payload(&self) -> &[u8] {
        match self {
            Transaction::Legacy(TxLegacy { input, .. }) => input.as_ref(),
            Transaction::Eip2930(TxEip2930 { input, .. }) => input.as_ref(),
            Transaction::Eip1559(TxEip1559 { input, .. }) => input.as_ref(),
            // Zilliqa transactions can have both code and data set, but code takes precedence if it is non-empty.
            Transaction::Zilliqa(TxZilliqa { code, data, .. }) => {
                if !code.is_empty() {
                    code.as_bytes()
                } else {
                    data.as_bytes()
                }
            }
            Transaction::Intershard(TxIntershard { payload, .. }) => payload,
        }
    }

    pub fn access_list(&self) -> Option<Vec<(Address, Vec<B256>)>> {
        match self {
            Transaction::Legacy(_) => None,
            Transaction::Eip2930(TxEip2930 { access_list, .. }) => Some(
                access_list
                    .0
                    .iter()
                    .map(|i| (i.address, i.storage_keys.clone()))
                    .collect(),
            ),
            Transaction::Eip1559(TxEip1559 { access_list, .. }) => Some(
                access_list
                    .0
                    .iter()
                    .map(|i| (i.address, i.storage_keys.clone()))
                    .collect(),
            ),
            Transaction::Zilliqa(_) => None,
            Transaction::Intershard(_) => None,
        }
    }
}

impl From<TxLegacy> for Transaction {
    fn from(tx: TxLegacy) -> Self {
        Transaction::Legacy(tx)
    }
}

impl From<TxEip2930> for Transaction {
    fn from(tx: TxEip2930) -> Self {
        Transaction::Eip2930(tx)
    }
}

impl From<TxEip1559> for Transaction {
    fn from(tx: TxEip1559) -> Self {
        Transaction::Eip1559(tx)
    }
}

impl From<TxZilliqa> for Transaction {
    fn from(tx: TxZilliqa) -> Self {
        Transaction::Zilliqa(tx)
    }
}

impl From<TxIntershard> for Transaction {
    fn from(tx: TxIntershard) -> Self {
        Transaction::Intershard(tx)
    }
}

/// Nonceless
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct TxIntershard {
    pub chain_id: u64,
    /// The bridge nonce alongside the source chain together guarantee hash uniqueness.
    pub bridge_nonce: u64,
    pub source_chain: u64,
    pub gas_price: u128,
    pub gas_limit: EvmGas,
    pub to_addr: Option<Address>,
    // Amount intentionally missing: cannot send native amount cross-shard
    pub payload: Vec<u8>,
}

impl TxIntershard {
    fn encode_fields(&self, out: &mut BytesMut) {
        self.chain_id.encode(out);
        self.source_chain.encode(out);
        self.bridge_nonce.encode(out);
        self.gas_price.encode(out);
        self.gas_limit.encode(out);
        encode_option_addr(&self.to_addr, out);
        self.payload.as_slice().encode(out);
    }
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct TxZilliqa {
    pub chain_id: u16,
    pub nonce: u64,
    pub gas_price: ZilAmount,
    pub gas_limit: ScillaGas,
    pub to_addr: Address,
    pub amount: ZilAmount,
    pub code: String,
    pub data: String,
}

impl TxZilliqa {
    pub fn get_deposit_gas(&self) -> Result<ScillaGas> {
        // Contract call
        if !self.to_addr.is_zero() && !self.data.is_empty() && self.code.is_empty() {
            Ok(ScillaGas(
                max(ZIL_CONTRACT_INVOKE_GAS, self.data.len()).try_into()?,
            ))
        }
        // Contract creation
        else if self.to_addr.is_zero() && !self.code.is_empty() {
            Ok(ScillaGas(
                max(ZIL_CONTRACT_CREATE_GAS, self.data.len() + self.code.len()).try_into()?,
            ))
        }
        // Transfer
        else if !self.to_addr.is_zero() && self.data.is_empty() && self.code.is_empty() {
            Ok(ScillaGas(ZIL_NORMAL_TXN_GAS.try_into()?))
        } else {
            warn!("transaction is none of: contract invocation, contract creation, transfer");
            Err(anyhow!("Unknown transaction type"))
        }
    }

    pub fn get_contract_address(&self, signer: &Address) -> Result<Address> {
        let mut hasher = Sha256::new();
        hasher.update(signer.as_slice());
        if self.nonce > 0 {
            hasher.update((self.nonce - 1).to_be_bytes());
        } else {
            return Err(anyhow!("Nonce must be greater than 0"));
        }
        let hashed = hasher.finalize();
        Ok(Address::from_slice(&hashed[12..]))
    }
}

/// A wrapper for ZIL amounts in the Zilliqa API. These are represented in units of (10^-12) ZILs, rather than (10^-18)
/// like in the rest of our code. The implementations of [Serialize], [Deserialize], [Display] and [FromStr] represent
/// the amount in units of (10^-12) ZILs, so this type can be used in the Zilliqa API layer.
#[derive(Debug, Copy, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(transparent)]
pub struct ZilAmount(u128);

impl ZilAmount {
    pub const ZERO: ZilAmount = ZilAmount(0);

    /// Construct a [ZilAmount] from an amount in (10^-18) ZILs. The value will be truncated and rounded down.
    pub fn from_amount(amount: u128) -> ZilAmount {
        ZilAmount(amount / 10u128.pow(6))
    }

    // Construct a [ZilAmount] from an amount in (10^-12) ZILs.
    pub fn from_raw(amount: u128) -> ZilAmount {
        ZilAmount(amount)
    }

    /// Get the ZIL amount in units of (10^-18) ZILs.
    pub fn get(self) -> u128 {
        self.0.checked_mul(10u128.pow(6)).expect("amount overflow")
    }

    /// Return the memory representation of this amount as a big-endian byte array.
    pub fn to_be_bytes(self) -> [u8; 16] {
        self.0.to_be_bytes()
    }

    pub fn checked_sub(&self, v: &Self) -> Option<Self> {
        if v.0 < self.0 {
            Some(ZilAmount(self.0 - v.0))
        } else {
            None
        }
    }

    // In ZIL, rounded down to the nearest ZIL unit.
    pub fn to_zils(self) -> u128 {
        self.0 / 10u128.pow(12)
    }

    // In ZIL, as a string representation of the exact float amount
    pub fn to_float_string(self) -> String {
        let integer_part = self.0 / 10u128.pow(12);
        let fractional_part = self.0 % 10u128.pow(12);
        format!("{}.{}", integer_part, fractional_part)
    }
}

impl Add for ZilAmount {
    type Output = ZilAmount;

    fn add(self, rhs: Self) -> Self::Output {
        ZilAmount(self.0.checked_add(rhs.0).expect("amount overflow"))
    }
}

impl PartialOrd for ZilAmount {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.0.cmp(&other.0))
    }
}

impl Display for ZilAmount {
    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
        self.0.fmt(f)
    }
}

impl FromStr for ZilAmount {
    type Err = <u128 as FromStr>::Err;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        Ok(Self(u128::from_str(s)?))
    }
}

/// Calculate the total price of a given `quantity` of [ScillaGas] at the specified `price`.
/// Note that the units of the `price` should really be ([ZilAmount] / [ScillaGas])
pub fn total_scilla_gas_price(quantity: ScillaGas, price: ZilAmount) -> ZilAmount {
    ZilAmount(
        (quantity.0 as u128)
            .checked_mul(price.0)
            .expect("amount overflow"),
    )
}

pub const EVM_GAS_PER_SCILLA_GAS: u64 = 420;

/// A quantity of Scilla gas. This is the currency used to pay for [TxZilliqa] transactions. When EVM gas is converted
/// to Scilla gas, the quantity is rounded down.
#[derive(Debug, Copy, Clone, Serialize, Deserialize, PartialEq, Eq, PartialOrd, Ord)]
#[serde(transparent)]
pub struct ScillaGas(pub u64);

impl ScillaGas {
    pub fn checked_sub(self, rhs: ScillaGas) -> Option<ScillaGas> {
        Some(ScillaGas(self.0.checked_sub(rhs.0)?))
    }
}

impl Sub for ScillaGas {
    type Output = ScillaGas;

    fn sub(self, rhs: Self) -> Self::Output {
        self.checked_sub(rhs).expect("scilla gas underflow")
    }
}

impl From<EvmGas> for ScillaGas {
    fn from(gas: EvmGas) -> Self {
        ScillaGas(gas.0 / EVM_GAS_PER_SCILLA_GAS)
    }
}

impl Display for ScillaGas {
    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
        self.0.fmt(f)
    }
}

impl FromStr for ScillaGas {
    type Err = <u64 as FromStr>::Err;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        Ok(Self(u64::from_str(s)?))
    }
}

/// A quantity of EVM gas. This is the currency used to pay for EVM transactions.
#[derive(Debug, Copy, Clone, Serialize, Deserialize, PartialEq, Eq, PartialOrd, Ord)]
#[serde(transparent)]
pub struct EvmGas(pub u64);

impl EvmGas {
    pub fn checked_sub(self, rhs: EvmGas) -> Option<EvmGas> {
        Some(EvmGas(self.0.checked_sub(rhs.0)?))
    }
}

impl Sub for EvmGas {
    type Output = EvmGas;

    fn sub(self, rhs: Self) -> Self::Output {
        self.checked_sub(rhs).expect("evm gas underflow")
    }
}

impl Add for EvmGas {
    type Output = EvmGas;

    fn add(self, rhs: Self) -> Self::Output {
        EvmGas(self.0.checked_add(rhs.0).expect("evm gas overflow"))
    }
}

impl From<ScillaGas> for EvmGas {
    fn from(gas: ScillaGas) -> Self {
        EvmGas(gas.0 * EVM_GAS_PER_SCILLA_GAS)
    }
}

impl Display for EvmGas {
    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
        self.0.fmt(f)
    }
}

impl FromStr for EvmGas {
    type Err = <u64 as FromStr>::Err;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        Ok(Self(u64::from_str(s)?))
    }
}

impl AddAssign for EvmGas {
    fn add_assign(&mut self, rhs: Self) {
        self.0.add_assign(rhs.0)
    }
}

impl alloy::rlp::Decodable for EvmGas {
    fn decode(buf: &mut &[u8]) -> alloy::rlp::Result<Self> {
        Ok(EvmGas(<u64 as alloy::rlp::Decodable>::decode(buf)?))
    }
}

impl alloy::rlp::Encodable for EvmGas {
    fn encode(&self, out: &mut dyn BufMut) {
        self.0.encode(out);
    }

    fn length(&self) -> usize {
        self.0.length()
    }
}

#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
pub struct EvmLog {
    pub address: Address,
    pub topics: Vec<B256>,
    pub data: Vec<u8>,
}

#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
pub struct ScillaLog {
    pub address: Address,
    #[serde(rename = "_eventname")]
    pub event_name: String,
    #[serde(with = "vec_param_value")]
    pub params: Vec<ParamValue>,
}

impl ScillaLog {
    pub fn into_evm(self) -> EvmLog {
        /// A version of [ScillaLog] which lets us serialise the `address` manually, so we can exclude the checksum, and doesn't encode the `params` values as strings.
        #[derive(Clone, Serialize, Debug)]
        pub struct ScillaLogRaw {
            address: String,
            #[serde(rename = "_eventname")]
            event_name: String,
            params: Vec<ParamValue>,
        }

        let address = self.address;
        let log = ScillaLogRaw {
            address: format!("{address:?}"),
            event_name: self.event_name,
            params: self.params,
        };

        // Unwrap is safe because [ScillaLogRaw::Serialize] is infallible.
        let data = serde_json::to_string(&log).unwrap().abi_encode();
        EvmLog {
            address,
            topics: vec![keccak256(
                format!("{}(string)", log.event_name).into_bytes(),
            )],
            data,
        }
    }
}

#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
pub enum Log {
    Evm(EvmLog),
    Scilla(ScillaLog),
}

impl Log {
    pub fn into_evm(self) -> Option<EvmLog> {
        match self {
            Log::Evm(l) => Some(l),
            _ => None,
        }
    }

    pub fn as_evm(&self) -> Option<&EvmLog> {
        match self {
            Log::Evm(l) => Some(l),
            _ => None,
        }
    }

    pub fn into_scilla(self) -> Option<ScillaLog> {
        match self {
            Log::Scilla(l) => Some(l),
            _ => None,
        }
    }

    pub fn compute_hash(&self) -> Hash {
        match self {
            Log::Scilla(log) => Hash::builder()
                .with(log.event_name.as_bytes())
                .with(
                    log.params
                        .iter()
                        .map(|param| param.compute_hash())
                        .map(|hash| hash.as_bytes().to_vec())
                        .concat(),
                )
                .with(log.address.as_slice())
                .finalize(),
            Log::Evm(log) => Hash::builder()
                .with(log.address.as_slice())
                .with(&log.data)
                .with(log.topics.iter().map(|topic| topic.to_vec()).concat())
                .finalize(),
        }
    }
}

/// A transaction receipt stores data about the execution of a transaction.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TransactionReceipt {
    pub block_hash: crypto::Hash,
    pub index: u64,
    pub tx_hash: crypto::Hash,
    pub success: bool,
    pub gas_used: EvmGas,
    pub cumulative_gas_used: EvmGas,
    pub contract_address: Option<Address>,
    pub logs: Vec<Log>,
    pub transitions: Vec<ScillaTransition>,
    pub accepted: Option<bool>,
    pub errors: BTreeMap<u64, Vec<ScillaError>>,
    pub exceptions: Vec<ScillaException>,
}

impl TransactionReceipt {
    pub fn compute_hash(&self) -> Hash {
        let success = [u8::from(self.success); 1];
        let accepted = [u8::from(self.accepted.unwrap_or_default()); 1];
        Hash::builder()
            .with(self.index.to_be_bytes())
            .with(self.tx_hash.as_bytes())
            .with(success.as_slice())
            .with(self.gas_used.0.to_be_bytes())
            .with(self.cumulative_gas_used.0.to_be_bytes())
            .with(
                self.contract_address
                    .unwrap_or_default()
                    .to_vec()
                    .as_slice(),
            )
            .with(
                self.logs
                    .iter()
                    .map(|log| log.compute_hash().as_bytes().to_vec())
                    .concat(),
            )
            .with(
                self.transitions
                    .iter()
                    .map(|transition| transition.compute_hash().as_bytes().to_vec())
                    .concat(),
            )
            .with(accepted.as_slice())
            .with(
                self.exceptions
                    .iter()
                    .map(|exception| exception.compute_hash().as_bytes().to_vec())
                    .concat(),
            )
            .finalize()
    }
}

/// RLP-encode an `Option<Address>`.
/// `None` is represented as an empty string.
fn encode_option_addr(addr: &Option<Address>, out: &mut BytesMut) {
    match addr {
        Some(addr) => {
            addr.encode(out);
        }
        None => {
            out.put_u8(EMPTY_STRING_CODE);
        }
    }
}

fn encode_zilliqa_transaction(txn: &TxZilliqa, pub_key: schnorr::PublicKey) -> Vec<u8> {
    let oneof8 = (!txn.code.is_empty()).then_some(Code::Code(txn.code.clone().into_bytes()));
    let oneof9 = (!txn.data.is_empty()).then_some(Data::Data(txn.data.clone().into_bytes()));
    let proto = ProtoTransactionCoreInfo {
        version: (((txn.chain_id) as u32) << 16) | 0x0001,
        toaddr: txn.to_addr.as_slice().to_vec(),
        senderpubkey: Some(pub_key.to_sec1_bytes().into()),
        amount: Some((txn.amount).to_be_bytes().to_vec().into()),
        gasprice: Some((txn.gas_price).to_be_bytes().to_vec().into()),
        gaslimit: txn.gas_limit.0,
        oneof2: Some(Nonce::Nonce(txn.nonce)),
        oneof8,
        oneof9,
    };
    prost::Message::encode_to_vec(&proto)
}

```

`zilliqa/src/zq1_proto.rs`:

```rs
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ByteArray {
    #[prost(bytes = "vec", tag = "1")]
    pub data: Vec<u8>,
}

impl From<Vec<u8>> for ByteArray {
    fn from(data: Vec<u8>) -> Self {
        ByteArray { data }
    }
}

impl From<Box<[u8]>> for ByteArray {
    fn from(data: Box<[u8]>) -> Self {
        ByteArray { data: data.into() }
    }
}

#[derive(Clone, PartialEq, prost::Message)]
pub struct ProtoTransactionCoreInfo {
    #[prost(uint32, tag = "1")]
    pub version: u32,
    #[prost(bytes = "vec", tag = "3")]
    pub toaddr: Vec<u8>,
    #[prost(message, optional, tag = "4")]
    pub senderpubkey: Option<ByteArray>,
    #[prost(message, optional, tag = "5")]
    pub amount: Option<ByteArray>,
    #[prost(message, optional, tag = "6")]
    pub gasprice: Option<ByteArray>,
    #[prost(uint64, tag = "7")]
    pub gaslimit: u64,
    #[prost(oneof = "Nonce", tags = "2")]
    pub oneof2: Option<Nonce>,
    #[prost(oneof = "Code", tags = "8")]
    pub oneof8: Option<Code>,
    #[prost(oneof = "Data", tags = "9")]
    pub oneof9: Option<Data>,
}

#[derive(Clone, PartialEq, prost::Oneof)]
pub enum Nonce {
    #[prost(uint64, tag = "2")]
    Nonce(u64),
}
#[derive(Clone, PartialEq, prost::Oneof)]
pub enum Code {
    #[prost(bytes, tag = "8")]
    Code(Vec<u8>),
}
#[derive(Clone, PartialEq, prost::Oneof)]
pub enum Data {
    #[prost(bytes, tag = "9")]
    Data(Vec<u8>),
}

```

`zilliqa/tests/it/admin.rs`:

```rs
use ethers::providers::Middleware;
use serde_json::Value;

use crate::Network;

#[zilliqa_macros::test]
async fn generate_checkpoint(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    network.run_until_block(&wallet, 8.into(), 800).await;
    let response: Value = wallet
        .provider()
        .request("admin_generateCheckpoint", ["0x4"])
        .await
        .unwrap();
    assert!(response["file_name"].is_string());
    assert!(
        !response["file_name"]
            .as_str()
            .unwrap()
            .to_string()
            .is_empty()
    );
    assert!(!response["hash"].as_str().unwrap().to_string().is_empty());
    assert_eq!(response["block"], "0x4");
}

#[zilliqa_macros::test]
async fn admin_votes_received_empty(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Query votes when no consensus activity has happened yet
    let response: Value = wallet
        .provider()
        .request("admin_votesReceived", ())
        .await
        .unwrap();

    // Verify all fields are empty
    assert!(response["votes"].as_array().unwrap().is_empty());
    assert!(response["buffered_votes"].as_array().unwrap().is_empty());
    assert!(response["new_views"].as_array().unwrap().is_empty());
}

#[zilliqa_macros::test]
async fn admin_votes_received_with_data(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Generate some blocks to trigger consensus activity
    // This should generate votes, possibly new views
    network.run_until_block(&wallet, 10.into(), 800).await;

    // Query votes after consensus activity
    let _response: Value = wallet
        .provider()
        .request("admin_votesReceived", ())
        .await
        .unwrap();
}

```

`zilliqa/tests/it/consensus.rs`:

```rs
use alloy::eips::BlockId;
use ethers::{
    providers::Middleware,
    types::{TransactionRequest, U64},
};
use primitive_types::{H160, H256, U256};
use tracing::*;
use zilliqa::{crypto::Hash, state::contract_addr};

use crate::{Network, get_reward_address, get_stakers};

// Test that all nodes can die and the network can restart (even if they startup at different
// times)
#[zilliqa_macros::test]
async fn network_can_die_restart(mut network: Network) {
    let start_block = 5;
    let finish_block = 10;

    // wait until at least 5 blocks have been produced
    network
        .run_until(
            |n| {
                let index = n.random_index();
                n.get_node(index).get_finalized_height().unwrap() >= start_block
            },
            100,
        )
        .await
        .unwrap();

    // Forcibly restart the network, with a random time delay between each node
    network.restart();

    // Panic if it can't progress to the target block
    network
        .run_until(
            |n| {
                let index = n.random_index();
                n.get_node(index).get_finalized_height().unwrap() >= finish_block
            },
            1000,
        )
        .await
        .expect("Failed to progress to target block");
}

fn get_block_number(n: &Network, index: usize) -> u64 {
    n.get_node(index).get_finalized_height().unwrap()
}

// test that even with some consensus messages being dropped, the network can still proceed
// note: this drops all messages, not just consensus messages, but there should only be
// consensus messages in the network anyway
#[zilliqa_macros::test]
async fn block_production_even_when_lossy_network(mut network: Network) {
    let failure_rate = 0.1;
    let start_block = 5;
    let finish_block = 8;

    let index = network.random_index();

    // wait until at least 5 blocks have been produced
    network
        .run_until(
            |n| n.get_node(index).get_finalized_height().unwrap() >= start_block,
            100,
        )
        .await
        .unwrap();

    // now, wait until block 15 has been produced, but dropping 10% of the messages.
    for _ in 0..1000000 {
        network.randomly_drop_messages_then_tick(failure_rate).await;
        if get_block_number(&network, index) >= finish_block {
            break;
        }
    }

    assert!(
        get_block_number(&network, index) >= finish_block,
        "block number should be at least {}, but was {}",
        finish_block,
        get_block_number(&network, index)
    );
}

// Test that new node joining the network catches up on blocks
#[zilliqa_macros::test]
async fn block_production(mut network: Network) {
    network
        .run_until(
            |n| {
                let index = n.random_index();
                n.get_node(index)
                    .get_block(BlockId::latest())
                    .unwrap()
                    .map_or(0, |b| b.number())
                    >= 5
            },
            100,
        )
        .await
        .unwrap();

    info!("Adding networked node.");
    let index = network.add_node();
    network
        .run_until(
            |n| {
                n.node_at(index)
                    .get_block(BlockId::latest())
                    .unwrap()
                    .map_or(0, |b| b.number())
                    >= 10
            },
            100,
        )
        .await
        .unwrap();
}

// test that when a fork occurs in the network, the node which has forked correctly reverts its state
// and progresses.
#[zilliqa_macros::test]
async fn handle_forking_correctly(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let _provider = wallet.provider();

    let start_block = 5;

    // wait until at least 5 blocks have been produced
    network
        .run_until(
            |n| {
                let index = n.random_index();
                n.get_node(index).get_finalized_height().unwrap() >= start_block
            },
            100,
        )
        .await
        .unwrap();

    let init_nonce = wallet
        .get_transaction_count(wallet.address(), None)
        .await
        .unwrap();

    let gap_nonce = init_nonce + 3;
    let gap_txn_count = 10;
    for num in 0..gap_txn_count {
        wallet
            .send_transaction(
                TransactionRequest::pay(H160::random(), 0).nonce(gap_nonce + num),
                None,
            )
            .await
            .unwrap()
            .tx_hash();
    }

    let next_block_threshold = 7;

    // wait until another blocks have been produced
    network
        .run_until(
            |n| {
                let index = n.random_index();
                n.get_node(index).get_finalized_height().unwrap() >= next_block_threshold
            },
            100,
        )
        .await
        .unwrap();

    fn verify_queued(network: &Network, expected_count: usize, index: usize) {
        let queued_count: usize = {
            let node = network.get_node(index);
            let pool = node.consensus.transaction_pool.read();
            pool.preview_content()
                .queued
                .values()
                .map(|x| x.len())
                .sum()
        };
        assert_eq!(queued_count, expected_count);
    }

    // Ensure txns are queued on both nodes
    verify_queued(&network, gap_txn_count, 0);
    verify_queued(&network, gap_txn_count, 1);

    // Send a single TX to the network that triggers txns inclusion
    let hash: H256 = wallet
        .send_transaction(
            TransactionRequest::pay(H160::random(), 10).nonce(init_nonce),
            None,
        )
        .await
        .unwrap()
        .tx_hash();

    network.drop_propose_messages_except_one().await;

    // Check that node 0 has executed the transaction while the others haven't
    let first = network
        .get_node(0)
        .get_transaction_receipt(Hash(hash.0))
        .unwrap();
    let second = network
        .get_node(1)
        .get_transaction_receipt(Hash(hash.0))
        .unwrap();

    // Only the first node should have executed the transaction
    assert!(first.is_some());
    assert!(second.is_none());

    let original_receipt = first.unwrap();

    trace!("Running until the network has reverted the block");
    network.run_until_synced(0).await;
    // Now we should be able to run the network until we get a different tx receipt from the first
    // node, which indicates that it has reverted the block
    network
        .run_until(
            |n| {
                let receipt = n.get_node(0).get_transaction_receipt(Hash(hash.0));
                match receipt {
                    Ok(Some(receipt)) => receipt.block_hash != original_receipt.block_hash,
                    _ => false,
                }
            },
            1000,
        )
        .await
        .unwrap();

    // Verify txns are still queued on both nodes
    verify_queued(&network, gap_txn_count, 0);
    verify_queued(&network, gap_txn_count, 1);
}

// Test that zero account has correct initial funds, is the source of rewards and is the sink of gas
#[zilliqa_macros::test]
async fn zero_account_per_block_balance_updates(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Check inital account values
    let block_height = wallet.get_block_number().await.unwrap();
    assert_eq!(block_height, U64::from(0));

    // Amount assigned to genesis account
    let genesis_account_expected_balance = network
        .get_node(0)
        .config
        .consensus
        .genesis_accounts
        .clone()[0]
        .1
        .0;
    let genesis_account_balance: u128 = wallet
        .get_balance(wallet.address(), None)
        .await
        .unwrap()
        .try_into()
        .unwrap();
    assert_eq!(genesis_account_expected_balance, genesis_account_balance);

    // Total intial stake spread across 4 validators
    let genesis_deposits = network
        .get_node(0)
        .config
        .consensus
        .genesis_deposits
        .clone();
    let total_staked: u128 = genesis_deposits[0].stake.0 * 4;

    // Zero account balance plus genesis account plus initial stakes plus deposit contract should equal total_native_token_supply
    let zero_account_balance: u128 = wallet
        .get_balance(H160::zero(), None)
        .await
        .unwrap()
        .try_into()
        .unwrap();
    let deposit_contract_balance: u128 = wallet
        .get_balance(H160(contract_addr::DEPOSIT_PROXY.into_array()), None)
        .await
        .unwrap()
        .try_into()
        .unwrap();
    let total_native_token_supply = network
        .get_node(0)
        .config
        .consensus
        .total_native_token_supply
        .0;
    assert_eq!(
        total_native_token_supply,
        zero_account_balance + total_staked + genesis_account_balance + deposit_contract_balance
    );

    // Mine first block
    network.run_until_block(&wallet, 1.into(), 50).await;

    let block = wallet.get_block(1).await.unwrap().unwrap();
    assert_eq!(block.transactions.len(), 0);

    // Check proposer was rewarded
    let miner: H160 = block.author.unwrap();
    let miner_balance_before = wallet
        .get_balance(miner, Some((block.number.unwrap() - 1).into()))
        .await
        .unwrap();
    let miner_balance_after = wallet
        .get_balance(miner, Some(block.number.unwrap().into()))
        .await
        .unwrap();
    assert!(miner_balance_before < miner_balance_after);

    // Check reward came from zero account balance
    let zero_account = H160::zero();
    let zero_account_balance_before = wallet
        .get_balance(zero_account, Some((block.number.unwrap() - 1).into()))
        .await
        .unwrap();
    let zero_account_balance_after = wallet
        .get_balance(zero_account, Some(block.number.unwrap().into()))
        .await
        .unwrap();
    assert!(zero_account_balance_before > zero_account_balance_after);
}

#[zilliqa_macros::test]
async fn gas_fees_should_be_transferred_to_zero_account(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let provider = wallet.provider();

    network.run_until_block(&wallet, 1.into(), 50).await;
    let hash = wallet
        .send_transaction(TransactionRequest::pay(wallet.address(), 10), None)
        .await
        .unwrap()
        .tx_hash();
    network.run_until_receipt(&wallet, hash, 200).await;

    let receipt = provider
        .get_transaction_receipt(hash)
        .await
        .unwrap()
        .unwrap();
    let block = wallet
        .get_block(receipt.block_number.unwrap())
        .await
        .unwrap()
        .unwrap();
    assert_eq!(block.transactions.len(), 1);

    let mut total_rewards = U256::zero();
    let stakers = get_stakers(&wallet).await;
    for staker in stakers {
        let reward_address = get_reward_address(&wallet, &staker).await;
        let reward_address_balance_before = wallet
            .get_balance(reward_address, Some((block.number.unwrap() - 1).into()))
            .await
            .unwrap();
        let reward_address_balance_after = wallet
            .get_balance(reward_address, Some(block.number.unwrap().into()))
            .await
            .unwrap();

        total_rewards += reward_address_balance_after - reward_address_balance_before;
    }

    let zero_account = H160::zero();
    let zero_account_balance_before = wallet
        .get_balance(zero_account, Some((block.number.unwrap() - 1).into()))
        .await
        .unwrap();
    let zero_account_balance_after = wallet
        .get_balance(zero_account, Some(block.number.unwrap().into()))
        .await
        .unwrap();

    assert_eq!(
        zero_account_balance_after,
        zero_account_balance_before - total_rewards
            + (receipt.gas_used.unwrap() * receipt.effective_gas_price.unwrap())
    );
}

// Test transaction pool state consistency during consensus operations
#[zilliqa_macros::test]
async fn test_transaction_pool_state_consistency_during_consensus(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Wait for network to be ready
    network.run_until_block(&wallet, 1.into(), 50).await;

    // Create multiple transactions from the same account with sequential nonces
    let _sender = wallet.address();
    let mut transactions = Vec::new();

    for nonce in 0..5 {
        let tx_request = TransactionRequest {
            to: Some(H160::random().into()),
            value: Some(U256::from(10)),
            gas: Some(U256::from(21000)),
            gas_price: Some(U256::from(1000000000)), // 1 gwei
            nonce: Some(U256::from(nonce)),
            ..Default::default()
        };

        let pending_tx = wallet.send_transaction(tx_request, None).await.unwrap();
        transactions.push(pending_tx.tx_hash());
    }

    // Let some transactions get processed
    network.run_until_block(&wallet, 3.into(), 100).await;

    // Send more transactions while consensus is processing
    for nonce in 5..10 {
        let tx_request = TransactionRequest {
            to: Some(H160::random().into()),
            value: Some(U256::from(10)),
            gas: Some(U256::from(21000)),
            gas_price: Some(U256::from(1000000000)),
            nonce: Some(U256::from(nonce)),
            ..Default::default()
        };

        let pending_tx = wallet.send_transaction(tx_request, None).await.unwrap();
        transactions.push(pending_tx.tx_hash());
    }

    // Check that all nodes have consistent transaction pool states
    network.run_until_block(&wallet, 6.into(), 200).await;

    // Verify transaction pool consistency across nodes
    for index in network.nodes.iter().map(|x| x.index) {
        let node = network.get_node(index);
        let pool_status = node.consensus.transaction_pool.read().preview_status();

        // The pending count should be consistent and reasonable
        assert!(
            pool_status.pending <= 20,
            "Pending count too high: {}",
            pool_status.pending
        );

        // Check that we can query pool content without panics
        let _content = node.consensus.transaction_pool.read().preview_content();
    }
}

// Test rapid transaction submission during block production
#[zilliqa_macros::test]
async fn test_rapid_transaction_submission_during_block_production(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Wait for network to be ready
    network.run_until_block(&wallet, 1.into(), 50).await;

    // Submit many transactions rapidly
    let mut submitted_hashes = Vec::new();

    // Rapid submission while blocks are being produced
    for batch in 0..5 {
        // Submit a batch of transactions
        for i in 0..3 {
            let nonce = batch * 3 + i;
            let tx_request = TransactionRequest {
                to: Some(H160::random().into()),
                value: Some(U256::from(10)),
                gas: Some(U256::from(21000)),
                gas_price: Some(U256::from(1000000000 + i)), // Vary gas price
                nonce: Some(U256::from(nonce)),
                ..Default::default()
            };

            let pending_tx = wallet.send_transaction(tx_request, None).await.unwrap();
            submitted_hashes.push(pending_tx.tx_hash());
        }

        // Allow some processing time between batches
        tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
    }

    // Let the network process all transactions
    network.run_until_block(&wallet, 8.into(), 300).await;

    // Check transaction pool state consistency
    let mut total_processed = 0;
    let mut total_pending = 0;

    for index in network.nodes.iter().map(|x| x.index) {
        let node = network.get_node(index);
        let pool_status = node.consensus.transaction_pool.read().preview_status();
        total_pending += pool_status.pending + pool_status.queued;

        // Count how many of our transactions were processed
        for &hash in &submitted_hashes {
            if node
                .get_transaction_receipt(Hash(hash.0))
                .unwrap()
                .is_some()
            {
                total_processed += 1;
                break; // Only count once across all nodes
            }
        }
    }

    // Most transactions should have been processed or be pending
    let total_submitted = submitted_hashes.len();
    assert!(
        total_processed + total_pending as usize >= total_submitted / 2,
        "Too many transactions lost: processed={}, pending={}, submitted={}",
        total_processed,
        total_pending,
        total_submitted
    );
}

// Test transaction replacement scenarios during consensus
#[zilliqa_macros::test]
async fn test_transaction_replacement_during_consensus(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Wait for network to be ready
    network.run_until_block(&wallet, 1.into(), 50).await;

    // Submit initial transaction with low gas price
    let initial_tx = wallet
        .send_transaction(
            TransactionRequest {
                to: Some(H160::random().into()),
                value: Some(U256::from(100)),
                gas: Some(U256::from(21000)),
                gas_price: Some(U256::from(1000000000)), // 1 gwei
                nonce: Some(U256::from(0)),
                ..Default::default()
            },
            None,
        )
        .await
        .unwrap();

    // Wait a bit for the transaction to propagate
    tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;

    // Replace with higher gas price transaction
    let replacement_tx = wallet
        .send_transaction(
            TransactionRequest {
                to: Some(H160::random().into()),
                value: Some(U256::from(200)),
                gas: Some(U256::from(21000)),
                gas_price: Some(U256::from(2000000000)), // 2 gwei
                nonce: Some(U256::from(0)),              // Same nonce
                ..Default::default()
            },
            None,
        )
        .await
        .unwrap();

    // Submit more transactions with subsequent nonces
    for nonce in 1..5 {
        let tx_request = TransactionRequest {
            to: Some(H160::random().into()),
            value: Some(U256::from(10)),
            gas: Some(U256::from(21000)),
            gas_price: Some(U256::from(1500000000)),
            nonce: Some(U256::from(nonce)),
            ..Default::default()
        };

        let _pending_tx = wallet.send_transaction(tx_request, None).await.unwrap();
    }

    // Let the network process transactions
    network.run_until_block(&wallet, 5.into(), 200).await;

    // Verify that transaction replacement worked correctly
    for index in network.nodes.iter().map(|x| x.index) {
        let node = network.get_node(index);

        // Check if the replacement transaction was processed
        let initial_receipt = node
            .get_transaction_receipt(Hash(initial_tx.tx_hash().0))
            .unwrap();
        let replacement_receipt = node
            .get_transaction_receipt(Hash(replacement_tx.tx_hash().0))
            .unwrap();

        // Either the replacement was processed, or neither was processed yet
        if replacement_receipt.is_some() {
            assert!(
                initial_receipt.is_none(),
                "Both original and replacement transactions were processed on node {}",
                index
            );
        }

        // Verify pool state consistency
        let pool_status = node.consensus.transaction_pool.read().preview_status();
        let content = node.consensus.transaction_pool.read().preview_content();

        // Check that the pending count matches the actual content
        let actual_pending: usize = content.pending.values().map(|v| v.len()).sum();
        let actual_queued: usize = content.queued.values().map(|v| v.len()).sum();

        assert_eq!(
            actual_pending as u64, pool_status.pending,
            "Pending count mismatch on node {}: actual={}, reported={}",
            index, actual_pending, pool_status.pending
        );
        assert_eq!(
            actual_queued as u64, pool_status.queued,
            "Queued count mismatch on node {}: actual={}, reported={}",
            index, actual_queued, pool_status.queued
        );
    }
}

// Test transaction pool under network partition and healing
#[zilliqa_macros::test]
async fn test_transaction_pool_during_network_partition(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Wait for network to be ready
    network.run_until_block(&wallet, 2.into(), 50).await;

    // Submit some initial transactions
    let mut transaction_hashes = Vec::new();
    for nonce in 0..3 {
        let tx_request = TransactionRequest {
            to: Some(H160::random().into()),
            value: Some(U256::from(10)),
            gas: Some(U256::from(21000)),
            gas_price: Some(U256::from(1000000000)),
            nonce: Some(U256::from(nonce)),
            ..Default::default()
        };

        let pending_tx = wallet.send_transaction(tx_request, None).await.unwrap();
        transaction_hashes.push(pending_tx.tx_hash());
    }

    // Simulate network issues by dropping many messages
    for _ in 0..50 {
        network.randomly_drop_messages_then_tick(0.3).await; // Drop 30% of messages
    }

    // Submit more transactions during network issues
    for nonce in 3..6 {
        let tx_request = TransactionRequest {
            to: Some(H160::random().into()),
            value: Some(U256::from(10)),
            gas: Some(U256::from(21000)),
            gas_price: Some(U256::from(1000000000)),
            nonce: Some(U256::from(nonce)),
            ..Default::default()
        };

        let pending_tx = wallet.send_transaction(tx_request, None).await.unwrap();
        transaction_hashes.push(pending_tx.tx_hash());
    }

    // Allow network to heal and process transactions
    network.run_until_block(&wallet, 8.into(), 500).await;

    // Verify all nodes have consistent transaction pool states after healing
    let mut node_states = Vec::new();
    for index in network.nodes.iter().map(|x| x.index) {
        let node = network.get_node(index);
        let pool_status = node.consensus.transaction_pool.read().preview_status();
        let content = node.consensus.transaction_pool.read().preview_content();

        // Verify internal consistency
        let actual_pending: usize = content.pending.values().map(|v| v.len()).sum();
        let actual_queued: usize = content.queued.values().map(|v| v.len()).sum();

        assert_eq!(
            actual_pending as u64, pool_status.pending,
            "Node {} pending count inconsistent: {} vs {}",
            index, actual_pending, pool_status.pending
        );
        assert_eq!(
            actual_queued as u64, pool_status.queued,
            "Node {} queued count inconsistent: {} vs {}",
            index, actual_queued, pool_status.queued
        );

        node_states.push((pool_status.pending, pool_status.queued));
    }

    // All nodes should have reasonably similar pool states
    let avg_pending =
        node_states.iter().map(|(p, _)| *p).sum::<u64>() as f64 / node_states.len() as f64;
    for (i, (pending, _)) in node_states.iter().enumerate() {
        let diff = (*pending as f64 - avg_pending).abs();
        assert!(
            diff <= avg_pending * 0.5 + 5.0, // Allow 50% variance + 5 transactions
            "Node {} pending count too different from average: {} vs avg {}",
            i,
            pending,
            avg_pending
        );
    }
}

```

`zilliqa/tests/it/debug.rs`:

```rs
use alloy::{
    primitives::{B256, Uint},
    rpc::types::trace::geth::TraceResult,
};
use ethers::{
    providers::Middleware,
    types::{H160, TransactionRequest},
};

use crate::Network;

// Tests for debug_getBadBlocks

// Tests for debug_getTrieFlushInterval

// Tests for debug_storageRangeAt

// Tests for debug_traceBlock

// Tests for debug_traceBlockByHash

// Tests for debug_traceBlockByNumber

#[zilliqa_macros::test]
async fn debug_trace_block_by_number(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Create a transaction to have something to trace
    let to_addr = H160::random();
    let tx = TransactionRequest::new().to(to_addr).value(1000).gas(21000);

    let tx_hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();

    // Wait for transaction to be mined
    let receipt = network.run_until_receipt(&wallet, tx_hash, 100).await;
    let block_number = receipt.block_number.unwrap();

    // Get trace
    let response: Vec<TraceResult> = wallet
        .provider()
        .request("debug_traceBlockByNumber", [block_number])
        .await
        .expect("Failed to call debug_traceBlockByNumber API");

    assert!(!response.is_empty());

    // Test with callTracer
    let tracer_options = serde_json::json!({
        "tracer": "callTracer"
    });

    let response: Vec<TraceResult> = wallet
        .provider()
        .request("debug_traceBlockByNumber", (block_number, tracer_options))
        .await
        .expect("Failed to call debug_traceBlockByNumber with tracer API");

    assert!(!response.is_empty());
}

// Tests for debug_traceCall

// Tests for debug_traceTransaction

#[zilliqa_macros::test]
async fn debug_trace_transaction_basic(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Create a simple transfer transaction
    let to_addr = H160::random();
    let tx = TransactionRequest::new().to(to_addr).value(1000).gas(21000);

    let tx_hash_sent = wallet.send_transaction(tx, None).await.unwrap().tx_hash();

    // Wait for transaction to be mined
    network.run_until_receipt(&wallet, tx_hash_sent, 100).await;

    // Get trace
    let response: TraceResult = wallet
        .provider()
        .request("debug_traceTransaction", [tx_hash_sent])
        .await
        .expect("Failed to call debug_traceTransaction API");

    match response {
        TraceResult::Success { result, tx_hash } => {
            dbg!(&result);
            let frame = result.try_into_default_frame().unwrap();
            assert_eq!(tx_hash.unwrap(), tx_hash_sent.to_fixed_bytes());
            assert!(!frame.failed);
            assert!(frame.gas == 21000);
        }
        _ => panic!("Expected success result"),
    }
}

#[zilliqa_macros::test]
async fn debug_trace_transaction_with_call_tracer(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Create a simple transfer transaction
    let to_addr = H160::random();
    let tx = TransactionRequest::new().to(to_addr).value(1000).gas(21000);

    let tx_hash_sent = wallet.send_transaction(tx, None).await.unwrap().tx_hash();

    // Wait for transaction to be mined
    network.run_until_receipt(&wallet, tx_hash_sent, 100).await;

    // Configure callTracer
    let tracer_options = serde_json::json!({
        "tracer": "callTracer",
        "tracerConfig": {
            "onlyTopCall": false
        }
    });

    // Get trace
    let response: TraceResult = wallet
        .provider()
        .request("debug_traceTransaction", (tx_hash_sent, tracer_options))
        .await
        .expect("Failed to call debug_traceTransaction API");

    match response {
        TraceResult::Success { result, tx_hash } => {
            dbg!(&result);
            let frame = result.try_into_call_frame().unwrap();
            assert_eq!(tx_hash.unwrap(), tx_hash_sent.to_fixed_bytes());
            assert!(Uint::from(21000) >= frame.gas_used);
            assert!(Uint::from(0) < frame.gas_used);
            assert!(frame.error.is_none())
        }
        _ => panic!("Expected success result"),
    }
}

#[zilliqa_macros::test]
async fn debug_trace_transaction_not_found(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let nonexistent_hash: B256 =
        "0x1234567890123456789012345678901234567890123456789012345678901234"
            .parse()
            .unwrap();

    let response: Result<TraceResult, _> = wallet
        .provider()
        .request("debug_traceTransaction", [nonexistent_hash])
        .await;

    assert!(response.is_err());
}

```

`zilliqa/tests/it/eth.rs`:

```rs
use std::{fmt::Debug, ops::DerefMut};

use alloy::primitives::{Address, hex};
use ethabi::{Token, ethereum_types::U64};
use ethers::{
    abi::FunctionExt,
    core::types::{Bytes, Signature},
    providers::{Middleware, MiddlewareError, Provider},
    types::{
        BlockId, BlockNumber, Eip1559TransactionRequest, Eip2930TransactionRequest, Filter,
        Transaction, TransactionReceipt, TransactionRequest,
        transaction::{
            eip2718::TypedTransaction,
            eip2930::{AccessList, AccessListItem},
        },
    },
    utils::keccak256,
};
use futures::{StreamExt, future::join_all};
use primitive_types::{H160, H256};
use serde::{Deserialize, Serialize};
use serde_json::{Value, json};

use crate::{LocalRpcClient, Network, Wallet, deploy_contract};

#[zilliqa_macros::test]
async fn call_block_number(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (hash, abi) = deploy_contract(
        "tests/it/contracts/CallMe.sol",
        "CallMe",
        0u128,
        &wallet,
        &mut network,
    )
    .await;

    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();

    let function = abi.function("currentBlock").unwrap();
    let call_tx = TransactionRequest::new()
        .to(receipt.contract_address.unwrap())
        .data(function.encode_input(&[]).unwrap());

    // Query the current block number with an `eth_call`.
    let response = wallet.call(&call_tx.clone().into(), None).await.unwrap();
    let block_number = function.decode_output(&response).unwrap()[0]
        .clone()
        .into_uint()
        .unwrap()
        .as_u64();

    // Verify it is correct.
    let expected_block_number = wallet.get_block_number().await.unwrap().as_u64();
    assert_eq!(block_number, expected_block_number);

    // Advance the network to the next block.
    network
        .run_until_async(
            || async { wallet.get_block_number().await.unwrap().as_u64() > block_number },
            50,
        )
        .await
        .unwrap();

    // Query the current block number with an `eth_call`.
    let response = wallet.call(&call_tx.clone().into(), None).await.unwrap();
    let new_block_number = function.decode_output(&response).unwrap()[0]
        .clone()
        .into_uint()
        .unwrap()
        .as_u64();

    // Verify it is correct.
    let expected_block_number = wallet.get_block_number().await.unwrap().as_u64();
    assert_eq!(new_block_number, expected_block_number);

    // Query the block number at the old block with an `eth_call`.
    let response = wallet
        .call(
            &call_tx.clone().into(),
            Some(BlockId::Number(BlockNumber::Number(block_number.into()))),
        )
        .await
        .unwrap();
    let old_block_number = function.decode_output(&response).unwrap()[0]
        .clone()
        .into_uint()
        .unwrap()
        .as_u64();

    // Verify it used the state from the old block.
    assert_eq!(old_block_number, block_number);
}

#[zilliqa_macros::test]
async fn get_block_transaction_count(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let provider = wallet.provider();

    async fn count_by_number<T: Debug + Serialize + Send + Sync>(
        provider: &Provider<LocalRpcClient>,
        number: T,
    ) -> u64 {
        provider
            .request::<_, U64>("eth_getBlockTransactionCountByNumber", [number])
            .await
            .unwrap()
            .as_u64()
    }

    async fn count_by_hash(provider: &Provider<LocalRpcClient>, hash: H256) -> u64 {
        provider
            .request::<_, U64>("eth_getBlockTransactionCountByHash", [hash])
            .await
            .unwrap()
            .as_u64()
    }
    network
        .run_until_async(
            || async { wallet.get_block_number().await.unwrap().as_u64() > 1 },
            50,
        )
        .await
        .unwrap();

    // Send a transaction.
    let hash = wallet
        .send_transaction(TransactionRequest::pay(H160::random(), 10), None)
        .await
        .unwrap()
        .tx_hash();

    network
        .run_until_async(
            || async {
                provider
                    .get_transaction_receipt(hash)
                    .await
                    .unwrap()
                    .is_some()
            },
            50,
        )
        .await
        .unwrap();

    let receipt = provider
        .get_transaction_receipt(hash)
        .await
        .unwrap()
        .unwrap();
    let block_hash = receipt.block_hash.unwrap();
    let block_number = receipt.block_number.unwrap();

    // Check the previous block has a transaction count of zero.
    let count = count_by_number(provider, block_number - 1).await;
    assert_eq!(count, 0);

    // Check this block has a transaction count of one.
    let count = count_by_number(provider, block_number).await;
    assert_eq!(count, 1);
    let count = count_by_hash(provider, block_hash).await;
    assert_eq!(count, 1);

    // The latest block is the one with our transaction, because we stopped running the network after our receipt
    // appeared. So the latest block should also have a count of one.
    let count = count_by_number(provider, "latest").await;
    assert_eq!(count, 1);
}

#[zilliqa_macros::test]
async fn get_transaction_count_pending(mut network: Network) {
    let wallet_1 = network.genesis_wallet().await;
    let wallet_2 = network.random_wallet().await;

    let provider = wallet_1.provider();

    async fn get_count<T: Debug + Serialize + Send + Sync>(
        address: H160,
        provider: &Provider<LocalRpcClient>,
        number: T,
    ) -> u64 {
        provider
            .request::<_, U64>("eth_getTransactionCount", (address, number))
            .await
            .unwrap()
            .as_u64()
    }

    // Both wallets should have no transactions pending.
    let count = get_count(wallet_1.address(), provider, "pending").await;
    assert_eq!(count, 0);
    let count = get_count(wallet_2.address(), provider, "pending").await;
    assert_eq!(count, 0);

    // Send a transaction from wallet 1 to wallet 2.
    let _hash_1 = wallet_1
        .send_transaction(
            TransactionRequest::pay(wallet_2.address(), 10).nonce(0),
            None,
        )
        .await
        .unwrap()
        .tx_hash();

    // Wallet 1 should now have 1 transaction pending, and no transactions in the latest block.
    let count = get_count(wallet_1.address(), provider, "pending").await;
    assert_eq!(count, 1);
    let count = get_count(wallet_1.address(), provider, "latest").await;
    assert_eq!(count, 0);

    // Send a transaction from wallet 1 to wallet 2.
    let hash_2 = wallet_1
        .send_transaction(
            TransactionRequest::pay(wallet_2.address(), 10).nonce(1),
            None,
        )
        .await
        .unwrap()
        .tx_hash();

    // Wallet 1 should now have 2 transactions pending, and still no transactions in the latest block.
    let count = get_count(wallet_1.address(), provider, "pending").await;
    assert_eq!(count, 2);
    let count = get_count(wallet_1.address(), provider, "latest").await;
    assert_eq!(count, 0);

    // Ensure transaction count is account specific.
    let count = get_count(wallet_2.address(), provider, "pending").await;
    assert_eq!(count, 0);

    // Process pending transaction
    network
        .run_until_async(
            || async {
                provider
                    .get_transaction_receipt(hash_2)
                    .await
                    .unwrap()
                    .is_some()
            },
            50,
        )
        .await
        .unwrap();

    // Wallet 1 should no longer have any pending transactions, and should have 2 transactions in the
    // latest block, leading to 2 returned for both "pending" and "latest".
    let count = get_count(wallet_1.address(), provider, "pending").await;
    assert_eq!(count, 2);
    let count = get_count(wallet_1.address(), provider, "latest").await;
    assert_eq!(count, 2);

    // Send a transaction from wallet 1 to wallet 2.
    wallet_1
        .send_transaction(
            TransactionRequest::pay(wallet_2.address(), 10).nonce(3),
            None,
        )
        .await
        .unwrap();

    // Wallet 1 should no longer have any pending transactions, and should have 2 transactions in the
    // latest block, leading to 2 returned for both "pending" and "latest".
    let count = get_count(wallet_1.address(), provider, "pending").await;
    assert_eq!(count, 2);

    // Send a transaction from wallet 1 to wallet 2.
    wallet_1
        .send_transaction(
            TransactionRequest::pay(wallet_2.address(), 10).nonce(2),
            None,
        )
        .await
        .unwrap();

    // Wallet 1 should no longer have any pending transactions, and should have 2 transactions in the
    // latest block, leading to 2 returned for both "pending" and "latest".
    let count = get_count(wallet_1.address(), provider, "pending").await;
    assert_eq!(count, 4);
}

#[zilliqa_macros::test]
async fn get_account_transaction_count(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let provider = wallet.provider();

    async fn count_at_block(provider: &Provider<LocalRpcClient>, params: (H160, U64)) -> u64 {
        provider
            .request::<_, U64>("eth_getTransactionCount", params)
            .await
            .unwrap()
            .as_u64()
    }

    network
        .run_until_async(
            || async { wallet.get_block_number().await.unwrap().as_u64() > 1 },
            50,
        )
        .await
        .unwrap();

    // Send a transaction.
    let hash = wallet
        .send_transaction(TransactionRequest::pay(H160::random(), 10), None)
        .await
        .unwrap()
        .tx_hash();

    network
        .run_until_async(
            || async {
                provider
                    .get_transaction_receipt(hash)
                    .await
                    .unwrap()
                    .is_some()
            },
            50,
        )
        .await
        .unwrap();

    let receipt = provider
        .get_transaction_receipt(hash)
        .await
        .unwrap()
        .unwrap();
    let block_number = receipt.block_number.unwrap();

    // Check the wallet has a transaction count of one.
    let count = count_at_block(provider, (wallet.address(), block_number)).await;
    assert_eq!(count, 1);

    // Check the wallet has a transaction count of zero at the previous block
    let count = count_at_block(provider, (wallet.address(), block_number - 1)).await;
    assert_eq!(count, 0);
}

#[zilliqa_macros::test]
async fn eth_get_transaction_receipt(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Deploy a contract to generate a transaction receipt
    let (hash, _abi) = deploy_contract(
        "tests/it/contracts/EmitEvents.sol",
        "EmitEvents",
        0u128,
        &wallet,
        &mut network,
    )
    .await;

    // Wait for the transaction to be mined
    network
        .run_until_async(
            || async {
                wallet
                    .get_transaction_receipt(hash)
                    .await
                    .unwrap()
                    .is_some()
            },
            50,
        )
        .await
        .unwrap();

    // Get the transaction receipt
    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();

    dbg!(&receipt);

    // Verify the transaction receipt fields
    assert_eq!(receipt.transaction_hash, hash);
    assert!(receipt.block_hash.is_some());
    assert!(receipt.block_number.is_some());
    assert_eq!(receipt.from, wallet.address());
    assert!(receipt.to.is_none()); // This is a contract deployment so to should be empty
    assert!(receipt.contract_address.is_some());
    assert!(receipt.cumulative_gas_used > 0.into());
    assert!(receipt.effective_gas_price.unwrap_or_default() > 0.into());
    assert!(receipt.gas_used.unwrap_or_default() > 0.into());
    assert_eq!(receipt.status.unwrap_or_default(), 1.into());
}

#[zilliqa_macros::test]
async fn get_transaction_receipt_sequential_log_indexes(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Deploy a contract that can emit events
    let (hash1, abi) = deploy_contract(
        "tests/it/contracts/EmitEvents.sol",
        "EmitEvents",
        0u128,
        &wallet,
        &mut network,
    )
    .await;

    let receipt1 = network.run_until_receipt(&wallet, hash1, 50).await;
    let contract_address = receipt1.contract_address.unwrap();

    // Call emitEvents() to generate some logs in block 1
    let emit_events = abi.function("emitEvents").unwrap();
    let tx1 = TransactionRequest::new()
        .to(contract_address)
        .data(emit_events.encode_input(&[]).unwrap());

    let tx1_hash = wallet.send_transaction(tx1, None).await.unwrap().tx_hash();

    let receipt1 = network.run_until_receipt(&wallet, tx1_hash, 50).await;

    // Verify logs in first block have sequential indexes starting at 0
    assert!(receipt1.logs.len() > 1);
    for (i, log) in receipt1.logs.iter().enumerate() {
        assert_eq!(log.log_index.unwrap().as_u64(), i as u64);
    }

    // Create another transaction in a new block
    let tx2 = TransactionRequest::new()
        .to(contract_address)
        .data(emit_events.encode_input(&[]).unwrap());

    let tx2_hash = wallet.send_transaction(tx2, None).await.unwrap().tx_hash();

    let receipt2 = network.run_until_receipt(&wallet, tx2_hash, 50).await;

    // Verify logs in second block also start at index 0
    assert!(receipt2.logs.len() > 1);
    for (i, log) in receipt2.logs.iter().enumerate() {
        assert_eq!(log.log_index.unwrap().as_u64(), i as u64);
    }

    // Verify blocks are different
    assert_ne!(receipt1.block_hash, receipt2.block_hash);
}

#[zilliqa_macros::test]
async fn get_logs(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (hash, contract) = deploy_contract(
        "tests/it/contracts/EmitEvents.sol",
        "EmitEvents",
        0u128,
        &wallet,
        &mut network,
    )
    .await;

    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();
    let contract_address = receipt.contract_address.unwrap();

    let emit_first = contract.function("emitEvents").unwrap();
    let call_tx = TransactionRequest::new()
        .to(contract_address)
        .data(emit_first.encode_input(&[]).unwrap());

    let call_tx_hash = wallet
        .send_transaction(call_tx, None)
        .await
        .unwrap()
        .tx_hash();
    // Wait until the transaction has succeeded.
    network
        .run_until_async(
            || async {
                wallet
                    .get_transaction_receipt(call_tx_hash)
                    .await
                    .unwrap()
                    .is_some()
            },
            50,
        )
        .await
        .unwrap();

    let receipt = wallet
        .get_transaction_receipt(call_tx_hash)
        .await
        .unwrap()
        .unwrap();

    // Make sure searching by both block hash and block number work.
    assert_eq!(
        wallet
            .get_logs(&Filter::new().at_block_hash(receipt.block_hash.unwrap()))
            .await
            .unwrap()
            .len(),
        2
    );
    assert_eq!(
        wallet
            .get_logs(&Filter::new().select(receipt.block_number.unwrap()))
            .await
            .unwrap()
            .len(),
        2
    );

    let base = Filter::new().at_block_hash(receipt.block_hash.unwrap());

    // Make sure filtering by address works.
    assert_eq!(
        wallet
            .get_logs(&base.clone().address(wallet.address()))
            .await
            .unwrap()
            .len(),
        0
    );
    assert_eq!(
        wallet
            .get_logs(&base.clone().address(contract_address))
            .await
            .unwrap()
            .len(),
        2
    );

    // Make sure filtering by topic works.
    let transfer = contract.event("Transfer").unwrap().signature();
    let approval = contract.event("Approval").unwrap().signature();
    let nonsense = H256::from_low_u64_be(123);

    // Filter by topic0.
    assert_eq!(
        wallet
            .get_logs(&base.clone().topic0(transfer))
            .await
            .unwrap()
            .len(),
        1
    );
    assert_eq!(
        wallet
            .get_logs(&base.clone().topic0(approval))
            .await
            .unwrap()
            .len(),
        1
    );
    assert_eq!(
        wallet
            .get_logs(&base.clone().topic0(nonsense))
            .await
            .unwrap()
            .len(),
        0
    );
    // Multiple topics in the same position act as an OR filter.
    assert_eq!(
        wallet
            .get_logs(&base.clone().topic0(vec![transfer, approval]))
            .await
            .unwrap()
            .len(),
        2
    );
    // Including extra topics in the OR filter doesn't make a difference.
    assert_eq!(
        wallet
            .get_logs(&base.clone().topic0(vec![transfer, approval, nonsense]))
            .await
            .unwrap()
            .len(),
        2
    );

    // Filter by topic1 (same value for both logs).
    let one = H256::from_low_u64_be(1);
    assert_eq!(
        wallet
            .get_logs(&base.clone().topic1(one))
            .await
            .unwrap()
            .len(),
        2
    );

    // Filter by topic2 (different value for each log).
    let two = H256::from_low_u64_be(2);
    let three = H256::from_low_u64_be(3);
    assert_eq!(
        wallet
            .get_logs(&base.clone().topic2(two))
            .await
            .unwrap()
            .len(),
        1
    );
    assert_eq!(
        wallet
            .get_logs(&base.clone().topic2(three))
            .await
            .unwrap()
            .len(),
        1
    );
    assert_eq!(
        wallet
            .get_logs(&base.clone().topic2(vec![two, three]))
            .await
            .unwrap()
            .len(),
        2
    );

    // Filter by multiple topics.
    assert_eq!(
        wallet
            .get_logs(
                &base
                    .clone()
                    .topic0(vec![transfer, approval])
                    .topic1(one)
                    .topic2(vec![two, three])
            )
            .await
            .unwrap()
            .len(),
        2
    );
}

#[zilliqa_macros::test]
async fn get_storage_at(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Example from https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_getstorageat.
    let (hash, abi) = deploy_contract(
        "tests/it/contracts/Storage.sol",
        "Storage",
        0u128,
        &wallet,
        &mut network,
    )
    .await;

    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();
    let contract_address = receipt.contract_address.unwrap();

    let value = wallet
        .get_storage_at(contract_address, H256::zero(), None)
        .await
        .unwrap();
    assert_eq!(value, H256::from_low_u64_be(1234));

    // Calculate the storage position with keccak(LeftPad32(key, 0), LeftPad32(map position, 0))
    let mut bytes = Vec::new();
    bytes.extend_from_slice(&[0; 12]);
    bytes.extend_from_slice(receipt.from.as_bytes());
    bytes.extend_from_slice(&[0; 31]);
    bytes.push(1);
    let position = H256::from_slice(&ethers::utils::keccak256(bytes));
    let value = wallet
        .get_storage_at(contract_address, position, None)
        .await
        .unwrap();
    assert_eq!(value, H256::from_low_u64_be(5678));

    // Save the current block number
    let old_block_number = wallet.get_block_number().await.unwrap().as_u64();

    // Modify the contract state.
    let function = abi.function("update").unwrap();
    let update_tx = TransactionRequest::new()
        .to(receipt.contract_address.unwrap())
        .data(function.encode_input(&[]).unwrap());
    let update_tx_hash = wallet
        .send_transaction(update_tx, None)
        .await
        .unwrap()
        .tx_hash();
    // Advance the network to the next block.
    network
        .run_until_async(
            || async {
                wallet
                    .get_transaction_receipt(update_tx_hash)
                    .await
                    .unwrap()
                    .is_some()
            },
            50,
        )
        .await
        .unwrap();

    // verify the new state
    let value = wallet
        .get_storage_at(contract_address, H256::zero(), None)
        .await
        .unwrap();
    assert_eq!(value, H256::from_low_u64_be(9876));

    // verify that the state at the old block can still be fetched correctly
    let value = wallet
        .get_storage_at(
            contract_address,
            H256::zero(),
            Some(BlockId::Number(BlockNumber::Number(
                old_block_number.into(),
            ))),
        )
        .await
        .unwrap();
    assert_eq!(value, H256::from_low_u64_be(1234));
}

/// Helper method for send transaction tests.
async fn send_transaction(
    network: &mut Network,
    wallet: &Wallet,
    mut tx: TypedTransaction,
) -> (Transaction, TransactionReceipt) {
    wallet.fill_transaction(&mut tx, None).await.unwrap();
    let sig = wallet.signer().sign_transaction_sync(&tx).unwrap();
    let expected_hash = tx.hash(&sig);
    let hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();
    assert_eq!(hash, expected_hash);

    network
        .run_until_async(
            || async {
                wallet
                    .get_transaction_receipt(hash)
                    .await
                    .unwrap()
                    .is_some()
            },
            50,
        )
        .await
        .unwrap();

    let tx = wallet.get_transaction(hash).await.unwrap().unwrap();
    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();

    (tx, receipt)
}

#[zilliqa_macros::test]
async fn send_legacy_transaction(mut network: Network) {
    let to = H160::random_using(network.rng.lock().unwrap().deref_mut());
    let tx = TransactionRequest::pay(to, 123).into();
    let wallet = network.genesis_wallet().await;
    let (tx, receipt) = send_transaction(&mut network, &wallet, tx).await;

    assert_eq!(tx.transaction_type.unwrap().as_u64(), 0);
    assert_eq!(receipt.to.unwrap(), to);
}

#[zilliqa_macros::test]
async fn send_eip2930_transaction(mut network: Network) {
    let (to, access_list) = {
        let mut rng = network.rng.lock().unwrap();
        let to = H160::random_using(rng.deref_mut());
        let access_list = AccessList(vec![AccessListItem {
            address: H160::random_using(rng.deref_mut()),
            storage_keys: vec![
                H256::random_using(rng.deref_mut()),
                H256::random_using(rng.deref_mut()),
            ],
        }]);
        (to, access_list)
    };
    let tx = Eip2930TransactionRequest::new(TransactionRequest::pay(to, 123), access_list.clone())
        .into();
    let wallet = network.genesis_wallet().await;
    let (tx, receipt) = send_transaction(&mut network, &wallet, tx).await;

    assert_eq!(tx.transaction_type.unwrap().as_u64(), 1);
    assert_eq!(tx.access_list.unwrap(), access_list);
    assert_eq!(receipt.to.unwrap(), to);
}

#[zilliqa_macros::test]
async fn send_eip1559_transaction(mut network: Network) {
    let (to, access_list) = {
        let mut rng = network.rng.lock().unwrap();
        let to = H160::random_using(rng.deref_mut());
        let access_list = AccessList(vec![AccessListItem {
            address: H160::random_using(rng.deref_mut()),
            storage_keys: vec![
                H256::random_using(rng.deref_mut()),
                H256::random_using(rng.deref_mut()),
            ],
        }]);
        (to, access_list)
    };
    let gas_price = network.random_wallet().await.get_gas_price().await.unwrap();
    let tx = Eip1559TransactionRequest::new()
        .to(to)
        .value(456)
        .access_list(access_list.clone())
        .max_fee_per_gas(gas_price)
        .max_priority_fee_per_gas(gas_price)
        .into();
    let wallet = network.genesis_wallet().await;
    let (tx, receipt) = send_transaction(&mut network, &wallet, tx).await;

    assert_eq!(tx.transaction_type.unwrap().as_u64(), 2);
    assert_eq!(tx.access_list.unwrap(), access_list);
    assert_eq!(tx.max_fee_per_gas.unwrap(), gas_price);
    assert_eq!(tx.max_priority_fee_per_gas.unwrap(), gas_price);
    assert_eq!(receipt.to.unwrap(), to);
}

/// Test which sends a legacy transaction, without the replay protection specified by EIP-155.
#[zilliqa_macros::test]
async fn send_legacy_transaction_without_chain_id(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let to = H160::random_using(network.rng.lock().unwrap().deref_mut());
    let tx = TransactionRequest::pay(to, 123);
    let mut tx: TypedTransaction = tx.into();
    wallet.fill_transaction(&mut tx, None).await.unwrap();
    // Clear the chain ID.
    let tx = TypedTransaction::Legacy(TransactionRequest {
        chain_id: None,
        ..tx.into()
    });

    let sig = wallet.signer().sign_hash(tx.sighash()).unwrap();
    let expected_hash = tx.hash(&sig);
    eprintln!("expected: {}", hex::encode(tx.rlp_signed(&sig)));

    // Drop down to the provider, to prevent the wallet middleware from setting the chain ID.
    let hash = wallet
        .provider()
        .send_raw_transaction(tx.rlp_signed(&sig))
        .await
        .unwrap()
        .tx_hash();

    assert_eq!(hash, expected_hash);

    network
        .run_until_async(
            || async {
                wallet
                    .get_transaction_receipt(hash)
                    .await
                    .unwrap()
                    .is_some()
            },
            50,
        )
        .await
        .unwrap();

    let tx = wallet.get_transaction(hash).await.unwrap().unwrap();
    assert_eq!(tx.transaction_type.unwrap().as_u64(), 0);
    assert_eq!(tx.chain_id, None);

    let balance = wallet.get_balance(to, None).await.unwrap().as_u128();
    assert_eq!(balance, 123);
}

#[zilliqa_macros::test]
async fn eth_call(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (hash, abi) = deploy_contract(
        "tests/it/contracts/SetGetContractValue.sol",
        "SetGetContractValue",
        0u128,
        &wallet,
        &mut network,
    )
    .await;

    network
        .run_until_async(
            || async {
                wallet
                    .get_transaction_receipt(hash)
                    .await
                    .unwrap()
                    .is_some()
            },
            50,
        )
        .await
        .unwrap();

    let getter = abi.function("getUint256").unwrap();

    let receipt = wallet.get_transaction_receipt(hash).await;

    assert!(receipt.is_ok());
    let receipt = receipt.unwrap().unwrap();

    let contract_address = receipt.contract_address.unwrap();

    let mut tx = TransactionRequest::new();
    tx.to = Some(contract_address.into());
    tx.data = Some(getter.selector().into());

    let value = wallet.call(&tx.into(), None).await.unwrap();

    assert_eq!(H256::from_slice(value.as_ref()), H256::from_low_u64_be(99));
}

#[zilliqa_macros::test]
async fn revert_transaction(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (hash, abi) = deploy_contract(
        "tests/it/contracts/RevertMe.sol",
        "RevertMe",
        0u128,
        &wallet,
        &mut network,
    )
    .await;

    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();
    let contract_address = receipt.contract_address.unwrap();
    let setter = abi.function("revertable").unwrap();
    let getter = abi.function("value").unwrap();

    // First ensure contract works
    let success_call = TransactionRequest::new()
        .to(contract_address)
        .data(setter.encode_input(&[Token::Bool(true)]).unwrap());
    let (_, receipt) = send_transaction(&mut network, &wallet, success_call.into()).await;
    assert_eq!(receipt.status.unwrap().as_u32(), 1);

    // Ensure value was incremented
    let check_call = TransactionRequest::new()
        .to(contract_address)
        .data(getter.selector());
    let value = wallet.call(&check_call.clone().into(), None).await.unwrap();
    let value = getter.decode_output(&value).unwrap()[0]
        .clone()
        .into_int()
        .unwrap();
    assert_eq!(value, 1.into());

    // Next ensure revert fails correctly
    let revert_call = TransactionRequest::new()
        .to(contract_address)
        .data(setter.encode_input(&[Token::Bool(false)]).unwrap())
        .gas(1_000_000); // Pass a gas limit, otherwise estimate_gas is called and fails due to the revert
    let (_, receipt) = send_transaction(&mut network, &wallet, revert_call.into()).await;
    assert_eq!(receipt.status.unwrap().as_u32(), 0);

    // Ensure value was NOT incremented a second time
    let value = wallet.call(&check_call.into(), None).await.unwrap();
    let value = getter.decode_output(&value).unwrap()[0]
        .clone()
        .into_int()
        .unwrap();
    assert_eq!(value, 1.into());
}

#[zilliqa_macros::test]
async fn gas_charged_on_revert(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (hash, abi) = deploy_contract(
        "tests/it/contracts/RevertMe.sol",
        "RevertMe",
        0u128,
        &wallet,
        &mut network,
    )
    .await;

    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();
    let contract_address = receipt.contract_address.unwrap();
    let setter = abi.function("revertable").unwrap();

    let gas_price = wallet.get_gas_price().await.unwrap();

    // Revert on contract failure. Ensure gas is consumed according to execution.
    let balance_before_call = wallet.get_balance(wallet.address(), None).await.unwrap();
    let large_gas_limit = 1_000_000;
    let revert_call = TransactionRequest::new()
        .to(contract_address)
        .data(setter.encode_input(&[Token::Bool(false)]).unwrap())
        .gas(large_gas_limit);
    let (_, receipt) = send_transaction(&mut network, &wallet, revert_call.into()).await;

    assert_eq!(receipt.status.unwrap().as_u32(), 0);
    assert!(receipt.gas_used.is_some());
    let gas_used = receipt.gas_used.unwrap();
    assert!(gas_used > 0.into());
    assert!(gas_used < large_gas_limit.into());
    let balance_after_call = wallet.get_balance(wallet.address(), None).await.unwrap();
    assert_eq!(
        balance_after_call,
        balance_before_call - gas_price * gas_used
    );

    // Revert on out-of-gas. Ensure entire gas limit is consumed.
    let balance_before_call = wallet.get_balance(wallet.address(), None).await.unwrap();

    // Set the gas limit of this transaction to be half of the previous successful call. This guarantees we will fail
    // due to running out of gas.
    let small_gas_limit = gas_used / 2;
    let fail_out_of_gas_call = TransactionRequest::new()
        .to(contract_address)
        .data(setter.encode_input(&[Token::Bool(true)]).unwrap())
        .gas(small_gas_limit);
    let (_, receipt) = send_transaction(&mut network, &wallet, fail_out_of_gas_call.into()).await;

    assert_eq!(receipt.status.unwrap().as_u32(), 0);
    let balance_after_call = wallet.get_balance(wallet.address(), None).await.unwrap();
    assert_eq!(
        balance_after_call,
        balance_before_call - gas_price * small_gas_limit
    );
}

#[zilliqa_macros::test]
async fn nonces_rejected_too_high(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let to: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    let mut tx = TransactionRequest::pay(to, 100);

    // Tx nonce of 1 should never get mined
    tx.nonce = Some(1.into());

    // Transform the transaction to its final form, so we can caculate the expected hash.
    let mut tx: TypedTransaction = tx.into();

    wallet.fill_transaction(&mut tx, None).await.unwrap();
    let sig = wallet.signer().sign_transaction_sync(&tx).unwrap();
    let _expected_hash = H256::from_slice(&keccak256(tx.rlp_signed(&sig)));

    let hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();

    let wait = network
        .run_until_async(
            || async {
                wallet
                    .get_transaction_receipt(hash)
                    .await
                    .unwrap()
                    .is_some()
            },
            50,
        )
        .await;

    // Times out trying to mine
    assert!(wait.is_err());
}

#[zilliqa_macros::test]
async fn nonces_respected_ordered(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let to: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();

    let mut txs_to_send: Vec<TypedTransaction> = Vec::new();
    let tx_send_amount = 10;
    let tx_send_iterations = 100;

    // collect up a bunch of TXs to send at once, but in reverse order
    for i in (0..tx_send_iterations).rev() {
        let mut tx = TransactionRequest::pay(to, tx_send_amount);
        tx.nonce = Some(i.into());
        let mut tx: TypedTransaction = tx.into();

        wallet.fill_transaction(&mut tx, None).await.unwrap();
        txs_to_send.push(tx);
    }

    // collect the promises and await on them
    let mut promises = Vec::new();

    // Send all of them
    for tx in txs_to_send {
        let prom = wallet.send_transaction(tx, None);
        promises.push(prom);
    }

    // Wait for all of them to be completed
    join_all(promises).await;

    // Wait until target account has got all the TXs
    let wait = network
        .run_until_async(
            || async {
                wallet.get_balance(to, None).await.unwrap()
                    == (tx_send_amount * tx_send_iterations).into()
            },
            10000,
        )
        .await;

    // doesn't time out trying to mine
    assert!(wait.is_ok());
}

#[zilliqa_macros::test]
async fn priority_fees_tx(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let to: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();

    let mut txs_to_send: Vec<TypedTransaction> = Vec::new();
    let tx_send_amount = 10;
    let tx_send_iterations = 10;

    // collect up a bunch of TXs to send at once, with two per nonce (one with a priority fee)
    // but starting from nonce 1 to allow the mempool time to see them all without being able to mine them yet
    for i in 1..tx_send_iterations {
        // This first one with a transfer amount of 1 should never get mined
        let mut tx = TransactionRequest::pay(to, 1);
        tx.nonce = Some(i.into());
        let mut tx: TypedTransaction = tx.into();
        wallet.fill_transaction(&mut tx, None).await.unwrap();
        let next_gas_price = tx.gas_price().unwrap() * 2; // double gas price for next one
        txs_to_send.push(tx);

        // Second priority tx
        let mut tx = TransactionRequest::pay(to, tx_send_amount);
        tx.nonce = Some(i.into());
        tx.gas_price = Some(next_gas_price);
        let mut tx: TypedTransaction = tx.into();

        wallet.fill_transaction(&mut tx, None).await.unwrap();
        txs_to_send.push(tx);
    }

    // collect the promises and await on them
    let mut promises = Vec::new();
    let txns_count = txs_to_send.len();
    // Send all of them
    for tx in txs_to_send {
        let prom = wallet.send_transaction(tx, None);
        promises.push(prom);
    }

    // Wait for all of them to be completed. We need to tick since they get broadcast around
    // as messages too and you can't guarantee which miner will try to create a block
    for prom in promises {
        let _hash = prom.await.unwrap().tx_hash();
        network.tick().await;
    }

    // Give enough time for all transactions to reach possible proposer
    for _ in 0..10 * txns_count {
        network.tick().await;
    }

    // Now send the first one
    let mut tx = TransactionRequest::pay(to, tx_send_amount);
    tx.nonce = Some(0.into());
    let mut tx: TypedTransaction = tx.into();

    wallet.fill_transaction(&mut tx, None).await.unwrap();
    wallet.send_transaction(tx, None).await.unwrap();

    // Wait until target account has got all the TXs
    let wait = network
        .run_until_async(
            || async {
                wallet.get_balance(to, None).await.unwrap()
                    == (tx_send_amount * tx_send_iterations).into()
            },
            100,
        )
        .await;

    // doesn't time out trying to mine
    assert!(wait.is_ok());
}

#[zilliqa_macros::test]
async fn pending_transaction_is_returned_by_get_transaction_by_hash(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let provider = wallet.provider();

    // Send a transaction.
    let hash = wallet
        .send_transaction(TransactionRequest::pay(H160::random(), 10), None)
        .await
        .unwrap()
        .tx_hash();

    // Check the transaction is returned with null values for the block.
    let tx = wallet.get_transaction(hash).await.unwrap().unwrap();
    assert_eq!(tx.block_hash, None);
    assert_eq!(tx.block_number, None);

    // Wait for the transaction to be mined.
    network
        .run_until_async(
            || async {
                provider
                    .get_transaction_receipt(hash)
                    .await
                    .unwrap()
                    .is_some()
            },
            50,
        )
        .await
        .unwrap();

    // Check the transaction is returned with non-null values for the block.
    let tx = wallet.get_transaction(hash).await.unwrap().unwrap();
    assert!(tx.block_hash.is_some());
    assert!(tx.block_number.is_some());
}

#[zilliqa_macros::test]
async fn get_transaction_by_index(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Send transaction in reverse nonce order to ensure they land in the same block
    let h1 = wallet
        .send_transaction(TransactionRequest::pay(H160::random(), 10).nonce(1), None)
        .await
        .unwrap()
        .tx_hash();

    let h2 = wallet
        .send_transaction(TransactionRequest::pay(H160::random(), 10).nonce(0), None)
        .await
        .unwrap()
        .tx_hash();

    let r1 = network.run_until_receipt(&wallet, h1, 50).await;
    let r2 = network.run_until_receipt(&wallet, h2, 50).await;

    // NOTE: they are not always in the same block
    if r1.block_hash == r2.block_hash {
        let block_hash = r1.block_hash.unwrap();
        let block_number = r1.block_number.unwrap();

        let txn = wallet
            .get_transaction_by_block_and_index(block_hash, 0u64.into())
            .await
            .unwrap()
            .unwrap();
        assert_eq!(txn.hash, h2);

        let txn = wallet
            .get_transaction_by_block_and_index(block_number, 1u64.into())
            .await
            .unwrap()
            .unwrap();
        assert_eq!(txn.hash, h1);
    } else {
        let block_hash = r2.block_hash.unwrap();
        let block_number = r1.block_number.unwrap();

        let txn = wallet
            .get_transaction_by_block_and_index(block_hash, 0u64.into())
            .await
            .unwrap()
            .unwrap();
        assert_eq!(txn.hash, h2);

        let txn = wallet
            .get_transaction_by_block_and_index(block_number, 0u64.into())
            .await
            .unwrap()
            .unwrap();
        assert_eq!(txn.hash, h1);
    }
}

#[zilliqa_macros::test]
async fn block_subscription(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let mut block_stream: ethers::providers::SubscriptionStream<
        '_,
        LocalRpcClient,
        ethers::types::Block<H256>,
    > = wallet.subscribe_blocks().await.unwrap();
    network.run_until_block(&wallet, 3.into(), 100).await;

    // Assert the stream contains next 3 blocks.
    assert_eq!(
        block_stream.next().await.unwrap().number.unwrap().as_u64(),
        1
    );
    assert_eq!(
        block_stream.next().await.unwrap().number.unwrap().as_u64(),
        2
    );
    assert_eq!(
        block_stream.next().await.unwrap().number.unwrap().as_u64(),
        3
    );

    assert!(block_stream.unsubscribe().await.unwrap());
}

#[zilliqa_macros::test]
async fn logs_subscription(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (hash, contract) = deploy_contract(
        "tests/it/contracts/EmitEvents.sol",
        "EmitEvents",
        0u128,
        &wallet,
        &mut network,
    )
    .await;

    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();
    let contract_address = receipt.contract_address.unwrap();

    // Our filtering logic is tested above by the `eth_getLogs` test, so in this test we just check whether logs are
    // returned at all from the subscription.
    let mut log_stream = wallet.subscribe_logs(&Filter::new()).await.unwrap();

    let emit_events = contract.function("emitEvents").unwrap();
    let call_tx = TransactionRequest::new()
        .to(contract_address)
        .data(emit_events.encode_input(&[]).unwrap());

    let call_tx_hash = wallet
        .send_transaction(call_tx, None)
        .await
        .unwrap()
        .tx_hash();
    network.run_until_receipt(&wallet, call_tx_hash, 50).await;

    assert_eq!(log_stream.next().await.unwrap().address, contract_address);
    assert_eq!(log_stream.next().await.unwrap().address, contract_address);

    assert!(log_stream.unsubscribe().await.unwrap());
}

#[zilliqa_macros::test]
async fn new_transaction_subscription(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let mut txn_stream = wallet.subscribe_full_pending_txs().await.unwrap();
    let mut hash_stream = wallet.subscribe_pending_txs().await.unwrap();

    let txn = TransactionRequest::pay(H160::random(), 10);
    let txn = wallet.send_transaction(txn, None).await.unwrap();

    // Note we don't wait for the transaction to be mined - The subscriptions should already contain this transaction.

    assert_eq!(txn_stream.next().await.unwrap().hash, txn.tx_hash());
    assert_eq!(hash_stream.next().await.unwrap(), txn.tx_hash());

    assert!(txn_stream.unsubscribe().await.unwrap());
    assert!(hash_stream.unsubscribe().await.unwrap());
}

#[zilliqa_macros::test]
async fn get_accounts_with_nonexistent_params(mut network: Network) {
    let client = network.rpc_client(0).await.unwrap();
    // Attempt to call eth_accounts (as a random example) with no parameters at all and check that the
    // call succeeds and the result is empty.
    let result = client
        .request_optional::<(), Vec<Address>>("eth_accounts", None)
        .await
        .unwrap();

    assert!(result.is_empty());
}

#[zilliqa_macros::test]
async fn get_accounts_with_extra_args(mut network: Network) {
    let client = network.rpc_client(0).await.unwrap();
    // Attempt to call eth_accounts (as a random example) with no parameters at all and check that the
    // call succeeds and the result is empty.
    let result = client
        .request_optional::<Vec<&str>, Vec<Address>>("eth_accounts", Some(vec!["extra"]))
        .await;

    assert!(result.is_err());
}

#[zilliqa_macros::test]
async fn deploy_deterministic_deployment_proxy(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let signer: H160 = "0x3fab184622dc19b6109349b94811493bf2a45362"
        .parse()
        .unwrap();

    let gas_price = 100000000000u128;
    let gas = 100000u128;

    // Send the signer enough money to cover the deployment.
    let tx = TransactionRequest::pay(signer, gas_price * gas);
    send_transaction(&mut network, &wallet, tx.into()).await;

    // Transaction from https://github.com/Arachnid/deterministic-deployment-proxy.
    let tx = TransactionRequest::new()
        .nonce(0)
        .gas_price(gas_price)
        .gas(gas)
        .value(0)
        .data(hex!("604580600e600039806000f350fe7fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffe03601600081602082378035828234f58015156039578182fd5b8082525050506014600cf3"));
    let tx = TypedTransaction::Legacy(tx);
    let signature = Signature {
        r: hex!("2222222222222222222222222222222222222222222222222222222222222222").into(),
        s: hex!("2222222222222222222222222222222222222222222222222222222222222222").into(),
        v: 27,
    };
    let raw_tx = tx.rlp_signed(&signature);
    let hash = wallet.send_raw_transaction(raw_tx).await.unwrap().tx_hash();

    let receipt = network.run_until_receipt(&wallet, hash, 150).await;

    assert_eq!(receipt.from, signer);
    assert_eq!(
        receipt.contract_address.unwrap(),
        "0x4e59b44847b379578588920ca78fbf26c0b4956c"
            .parse()
            .unwrap()
    );
}

#[zilliqa_macros::test]
async fn test_send_transaction_errors(mut network: Network) {
    let wallet = network.random_wallet().await;
    network.run_until_block(&wallet, 3.into(), 70).await;

    async fn send_transaction_get_error(wallet: &Wallet, tx: TransactionRequest) -> (i64, String) {
        let result = wallet.send_transaction(tx, None).await;
        assert!(result.is_err());
        let val = result.unwrap_err();
        let err = val.as_error_response().unwrap();
        (err.code, err.message.to_string())
    }
    async fn send_raw_transaction_get_error(wallet: &Wallet, tx: Bytes) -> (i64, String) {
        let result = wallet.send_raw_transaction(tx).await;
        assert!(result.is_err());
        let val = result.unwrap_err();
        let err = val.as_error_response().unwrap();
        (err.code, err.message.to_string())
    }
    let gas_price = 100000000000u128;
    let gas = 100000u128;

    // Give the signer some funds.
    let tx = TransactionRequest::pay(wallet.address(), 2 * gas_price * gas);
    let genesis_wallet = network.genesis_wallet().await;
    send_transaction(&mut network, &genesis_wallet, tx.into()).await;

    // Deliberately set too low a gas fee
    {
        let tx = TransactionRequest::pay(H160::random(), 10).gas(1);
        let (code, msg) = send_transaction_get_error(&wallet, tx).await;
        assert_eq!(code, -32602);
        assert!(msg.to_lowercase().contains("gas"));
    }
    {
        let tx = TransactionRequest::pay(H160::random(), gas_price * gas)
            .gas_price(gas_price)
            .gas(gas);
        let sig = wallet.signer().sign_hash(tx.sighash()).unwrap();
        let mut signed = tx.rlp_signed(&sig).iter().cloned().collect::<Vec<u8>>();
        // Corrupt the transaction data.
        signed[1] += 2;
        let (code, _) = send_raw_transaction_get_error(&wallet, signed.into()).await;
        assert_eq!(code, -32603);
    }
    // it would be nice to test bad signatures, but generating one without
    // causing other spurious errors appears to be hard.
    {
        let tx = TransactionRequest::pay(H160::random(), 200 * gas_price * gas).nonce(547);
        let (code, msg) = send_transaction_get_error(&wallet, tx).await;
        assert_eq!(code, -32603);
        assert!(msg.to_lowercase().contains("funds"));
    }
}

#[derive(Clone, Deserialize, Serialize, Debug, PartialEq, Eq)]
#[serde(rename_all = "camelCase")]
pub struct SyncingStruct {
    pub starting_block: u64,
    pub current_block: u64,
    pub highest_block: u64,
}

#[derive(Clone, Serialize, Deserialize, Debug, PartialEq, Eq)]
#[serde(untagged)]
pub enum SyncingResult {
    Bool(bool),
    Struct(SyncingStruct),
}

#[zilliqa_macros::test]
async fn test_eth_syncing(mut network: Network) {
    let client = network.rpc_client(0).await.unwrap();
    let wallet = network.random_wallet().await;
    network.run_until_block(&wallet, 3.into(), 70).await;

    let result = client
        .request_optional::<(), SyncingResult>("eth_syncing", None)
        .await
        .unwrap();
    assert_eq!(result, SyncingResult::Bool(false))
}

#[zilliqa_macros::test]
async fn get_block_receipts(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let provider = wallet.provider();

    // Deploy a contract to generate a transaction
    let (hash1, _) = deploy_contract(
        "tests/it/contracts/EmitEvents.sol",
        "EmitEvents",
        0u128,
        &wallet,
        &mut network,
    )
    .await;

    let receipt1 = network.run_until_receipt(&wallet, hash1, 50).await;
    let block_hash = receipt1.block_hash.unwrap();

    // Get receipts by block hash
    let receipts: Vec<TransactionReceipt> = provider
        .request("eth_getBlockReceipts", [block_hash])
        .await
        .unwrap();

    assert_eq!(receipts.len(), 1);
    assert!(receipts.iter().any(|r| r.transaction_hash == hash1));

    // Verify receipts match individual receipt queries
    let individual1 = provider
        .get_transaction_receipt(hash1)
        .await
        .unwrap()
        .unwrap();

    assert!(receipts.contains(&individual1));
}

#[zilliqa_macros::test]
async fn test_block_filter(mut network: Network) {
    println!("Starting block filter test");
    let wallet = network.random_wallet().await;
    let provider = wallet.provider();

    // Create a new block filter
    println!("Creating new block filter");
    let filter_id: u128 = provider.request("eth_newBlockFilter", ()).await.unwrap();
    println!("Created filter with ID: {}", filter_id);

    // Generate some blocks
    println!("Generating blocks");
    network.run_until_block(&wallet, 3.into(), 50).await;
    println!("Generated blocks");

    // Get filter changes - should return the new block hashes
    println!("Getting filter changes");
    let changes_result: serde_json::Value = provider
        .request("eth_getFilterChanges", [filter_id])
        .await
        .unwrap();
    let changes: Vec<H256> = serde_json::from_value(changes_result).unwrap();
    println!("Got {} changes", changes.len());

    // We should have at least 2 new blocks (not counting the block at which we created the filter)
    assert!(!changes.is_empty());
    assert!(changes.len() >= 2);

    // Changes should be valid block hashes
    println!("Verifying block hashes");
    for hash in &changes {
        println!("Checking block hash: {}", hash);
        let block = provider
            .get_block(BlockId::Hash(*hash))
            .await
            .unwrap()
            .unwrap();
        block.number.unwrap();
    }

    // Calling get_filter_changes again should return empty as we've already retrieved the changes
    println!("Getting filter changes second time");
    let changes_result: serde_json::Value = provider
        .request("eth_getFilterChanges", [filter_id])
        .await
        .unwrap();
    let changes: Vec<H256> = serde_json::from_value(changes_result).unwrap();
    println!("Got {} changes on second call", changes.len());
    dbg!(&changes);
    assert!(changes.is_empty());

    println!("Removing filter");
    let filter_removed_successfully: bool = provider
        .request("eth_uninstallFilter", [filter_id])
        .await
        .unwrap();
    println!("Filter removed: {}", filter_removed_successfully);
    assert!(filter_removed_successfully);
}

#[zilliqa_macros::test]
async fn test_pending_transaction_filter(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let provider = wallet.provider();

    // Create a new pending transaction filter
    println!("Creating new pending transaction filter");
    let filter_id: u128 = provider
        .request("eth_newPendingTransactionFilter", ())
        .await
        .unwrap();
    println!("Created filter with ID: {}", filter_id);

    // Send a transaction.
    let hash = wallet
        .send_transaction(TransactionRequest::pay(H160::random(), 10), None)
        .await
        .unwrap()
        .tx_hash();

    // Get filter changes - should return the pending transaction hashes
    println!("Getting filter changes");
    let changes_result: serde_json::Value = provider
        .request("eth_getFilterChanges", [filter_id])
        .await
        .unwrap();
    let changes: Vec<H256> = serde_json::from_value(changes_result).unwrap();
    println!("Got {} changes", changes.len());

    assert!(changes.contains(&hash));

    // Calling get_filter_changes again should return empty
    println!("Getting filter changes second time");
    let changes_result: serde_json::Value = provider
        .request("eth_getFilterChanges", [filter_id])
        .await
        .unwrap();
    let changes: Vec<H256> = serde_json::from_value(changes_result).unwrap();
    println!("Got {} changes on second call", changes.len());
    assert!(changes.is_empty());
}

#[zilliqa_macros::test]
async fn test_log_filter(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let provider = wallet.provider();

    let (hash, contract) = deploy_contract(
        "tests/it/contracts/EmitEvents.sol",
        "EmitEvents",
        0u128,
        &wallet,
        &mut network,
    )
    .await;

    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();
    let contract_address = receipt.contract_address.unwrap();

    // Create a filter for contract events
    println!("Creating event filter");
    let filter = json!({
        "fromBlock": "latest",
        "address": contract_address,
    });
    let filter_id: u128 = provider.request("eth_newFilter", [filter]).await.unwrap();
    println!("Created filter with ID: {}", filter_id);

    let emit_events = contract.function("emitEvents").unwrap();
    let call_tx = TransactionRequest::new()
        .to(contract_address)
        .data(emit_events.encode_input(&[]).unwrap());

    let call_tx_hash = wallet
        .send_transaction(call_tx, None)
        .await
        .unwrap()
        .tx_hash();
    network.run_until_receipt(&wallet, call_tx_hash, 50).await;

    // Get filter changes
    println!("Getting filter changes");
    let logs_result: serde_json::Value = provider
        .request("eth_getFilterChanges", [filter_id])
        .await
        .unwrap();
    dbg!(&logs_result);
    let logs: Vec<serde_json::Value> = serde_json::from_value(logs_result).unwrap();
    println!("Got {} logs", logs.len());

    assert_eq!(logs.len(), 2);

    // Test get_filter_logs
    println!("Testing get_filter_logs");
    let logs_via_get_result: serde_json::Value = provider
        .request("eth_getFilterLogs", [filter_id])
        .await
        .unwrap();
    let logs_via_get: Vec<serde_json::Value> = serde_json::from_value(logs_via_get_result).unwrap();
    assert_eq!(logs, logs_via_get);

    // Calling get_filter_changes again should return empty
    println!("Getting filter changes second time");
    let changes_result: serde_json::Value = provider
        .request("eth_getFilterChanges", [filter_id])
        .await
        .unwrap();
    let changes: Vec<serde_json::Value> = serde_json::from_value(changes_result).unwrap();
    println!("Got {} changes on second call", changes.len());
    assert!(changes.is_empty());

    println!("Removing filter");
    let filter_removed_successfully: bool = provider
        .request("eth_uninstallFilter", [filter_id])
        .await
        .unwrap();
    println!("Filter removed: {}", filter_removed_successfully);
    assert!(filter_removed_successfully);
}

#[zilliqa_macros::test]
async fn test_invalid_filter_id(mut network: Network) {
    println!("Starting invalid filter ID test");
    let wallet = network.random_wallet().await;
    let provider = wallet.provider();

    // Try to get changes for non-existent filter
    println!("Attempting to get changes for invalid filter ID");
    let result = provider
        .request::<_, Value>("eth_getFilterChanges", ["0x123"])
        .await;
    assert!(result.is_err());
}

#[zilliqa_macros::test]
async fn test_uninstall_filter(mut network: Network) {
    println!("Starting uninstall filter test");
    let wallet = network.random_wallet().await;
    let provider = wallet.provider();

    // Create a new filter
    println!("Creating new block filter");
    let filter_id: u128 = provider.request("eth_newBlockFilter", ()).await.unwrap();
    println!("Created filter with ID: {}", filter_id);

    // Verify filter exists by using it
    println!("Verifying filter exists");
    let _changes: Vec<H256> = provider
        .request("eth_getFilterChanges", [filter_id])
        .await
        .unwrap();
    println!("Filter verified");

    // Successfully uninstall the filter
    println!("Uninstalling filter");
    let filter_removed: bool = provider
        .request("eth_uninstallFilter", [filter_id])
        .await
        .unwrap();
    println!("Filter removed: {}", filter_removed);
    assert!(filter_removed);

    // Verify filter no longer exists
    println!("Verifying filter no longer exists");
    let result = provider
        .request::<_, Value>("eth_getFilterChanges", [filter_id])
        .await;
    assert!(result.is_err());
}

#[zilliqa_macros::test]
async fn get_block_by_number(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let provider = wallet.provider();

    // Make sure there's at least one block to retrieve
    network.run_until_block(&wallet, 2u64.into(), 50).await;

    // Get the latest block number
    let latest_number = provider.get_block_number().await.unwrap();

    // Query eth_getBlockByNumber with 'latest', full transactions requested
    let block = provider
        .request::<_, serde_json::Value>("eth_getBlockByNumber", (latest_number, true))
        .await
        .unwrap();

    // Some block fields should always be present
    assert_eq!(
        block["number"],
        serde_json::json!(format!("0x{:x}", latest_number.as_u64()))
    );
    assert!(block["hash"].as_str().unwrap().starts_with("0x"));
    assert!(block["parentHash"].as_str().unwrap().starts_with("0x"));
    assert_eq!(block["uncles"], serde_json::json!([])); // No uncles in ZQ2

    // Specific required fields
    // difficulty: 0x0
    assert_eq!(block["difficulty"], serde_json::json!("0x0"));

    // sha3Uncles: RLP( [] ), 0x1dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d49347
    assert_eq!(
        block["sha3Uncles"],
        serde_json::json!("0x1dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d49347")
    );

    // miner is a proper address, not "None"
    let miner = block["miner"].as_str().unwrap();
    assert!(
        miner.starts_with("0x") && miner.len() == 42,
        "Miner field is not a 20-byte address: {miner}"
    );

    // Some other typical fields
    assert!(block["transactions"].is_array());

    // Block gasLimit/gasUsed, timestamp, size are all nonzero/zero
    assert!(block["gasLimit"].as_str().unwrap().starts_with("0x"));
    assert!(block["gasUsed"].as_str().unwrap().starts_with("0x"));
    assert!(block["timestamp"].as_str().unwrap().starts_with("0x"));
    assert!(u64::from_str_radix(&block["size"].as_str().unwrap()[2..], 16).unwrap() > 0);
}

```

`zilliqa/tests/it/main.rs`:

```rs
use alloy::primitives::Address;
use ethabi::Token;
use ethers::{
    abi::Tokenize,
    providers::{Middleware, PubsubClient},
    types::TransactionRequest,
};
use parking_lot::{RwLock, RwLockWriteGuard};
use primitive_types::{H160, U256};
use serde_json::{Value, value::RawValue};
use zilliqa::{
    cfg::new_view_broadcast_interval_default, contracts, crypto::NodePublicKey,
    state::contract_addr,
};
mod admin;
mod consensus;
mod debug;
mod eth;
mod ots;
mod persistence;
mod staking;
mod sync;
mod trace;
mod txpool;
mod unreliable;
mod web3;
mod zil;

use std::{
    collections::{HashMap, HashSet},
    env,
    fmt::Debug,
    fs::{self},
    ops::DerefMut,
    path::Path,
    pin::Pin,
    rc::Rc,
    sync::{
        Arc, Mutex,
        atomic::{AtomicPtr, AtomicU64, AtomicUsize, Ordering},
    },
    time::Duration,
};

use anyhow::{Result, anyhow};
use async_trait::async_trait;
use ethers::{
    abi::Contract,
    prelude::{DeploymentTxFactory, SignerMiddleware},
    providers::{HttpClientError, JsonRpcClient, JsonRpcError, Provider},
    signers::LocalWallet,
    types::{Bytes, H256, TransactionReceipt, U64},
    utils::{get_contract_address, secret_key_to_address},
};
use foundry_compilers::{
    artifacts::{EvmVersion, SolcInput, Source},
    solc::{Solc, SolcLanguage},
};
use fs_extra::dir::*;
use futures::{Future, FutureExt, Stream, StreamExt, stream::BoxStream};
use itertools::Itertools;
use jsonrpsee::{
    RpcModule,
    types::{Id, Notification, RequestSer, Response, ResponsePayload},
};
use k256::ecdsa::SigningKey;
use libp2p::PeerId;
use rand::{Rng, seq::SliceRandom};
use rand_chacha::ChaCha8Rng;
use serde::{Serialize, de::DeserializeOwned};
use tempfile::TempDir;
use tokio::sync::mpsc::{self, UnboundedSender};
use tokio_stream::wrappers::{ReceiverStream, UnboundedReceiverStream};
use tracing::*;
use zilliqa::{
    api,
    cfg::{
        Amount, ApiServer, Checkpoint, ConsensusConfig, ContractUpgradeConfig, ContractUpgrades,
        Fork, GenesisDeposit, NodeConfig, SyncConfig, allowed_timestamp_skew_default,
        block_request_batch_size_default, block_request_limit_default, consensus_timeout_default,
        eth_chain_id_default, failed_request_sleep_duration_default, genesis_fork_default,
        max_blocks_in_flight_default, max_rpc_response_size_default, scilla_ext_libs_path_default,
        state_cache_size_default, state_rpc_limit_default, total_native_token_supply_default,
        u64_max,
    },
    crypto::{SecretKey, TransactionPublicKey},
    db,
    message::{ExternalMessage, InternalMessage},
    node::{Node, RequestId},
    node_launcher::ResponseChannel,
    sync::SyncPeers,
    transaction::EvmGas,
};

/// Helper struct for network.add_node()
#[derive(Default)]
pub struct NewNodeOptions {
    secret_key: Option<SecretKey>,
    onchain_key: Option<SigningKey>,
    checkpoint: Option<Checkpoint>,
    prune_interval: Option<u64>,
    base_height: Option<u64>,
}

impl NewNodeOptions {
    fn secret_key_or_random(&self, rng: Arc<Mutex<ChaCha8Rng>>) -> SecretKey {
        self.secret_key
            .unwrap_or_else(|| SecretKey::new_from_rng(rng.lock().unwrap().deref_mut()).unwrap())
    }

    fn onchain_key_or_random(&self, rng: Arc<Mutex<ChaCha8Rng>>) -> SigningKey {
        self.onchain_key
            .clone()
            .unwrap_or_else(|| k256::ecdsa::SigningKey::random(rng.lock().unwrap().deref_mut()))
    }
}

/// (source, destination, message) for both
#[derive(Debug, Clone)]
#[allow(clippy::large_enum_variant)]
enum AnyMessage {
    External(ExternalMessage),
    Internal(u64, u64, InternalMessage),
    Response {
        channel: ResponseChannel,
        message: ExternalMessage,
    },
}

type Wallet = SignerMiddleware<Provider<LocalRpcClient>, LocalWallet>;

type StreamMessage = (PeerId, Option<(PeerId, RequestId)>, AnyMessage);

// allowing it because the Result gets unboxed immediately anyway, significantly simplifying the
// type
#[allow(clippy::type_complexity)]
fn node(
    config: NodeConfig,
    secret_key: SecretKey,
    onchain_key: SigningKey,
    index: usize,
    datadir: Option<TempDir>,
) -> Result<(
    TestNode,
    BoxStream<'static, StreamMessage>,
    BoxStream<'static, StreamMessage>,
    BoxStream<'static, StreamMessage>,
)> {
    let (message_sender, message_receiver) = mpsc::unbounded_channel();
    let message_receiver = UnboundedReceiverStream::new(message_receiver);
    // Augment the `message_receiver` stream to include the sender's `PeerId`.
    let peer_id = secret_key.to_libp2p_keypair().public().to_peer_id();
    let message_receiver = message_receiver
        .map(move |(dest, _, message)| (peer_id, dest, AnyMessage::External(message)))
        .boxed();

    let (local_message_sender, local_message_receiver) = mpsc::unbounded_channel();
    let local_message_receiver = UnboundedReceiverStream::new(local_message_receiver);
    // Augment the `message_receiver` stream to include the sender and receiver's `PeerId`.
    let local_message_receiver = local_message_receiver
        .map(move |(src, dest, message)| {
            (
                peer_id,
                Some((peer_id, RequestId::default())),
                AnyMessage::Internal(src, dest, message),
            )
        })
        .boxed();

    let (request_responses_sender, request_responses_receiver) = mpsc::unbounded_channel();
    let request_responses_receiver =
        UnboundedReceiverStream::new(request_responses_receiver).boxed();
    let request_responses_receiver = request_responses_receiver
        // A bit of a hack here - We keep the destination of responses as `None` for now (as if they were a broadcast)
        // and look up the destination via the channel later.
        .map(move |(channel, message)| (peer_id, None, AnyMessage::Response { channel, message }))
        .boxed();

    let (reset_timeout_sender, reset_timeout_receiver) = mpsc::unbounded_channel();
    std::mem::forget(reset_timeout_receiver);

    let peer_id = secret_key.to_libp2p_keypair().public().to_peer_id();
    let sync_peers = Arc::new(SyncPeers::new(peer_id));
    let swarm_peers = Arc::new(AtomicPtr::new(Box::into_raw(Box::new(Vec::new()))));

    let node = Node::new(
        NodeConfig {
            data_dir: datadir
                .as_ref()
                .map(|d| d.path().to_str().unwrap().to_string()),
            ..config
        },
        secret_key,
        message_sender,
        local_message_sender,
        request_responses_sender,
        reset_timeout_sender,
        Arc::new(AtomicUsize::new(0)),
        sync_peers.clone(),
        swarm_peers,
    )?;
    let node = Arc::new(RwLock::new(node));
    let rpc_module = api::rpc_module(node.clone(), &api::all_enabled());

    Ok((
        TestNode {
            index,
            peer_id,
            secret_key,
            onchain_key,
            inner: node,
            dir: datadir,
            rpc_module,
            peers: sync_peers,
        },
        message_receiver,
        local_message_receiver,
        request_responses_receiver,
    ))
}

/// A node within a test [Network].
struct TestNode {
    index: usize,
    secret_key: SecretKey,
    onchain_key: SigningKey,
    peer_id: PeerId,
    rpc_module: RpcModule<Arc<RwLock<Node>>>,
    inner: Arc<RwLock<Node>>,
    dir: Option<TempDir>,
    peers: Arc<SyncPeers>,
}

struct Network {
    pub genesis_deposits: Vec<GenesisDeposit>,
    /// Child shards.
    pub children: HashMap<u64, Network>,
    pub shard_id: u64,
    // We keep `nodes` and `receivers` separate so we can independently borrow each half of this struct, while keeping
    // the borrow checker happy.
    nodes: Vec<TestNode>,
    // We keep track of a list of disconnected nodes. These nodes will not recieve any messages until they are removed
    // from this list.
    disconnected: HashSet<usize>,
    /// A stream of messages from each node. The stream items are a tuple of (source, destination, message).
    /// If the destination is `None`, the message is a broadcast.
    receivers: Vec<BoxStream<'static, StreamMessage>>,
    /// When we send a request to a node, we also send it a [ResponseChannel]. The node sends a response to that
    /// request by passing the [ResponseChannel] back to us. This map lets us remember who to send that response to,
    /// based on who the initial request was from.
    pending_responses: HashMap<ResponseChannel, PeerId>,
    /// Counter for the next unassigned response channel ID. Starts at 0 and increments with each request.
    response_channel_id: u64,
    resend_message: UnboundedSender<StreamMessage>,
    send_to_parent: Option<UnboundedSender<StreamMessage>>,
    rng: Arc<Mutex<ChaCha8Rng>>,
    /// The seed input for the node - because rng.get_seed() returns a different, internal
    /// representation
    seed: u64,
    pub genesis_key: SigningKey,
    scilla_address: String,
    scilla_stdlib_dir: String,
    do_checkpoints: bool,
    blocks_per_epoch: u64,
    deposit_v3_upgrade_block_height: Option<u64>,
    scilla_server_socket_directory: String,
}

impl Network {
    // This is only used in the zilliqa_macros::test macro. Consider refactoring this to a builder
    // or removing entirely (and calling new_shard there)?
    /// Create a main shard network with reasonable defaults.
    #[allow(clippy::too_many_arguments)]
    pub fn new(
        rng: Arc<Mutex<ChaCha8Rng>>,
        nodes: usize,
        seed: u64,
        scilla_address: String,
        scilla_stdlib_dir: String,
        do_checkpoints: bool,
        blocks_per_epoch: u64,
        deposit_v3_upgrade_block_height: Option<u64>,
        scilla_server_socket_directory: String,
    ) -> Network {
        Self::new_shard(
            rng,
            nodes,
            None,
            eth_chain_id_default(),
            seed,
            None,
            scilla_address,
            scilla_stdlib_dir,
            do_checkpoints,
            blocks_per_epoch,
            deposit_v3_upgrade_block_height,
            scilla_server_socket_directory,
        )
    }

    #[allow(clippy::too_many_arguments)]
    pub fn new_shard(
        rng: Arc<Mutex<ChaCha8Rng>>,
        nodes: usize,
        send_to_parent: Option<UnboundedSender<StreamMessage>>,
        shard_id: u64,
        seed: u64,
        keys: Option<Vec<SecretKey>>,
        scilla_address: String,
        scilla_stdlib_dir: String,
        do_checkpoints: bool,
        blocks_per_epoch: u64,
        deposit_v3_upgrade_block_height: Option<u64>,
        scilla_server_socket_directory: String,
    ) -> Network {
        let mut signing_keys = keys.unwrap_or_else(|| {
            (0..nodes)
                .map(|_| SecretKey::new_from_rng(rng.lock().unwrap().deref_mut()).unwrap())
                .collect()
        });
        // Sort the keys in the same order as they will occur in the consensus committee. This means node indices line
        // up with indices in the committee, making logs easier to read.
        signing_keys.sort_unstable_by_key(|key| key.to_libp2p_keypair().public().to_peer_id());

        let onchain_keys: Vec<_> = (0..nodes)
            .map(|_| k256::ecdsa::SigningKey::random(rng.lock().unwrap().deref_mut()))
            .collect();

        let keys: Vec<(_, _)> = signing_keys.into_iter().zip(onchain_keys).collect();

        let genesis_key = SigningKey::random(rng.lock().unwrap().deref_mut());

        // The initial stake of each node.
        let stake = 32_000_000_000_000_000_000u128;
        let genesis_deposits: Vec<_> = keys
            .iter()
            .map(|k| GenesisDeposit {
                public_key: k.0.node_public_key(),
                peer_id: k.0.to_libp2p_keypair().public().to_peer_id(),
                stake: stake.into(),
                reward_address: TransactionPublicKey::Ecdsa(*k.1.verifying_key(), true).into_addr(),
                control_address: TransactionPublicKey::Ecdsa(*k.1.verifying_key(), true)
                    .into_addr(),
            })
            .collect();

        let contract_upgrades = {
            if let Some(deposit_v3_upgrade_block_height_value) = deposit_v3_upgrade_block_height {
                ContractUpgrades::new(
                    Some(ContractUpgradeConfig::from_height(
                        deposit_v3_upgrade_block_height_value,
                    )),
                    None,
                    None,
                )
            } else {
                ContractUpgrades::new(None, None, None)
            }
        };

        let config = NodeConfig {
            eth_chain_id: shard_id,
            consensus: ConsensusConfig {
                genesis_deposits: genesis_deposits.clone(),
                is_main: send_to_parent.is_none(),
                consensus_timeout: consensus_timeout_default(),
                // Give a genesis account 1 billion ZIL.
                genesis_accounts: Self::genesis_accounts(&genesis_key),
                block_time: Duration::from_millis(25),
                scilla_address: scilla_address.clone(),
                scilla_stdlib_dir: scilla_stdlib_dir.clone(),
                scilla_ext_libs_path: scilla_ext_libs_path_default(),
                scilla_server_socket_directory: scilla_server_socket_directory.clone(),
                rewards_per_hour: 204_000_000_000_000_000_000_000u128.into(),
                blocks_per_hour: 3600 * 40,
                minimum_stake: 32_000_000_000_000_000_000u128.into(),
                eth_block_gas_limit: EvmGas(84000000),
                gas_price: 4_761_904_800_000u128.into(),
                main_shard_id: None,
                blocks_per_epoch,
                epochs_per_checkpoint: 1,
                total_native_token_supply: total_native_token_supply_default(),
                contract_upgrades,
                forks: vec![],
                genesis_fork: Fork {
                    scilla_call_gas_exempt_addrs: vec![
                        // Allow the *third* contract deployed by the genesis key to call `scilla_call` for free.
                        Address::new(
                            get_contract_address(secret_key_to_address(&genesis_key).0, 2).0,
                        ),
                    ],
                    ..genesis_fork_default()
                },
                new_view_broadcast_interval: new_view_broadcast_interval_default(),
            },
            api_servers: vec![ApiServer {
                port: 4201,
                enabled_apis: api::all_enabled(),
            }],
            allowed_timestamp_skew: allowed_timestamp_skew_default(),
            data_dir: None,
            state_cache_size: state_cache_size_default(),
            load_checkpoint: None,
            do_checkpoints,
            block_request_limit: block_request_limit_default(),
            sync: SyncConfig {
                max_blocks_in_flight: max_blocks_in_flight_default(),
                block_request_batch_size: block_request_batch_size_default(),
                prune_interval: u64_max(),
                base_height: u64_max(),
                ignore_passive: false,
            },
            state_rpc_limit: state_rpc_limit_default(),
            failed_request_sleep_duration: failed_request_sleep_duration_default(),
            enable_ots_indices: true,
            max_rpc_response_size: max_rpc_response_size_default(),
        };

        let (nodes, external_receivers, local_receivers, request_response_receivers): (
            Vec<_>,
            Vec<_>,
            Vec<_>,
            Vec<_>,
        ) = keys
            .into_iter()
            .enumerate()
            .map(|(i, key)| {
                node(
                    config.clone(),
                    key.0,
                    key.1,
                    i,
                    Some(tempfile::tempdir().unwrap()),
                )
                .unwrap()
            })
            .multiunzip();

        let mut receivers: Vec<_> = external_receivers
            .into_iter()
            .chain(local_receivers)
            .chain(request_response_receivers)
            .collect();

        let (resend_message, receive_resend_message) = mpsc::unbounded_channel::<StreamMessage>();
        let receive_resend_message = UnboundedReceiverStream::new(receive_resend_message).boxed();
        receivers.push(receive_resend_message);

        let mut peers = nodes.iter().map(|n| n.peer_id).collect_vec();
        peers.shuffle(rng.lock().unwrap().deref_mut());

        for node in &nodes {
            trace!(
                "Node {}: {} (dir: {})",
                node.index,
                node.peer_id,
                node.dir.as_ref().unwrap().path().to_string_lossy(),
            );
            node.peers.add_peers(peers.clone());
        }

        Network {
            genesis_deposits,
            nodes,
            disconnected: HashSet::new(),
            send_to_parent,
            shard_id,
            receivers,
            pending_responses: HashMap::new(),
            response_channel_id: 0,
            resend_message,
            rng,
            seed,
            children: HashMap::new(),
            genesis_key,
            scilla_address,
            do_checkpoints,
            blocks_per_epoch,
            scilla_stdlib_dir,
            deposit_v3_upgrade_block_height,
            scilla_server_socket_directory,
        }
    }

    fn genesis_accounts(genesis_key: &SigningKey) -> Vec<(Address, Amount)> {
        vec![(
            Address::new(secret_key_to_address(genesis_key).0),
            1_000_000_000u128
                .checked_mul(10u128.pow(18))
                .unwrap()
                .into(),
        )]
    }

    pub fn is_main(&self) -> bool {
        self.send_to_parent.is_none()
    }

    pub fn add_node(&mut self) -> usize {
        self.add_node_with_options(Default::default())
    }

    pub fn add_node_with_options(&mut self, options: NewNodeOptions) -> usize {
        let contract_upgrades = if self.deposit_v3_upgrade_block_height.is_some() {
            ContractUpgrades::new(
                Some(ContractUpgradeConfig::from_height(
                    self.deposit_v3_upgrade_block_height.unwrap(),
                )),
                None,
                None,
            )
        } else {
            ContractUpgrades::new(None, None, None)
        };
        let config = NodeConfig {
            eth_chain_id: self.shard_id,
            api_servers: vec![ApiServer {
                port: 4201,
                enabled_apis: api::all_enabled(),
            }],
            allowed_timestamp_skew: allowed_timestamp_skew_default(),
            data_dir: None,
            state_cache_size: state_cache_size_default(),
            load_checkpoint: options.checkpoint.clone(),
            do_checkpoints: self.do_checkpoints,
            consensus: ConsensusConfig {
                genesis_deposits: self.genesis_deposits.clone(),
                is_main: self.is_main(),
                consensus_timeout: consensus_timeout_default(),
                genesis_accounts: Self::genesis_accounts(&self.genesis_key),
                block_time: Duration::from_millis(25),
                scilla_server_socket_directory: self.scilla_server_socket_directory.clone(),
                rewards_per_hour: 204_000_000_000_000_000_000_000u128.into(),
                blocks_per_hour: 3600 * 40,
                minimum_stake: 32_000_000_000_000_000_000u128.into(),
                eth_block_gas_limit: EvmGas(84000000),
                gas_price: 4_761_904_800_000u128.into(),
                main_shard_id: None,
                scilla_address: self.scilla_address.clone(),
                blocks_per_epoch: self.blocks_per_epoch,
                epochs_per_checkpoint: 1,
                scilla_stdlib_dir: self.scilla_stdlib_dir.clone(),
                scilla_ext_libs_path: scilla_ext_libs_path_default(),
                total_native_token_supply: total_native_token_supply_default(),
                contract_upgrades,
                forks: vec![],
                genesis_fork: Fork {
                    scilla_call_gas_exempt_addrs: vec![
                        // Allow the *third* contract deployed by the genesis key to call `scilla_call` for free.
                        Address::new(
                            get_contract_address(secret_key_to_address(&self.genesis_key).0, 2).0,
                        ),
                    ],
                    ..genesis_fork_default()
                },
                new_view_broadcast_interval: new_view_broadcast_interval_default(),
            },
            block_request_limit: block_request_limit_default(),
            sync: SyncConfig {
                max_blocks_in_flight: max_blocks_in_flight_default(),
                block_request_batch_size: block_request_batch_size_default(),
                prune_interval: options.prune_interval.unwrap_or(u64_max()),
                base_height: options.base_height.unwrap_or(u64_max()),
                ignore_passive: false,
            },
            state_rpc_limit: state_rpc_limit_default(),
            failed_request_sleep_duration: failed_request_sleep_duration_default(),
            enable_ots_indices: true,
            max_rpc_response_size: max_rpc_response_size_default(),
        };

        let secret_key = options.secret_key_or_random(self.rng.clone());
        let onchain_key = options.onchain_key_or_random(self.rng.clone());
        let (node, receiver, local_receiver, request_responses) =
            node(config, secret_key, onchain_key, self.nodes.len(), None).unwrap();

        let mut peers = self.nodes.iter().map(|n| n.peer_id).collect_vec();
        peers.shuffle(self.rng.lock().unwrap().deref_mut());
        node.peers.add_peers(peers.clone());

        trace!("Node {}: {}", node.index, node.peer_id);

        let index = node.index;

        self.nodes.push(node);
        self.receivers.push(receiver);
        self.receivers.push(local_receiver);
        self.receivers.push(request_responses);

        index
    }

    pub fn restart(&mut self) {
        // We copy the data dirs from the original network, and re-use the same private keys.

        // Note: the tempdir object has to be held in the vector or the OS
        // will delete it when it goes out of scope.
        let mut options = CopyOptions::new();
        options.copy_inside = true;

        // Collect the keys from the validators
        let keys = self
            .nodes
            .iter()
            .map(|n| (n.secret_key, n.onchain_key.clone()))
            .collect::<Vec<_>>();

        let (nodes, external_receivers, local_receivers, request_response_receivers): (
            Vec<_>,
            Vec<_>,
            Vec<_>,
            Vec<_>,
        ) = keys
            .into_iter()
            .enumerate()
            .map(|(i, key)| {
                // Copy the persistence over
                let new_data_dir = tempfile::tempdir().unwrap();

                info!("Copying data dir over");

                if let Ok(mut entry) = fs::read_dir(self.nodes[i].dir.as_ref().unwrap().path()) {
                    let entry = entry.next().unwrap().unwrap();
                    info!("Copying {:?} to {:?}", entry, new_data_dir);

                    copy(entry.path(), new_data_dir.path(), &options).unwrap();
                } else {
                    warn!("Failed to copy data dir over");
                }

                let config = self.nodes[i].inner.read().config.clone();

                node(config, key.0, key.1, i, Some(new_data_dir)).unwrap()
            })
            .multiunzip();

        let mut receivers: Vec<_> = external_receivers
            .into_iter()
            .chain(local_receivers)
            .chain(request_response_receivers)
            .collect();

        let mut peers = nodes.iter().map(|n| n.peer_id).collect_vec();
        peers.shuffle(self.rng.lock().unwrap().deref_mut());

        for node in &nodes {
            trace!(
                "Node {}: {} (dir: {})",
                node.index,
                node.peer_id,
                node.dir.as_ref().unwrap().path().to_string_lossy(),
            );
            node.peers.add_peers(peers.clone());
        }

        let (resend_message, receive_resend_message) = mpsc::unbounded_channel::<StreamMessage>();
        let receive_resend_message = UnboundedReceiverStream::new(receive_resend_message).boxed();
        receivers.push(receive_resend_message);

        self.nodes = nodes;
        self.receivers = receivers;
        self.resend_message = resend_message;

        // Now trigger a timeout in all of the nodes until we see network activity again
        // this could of course spin forever, but the test itself should time out.
        loop {
            for node in &self.nodes {
                node.inner
                    .write()
                    .process_transactions_to_broadcast()
                    .unwrap();
                // Trigger a tick so that block fetching can operate.
                if node.inner.write().handle_timeout().unwrap() {
                    return;
                }
                zilliqa::time::advance(Duration::from_millis(500));
            }
        }
    }

    fn collect_messages(&mut self) -> Vec<StreamMessage> {
        let mut messages = vec![];

        // Poll the receiver with `unconstrained` to ensure it won't be pre-empted. This makes sure we always
        // get an item if it has been sent. It does not lead to starvation, because we evaluate the returned
        // future with `.now_or_never()` which instantly returns `None` if the future is not ready.
        for receiver in self.receivers.iter_mut() {
            loop {
                match tokio::task::unconstrained(receiver.next()).now_or_never() {
                    Some(Some(message)) => {
                        messages.push(message);
                    }
                    Some(None) => {
                        warn!("Stream was unreachable!");
                        unreachable!("stream was terminated, this should be impossible");
                    }
                    None => {
                        break;
                    }
                }
            }
        }
        messages
    }

    // Take all the currently ready messages from the stream,
    // remove N-1 propose messages we see where network size = N and the remaining one is
    // the first node in the vector
    // *** Only perform this when the propose message contains one or more txs.
    pub async fn drop_propose_messages_except_one(&mut self) {
        let mut counter = 0;
        let mut proposals_seen = 0;
        let mut broadcast_handled = false;

        trace!("Dropping propose messages except one");

        loop {
            // Generate some messages
            self.tick().await;

            counter += 1;

            if counter >= 100 {
                panic!("Possibly looping forever looking for propose messages.");
            }

            let mut messages = self.collect_messages();

            if messages.is_empty() {
                warn!("Messages were empty - advance time faster!");
                zilliqa::time::advance(Duration::from_millis(50));
                continue;
            }

            // filter out all the propose messages, except node 0. If the proposal is a broadcast,
            // repackage it as direct messages to all nodes except node 0.
            let mut removed_items = Vec::new();

            // Remove the matching messages
            messages.retain(|(s, d, m)| {
                if let AnyMessage::External(ExternalMessage::Proposal(prop)) = m {
                    if !prop.transactions.is_empty() {
                        removed_items.push((*s, *d, m.clone()));
                        return false;
                    }
                }
                true
            });

            // Handle the removed proposes correctly for both cases of broadcast and single cast
            for (s, d, m) in removed_items {
                // If specifically to a node, only allow node 0
                if let Some((dest, id)) = d {
                    // We actually want to allow this message, put it back into the queue
                    if dest == self.nodes[0].peer_id {
                        messages.push((s, Some((dest, id)), m));
                        continue;
                    }

                    // This counts as it getting dropped
                    proposals_seen += 1;
                } else {
                    // Broadcast seen! Push it back into the queue with specific destination of node 0
                    messages.push((s, Some((self.nodes[0].peer_id, RequestId::default())), m));

                    broadcast_handled = true;
                    break;
                }
            }

            // All but one allowed through, we can now quit
            if proposals_seen == self.nodes.len() - 1 || broadcast_handled {
                // Now process all available messages to make sure the nodes execute them
                trace!(
                    "Processing all remaining messages of len {}",
                    messages.len()
                );

                for message in messages {
                    self.handle_message(message);
                }

                break;
            }

            // Requeue the other messages
            for message in messages {
                self.resend_message.send(message).unwrap();
            }
        }

        trace!("Finished dropping propose messages except one");
    }

    // Drop the first message in each node queue with N% probability per tick
    pub async fn randomly_drop_messages_then_tick(&mut self, failure_rate: f64) {
        if !(0.0..=1.0).contains(&failure_rate) {
            panic!("failure rate is a probability and must be between 0 and 1");
        }

        for receiver in self.receivers.iter_mut() {
            // Peek at the messages in the queue

            let drop = self.rng.lock().unwrap().gen_bool(failure_rate);
            if drop {
                // Don't really care too much what the reciever has, just pop something off if
                // possible
                match tokio::task::unconstrained(receiver.next()).now_or_never() {
                    Some(None) => {
                        unreachable!("stream was terminated, this should be impossible");
                    }
                    Some(Some(message)) => {
                        info!("***** Randomly dropping message: {:?}", message);
                    }
                    _ => {}
                }
            }
        }

        self.tick().await;
    }

    pub async fn tick(&mut self) {
        // Advance time.
        zilliqa::time::advance(Duration::from_millis(1));

        // Take all the currently ready messages from the stream.
        let mut messages = self.collect_messages();

        trace!(
            "{} possible messages to send ({:?})",
            messages.len(),
            messages
                .iter()
                .map(|(s, d, m)| format_message(&self.nodes, *s, *d, m))
                .collect::<Vec<_>>()
        );

        if messages.is_empty() {
            trace!("Messages were empty - advance time and trigger timeout in all nodes!");
            zilliqa::time::advance(Duration::from_millis(1000));

            for (index, node) in self.nodes.iter().enumerate() {
                let span = tracing::span!(tracing::Level::INFO, "handle_timeout", index);

                span.in_scope(|| {
                    node.inner
                        .write()
                        .process_transactions_to_broadcast()
                        .unwrap();
                    node.inner.write().handle_timeout().unwrap();
                });
            }
            return;
        }

        // Immediately handle most InternalMessages:
        //  - any IntershardCall messages to children - forward them (through handle_message) and the child network will handle them
        //  - any LaunchLink messages: just launch the link
        //  - any ExportBlockCheckpoint messages: just run the export
        //  - any LaunchShard messages to the parent - just forward them (through send_to_parent) and the parent network will handle them
        //
        //  Being internal, these messages don't really depend on network conditions or other
        //  nodes, and randomising them would needlessly complicate related tests without being
        //  useful.
        messages.retain(|m| match m.2 {
            AnyMessage::Internal(_, destination, InternalMessage::IntershardCall(_))
                if self.shard_id != destination =>
            {
                self.handle_message(m.clone());
                false
            }
            AnyMessage::Internal(_, _, InternalMessage::LaunchLink(_)) => {
                self.handle_message(m.clone());
                false
            }
            AnyMessage::Internal(_, _, InternalMessage::ExportBlockCheckpoint(..)) => {
                self.handle_message(m.clone());
                false
            }
            AnyMessage::Internal(_, _, InternalMessage::LaunchShard(new_network_id)) => {
                // if-let guards are experimental so we nest the check...
                if let Some(send_to_parent) = self.send_to_parent.as_ref() {
                    trace!("Child network {} got LaunchShard({new_network_id}) message; forwarding to parent to handle", self.shard_id);
                    send_to_parent.send(m.clone()).unwrap();
                    false
                } else {
                    true
                }
            }
            AnyMessage::External(ExternalMessage::InjectedProposal(_)) => {
                self.handle_message(m.clone());
                false
            }
            _ => true,
        });

        // Pick a random message
        if !messages.is_empty() {
            let index = self.rng.lock().unwrap().gen_range(0..messages.len());
            let (source, destination, message) = messages.swap_remove(index);
            // Requeue the other messages
            for message in messages {
                self.resend_message.send(message).unwrap();
            }
            trace!(
                "{}",
                format_message(&self.nodes, source, destination, &message)
            );

            self.handle_message((source, destination, message))
        }
    }

    fn handle_message(&mut self, message: StreamMessage) {
        let (source, destination, ref contents) = message;
        info!(%source, ?destination);
        let sender_node = self
            .nodes
            .iter()
            .find(|&node| node.peer_id == source)
            .expect("Sender should be on the nodes list");
        let sender_chain_id = sender_node.inner.read().config.eth_chain_id;
        match contents {
            AnyMessage::Internal(source_shard, destination_shard, internal_message) => {
                trace!(
                    "Handling internal message from node in shard {source_shard}, targetting {destination_shard}"
                );
                match internal_message {
                    InternalMessage::LaunchShard(new_network_id) => {
                        let secret_key = self.find_node(source).unwrap().1.secret_key;
                        if let Some(child_network) = self.children.get_mut(new_network_id) {
                            if child_network.find_node(source).is_none() {
                                trace!(
                                    "Launching shard node for {new_network_id} - adding new node to shard"
                                );
                                child_network.add_node_with_options(NewNodeOptions {
                                    secret_key: Some(secret_key),
                                    ..Default::default()
                                });
                            } else {
                                trace!(
                                    "Received messaged to launch new node in {new_network_id}, but node {source} already exists in that network"
                                );
                            }
                        } else {
                            info!("Launching node in new shard network {new_network_id}");
                            self.children.insert(
                                *new_network_id,
                                Network::new_shard(
                                    self.rng.clone(),
                                    1,
                                    Some(self.resend_message.clone()),
                                    *new_network_id,
                                    self.seed,
                                    Some(vec![secret_key]),
                                    self.scilla_address.clone(),
                                    self.scilla_stdlib_dir.clone(),
                                    self.do_checkpoints,
                                    self.blocks_per_epoch,
                                    self.deposit_v3_upgrade_block_height,
                                    self.scilla_server_socket_directory.clone(),
                                ),
                            );
                        }
                    }
                    InternalMessage::LaunchLink(_) | InternalMessage::IntershardCall(_) => {
                        if *destination_shard == self.shard_id {
                            let (destination, _) = destination.expect("Local messages are intended to always have the node's own peerid as destination within in the test harness");
                            let idx_node = self.find_node(destination);
                            if let Some((idx, node)) = idx_node {
                                trace!(
                                    "Handling intershard message {:?} from shard {}, in node {} of shard {}",
                                    internal_message, source_shard, idx, self.shard_id
                                );
                                node.inner
                                    .write()
                                    .handle_internal_message(
                                        *source_shard,
                                        internal_message.clone(),
                                    )
                                    .unwrap();
                            } else {
                                warn!(
                                    "Dropping intershard message addressed to node that isn't running that shard!"
                                );
                                trace!(?message);
                            }
                        } else if let Some(network) = self.children.get_mut(destination_shard) {
                            trace!(
                                "Forwarding intershard message from shard {} to subshard {}...",
                                self.shard_id, destination_shard
                            );
                            network.resend_message.send(message).unwrap();
                        } else if let Some(send_to_parent) = self.send_to_parent.as_ref() {
                            trace!(
                                "Found intershard message that matches none of our children, forwarding it to our parent so they may hopefully route it..."
                            );
                            send_to_parent.send(message).unwrap();
                        } else {
                            warn!("Dropping intershard message for shard that does not exist");
                            trace!(?message);
                        }
                    }
                    InternalMessage::ExportBlockCheckpoint(
                        block,
                        transactions,
                        parent,
                        trie_storage,
                        output,
                    ) => {
                        assert!(
                            self.do_checkpoints,
                            "Node requested a checkpoint checkpoint export to {}, despite checkpoints beind disabled in the config",
                            output.to_string_lossy()
                        );
                        trace!("Exporting checkpoint to path {}", output.to_string_lossy());
                        db::checkpoint_block_with_state(
                            block,
                            transactions,
                            parent,
                            trie_storage.clone(),
                            *source_shard,
                            output,
                        )
                        .unwrap();
                    }
                    InternalMessage::SubscribeToGossipSubTopic(topic) => {
                        debug!("subscribing to topic {:?}", topic);
                    }
                    InternalMessage::UnsubscribeFromGossipSubTopic(topic) => {
                        debug!("unsubscribing from topic {:?}", topic);
                    }
                }
            }
            AnyMessage::External(external_message) => {
                info!(%external_message, "external");

                let cbor_size =
                    cbor4ii::serde::to_vec(Vec::with_capacity(1024 * 1024), &external_message)
                        .unwrap()
                        .len();

                match destination {
                    Some((destination, _)) => {
                        assert!(
                            cbor_size < 1024 * 1024,
                            "request overflow {} {:?}",
                            cbor_size,
                            external_message
                        );

                        // Direct message
                        let (index, node) = self
                            .nodes
                            .iter()
                            .enumerate()
                            .find(|(_, n)| n.peer_id == destination)
                            .unwrap();
                        if !self.disconnected.contains(&index) {
                            let span =
                                tracing::span!(tracing::Level::INFO, "handle_message", index);
                            span.in_scope(|| {
                                let mut inner = node.inner.write();
                                // Send to nodes only in the same shard (having same chain_id)
                                if inner.config.eth_chain_id == sender_chain_id {
                                    let response_channel =
                                        ResponseChannel::Remote(self.response_channel_id);
                                    self.response_channel_id += 1;
                                    self.pending_responses
                                        .insert(response_channel.clone(), source);
                                    // Re-route Sync
                                    match external_message {
                                        ExternalMessage::MetaDataRequest(_)
                                        | ExternalMessage::MultiBlockRequest(_)
                                        | ExternalMessage::BlockRequest(_)
                                        | ExternalMessage::PassiveSyncRequest(_) => inner
                                            .handle_broadcast(
                                                source,
                                                external_message.clone(),
                                                response_channel,
                                            )
                                            .unwrap(),
                                        _ => inner
                                            .handle_request(
                                                source,
                                                "(synthetic_id)",
                                                external_message.clone(),
                                                response_channel,
                                            )
                                            .unwrap(),
                                    }
                                }
                            });
                        }
                    }
                    None => {
                        assert!(
                            cbor_size < 1024 * 1024,
                            "broadcast overflow {} {:?}",
                            cbor_size,
                            external_message
                        );

                        // Broadcast
                        for (index, node) in self.nodes.iter().enumerate() {
                            if self.disconnected.contains(&index) {
                                continue;
                            }
                            let span =
                                tracing::span!(tracing::Level::INFO, "handle_message", index);
                            span.in_scope(|| {
                                let mut inner = node.inner.write();
                                // Send to nodes only in the same shard (having same chain_id)
                                if inner.config.eth_chain_id == sender_chain_id {
                                    // Re-route Proposals from Broadcast to Requests
                                    match external_message {
                                        ExternalMessage::Proposal(_) => inner
                                            .handle_request(
                                                source,
                                                "(faux-id)",
                                                external_message.clone(),
                                                ResponseChannel::Local,
                                            )
                                            .unwrap(),
                                        ExternalMessage::BatchedTransactions(transactions) => {
                                            let mut verified = Vec::new();
                                            for tx in transactions {
                                                let tx = tx.clone().verify().unwrap();
                                                verified.push(tx);
                                            }
                                            inner.handle_broadcast_transactions(verified).unwrap();
                                        }
                                        _ => inner
                                            .handle_broadcast(
                                                source,
                                                external_message.clone(),
                                                ResponseChannel::Local,
                                            )
                                            .unwrap(),
                                    }
                                }
                            });
                        }
                    }
                }
            }
            AnyMessage::Response { channel, message } => {
                info!(%message, ?channel, "response");

                let cbor_size =
                    cbor4ii::serde::to_vec(Vec::with_capacity(1024 * 1024 * 10), &message)
                        .unwrap()
                        .len();
                assert!(
                    cbor_size < 1024 * 1024 * 10,
                    "response overflow {} {:?}",
                    cbor_size,
                    message
                );

                // skip on faux response
                if let Some(destination) = self.pending_responses.remove(channel) {
                    let (index, node) = self
                        .nodes
                        .iter()
                        .enumerate()
                        .find(|(_, n)| n.peer_id == destination)
                        .unwrap();
                    if !self.disconnected.contains(&index) {
                        let span = tracing::span!(tracing::Level::INFO, "handle_message", index);
                        span.in_scope(|| {
                            let mut inner = node.inner.write();
                            // Send to nodes only in the same shard (having same chain_id)
                            if inner.config.eth_chain_id == sender_chain_id {
                                inner.handle_response(source, message.clone()).unwrap();
                            }
                        });
                    }
                }
            }
        }
    }

    async fn run_until_synced(&mut self, index: usize) {
        let check = loop {
            let i = self.random_index();
            if i != index && !self.disconnected.contains(&i) {
                break i;
            }
        };
        self.run_until(
            |net| {
                let syncing = net.get_node(index).consensus.sync.am_syncing().unwrap();
                let height_i = net.get_node(index).get_finalized_height().unwrap();
                let height_c = net.get_node(check).get_finalized_height().unwrap();
                height_c == height_i && height_i > 0 && !syncing
            },
            2000,
        )
        .await
        .unwrap();
    }

    async fn run_until(
        &mut self,
        mut condition: impl FnMut(&mut Network) -> bool,
        mut timeout: usize,
    ) -> Result<()> {
        let initial_timeout = timeout;

        while !condition(self) {
            if timeout == 0 {
                return Err(anyhow!(
                    "condition was still false after {initial_timeout} ticks"
                ));
            }
            self.tick().await;
            timeout -= 1;
        }

        Ok(())
    }

    pub async fn run_until_async<Fut: Future<Output = bool>>(
        &mut self,
        mut condition: impl FnMut() -> Fut,
        mut timeout: usize,
    ) -> Result<()> {
        let initial_timeout = timeout;

        while !condition().await {
            if timeout == 0 {
                return Err(anyhow!(
                    "condition was still false after {initial_timeout} ticks"
                ));
            }
            self.tick().await;
            timeout -= 1;
        }

        Ok(())
    }

    pub async fn run_until_receipt(
        &mut self,
        wallet: &Wallet,
        hash: H256,
        timeout: usize,
    ) -> TransactionReceipt {
        self.run_until_async(
            || async {
                wallet
                    .get_transaction_receipt(hash)
                    .await
                    .unwrap()
                    .is_some()
            },
            timeout,
        )
        .await
        .unwrap();
        wallet.get_transaction_receipt(hash).await.unwrap().unwrap()
    }

    pub async fn run_until_block(&mut self, wallet: &Wallet, target_block: U64, timeout: usize) {
        self.run_until_async(
            || async { wallet.get_block_number().await.unwrap() >= target_block },
            timeout,
        )
        .await
        .unwrap();
    }

    pub async fn run_until_block_finalized(
        &mut self,
        target_block: u64,
        mut timeout: usize,
    ) -> Result<()> {
        let initial_timeout = timeout;
        let db = self.get_node(0).db.clone();
        loop {
            if let Some(view) = db.get_finalized_view()? {
                if let Some(block) = db.get_block_by_view(view)? {
                    if block.number() >= target_block {
                        return Ok(());
                    }
                }
            }
            if timeout == 0 {
                return Err(anyhow!(
                    "condition was still false after {initial_timeout} ticks"
                ));
            }
            self.tick().await;
            timeout -= 1;
        }
    }

    pub fn disconnect_node(&mut self, index: usize) {
        self.disconnected.insert(index);
    }

    pub fn connect_node(&mut self, index: usize) {
        self.disconnected.remove(&index);
    }

    pub fn random_index(&mut self) -> usize {
        self.rng.lock().unwrap().gen_range(0..self.nodes.len())
    }

    pub async fn wallet_of_node(
        &mut self,
        index: usize,
    ) -> SignerMiddleware<Provider<LocalRpcClient>, LocalWallet> {
        let key = SigningKey::random(self.rng.lock().unwrap().deref_mut());
        let wallet: LocalWallet = key.into();
        let node = &self.nodes[index];
        let client = LocalRpcClient {
            id: Arc::new(AtomicU64::new(0)),
            rpc_module: node.rpc_module.clone(),
            subscriptions: Arc::new(Mutex::new(HashMap::new())),
        };
        let provider = Provider::new(client);

        SignerMiddleware::new_with_provider_chain(provider, wallet)
            .await
            .unwrap()
    }

    /// Returns (index, TestNode)
    fn find_node(&self, peer_id: PeerId) -> Option<(usize, &TestNode)> {
        self.nodes
            .iter()
            .enumerate()
            .find(|(_, n)| n.peer_id == peer_id)
    }

    pub fn get_node(&self, index: usize) -> RwLockWriteGuard<Node> {
        self.nodes[index].inner.write()
    }

    pub fn get_node_raw(&self, index: usize) -> &TestNode {
        &self.nodes[index]
    }

    pub fn remove_node(&mut self, idx: usize) -> TestNode {
        let _ = self.receivers.remove(idx);
        self.nodes.remove(idx)
    }

    pub fn node_at(&mut self, index: usize) -> RwLockWriteGuard<Node> {
        self.nodes[index].inner.write()
    }

    pub async fn rpc_client(&mut self, index: usize) -> Result<LocalRpcClient> {
        Ok(LocalRpcClient {
            id: Arc::new(AtomicU64::new(0)),
            rpc_module: self.nodes[index].rpc_module.clone(),
            subscriptions: Arc::new(Mutex::new(HashMap::new())),
        })
    }

    pub async fn wallet_from_key(&mut self, key: SigningKey) -> Wallet {
        let wallet: LocalWallet = key.into();
        let node = self
            .nodes
            .choose(self.rng.lock().unwrap().deref_mut())
            .unwrap();
        trace!(index = node.index, "node selected for wallet");
        let client = LocalRpcClient {
            id: Arc::new(AtomicU64::new(0)),
            rpc_module: node.rpc_module.clone(),
            subscriptions: Arc::new(Mutex::new(HashMap::new())),
        };
        let provider = Provider::new(client);

        SignerMiddleware::new_with_provider_chain(provider, wallet)
            .await
            .unwrap()
    }

    pub async fn genesis_wallet(&mut self) -> Wallet {
        self.wallet_from_key(self.genesis_key.clone()).await
    }

    pub async fn random_wallet(&mut self) -> Wallet {
        let key = SigningKey::random(self.rng.lock().unwrap().deref_mut());
        self.wallet_from_key(key).await
    }
}

fn format_message(
    nodes: &[TestNode],
    source: PeerId,
    destination: Option<(PeerId, RequestId)>,
    message: &AnyMessage,
) -> String {
    let message = match message {
        AnyMessage::External(message) => format!("{message}"),
        AnyMessage::Internal(_source_shard, _destination_shard, message) => format!("{message}"),
        AnyMessage::Response { message, .. } => format!("{message}"),
    };

    let source_index = nodes.iter().find(|n| n.peer_id == source).unwrap().index;
    if let Some((destination, _)) = destination {
        let destination_index = nodes
            .iter()
            .find(|n| n.peer_id == destination)
            .unwrap()
            .index;
        format!("{source_index} -> {destination_index}: {message}")
    } else {
        format!("{source_index} -> *: {message}")
    }
}

fn compile_contract(path: &str, contract: &str) -> (Contract, Bytes) {
    // create temporary .sol file to avoid solc compilation error
    let full_path = format!("{}/{}", env!("CARGO_MANIFEST_DIR"), path);
    let source_path = Path::new(&full_path);
    let target_file = tempfile::Builder::new()
        .suffix(".sol")
        .tempfile()
        .expect("tempfile target");
    let target_pathbuf = target_file.into_temp_path().to_path_buf();
    let target_path = &target_pathbuf.as_path();

    std::fs::copy(source_path, target_path).expect("copy .sol");

    // configure solc compiler
    let solc_input = SolcInput::new(
        SolcLanguage::Solidity,
        Source::read_all_files(vec![target_pathbuf.clone()]).expect("missing target"),
        Default::default(),
    )
    .evm_version(EvmVersion::Shanghai); // ensure compatible with EVM version in exec.rs

    // compile .sol file
    let solc = Solc::find_or_install(&semver::Version::new(0, 8, 28)).expect("solc missing");
    let output = solc.compile_exact(&solc_input).expect("solc compile_exact");

    if output.has_error() {
        panic!("failed to compile contract with error  {:?}", output.errors);
    }

    // extract output
    let contract = output
        .get(target_path, contract)
        .expect("output_contracts error");

    let abi = contract.abi.expect("jsonabi error");
    let bytecode = contract.bytecode().expect("bytecode error");

    // Convert from the `alloy` representation of an ABI to the `ethers` representation, via JSON
    let abi = serde_json::from_slice(
        serde_json::to_vec(abi)
            .expect("serialisation abi")
            .as_slice(),
    )
    .expect("deserialisation abi");
    let bytecode = serde_json::from_slice(
        serde_json::to_vec(bytecode)
            .expect("serialisation bytecode")
            .as_slice(),
    )
    .expect("deserialisation bytecode");

    (abi, bytecode)
}

async fn deploy_contract(
    path: &str,
    contract: &str,
    value: u128,
    wallet: &Wallet,
    network: &mut Network,
) -> (H256, Contract) {
    deploy_contract_with_args(path, contract, (), value, wallet, network).await
}

async fn deploy_contract_with_args<T: Tokenize>(
    path: &str,
    contract: &str,
    constructor_args: T,
    value: u128,
    wallet: &Wallet,
    network: &mut Network,
) -> (H256, Contract) {
    let (abi, bytecode) = compile_contract(path, contract);

    let factory = DeploymentTxFactory::new(abi, bytecode, wallet.clone());
    let mut deployer = factory.deploy(constructor_args).unwrap();
    if value > 0 {
        deployer.tx.set_value(value);
    }

    let abi = deployer.abi().clone();
    {
        let hash = wallet
            .send_transaction(deployer.tx, None)
            .await
            .unwrap()
            .tx_hash();

        network
            .run_until_async(
                || async {
                    wallet
                        .get_transaction_receipt(hash)
                        .await
                        .unwrap()
                        .is_some()
                },
                200,
            )
            .await
            .unwrap();

        (hash, abi)
    }
}

async fn fund_wallet(network: &mut Network, from_wallet: &Wallet, to_wallet: &Wallet) {
    let hash = from_wallet
        .send_transaction(
            TransactionRequest::pay(to_wallet.address(), 100_000_000_000_000_000_000u128),
            None,
        )
        .await
        .unwrap()
        .tx_hash();
    network.run_until_receipt(to_wallet, hash, 100).await;
}

async fn get_reward_address(
    wallet: &SignerMiddleware<Provider<LocalRpcClient>, LocalWallet>,
    staker: &NodePublicKey,
) -> H160 {
    let tx = TransactionRequest::new()
        .to(H160(contract_addr::DEPOSIT_PROXY.into_array()))
        .data(
            contracts::deposit::GET_REWARD_ADDRESS
                .encode_input(&[Token::Bytes(staker.as_bytes())])
                .unwrap(),
        );
    let return_value = wallet.call(&tx.into(), None).await.unwrap();
    contracts::deposit::GET_REWARD_ADDRESS
        .decode_output(&return_value)
        .unwrap()[0]
        .clone()
        .into_address()
        .unwrap()
}

async fn get_stakers(
    wallet: &SignerMiddleware<Provider<LocalRpcClient>, LocalWallet>,
) -> Vec<NodePublicKey> {
    let tx = TransactionRequest::new()
        .to(H160(contract_addr::DEPOSIT_PROXY.into_array()))
        .data(contracts::deposit::GET_STAKERS.encode_input(&[]).unwrap());
    let stakers = wallet.call(&tx.into(), None).await.unwrap();
    let stakers = contracts::deposit::GET_STAKERS
        .decode_output(&stakers)
        .unwrap()[0]
        .clone()
        .into_array()
        .unwrap();

    stakers
        .into_iter()
        .map(|k| NodePublicKey::from_bytes(&k.into_bytes().unwrap()).unwrap())
        .collect()
}

/// An implementation of [JsonRpcClient] which sends requests directly to an [RpcModule], without making any network
/// calls.
#[derive(Debug, Clone)]
pub struct LocalRpcClient {
    id: Arc<AtomicU64>,
    rpc_module: RpcModule<Arc<RwLock<Node>>>,
    subscriptions: Arc<Mutex<HashMap<u64, mpsc::Receiver<String>>>>,
}

impl LocalRpcClient {
    /// A version of request that allows the params to be optional, so we can test behaviour under
    /// those circumstances.
    async fn request_optional<T, R>(
        &self,
        method: &str,
        params: Option<T>,
    ) -> Result<R, <LocalRpcClient as JsonRpcClient>::Error>
    where
        T: Debug + Serialize + Send + Sync,
        R: DeserializeOwned + Send,
    {
        // There are some hacks in here for `eth_subscribe` and `eth_unsubscribe`. `RpcModule` does not let us control
        // the `id_provider` and it produces subscription IDs incompatible with Ethereum clients. Specifically, it
        // produces integers and `ethers-rs` expects hex-encoded integers. Our hacks convert to this encoding.

        let next_id = self.id.fetch_add(1, Ordering::SeqCst);
        let mut params: Option<Value> = params.map(|p| serde_json::to_value(&p).unwrap());
        if method == "eth_unsubscribe" {
            params.iter_mut().for_each(|p| {
                let id = p.as_array_mut().unwrap().get_mut(0).unwrap();
                let str_id = id.as_str().unwrap().strip_prefix("0x").unwrap();
                *id = u64::from_str_radix(str_id, 16).unwrap().into();
            });
        }
        let payload = RequestSer::owned(
            Id::Number(next_id),
            method,
            params.map(|x| serde_json::value::to_raw_value(&x).unwrap()),
        );
        let request = serde_json::to_string(&payload).unwrap();

        let (response, rx) = self
            .rpc_module
            .raw_json_request(&request, 64)
            .await
            .unwrap();

        if method == "eth_subscribe" {
            let sub_response = serde_json::from_str::<Response<u64>>(&response);
            if let Ok(Response {
                payload: ResponsePayload::Success(id),
                ..
            }) = sub_response
            {
                let id = id.into_owned();
                self.subscriptions.lock().unwrap().insert(id, rx);
                let r = serde_json::from_str(&format!("\"{:#x}\"", id)).unwrap();
                return Ok(r);
            }
        }

        let response: Response<Rc<R>> = serde_json::from_str(&response).unwrap();

        let r = match response.payload {
            ResponsePayload::Success(r) => r,
            ResponsePayload::Error(e) => {
                return Err(JsonRpcError {
                    code: e.code() as i64,
                    message: e.message().to_owned(),
                    data: e.data().map(|d| serde_json::to_value(d).unwrap()),
                }
                .into());
            }
        };

        let r = Rc::try_unwrap(r.into_owned()).unwrap_or_else(|_| panic!());
        Ok(r)
    }
}

#[async_trait]
impl PubsubClient for LocalRpcClient {
    type NotificationStream = Pin<Box<dyn Stream<Item = Box<RawValue>> + Send + Sync + 'static>>;

    fn subscribe<T: Into<U256>>(&self, id: T) -> Result<Self::NotificationStream, Self::Error> {
        let id: U256 = id.into();
        let rx = self
            .subscriptions
            .lock()
            .unwrap()
            .remove(&id.as_u64())
            .unwrap();
        Ok(Box::pin(ReceiverStream::new(rx).map(|s| {
            serde_json::value::to_raw_value(
                &serde_json::from_str::<Notification<Value>>(&s)
                    .unwrap()
                    .params["result"],
            )
            .unwrap()
        })))
    }

    fn unsubscribe<T: Into<U256>>(&self, id: T) -> Result<(), Self::Error> {
        let id: U256 = id.into();
        self.subscriptions.lock().unwrap().remove(&id.as_u64());
        Ok(())
    }
}

#[async_trait]
impl JsonRpcClient for LocalRpcClient {
    type Error = HttpClientError;

    async fn request<T, R>(&self, method: &str, params: T) -> Result<R, Self::Error>
    where
        T: Debug + Serialize + Send + Sync,
        R: DeserializeOwned + Send,
    {
        self.request_optional(method, Some(params)).await
    }
}

```

`zilliqa/tests/it/ots.rs`:

```rs
use std::{ops::DerefMut, str::FromStr};

use ethabi::Token;
use ethers::{
    contract::EthError,
    providers::Middleware,
    types::{TransactionRequest, U64},
    utils,
};
use futures::future::join_all;
use itertools::Itertools;
use primitive_types::{H160, H256};
use serde_json::Value;

use crate::{Network, Wallet, deploy_contract};

async fn search_transactions(
    wallet: &Wallet,
    address: H160,
    block_number: u64,
    page_size: usize,
    reverse: bool,
) -> Value {
    let method = if reverse {
        "ots_searchTransactionsBefore"
    } else {
        "ots_searchTransactionsAfter"
    };
    wallet
        .provider()
        .request(
            method,
            [
                utils::serialize(&address),
                utils::serialize(&block_number),
                utils::serialize(&page_size),
            ],
        )
        .await
        .unwrap()
}

#[zilliqa_macros::test]
async fn search_transactions_evm(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    network.run_until_block(&wallet, 2.into(), 70).await;

    let (hash, caller_abi) = deploy_contract(
        "tests/it/contracts/CallingContract.sol",
        "Caller",
        0u128,
        &wallet,
        &mut network,
    )
    .await;
    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();
    let caller_address = receipt.contract_address.unwrap();

    let (hash, _) = deploy_contract(
        "tests/it/contracts/CallingContract.sol",
        "Callee",
        0u128,
        &wallet,
        &mut network,
    )
    .await;
    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();
    let callee_address = receipt.contract_address.unwrap();

    let data = caller_abi
        .function("setX")
        .unwrap()
        .encode_input(&[Token::Address(callee_address), Token::Uint(123.into())])
        .unwrap();

    let tx = TransactionRequest::new().to(caller_address).data(data);
    let hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();
    network.run_until_receipt(&wallet, hash, 50).await;

    // Search for the transaction with: the sender, the caller contract and the callee contract.
    let response = search_transactions(&wallet, wallet.address(), 0, 1, false).await;
    assert_eq!(response["txs"].as_array().unwrap().len(), 1);
    let response = search_transactions(&wallet, caller_address, 0, 1, false).await;
    assert_eq!(response["txs"].as_array().unwrap().len(), 1);
    let response = search_transactions(&wallet, callee_address, 0, 1, false).await;
    assert_eq!(response["txs"].as_array().unwrap().len(), 1);
}

// TODO: Add test for searching for internal Scilla contract calls once they are supported.

#[zilliqa_macros::test]
async fn search_transactions_paging(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    network.run_until_block(&wallet, 2.into(), 70).await;

    // Generate 16 transactions.
    let to = H160::random_using(network.rng.lock().unwrap().deref_mut());
    let hashes: Vec<_> = join_all((0..16).map(|i| {
        let wallet = &wallet;
        async move {
            let tx = TransactionRequest::pay(to, 123).nonce(i);
            wallet.send_transaction(tx, None).await.unwrap().tx_hash()
        }
    }))
    .await;

    for h in hashes {
        network.run_until_receipt(&wallet, h, 100).await;
    }

    let page_size = 8;
    let response = search_transactions(&wallet, wallet.address(), 0, page_size, false).await;
    let txs = response["txs"].as_array().unwrap();
    // Response should include at least as many transactions as the page size.
    assert!(txs.len() >= page_size);
    // It should include all transactions from the last block (even if this results in more txs than `page_size`).
    let last_block_hash = txs[txs.len() - 1]["blockHash"].as_str().unwrap();
    let last_block = wallet
        .get_block(H256::from_str(last_block_hash).unwrap())
        .await
        .unwrap()
        .unwrap();
    assert_eq!(
        txs.iter()
            .filter(|tx| tx["blockHash"] == last_block_hash)
            .count(),
        last_block.transactions.len()
    );
    // It should be marked as the last (earliest) page because we started from the genesis block.
    assert!(response["lastPage"].as_bool().unwrap());

    let response = search_transactions(&wallet, wallet.address(), 0, 16, false).await;
    let txs = response["txs"].as_array().unwrap();
    // It should be marked as the first (latest) page because we queried for all 16 transactions.
    assert!(response["firstPage"].as_bool().unwrap());
    // Transactions should be returned in descending order (latest to earliest)
    assert!(
        txs.iter()
            .map(|tx| (
                tx["blockNumber"].as_str().unwrap().parse::<U64>().unwrap(),
                tx["transactionIndex"]
                    .as_str()
                    .unwrap()
                    .parse::<U64>()
                    .unwrap(),
            ))
            .tuple_windows()
            .all(|(a, b)| a > b)
    );

    let response = search_transactions(&wallet, wallet.address(), 0, 1, true).await;
    let txs = response["txs"].as_array().unwrap();
    // Searching in reverse from the latest block and a page size of 1 should only yield results from a single block.
    assert!(!txs.is_empty());
    assert!(
        txs.iter()
            .map(|tx| tx["blockHash"].as_str().unwrap())
            .all_equal()
    );
    // Transactions should be returned in descending order (latest to earliest)
    assert!(
        txs.iter()
            .map(|tx| (
                tx["blockNumber"].as_str().unwrap().parse::<U64>().unwrap(),
                tx["transactionIndex"]
                    .as_str()
                    .unwrap()
                    .parse::<U64>()
                    .unwrap(),
            ))
            .tuple_windows()
            .all(|(a, b)| a > b)
    );
}

#[zilliqa_macros::test]
async fn contract_creator(mut network: Network) {
    async fn get_contract_creator(wallet: &Wallet, address: H160) -> Option<(H256, H160)> {
        let response: Value = wallet
            .provider()
            .request("ots_getContractCreator", [address])
            .await
            .unwrap();

        if response.is_null() {
            None
        } else {
            Some((
                response["hash"].as_str().unwrap().parse().unwrap(),
                response["creator"].as_str().unwrap().parse().unwrap(),
            ))
        }
    }

    let wallet = network.genesis_wallet().await;
    network.run_until_block(&wallet, 2.into(), 70).await;

    // EOAs have no creator
    assert_eq!(get_contract_creator(&wallet, wallet.address()).await, None);

    let (hash, abi) = deploy_contract(
        "tests/it/contracts/ContractCreatesAnotherContract.sol",
        "Creator",
        0u128,
        &wallet,
        &mut network,
    )
    .await;
    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();
    let creator_address = receipt.contract_address.unwrap();

    // The EOA is the creator of the `Creator` contract.
    assert_eq!(
        get_contract_creator(&wallet, creator_address).await,
        Some((hash, wallet.address()))
    );

    let data = abi.function("create").unwrap().encode_input(&[]).unwrap();

    let tx = TransactionRequest::new().to(creator_address).data(data);
    let hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();
    let receipt = network.run_until_receipt(&wallet, hash, 50).await;
    let log = abi
        .event("Created")
        .unwrap()
        .parse_log_whole(receipt.logs[0].clone().into())
        .unwrap();
    let create_me_address = log.params[0].value.clone().into_address().unwrap();

    // The `Creator` is the creator of the `CreateMe` contract.
    assert_eq!(
        get_contract_creator(&wallet, create_me_address).await,
        Some((hash, creator_address))
    );

    // TODO: Test Scilla contract
}

#[zilliqa_macros::test]
async fn trace_transaction(mut network: Network) {
    async fn get_trace(wallet: &Wallet, hash: H256) -> Value {
        wallet
            .provider()
            .request("ots_traceTransaction", [hash])
            .await
            .unwrap()
    }

    let wallet = network.genesis_wallet().await;
    network.run_until_block(&wallet, 2.into(), 70).await;

    let (hash, caller_abi) = deploy_contract(
        "tests/it/contracts/CallingContract.sol",
        "Caller",
        0u128,
        &wallet,
        &mut network,
    )
    .await;
    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();
    let caller_address = receipt.contract_address.unwrap();

    let trace = get_trace(&wallet, hash).await;
    assert_eq!(trace.as_array().unwrap().len(), 1);
    let entry = &trace[0];
    assert_eq!(entry["type"], "CREATE");
    assert_eq!(entry["depth"], 0);
    assert_eq!(
        entry["from"].as_str().unwrap().parse::<H160>().unwrap(),
        wallet.address()
    );
    assert_eq!(
        entry["to"].as_str().unwrap().parse::<H160>().unwrap(),
        caller_address
    );

    let (hash, _) = deploy_contract(
        "tests/it/contracts/CallingContract.sol",
        "Callee",
        0u128,
        &wallet,
        &mut network,
    )
    .await;
    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();
    let callee_address = receipt.contract_address.unwrap();

    let data = caller_abi
        .function("setX")
        .unwrap()
        .encode_input(&[Token::Address(callee_address), Token::Uint(123.into())])
        .unwrap();

    let tx = TransactionRequest::new().to(caller_address).data(data);
    let hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();
    network.run_until_receipt(&wallet, hash, 50).await;

    let trace = get_trace(&wallet, hash).await;
    assert_eq!(trace.as_array().unwrap().len(), 2);
    let first = &trace[0];
    let second = &trace[1];
    assert_eq!(first["type"], "CALL");
    assert_eq!(first["depth"], 0);
    assert_eq!(
        first["to"].as_str().unwrap().parse::<H160>().unwrap(),
        caller_address
    );
    assert_eq!(second["type"], "CALL");
    assert_eq!(second["depth"], 1);
    assert_eq!(
        second["to"].as_str().unwrap().parse::<H160>().unwrap(),
        callee_address
    );

    // TODO: Test Scilla contract
}

#[zilliqa_macros::test]
async fn get_transaction_error(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    network.run_until_block(&wallet, 2.into(), 70).await;

    let (hash, abi) = deploy_contract(
        "tests/it/contracts/RevertMe.sol",
        "RevertMe",
        0u128,
        &wallet,
        &mut network,
    )
    .await;
    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();
    let address = receipt.contract_address.unwrap();

    let revertable = abi.function("revertable").unwrap();

    let data = revertable.encode_input(&[Token::Bool(false)]).unwrap();
    let tx = TransactionRequest::new()
        .to(address)
        .data(data)
        .gas(1_000_000);
    let hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();
    network.run_until_receipt(&wallet, hash, 50).await;

    let error: String = wallet
        .provider()
        .request("ots_getTransactionError", [hash])
        .await
        .unwrap();
    println!("{error}");
    let error = error.strip_prefix("0x").unwrap();
    let error = hex::decode(error).unwrap();
    let error = String::decode_with_selector(&error).unwrap();
    assert_eq!(error, "Reverting.");

    // TODO: Test Scilla contract
}

```

`zilliqa/tests/it/persistence.rs`:

```rs
use std::{fs, ops::DerefMut};

use alloy::eips::BlockId;
use ethabi::Token;
use ethers::{providers::Middleware, types::TransactionRequest};
use k256::ecdsa::SigningKey;
use primitive_types::H160;
use rand::Rng;
use tracing::*;
use zilliqa::{
    cfg::Checkpoint,
    crypto::{Hash, SecretKey},
};

use crate::{
    Network, NewNodeOptions, TestNode, deploy_contract,
    zil::{
        deploy_scilla_contract, scilla_test_contract_code, scilla_test_contract_data,
        zilliqa_account,
    },
};

#[zilliqa_macros::test]
async fn block_and_tx_data_persistence(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    // send and include tx
    let hash = Hash(
        wallet
            .send_transaction(TransactionRequest::pay(H160::random(), 10), None)
            .await
            .unwrap()
            .tx_hash()
            .0,
    );

    let index = network.random_index();

    network
        .run_until(
            |n| {
                n.get_node(index)
                    .get_transaction_receipt(hash)
                    .unwrap()
                    .is_some()
            },
            450,
        )
        .await
        .unwrap();

    let latest_block_number = network
        .get_node(index)
        .get_block(BlockId::latest())
        .unwrap()
        .map_or(0, |b| b.number());

    // make one block without txs
    network
        .run_until(
            |n| {
                let block = n
                    .get_node(index)
                    .get_block(BlockId::latest())
                    .unwrap()
                    .map_or(0, |b| b.number());
                block > latest_block_number
            },
            450,
        )
        .await
        .unwrap();

    let receipt = wallet
        .provider()
        .get_transaction_receipt(hash.0)
        .await
        .unwrap()
        .unwrap();

    // make one block without txs
    network
        .run_until(
            |n| {
                let block = n
                    .get_node(index)
                    .get_block(BlockId::latest())
                    .unwrap()
                    .map_or(0, |b| b.number());
                block > receipt.block_number.unwrap().as_u64()
            },
            450,
        )
        .await
        .unwrap();

    let node = network.remove_node(index);

    let inner = node.inner.read();
    let last_number = inner.number() - 2;
    let receipt = inner.get_transaction_receipt(hash).unwrap().unwrap();
    let block_with_tx = inner.get_block(receipt.block_hash).unwrap().unwrap();
    let last_block = inner.get_block(last_number).unwrap().unwrap();
    let tx = inner.get_transaction_by_hash(hash).unwrap().unwrap();
    let current_view = inner.get_current_view().unwrap();
    let finalized_view = inner.get_finalized_height().unwrap();
    // sanity check
    assert_eq!(tx.hash, hash);
    assert_eq!(block_with_tx.transactions.len(), 1);
    assert_ne!(current_view, finalized_view);

    // drop and re-create the node using the same datadir:
    drop(inner);
    let config = node.inner.read().config.clone();
    #[allow(clippy::redundant_closure_call)]
    let dir = (|mut node: TestNode| node.dir.take())(node).unwrap(); // move dir out and drop the rest of node
    let mut rng = network.rng.lock().unwrap();
    let result = crate::node(
        config,
        SecretKey::new_from_rng(rng.deref_mut()).unwrap(),
        SigningKey::random(rng.deref_mut()),
        0,
        Some(dir),
    );

    // Sometimes, the dropping Arc<Node> (by dropping the TestNode above) does not actually drop
    // the underlying Node. See: https://github.com/Zilliqa/zq2/issues/299
    // As this is very painful to debug, should only ever be relevant for tests like these, and CI
    // should run enough samples to still have decent test coverage, we simply skip the rest of the
    // test if this happens.
    let Ok((newnode, _, _, _)) = result else {
        warn!(
            "Failed to release database lock. Skipping test, with seed {}.",
            network.seed
        );
        return;
    };
    let inner = newnode.inner.read();

    // ensure all blocks created were saved up till the last one
    let loaded_last_block = inner.get_block(last_number).unwrap();
    assert!(loaded_last_block.is_some());
    assert_eq!(loaded_last_block.unwrap().hash(), last_block.hash());

    // ensure tx was saved, including its receipt
    let loaded_tx_block = inner.get_block(block_with_tx.number()).unwrap().unwrap();
    assert_eq!(loaded_tx_block.hash(), block_with_tx.hash());
    assert_eq!(loaded_tx_block.transactions.len(), 1);
    assert!(inner.get_transaction_receipt(hash).unwrap().is_some());
    assert_eq!(
        inner
            .get_transaction_by_hash(hash)
            .unwrap()
            .unwrap()
            .tx
            .into_transaction()
            .payload(),
        tx.tx.into_transaction().payload()
    );

    // ensure were back on the same view
    assert_eq!(current_view, inner.get_current_view().unwrap());
    assert_eq!(finalized_view, inner.get_finalized_height().unwrap());
}

#[zilliqa_macros::test(do_checkpoints)]
async fn checkpoints_test(mut network: Network) {
    // Populate network with transactions
    let wallet = network.genesis_wallet().await;
    let (hash, abi) = deploy_contract(
        "tests/it/contracts/Storage.sol",
        "Storage",
        0u128,
        &wallet,
        &mut network,
    )
    .await;

    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();
    let contract_address = receipt.contract_address.unwrap();

    let new_val = 3281u64;

    // set some storage items with transactions
    // Evm
    let function = abi.function("set").unwrap();
    let mut address_buf = [0u8; 20];
    network.rng.lock().unwrap().fill(&mut address_buf);
    let update_tx = TransactionRequest::new().to(contract_address).data(
        function
            .encode_input(&[
                Token::Address(address_buf.into()),
                Token::Uint(new_val.into()),
            ])
            .unwrap(),
    );
    let update_tx_hash = wallet
        .send_transaction(update_tx, None)
        .await
        .unwrap()
        .tx_hash();
    network
        .run_until_receipt(&wallet, update_tx_hash, 100)
        .await;
    // Scilla
    let (secret_key, address) = zilliqa_account(&mut network, &wallet).await;
    let code = scilla_test_contract_code();
    let data = scilla_test_contract_data(address);
    let scilla_contract_address =
        deploy_scilla_contract(&mut network, &wallet, &secret_key, &code, &data, 0_u128).await;

    // Run until block 19 so that we can insert a tx in block 20 (note that this transaction may not *always* appear in the desired block, therefore we do not assert its presence later)
    network.run_until_block(&wallet, 19.into(), 400).await;

    let _hash = wallet
        .send_transaction(TransactionRequest::pay(wallet.address(), 10), None)
        .await
        .unwrap()
        .tx_hash();

    // wait 20 blocks for checkpoint to happen - then 3 more to finalize that block
    network.run_until_block(&wallet, 33.into(), 400).await;

    let checkpoint_files = network
        .nodes
        .iter()
        .map(|node| {
            node.dir
                .as_ref()
                .unwrap()
                .path()
                .join(network.shard_id.to_string())
                .join("checkpoints")
                .join("30")
        })
        .collect::<Vec<_>>();

    let mut len_check = 0;
    for path in &checkpoint_files {
        let metadata = fs::metadata(path).unwrap();
        assert!(metadata.is_file());
        let file_len = metadata.len();
        assert!(file_len != 0);
        assert!(len_check == 0 || len_check == file_len); // len_check = 0 on first loop iteration
        len_check = file_len;
    }

    // Create new node and pass it one of those checkpoint files
    let checkpoint_path = checkpoint_files[0].to_str().unwrap().to_owned();
    let checkpoint_hash = wallet.get_block(30).await.unwrap().unwrap().hash.unwrap();
    let new_node_idx = network.add_node_with_options(NewNodeOptions {
        checkpoint: Some(Checkpoint {
            file: checkpoint_path,
            hash: Hash(checkpoint_hash.0),
        }),
        ..Default::default()
    });

    // Confirm wallet and new_node_wallet have the same block and state
    let new_node_wallet = network.wallet_of_node(new_node_idx).await;
    let latest_block_number = new_node_wallet.get_block_number().await.unwrap();
    assert_eq!(latest_block_number, 30.into());

    let block = wallet
        .get_block(latest_block_number)
        .await
        .unwrap()
        .unwrap();
    let block_from_checkpoint = new_node_wallet
        .get_block(latest_block_number)
        .await
        .unwrap()
        .unwrap();
    assert_eq!(block.transactions, block_from_checkpoint.transactions);
    // Check access to previous block state via fetching author of current block
    assert_eq!(block.author, block_from_checkpoint.author);

    // Check storage
    // Evm
    let storage_getter = abi.function("pos1").unwrap();
    let check_storage_tx = TransactionRequest::new().to(contract_address).data(
        storage_getter
            .encode_input(&[Token::Address(address_buf.into())])
            .unwrap(),
    );
    let storage = new_node_wallet
        .call(&check_storage_tx.into(), None)
        .await
        .unwrap();
    let val = storage_getter.decode_output(&storage).unwrap();
    assert_eq!(val[0], Token::Uint(new_val.into()));
    // Scilla
    let state: serde_json::Value = network
        .random_wallet()
        .await
        .provider()
        .request("GetSmartContractState", [scilla_contract_address])
        .await
        .unwrap();
    assert_eq!(state["welcome_msg"], "default");

    // check the new node catches up and keeps up with block production
    network.run_until_synced(new_node_idx).await;
    network
        .run_until_block(&new_node_wallet, 40.into(), 400)
        .await;

    // check account nonce of old wallet
    let nonce = new_node_wallet
        .get_transaction_count(wallet.address(), None)
        .await
        .unwrap();
    assert_eq!(nonce, 4.into());
}

```

`zilliqa/tests/it/staking.rs`:

```rs
use std::ops::DerefMut;

use blsful::vsss_rs::ShareIdentifier;
use ethabi::Token;
use ethers::{
    middleware::SignerMiddleware,
    providers::{Middleware, Provider},
    signers::LocalWallet,
    types::{BlockId, BlockNumber, TransactionRequest},
};
use primitive_types::{H160, H256};
use rand::Rng;
use revm::primitives::Address;
use tracing::{info, trace};
use zilliqa::{
    contracts,
    crypto::{BlsSignature, NodePublicKey, SecretKey},
    message::MAX_COMMITTEE_SIZE,
    state::contract_addr,
};

use crate::{LocalRpcClient, Network, Wallet, fund_wallet, get_reward_address, get_stakers};

async fn check_miner_got_reward(
    wallet: &SignerMiddleware<Provider<LocalRpcClient>, LocalWallet>,
    block: impl Into<BlockId> + Send + Sync,
) {
    let block = wallet.get_block(block).await.unwrap().unwrap();
    let miner = block.author.unwrap();
    let balance_before = wallet
        .get_balance(miner, Some((block.number.unwrap() - 1).into()))
        .await
        .unwrap();
    let balance_after = wallet
        .get_balance(miner, Some(block.number.unwrap().into()))
        .await
        .unwrap();

    assert!(balance_before < balance_after);
}

async fn deposit_stake(
    network: &mut Network,
    control_wallet: &SignerMiddleware<Provider<LocalRpcClient>, LocalWallet>,
    staker_wallet: &SignerMiddleware<Provider<LocalRpcClient>, LocalWallet>,
    new_validator_key: SecretKey,
    stake: u128,
    reward_address: H160,
    deposit_signature: blsful::ProofOfPossession<blsful::Bls12381G2Impl>,
) -> H256 {
    // Transfer the new validator enough ZIL to stake.
    let tx = TransactionRequest::pay(staker_wallet.address(), stake + 58190476400000000000);
    let hash = control_wallet
        .send_transaction(tx, None)
        .await
        .unwrap()
        .tx_hash();
    network.run_until_receipt(staker_wallet, hash, 101).await;

    // Stake the new validator's funds.
    let tx = TransactionRequest::new()
        .to(H160(contract_addr::DEPOSIT_PROXY.into_array()))
        .value(stake)
        // Set a high gas limit manually, in case the gas estimate and transaction cross an epoch boundary, in which
        // case our estimate will be incorrect.
        .gas(5_000_000)
        .data(
            contracts::deposit::DEPOSIT
                .encode_input(&[
                    Token::Bytes(new_validator_key.node_public_key().as_bytes()),
                    Token::Bytes(
                        new_validator_key
                            .to_libp2p_keypair()
                            .public()
                            .to_peer_id()
                            .to_bytes(),
                    ),
                    Token::Bytes(deposit_signature.0.to_compressed().to_vec()),
                    Token::Address(reward_address),
                ])
                .unwrap(),
        );
    let hash = staker_wallet
        .send_transaction(tx, None)
        .await
        .unwrap()
        .tx_hash();
    let receipt = network.run_until_receipt(staker_wallet, hash, 102).await;
    assert_eq!(receipt.status.unwrap().as_u64(), 1);
    hash
}

#[allow(clippy::too_many_arguments)]
async fn deposit_v3_stake(
    network: &mut Network,
    control_wallet: &SignerMiddleware<Provider<LocalRpcClient>, LocalWallet>,
    staker_wallet: &SignerMiddleware<Provider<LocalRpcClient>, LocalWallet>,
    new_validator_key: SecretKey,
    stake: u128,
    reward_address: H160,
    signing_address: H160,
    deposit_signature: BlsSignature,
) -> H256 {
    // Transfer the new validator enough ZIL to stake.
    let tx = TransactionRequest::pay(staker_wallet.address(), stake + 58190476400000000000);
    let hash = control_wallet
        .send_transaction(tx, None)
        .await
        .unwrap()
        .tx_hash();
    network.run_until_receipt(staker_wallet, hash, 103).await;

    // Stake the new validator's funds.
    let tx = TransactionRequest::new()
        .to(H160(contract_addr::DEPOSIT_PROXY.into_array()))
        .value(stake)
        // Set a high gas limit manually, in case the gas estimate and transaction cross an epoch boundary, in which
        // case our estimate will be incorrect.
        .gas(5_000_000)
        .data(
            contracts::deposit_v3::DEPOSIT
                .encode_input(&[
                    Token::Bytes(new_validator_key.node_public_key().as_bytes()),
                    Token::Bytes(
                        new_validator_key
                            .to_libp2p_keypair()
                            .public()
                            .to_peer_id()
                            .to_bytes(),
                    ),
                    Token::Bytes(deposit_signature.to_bytes()),
                    Token::Address(reward_address),
                    Token::Address(signing_address),
                ])
                .unwrap(),
        );
    let hash = staker_wallet
        .send_transaction(tx, None)
        .await
        .unwrap()
        .tx_hash();
    let receipt = network.run_until_receipt(staker_wallet, hash, 104).await;
    assert_eq!(receipt.status.unwrap().as_u64(), 1);
    hash
}

async fn current_epoch(
    wallet: &SignerMiddleware<Provider<LocalRpcClient>, LocalWallet>,
    block: Option<u64>,
) -> u64 {
    let tx = TransactionRequest::new()
        .to(H160(contract_addr::DEPOSIT_PROXY.into_array()))
        .data(contracts::deposit::CURRENT_EPOCH.encode_input(&[]).unwrap());
    let response = wallet
        .call(&tx.into(), block.map(|b| b.into()))
        .await
        .unwrap();
    let epoch = contracts::deposit::CURRENT_EPOCH
        .decode_output(&response)
        .unwrap()
        .remove(0)
        .into_uint()
        .unwrap()
        .as_u64();
    let current_block = block.unwrap_or(wallet.get_block_number().await.unwrap().as_u64());

    // Sanity check that epochs are calculated correctly (assuming `blocks_per_epoch = 2`).
    assert_eq!(epoch, current_block / 2);

    epoch
}

async fn unstake_amount(network: &mut Network, control_wallet: &Wallet, amount: u128) -> H256 {
    let tx = TransactionRequest::new()
        .to(H160(contract_addr::DEPOSIT_PROXY.into_array()))
        .data(
            contracts::deposit::UNSTAKE
                .encode_input(&[Token::Uint(amount.into())])
                .unwrap(),
        )
        .gas(10000000); // TODO: Why needed?
    let hash = control_wallet
        .send_transaction(tx, None)
        .await
        .unwrap()
        .tx_hash();
    let receipt = network.run_until_receipt(control_wallet, hash, 200).await;
    assert_eq!(receipt.status.unwrap().as_u64(), 1);
    hash
}

async fn get_stake(wallet: &Wallet, staker: &NodePublicKey) -> u128 {
    let tx = TransactionRequest::new()
        .to(H160(contract_addr::DEPOSIT_PROXY.into_array()))
        .data(
            contracts::deposit::GET_STAKE
                .encode_input(&[Token::Bytes(staker.as_bytes())])
                .unwrap(),
        );
    let output = wallet.call(&tx.into(), None).await.unwrap();

    contracts::deposit::GET_STAKE
        .decode_output(&output)
        .unwrap()[0]
        .clone()
        .into_uint()
        .unwrap()
        .as_u128()
}

async fn get_total_stake(wallet: &Wallet) -> u128 {
    let tx = TransactionRequest::new()
        .to(H160(contract_addr::DEPOSIT_PROXY.into_array()))
        .data(
            contracts::deposit::GET_TOTAL_STAKE
                .encode_input(&[])
                .unwrap(),
        );

    let stake = wallet.call(&tx.into(), None).await.unwrap();
    let stake = contracts::deposit::GET_TOTAL_STAKE
        .decode_output(&stake)
        .unwrap()[0]
        .clone()
        .into_uint()
        .unwrap();

    stake.as_u128()
}

async fn get_minimum_deposit(
    wallet: &SignerMiddleware<Provider<LocalRpcClient>, LocalWallet>,
) -> u128 {
    let tx = TransactionRequest::new()
        .to(H160(contract_addr::DEPOSIT_PROXY.into_array()))
        .data(contracts::deposit::MIN_DEPOSIT.encode_input(&[]).unwrap());
    let deposit = wallet.call(&tx.into(), None).await.unwrap();

    let deposit = contracts::deposit::MIN_DEPOSIT
        .decode_output(&deposit)
        .unwrap()[0]
        .clone()
        .into_uint()
        .unwrap();

    deposit.as_u128()
}

async fn get_maximum_stakers(
    wallet: &SignerMiddleware<Provider<LocalRpcClient>, LocalWallet>,
) -> u128 {
    let tx = TransactionRequest::new()
        .to(H160(contract_addr::DEPOSIT_PROXY.into_array()))
        .data(contracts::deposit::MAX_STAKERS.encode_input(&[]).unwrap());
    let deposit = wallet.call(&tx.into(), None).await.unwrap();

    let deposit = contracts::deposit::MAX_STAKERS
        .decode_output(&deposit)
        .unwrap()[0]
        .clone()
        .into_uint()
        .unwrap();

    deposit.as_u128()
}

async fn get_blocks_per_epoch(
    wallet: &SignerMiddleware<Provider<LocalRpcClient>, LocalWallet>,
) -> u64 {
    let tx = TransactionRequest::new()
        .to(H160(contract_addr::DEPOSIT_PROXY.into_array()))
        .data(
            contracts::deposit::BLOCKS_PER_EPOCH
                .encode_input(&[])
                .unwrap(),
        );
    let deposit = wallet.call(&tx.into(), None).await.unwrap();

    let deposit = contracts::deposit::BLOCKS_PER_EPOCH
        .decode_output(&deposit)
        .unwrap()[0]
        .clone()
        .into_uint()
        .unwrap();

    deposit.as_u64()
}

async fn get_signing_address(
    wallet: &SignerMiddleware<Provider<LocalRpcClient>, LocalWallet>,
    staker: &NodePublicKey,
) -> H160 {
    let tx = TransactionRequest::new()
        .to(H160(contract_addr::DEPOSIT_PROXY.into_array()))
        .data(
            contracts::deposit_v3::GET_SIGNING_ADDRESS
                .encode_input(&[Token::Bytes(staker.as_bytes())])
                .unwrap(),
        );
    let return_value = wallet.call(&tx.into(), None).await.unwrap();
    contracts::deposit_v3::GET_SIGNING_ADDRESS
        .decode_output(&return_value)
        .unwrap()[0]
        .clone()
        .into_address()
        .unwrap()
}
#[allow(dead_code)]
async fn get_control_address(
    wallet: &SignerMiddleware<Provider<LocalRpcClient>, LocalWallet>,
    staker: &NodePublicKey,
) -> H160 {
    let tx = TransactionRequest::new()
        .to(H160(contract_addr::DEPOSIT_PROXY.into_array()))
        .data(
            contracts::deposit_v3::GET_CONTROL_ADDRESS
                .encode_input(&[Token::Bytes(staker.as_bytes())])
                .unwrap(),
        );
    let return_value = wallet.call(&tx.into(), None).await.unwrap();
    contracts::deposit_v3::GET_CONTROL_ADDRESS
        .decode_output(&return_value)
        .unwrap()[0]
        .clone()
        .into_address()
        .unwrap()
}

#[zilliqa_macros::test]
async fn deposit_storage_initially_set(mut network: Network) {
    let wallet = network.random_wallet().await;
    assert_eq!(
        get_minimum_deposit(&wallet).await,
        *network.nodes[0].inner.read().config.consensus.minimum_stake
    );
    assert_eq!(
        get_maximum_stakers(&wallet).await,
        MAX_COMMITTEE_SIZE as u128
    );
    assert_eq!(
        get_blocks_per_epoch(&wallet).await,
        network.nodes[0]
            .inner
            .read()
            .config
            .consensus
            .blocks_per_epoch
    );

    let stakers = get_stakers(&wallet).await;
    assert_eq!(
        stakers.len(),
        network.nodes[0]
            .inner
            .read()
            .config
            .consensus
            .genesis_deposits
            .len()
    );

    // deposit contract gensis balance
    let total_stake = get_total_stake(&wallet).await;
    let deposit_balance = wallet
        .get_balance(H160(contract_addr::DEPOSIT_PROXY.into_array()), None)
        .await
        .unwrap()
        .as_u128();

    assert_ne!(deposit_balance, 0);
    assert_eq!(total_stake, deposit_balance);
}

#[zilliqa_macros::test]
async fn rewards_are_sent_to_reward_address_of_proposer(mut network: Network) {
    let wallet = network.random_wallet().await;

    let stakers = get_stakers(&wallet).await;
    assert_eq!(stakers.len(), 4);

    network.run_until_block(&wallet, 1.into(), 80).await;

    check_miner_got_reward(&wallet, 1).await;
}

#[zilliqa_macros::test(blocks_per_epoch = 2, deposit_v3_upgrade_block_height = 24)]
async fn validators_can_join_and_become_proposer(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // randomise the current epoch state and current leader
    let blocks_to_prerun = network.rng.lock().unwrap().gen_range(0..4);
    network
        .run_until_block(&wallet, blocks_to_prerun.into(), 200)
        .await;

    // First test joining deposit_v2
    let index = network.add_node();
    let new_validator_key = network.get_node_raw(index).secret_key;
    let reward_address = H160::random_using(&mut network.rng.lock().unwrap().deref_mut());

    let stakers = get_stakers(&wallet).await;
    assert_eq!(stakers.len(), 4);
    assert!(!stakers.contains(&new_validator_key.node_public_key()));

    let staker_wallet = network.wallet_of_node(index).await;
    let pop_sinature = new_validator_key.pop_prove();

    // This has to be done before `contract_upgrade_block_heights` which is 24, by default in this test
    let deposit_hash = deposit_stake(
        &mut network,
        &wallet,
        &staker_wallet,
        new_validator_key,
        32 * 10u128.pow(18),
        reward_address,
        pop_sinature,
    )
    .await;

    let deposit_block = wallet
        .get_transaction_receipt(deposit_hash)
        .await
        .unwrap()
        .unwrap()
        .block_number
        .unwrap()
        .as_u64();
    info!(deposit_block);

    // The new validator should become part of the committee exactly two epochs after the one in which the deposit was
    // made.
    let deposit_epoch = current_epoch(&wallet, Some(deposit_block)).await;
    network
        .run_until_async(
            || async {
                let should_be_in_committee =
                    current_epoch(&wallet, None).await == deposit_epoch + 2;

                let stakers = get_stakers(&wallet).await;
                if !should_be_in_committee {
                    assert_eq!(stakers.len(), 4);
                    assert!(!stakers.contains(&new_validator_key.node_public_key()));
                    false // Keep running
                } else {
                    assert_eq!(stakers.len(), 5);
                    assert!(stakers.contains(&new_validator_key.node_public_key()));
                    true
                }
            },
            200,
        )
        .await
        .unwrap();

    // Check the new validator eventually gets to be a block proposer.
    network
        .run_until_async(
            || async {
                wallet
                    .get_block(BlockNumber::Latest)
                    .await
                    .unwrap()
                    .unwrap()
                    .author
                    .unwrap()
                    == reward_address
            },
            500,
        )
        .await
        .unwrap();
    check_miner_got_reward(&wallet, BlockNumber::Latest).await;

    // Now test joining deposit_v3
    let index = network.add_node();
    let new_validator_priv_key = network.get_node_raw(index).secret_key;
    let new_validator_pub_key = new_validator_priv_key.node_public_key();
    let reward_address = H160::random_using(&mut network.rng.lock().unwrap().deref_mut());
    let signing_address = H160::random_using(&mut network.rng.lock().unwrap().deref_mut());

    let stakers = get_stakers(&wallet).await;
    assert_eq!(stakers.len(), 5);
    assert!(!stakers.contains(&new_validator_pub_key));

    let staker_wallet = network.wallet_of_node(index).await;
    let deposit_signature = new_validator_priv_key.deposit_auth_signature(
        network.shard_id,
        Address::from(staker_wallet.address().to_fixed_bytes()),
    );

    // Give new node time to catch up to block including deposit_v3 deployment
    network
        .run_until_block(&staker_wallet, 24.into(), 424)
        .await;

    let deposit_hash = deposit_v3_stake(
        &mut network,
        &wallet,
        &staker_wallet,
        new_validator_priv_key,
        32 * 10u128.pow(18),
        reward_address,
        signing_address,
        deposit_signature,
    )
    .await;

    let deposit_block = wallet
        .get_transaction_receipt(deposit_hash)
        .await
        .unwrap()
        .unwrap()
        .block_number
        .unwrap()
        .as_u64();
    info!(deposit_block);

    // Check set staker's addresses
    assert_eq!(
        get_reward_address(&staker_wallet, &new_validator_pub_key).await,
        reward_address
    );
    assert_eq!(
        get_signing_address(&staker_wallet, &new_validator_pub_key).await,
        signing_address
    );

    // The new validator should become part of the committee exactly two epochs after the one in which the deposit was
    // made.
    let deposit_epoch = current_epoch(&wallet, Some(deposit_block)).await;
    network
        .run_until_async(
            || async {
                let should_be_in_committee =
                    current_epoch(&wallet, None).await == deposit_epoch + 2;

                let stakers = get_stakers(&wallet).await;
                if !should_be_in_committee {
                    assert_eq!(stakers.len(), 5);
                    assert!(!stakers.contains(&new_validator_priv_key.node_public_key()));
                    false // Keep running
                } else {
                    assert_eq!(stakers.len(), 6);
                    assert!(stakers.contains(&new_validator_priv_key.node_public_key()));
                    true
                }
            },
            200,
        )
        .await
        .unwrap();
}

#[zilliqa_macros::test(blocks_per_epoch = 2)]
async fn block_proposers_are_selected_proportionally_to_their_stake(mut network: Network) {
    // The starting configuration is 4 nodes with a stake of 32 ZIL each. We'll add a 5th node with a stake of 1024 ZIL
    // and check that it produces a statistically significant proportion of the subsequent blocks.

    let wallet = network.genesis_wallet().await;

    let index = network.add_node();
    let new_validator_key = network.get_node_raw(index).secret_key;
    let reward_address = H160::random_using(&mut network.rng.lock().unwrap().deref_mut());

    let staker_wallet = network.wallet_of_node(index).await;
    let pop_signature = new_validator_key.pop_prove();

    network.run_until_synced(index).await;
    deposit_stake(
        &mut network,
        &wallet,
        &staker_wallet,
        new_validator_key,
        1024 * 10u128.pow(18),
        reward_address,
        pop_signature,
    )
    .await;

    // Start counting at the point where the new validator becomes a block proposer. This guarantees it is now part of
    // the consensus committee.
    network
        .run_until_async(
            || async {
                wallet
                    .get_block(BlockNumber::Latest)
                    .await
                    .unwrap()
                    .unwrap()
                    .author
                    .unwrap()
                    == reward_address
            },
            1000,
        )
        .await
        .unwrap();

    let current_block = wallet.get_block_number().await.unwrap().as_u64();
    info!(current_block, ?reward_address, "deposit staked");
    network
        .run_until_async(
            || async { wallet.get_block_number().await.unwrap().as_u64() >= current_block + 20 },
            1000,
        )
        .await
        .unwrap();

    let mut proposers = vec![];
    for b in current_block..=(current_block + 20) {
        let block = wallet.get_block(b).await.unwrap().unwrap();
        proposers.push(block.author.unwrap());
    }
    trace!(?proposers);

    // The chance of our new node being the proposer in any single block should be `1024 / (1024 + 32 * 4) ~= 0.89`.
    // Taking a binomial distribution of `X ~ bin(20, 0.89)`, we select a boundary value of 6 blocks, because
    // `P(X < 6) ~= 4.35 * 10^-11`. This is false-negative rate of this test. Conversely, if we take `Y ~ bin(20, 0.2)`
    // as one of the possible distributions if our implemention is wrong (if proposers are equally likely), we get
    // `P(Y < 6) ~= 0.80`, meaning this test is likely to (correctly) fail.
    assert!(
        proposers
            .iter()
            .filter(|addr| **addr == reward_address)
            .count()
            >= 6
    );
}

#[zilliqa_macros::test(blocks_per_epoch = 2)]
async fn validators_can_unstake(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // randomise the current epoch state and current leader
    let blocks_to_prerun = network.rng.lock().unwrap().gen_range(0..8);
    network
        .run_until_block(&wallet, blocks_to_prerun.into(), 400)
        .await;

    let validator_idx = network.random_index();
    let validator_blskey = network
        .get_node_raw(validator_idx)
        .secret_key
        .node_public_key();
    let validator_control_wallet = network
        .wallet_from_key(network.get_node_raw(validator_idx).onchain_key.clone())
        .await;
    fund_wallet(&mut network, &wallet, &validator_control_wallet).await;

    let stakers = get_stakers(&wallet).await;
    assert_eq!(stakers.len(), 4);
    assert!(stakers.contains(&validator_blskey));

    // unstake validator's entire stake
    let stake = get_stake(&wallet, &validator_blskey).await;
    let unstake_hash = unstake_amount(&mut network, &validator_control_wallet, stake).await;
    let unstake_block = network
        .run_until_receipt(&wallet, unstake_hash, 100)
        .await
        .block_number
        .unwrap()
        .as_u64();

    // The validator should leave the committee exactly two epochs after the one in which the withdrawal was made.
    let unstake_epoch = current_epoch(&wallet, Some(unstake_block)).await;
    network
        .run_until_async(
            || async {
                let should_be_in_committee =
                    current_epoch(&wallet, None).await != unstake_epoch + 2;

                let stakers = get_stakers(&wallet).await;
                if should_be_in_committee {
                    assert_eq!(stakers.len(), 4);
                    assert!(stakers.contains(&validator_blskey));
                    false // Keep running
                } else {
                    assert_eq!(stakers.len(), 3);
                    assert!(!stakers.contains(&validator_blskey));
                    true
                }
            },
            200,
        )
        .await
        .unwrap();

    // ensure network still runs well
    network
        .run_until_async(
            || async {
                let stakers = get_stakers(&wallet).await;
                assert_eq!(stakers.len(), 3);
                assert!(!stakers.contains(&validator_blskey));
                wallet.get_block_number().await.unwrap().as_u64() >= unstake_block + 15
            },
            1000,
        )
        .await
        .unwrap();
}

// TODO: Tests for:
// * partial unstaking staying above the minimum
// * partial unstaking under the minimum (should fail)
// * increase stake (deposit topup)
// * updating staker details (reward address, control address)
// * disallow access to callers other than the controlAddress
// * withdraw stake after 2 weeks (exercise the circular buffer logic or test it separately if difficult to do here)

```

`zilliqa/tests/it/sync.rs`:

```rs
use std::fs;

use ethers::{providers::Middleware, types::TransactionRequest};
use tracing::info;
use zilliqa::{cfg::Checkpoint, crypto::Hash};

use crate::{Network, NewNodeOptions};

// Test a pruning node does not hold old blocks.
#[zilliqa_macros::test]
async fn prune_interval(mut network: Network) {
    network.run_until_block_finalized(5, 100).await.unwrap();

    info!("Adding pruned node.");
    let index = network.add_node_with_options(crate::NewNodeOptions {
        prune_interval: Some(20),
        ..Default::default()
    });
    network.run_until_synced(index).await;

    network.run_until_block_finalized(25, 1000).await.unwrap();

    let range = network.node_at(index).db.available_range().unwrap();
    info!("Pruned range: {range:?}");
    assert_eq!(range.count(), 20);
}

#[zilliqa_macros::test(do_checkpoints)]
async fn base_height(mut network: Network) {
    // Populate network with transactions
    let wallet = network.genesis_wallet().await;
    // Run until block 9 so that we can insert a tx in block 10 (note that this transaction may not *always* appear in the desired block, therefore we do not assert its presence later)
    network.run_until_block(&wallet, 9.into(), 200).await;

    let _hash = wallet
        .send_transaction(TransactionRequest::pay(wallet.address(), 10), None)
        .await
        .unwrap()
        .tx_hash();

    // wait 10 blocks for checkpoint to happen - then 3 more to finalize that block
    network.run_until_block(&wallet, 13.into(), 200).await;

    let checkpoint_files = network
        .nodes
        .iter()
        .map(|node| {
            node.dir
                .as_ref()
                .unwrap()
                .path()
                .join(network.shard_id.to_string())
                .join("checkpoints")
                .join("10")
        })
        .collect::<Vec<_>>();

    let mut len_check = 0;
    for path in &checkpoint_files {
        let metadata = fs::metadata(path).unwrap();
        assert!(metadata.is_file());
        let file_len = metadata.len();
        assert!(file_len != 0);
        assert!(len_check == 0 || len_check == file_len); // len_check = 0 on first loop iteration
        len_check = file_len;
    }

    // Add a non-validator node, since passive-sync does not work otherwise
    let non_validator_idx = network.add_node();

    // Create new node and pass it one of those checkpoint files
    let checkpoint_path = checkpoint_files[0].to_str().unwrap().to_owned();
    let checkpoint_hash = wallet.get_block(10).await.unwrap().unwrap().hash.unwrap();
    let new_node_idx = network.add_node_with_options(NewNodeOptions {
        checkpoint: Some(Checkpoint {
            file: checkpoint_path,
            hash: Hash(checkpoint_hash.0),
        }),
        base_height: Some(3),
        ..Default::default()
    });

    // Confirm wallet and new_node_wallet have the same block and state
    let new_node_wallet = network.wallet_of_node(new_node_idx).await;
    let latest_block_number = new_node_wallet.get_block_number().await.unwrap();
    assert_eq!(latest_block_number, 10.into());

    // check the new node catches up and keeps up with block production
    network.run_until_synced(non_validator_idx).await;
    network.run_until_synced(new_node_idx).await;
    network
        .run_until_block(&new_node_wallet, 20.into(), 200)
        .await;

    // check range of new wallet
    let base_height = *network
        .node_at(new_node_idx)
        .db
        .available_range()
        .unwrap()
        .start();
    assert_eq!(base_height, 3);
}

```

`zilliqa/tests/it/trace.rs`:

```rs
use std::str::FromStr;

use alloy::{primitives::B256, rpc::types::trace::parity::TraceResults};
use ethers::{
    providers::Middleware,
    types::{H160, TransactionRequest},
};
use serde_json::Value;

use crate::Network;

#[zilliqa_macros::test]
async fn trace_transaction_basic(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Create a simple transfer transaction
    let to_addr = H160::random();
    let tx = TransactionRequest::new().to(to_addr).value(1000).gas(21000);

    let tx_hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();

    // Wait for transaction to be mined
    network.run_until_receipt(&wallet, tx_hash, 100).await;

    // Get trace
    let response: Value = wallet
        .provider()
        .request("trace_transaction", [tx_hash])
        .await
        .expect("Failed to call trace_transaction API");

    let trace: TraceResults = serde_json::from_value(response).unwrap();
    assert!(!trace.trace.is_empty());
}

#[zilliqa_macros::test]
async fn trace_transaction_not_found(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let nonexistent_hash =
        B256::from_str("0x1234567890123456789012345678901234567890123456789012345678901234")
            .unwrap();

    let response: Result<TraceResults, _> = wallet
        .provider()
        .request("trace_transaction", [nonexistent_hash])
        .await;

    assert!(response.is_err());
}

#[zilliqa_macros::test]
async fn trace_block_basic(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Create some transactions in a block
    let to_addr = H160::random();
    let tx = TransactionRequest::new().to(to_addr).value(1000).gas(21000);

    let tx_hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();

    // Wait for block to be mined
    let receipt = network.run_until_receipt(&wallet, tx_hash, 100).await;
    let block_number = receipt.block_number.unwrap();

    // Get block trace
    let response: Value = wallet
        .provider()
        .request("trace_block", [block_number])
        .await
        .expect("Failed to call trace_block API");

    let traces: Vec<TraceResults> = serde_json::from_value(response).unwrap();
    assert!(!traces.is_empty());
}

#[zilliqa_macros::test]
async fn trace_filter_basic(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Create transactions from different addresses
    let to_addr = H160::random();
    let tx1 = TransactionRequest::new().to(to_addr).value(1000).gas(21000);

    let tx_hash1 = wallet.send_transaction(tx1, None).await.unwrap().tx_hash();
    let receipt1 = network.run_until_receipt(&wallet, tx_hash1, 100).await;

    let filter = serde_json::json!({
        "fromBlock": receipt1.block_number.unwrap(),
        "toBlock": receipt1.block_number.unwrap(),
        "fromAddress": [wallet.address()],
        "toAddress": [to_addr],
    });

    let response: Value = wallet
        .provider()
        .request("trace_filter", [filter])
        .await
        .expect("Failed to call trace_filter API");

    let traces: Vec<TraceResults> = serde_json::from_value(response).unwrap();
    assert!(!traces.is_empty());

    // Verify trace contains expected addresses
    for trace in traces {
        for trace in trace.trace {
            let action = trace.action;
            let (from_address_result, to_address_result) = match action {
                alloy::rpc::types::trace::parity::Action::Call(call_action) => {
                    (call_action.from, call_action.to)
                }
                _ => panic!("Unexpected action type"),
            };
            assert_eq!(from_address_result.0, wallet.address().0);
            assert_eq!(to_address_result.0, to_addr.0);
        }
    }
}

#[zilliqa_macros::test]
async fn trace_filter_pagination(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Create multiple transactions
    let mut receipts = Vec::new();
    for _ in 0..5 {
        let to_addr = H160::random();
        let tx = TransactionRequest::new().to(to_addr).value(1000).gas(21000);

        let tx_hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();
        receipts.push(network.run_until_receipt(&wallet, tx_hash, 100).await);
    }

    let first_block = receipts.first().unwrap().block_number.unwrap();
    let last_block = receipts.last().unwrap().block_number.unwrap();

    // Test pagination
    let filter = serde_json::json!({
        "fromBlock": first_block,
        "toBlock": last_block,
        "after": 0,
        "count": 2
    });

    let response: Value = wallet
        .provider()
        .request("trace_filter", [filter])
        .await
        .expect("Failed to call trace_filter API");

    let traces: Vec<TraceResults> = serde_json::from_value(response).unwrap();
    assert_eq!(traces.len(), 2);
}

```

`zilliqa/tests/it/txpool.rs`:

```rs
use ethers::{core::types::TransactionRequest, providers::Middleware};
use primitive_types::H160;
use serde_json::Value;

use crate::Network;

// txpool_content tests

#[zilliqa_macros::test]
async fn txpool_content(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let provider = wallet.provider();

    // First check that the txpool is empty
    let empty_response: Value = provider
        .request("txpool_content", ())
        .await
        .expect("Failed to call txpool_content API");

    assert!(
        empty_response.get("pending").is_none(),
        "Expected empty pending transactions"
    );
    assert!(
        empty_response.get("queued").is_none(),
        "Expected empty queued transactions"
    );

    // Send a transaction but don't mine it yet
    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    let tx = TransactionRequest::pay(to_addr, 100).gas(21000);
    let tx_hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();

    // Now check the txpool to see if our transaction is there
    let response: Value = provider
        .request("txpool_content", ())
        .await
        .expect("Failed to call txpool_content API");

    let pending = response["pending"].as_object().unwrap();
    assert!(
        !pending.is_empty(),
        "Expected non-empty pending transactions"
    );

    // Convert wallet address to lowercase string for comparison
    let wallet_addr = format!("{:?}", wallet.address()).to_lowercase();

    // Check if our transaction is in the pending pool
    let found = pending.iter().any(|(addr, txs)| {
        addr.to_lowercase() == wallet_addr
            && txs.as_object().is_some()
            && !txs.as_object().unwrap().is_empty()
    });
    assert!(found, "Couldn't find our transaction in the pending pool");

    // Mine the block with our transaction
    network
        .run_until_async(
            || async {
                provider
                    .get_transaction_receipt(tx_hash)
                    .await
                    .unwrap()
                    .is_some()
            },
            50,
        )
        .await
        .unwrap();

    // Check that the txpool is empty again
    let final_response: Value = provider
        .request("txpool_content", ())
        .await
        .expect("Failed to call txpool_content API");

    assert!(
        final_response.get("pending").is_none(),
        "Expected empty pending transactions after mining"
    );
    assert!(
        final_response.get("queued").is_none(),
        "Expected empty queued transactions after mining"
    );
}

// txpool_content_from tests

#[zilliqa_macros::test]
async fn txpool_content_from(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let provider = wallet.provider();

    // Send a transaction but don't mine it yet
    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    let tx = TransactionRequest::pay(to_addr, 100).gas(21000);
    let _tx_hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();

    // Check the txpool for transactions from our wallet address
    let response: Value = provider
        .request("txpool_contentFrom", [wallet.address()])
        .await
        .expect("Failed to call txpool_contentFrom API");

    let pending = response["pending"].as_object().unwrap();
    assert!(
        !pending.is_empty(),
        "Expected non-empty pending transactions for our address"
    );

    // Convert wallet address to lowercase string for comparison
    let wallet_addr = format!("{:?}", wallet.address()).to_lowercase();

    // Check if our transaction is in the pending pool
    let found = pending
        .iter()
        .any(|(addr, _)| addr.to_lowercase() == wallet_addr);
    assert!(found, "Couldn't find our address in the pending pool");

    // Try with a different address that should have no transactions
    let random_addr = H160::random();
    let empty_response: Value = provider
        .request("txpool_contentFrom", [random_addr])
        .await
        .expect("Failed to call txpool_contentFrom API with random address");

    assert!(
        empty_response.get("pending").is_none(),
        "Expected empty pending transactions for random address"
    );
    assert!(
        empty_response.get("queued").is_none(),
        "Expected empty queued transactions for random address"
    );
}

#[zilliqa_macros::test]
async fn txpool_content_from_with_queued(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let provider = wallet.provider();

    // Send transactions with nonces out of order to create queued transactions
    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();

    // First send a transaction with nonce 2 (should be queued)
    let tx_queued = TransactionRequest::pay(to_addr, 300).gas(21000).nonce(2);
    let _ = wallet
        .send_transaction(tx_queued, None)
        .await
        .unwrap()
        .tx_hash();

    // Then send a transaction with nonce 0 (should be pending)
    let tx_pending = TransactionRequest::pay(to_addr, 100).gas(21000).nonce(0);
    let _ = wallet
        .send_transaction(tx_pending, None)
        .await
        .unwrap()
        .tx_hash();

    // Check txpool_contentFrom for our wallet
    let content: Value = provider
        .request("txpool_contentFrom", [wallet.address()])
        .await
        .expect("Failed to call txpool_contentFrom API");

    // Verify there's a transaction in the pending section
    let pending = content["pending"].as_object().unwrap();
    assert!(!pending.is_empty(), "Expected transactions in pending");

    // Verify there's a transaction in the queued section
    let queued = content["queued"].as_object().unwrap();
    assert!(!queued.is_empty(), "Expected transactions in queued");

    // Check for a random address - should be empty
    let random_addr = H160::random();
    let empty_content: Value = provider
        .request("txpool_contentFrom", [random_addr])
        .await
        .expect("Failed to call txpool_contentFrom API with random address");

    assert!(
        empty_content.get("pending").is_none(),
        "Expected empty pending for random address"
    );
    assert!(
        empty_content.get("queued").is_none(),
        "Expected empty queued for random address"
    );
}

// txpool_inspect tests

#[zilliqa_macros::test]
async fn txpool_inspect(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let provider = wallet.provider();

    // First check that the txpool is empty
    let empty_response: Value = provider
        .request("txpool_inspect", ())
        .await
        .expect("Failed to call txpool_inspect API");

    assert!(
        empty_response.get("pending").is_none(),
        "Expected empty pending transactions"
    );
    assert!(
        empty_response.get("queued").is_none(),
        "Expected empty queued transactions"
    );

    // Send a transaction but don't mine it yet
    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    let value = 1234;
    let gas = 21000;
    let tx = TransactionRequest::pay(to_addr, value).gas(gas);
    let tx_hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();

    // Now check the txpool inspect to see if our transaction is there
    let response: Value = provider
        .request("txpool_inspect", ())
        .await
        .expect("Failed to call txpool_inspect API");

    // Check structure and content
    let pending = response["pending"].as_object().unwrap();
    assert!(
        !pending.is_empty(),
        "Expected non-empty pending transactions"
    );

    // Convert wallet address to lowercase string for comparison
    let wallet_addr = format!("{:?}", wallet.address()).to_lowercase();

    // Check if our transaction is in the pending pool
    // The summary should contain the to address, value, and gas information
    let found = pending.iter().any(|(addr, txs)| {
        if addr.to_lowercase() == wallet_addr && txs.as_object().is_some() {
            let txs_obj = txs.as_object().unwrap();
            if !txs_obj.is_empty() {
                // Check if any of the transaction summaries contain our transaction details
                for (_, summary) in txs_obj {
                    let summary_str = summary.as_str().unwrap().to_lowercase();
                    let to_addr_string = format!("{:?}", to_addr);
                    let value_string = value.to_string();
                    if summary_str.contains(&to_addr_string) && summary_str.contains(&value_string)
                    {
                        return true;
                    }
                }
            }
        }
        false
    });
    assert!(found, "Couldn't find our transaction in the pending pool");

    // Mine the block with our transaction
    network
        .run_until_async(
            || async {
                provider
                    .get_transaction_receipt(tx_hash)
                    .await
                    .unwrap()
                    .is_some()
            },
            50,
        )
        .await
        .unwrap();

    // Check that the txpool is empty again
    let final_response: Value = provider
        .request("txpool_inspect", ())
        .await
        .expect("Failed to call txpool_inspect API");

    assert!(
        final_response.get("pending").is_none(),
        "Expected empty pending transactions after mining"
    );
    assert!(
        final_response.get("queued").is_none(),
        "Expected empty queued transactions after mining"
    );
}

#[zilliqa_macros::test]
async fn txpool_inspect_with_queued(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let provider = wallet.provider();

    // Send transactions with nonces out of order to create queued transactions
    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();

    // First send a transaction with nonce 2 (should be queued)
    let tx_queued = TransactionRequest::pay(to_addr, 300).gas(21000).nonce(2);
    let tx_hash_queued = wallet
        .send_transaction(tx_queued, None)
        .await
        .unwrap()
        .tx_hash();

    // Then send a transaction with nonce 0 (should be pending)
    let tx_pending = TransactionRequest::pay(to_addr, 100).gas(21000).nonce(0);
    let tx_hash_pending = wallet
        .send_transaction(tx_pending, None)
        .await
        .unwrap()
        .tx_hash();

    // Check txpool_inspect to verify transaction locations
    let inspect: Value = provider
        .request("txpool_inspect", ())
        .await
        .expect("Failed to call txpool_inspect API");

    let wallet_addr = format!("{:?}", wallet.address()).to_lowercase();

    // Verify the pending section has our transaction
    let pending = inspect["pending"].as_object().unwrap();
    let pending_entry = pending
        .iter()
        .find(|(addr, _)| addr.to_lowercase() == wallet_addr);
    assert!(
        pending_entry.is_some(),
        "Wallet address not found in pending"
    );

    // Verify the queued section has our transaction
    let queued = inspect["queued"].as_object().unwrap();
    let queued_entry = queued
        .iter()
        .find(|(addr, _)| addr.to_lowercase() == wallet_addr);
    assert!(queued_entry.is_some(), "Wallet address not found in queued");

    // Send another transaction so we can mine
    let tx_nonce_1 = TransactionRequest::pay(to_addr, 200).gas(21000).nonce(1);
    wallet
        .send_transaction(tx_nonce_1, None)
        .await
        .unwrap()
        .tx_hash();

    // Mine the transactions
    network
        .run_until_async(
            || async {
                provider
                    .get_transaction_receipt(tx_hash_pending)
                    .await
                    .unwrap()
                    .is_some()
                    && provider
                        .get_transaction_receipt(tx_hash_queued)
                        .await
                        .unwrap()
                        .is_some()
            },
            50,
        )
        .await
        .unwrap();

    // Check that the txpool is empty again
    let final_inspect: Value = provider
        .request("txpool_inspect", ())
        .await
        .expect("Failed to call txpool_inspect API");

    assert!(
        final_inspect.get("pending").is_none(),
        "Expected empty pending transactions after mining"
    );
    assert!(
        final_inspect.get("queued").is_none(),
        "Expected empty queued transactions after mining"
    );
}

// txpool_status tests

#[zilliqa_macros::test]
async fn txpool_status(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let provider = wallet.provider();

    // First check that the txpool is empty
    let empty_response: Value = provider
        .request("txpool_status", ())
        .await
        .expect("Failed to call txpool_status API");

    assert_eq!(
        empty_response["pending"].as_u64().unwrap(),
        0,
        "Expected 0 pending transactions"
    );
    assert_eq!(
        empty_response["queued"].as_u64().unwrap(),
        0,
        "Expected 0 queued transactions"
    );

    // Send multiple transactions but don't mine them yet
    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();

    // Send 3 transactions with different nonces
    let tx1 = TransactionRequest::pay(to_addr, 100).gas(21000).nonce(0);
    let tx_hash1 = wallet.send_transaction(tx1, None).await.unwrap().tx_hash();

    let tx2 = TransactionRequest::pay(to_addr, 200).gas(21000).nonce(1);
    let tx_hash2 = wallet.send_transaction(tx2, None).await.unwrap().tx_hash();

    let tx3 = TransactionRequest::pay(to_addr, 300).gas(21000).nonce(2);
    let tx_hash3 = wallet.send_transaction(tx3, None).await.unwrap().tx_hash();

    // Now check the txpool status to see if our transactions are counted
    let response: Value = provider
        .request("txpool_status", ())
        .await
        .expect("Failed to call txpool_status API");

    assert_eq!(
        response["pending"].as_u64().unwrap(),
        3,
        "Expected 3 pending transactions"
    );
    assert_eq!(
        response["queued"].as_u64().unwrap(),
        0,
        "Expected 0 queued transactions"
    );

    // Mine the block with our transactions
    network
        .run_until_async(
            || async {
                provider
                    .get_transaction_receipt(tx_hash1)
                    .await
                    .unwrap()
                    .is_some()
                    && provider
                        .get_transaction_receipt(tx_hash2)
                        .await
                        .unwrap()
                        .is_some()
                    && provider
                        .get_transaction_receipt(tx_hash3)
                        .await
                        .unwrap()
                        .is_some()
            },
            50,
        )
        .await
        .unwrap();

    // Check that the txpool is empty again
    let final_response: Value = provider
        .request("txpool_status", ())
        .await
        .expect("Failed to call txpool_status API");

    assert_eq!(
        final_response["pending"].as_u64().unwrap(),
        0,
        "Expected 0 pending transactions after mining"
    );
    assert_eq!(
        final_response["queued"].as_u64().unwrap(),
        0,
        "Expected 0 queued transactions after mining"
    );
}

#[zilliqa_macros::test]
async fn txpool_status_with_queued(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let provider = wallet.provider();

    // Send transactions with nonces out of order to create queued transactions
    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();

    // First send a transaction with nonce 2 (should be queued)
    let tx_queued = TransactionRequest::pay(to_addr, 300).gas(21000).nonce(2);
    let _ = wallet
        .send_transaction(tx_queued, None)
        .await
        .unwrap()
        .tx_hash();

    // Check txpool status - should show 0 pending, 1 queued
    let response1: Value = provider
        .request("txpool_status", ())
        .await
        .expect("Failed to call txpool_status API");

    assert_eq!(
        response1["pending"].as_u64().unwrap(),
        0,
        "Expected 0 pending transactions"
    );
    assert_eq!(
        response1["queued"].as_u64().unwrap(),
        1,
        "Expected 1 queued transaction"
    );

    // Send transaction with nonce 0 (should be pending)
    let tx_pending = TransactionRequest::pay(to_addr, 100).gas(21000).nonce(0);
    let _ = wallet
        .send_transaction(tx_pending, None)
        .await
        .unwrap()
        .tx_hash();

    // Check txpool status - should show 1 pending, 1 queued
    let response2: Value = provider
        .request("txpool_status", ())
        .await
        .expect("Failed to call txpool_status API");

    assert_eq!(
        response2["pending"].as_u64().unwrap(),
        1,
        "Expected 1 pending transaction"
    );
    assert_eq!(
        response2["queued"].as_u64().unwrap(),
        1,
        "Expected 1 queued transaction"
    );
}

```

`zilliqa/tests/it/unreliable.rs`:

```rs
use crate::Network;

#[zilliqa_macros::test]
async fn blocks_are_produced_while_a_node_restarts(mut network: Network) {
    let restarted_node = network.random_index();
    let wallet = network.wallet_of_node(restarted_node).await;

    // Select a wallet connected to a different node, so we can query the network when the first node is disconnected.
    let other_wallet = loop {
        let i = network.random_index();
        if i != restarted_node {
            break i;
        }
    };
    let other_wallet = network.wallet_of_node(other_wallet).await;

    // Produce a few blocks to start with. Enough for everyone to join the consensus committee.
    // TODO(#721): Once the committee is visible in the API, we can avoid waiting as long.
    network.run_until_block(&wallet, 8.into(), 400).await;

    // Disconnect the node we are 'restarting'.
    network.disconnect_node(restarted_node);

    // Produce 2 more blocks.
    network.run_until_block(&other_wallet, 10.into(), 400).await;

    // Reconnect the 'restarted' node.
    network.connect_node(restarted_node);

    // TODO(#721): We should assert here that a new view occurred if-and-only-if the 'restarted' node was the proposer
    // of blocks 3 or 4. This would tell us that we aren't producing new views unnecessarily.

    // Ensure more blocks are produced.
    network.run_until_block(&wallet, 12.into(), 400).await;
}

```

`zilliqa/tests/it/web3.rs`:

```rs
use ethers::providers::Middleware;

use crate::Network;

#[zilliqa_macros::test]
async fn sha3(mut network: Network) {
    let wallet = network.random_wallet().await;

    // Example from https://ethereum.org/en/developers/docs/apis/json-rpc/#web3_sha3
    let result: String = wallet
        .provider()
        .request("web3_sha3", ["0x68656c6c6f20776f726c64"])
        .await
        .unwrap();
    assert_eq!(
        result,
        "0x47173285a8d7341e5e972fc677286384f802f8ef42a5ec5f03bbfa254cb01fad"
    )
}

```

`zilliqa/tests/it/zil.rs`:

```rs
use std::{ops::DerefMut, str::FromStr};

use alloy::primitives::Address;
use anyhow::Result;
use bech32::{Bech32, Hrp};
use ethabi::{ParamType, Token};
use ethers::{
    providers::{Middleware, ProviderError},
    types::TransactionRequest,
    utils::keccak256,
};
use k256::{PublicKey, elliptic_curve::sec1::ToEncodedPoint};
use primitive_types::{H160, H256, U128};
use prost::Message;
use serde::Deserialize;
use serde_json::{Value, json};
use sha2::{Digest, Sha256};
use tracing::debug;
use zilliqa::{
    api::types::zil::GetTxResponse,
    schnorr,
    zq1_proto::{Code, Data, Nonce, ProtoTransactionCoreInfo},
};

use crate::{Network, Wallet, deploy_contract};

pub async fn zilliqa_account(network: &mut Network, wallet: &Wallet) -> (schnorr::SecretKey, H160) {
    zilliqa_account_with_funds(network, wallet, 1000 * 10u128.pow(18)).await
}

pub async fn zilliqa_account_with_funds(
    network: &mut Network,
    wallet: &Wallet,
    funds: u128,
) -> (schnorr::SecretKey, H160) {
    // Generate a Zilliqa account.
    let secret_key = schnorr::SecretKey::random(network.rng.lock().unwrap().deref_mut());
    let public_key = secret_key.public_key();
    let hashed = Sha256::digest(public_key.to_encoded_point(true).as_bytes());
    let address = H160::from_slice(&hashed[12..]);

    // Send the Zilliqa account some funds.
    let tx = TransactionRequest::pay(address, funds);
    let hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();
    network
        .run_until_async(
            || async {
                wallet
                    .provider()
                    .request::<[_; 1], Option<Value>>("GetTransaction", [hash])
                    .await
                    .is_ok()
            },
            200,
        )
        .await
        .unwrap();

    // Verify the Zilliqa account has funds using the `GetBalance` API.
    let response: Value = wallet
        .provider()
        .request("GetBalance", [address])
        .await
        .unwrap();

    let resp_eth = wallet
        .provider()
        .request::<[&str; 2], String>(
            "eth_getBalance",
            [
                &Address::new(*address.as_fixed_bytes()).to_checksum(None),
                "latest",
            ],
        )
        .await
        .unwrap();
    let eth_balance: U128 =
        U128::from_str_radix(resp_eth.strip_prefix("0x").unwrap_or(&resp_eth), 16).unwrap();

    // This is in decimal!
    let zil_balance = U128::from_str_radix(response["balance"].as_str().unwrap(), 10).unwrap();

    assert_eq!(zil_balance * U128::from(10u128.pow(6)), funds.into());
    assert_eq!(eth_balance, funds.into());
    assert_eq!(response["nonce"].as_u64().unwrap(), 0);

    (secret_key, address)
}

enum ToAddr {
    Address(H160),
    StringVal(String),
}

#[allow(clippy::too_many_arguments)]
async fn issue_create_transaction(
    wallet: &Wallet,
    public_key: &PublicKey,
    gas_price: u128,
    _network: &mut Network,
    secret_key: &schnorr::SecretKey,
    nonce: u64,
    to_addr: ToAddr,
    amount: u128,
    gas_limit: u64,
    code: Option<&str>,
    data: Option<&str>,
) -> Result<Value> {
    let chain_id = wallet.get_chainid().await.unwrap().as_u32() - 0x8000;
    let version = (chain_id << 16) | 1u32;
    let (to_addr_val, to_addr_string) = match to_addr {
        ToAddr::Address(v) => {
            let vec = v.as_bytes().to_vec();
            (
                vec.clone(),
                Address::from_slice(vec.as_slice()).to_checksum(None),
            )
        }
        ToAddr::StringVal(v) => (
            H160::from_str(&v).unwrap().as_bytes().to_vec(),
            v.to_string(),
        ),
    };
    let proto = ProtoTransactionCoreInfo {
        version,
        toaddr: to_addr_val,
        senderpubkey: Some(public_key.to_sec1_bytes().into()),
        amount: Some(amount.to_be_bytes().to_vec().into()),
        gasprice: Some(gas_price.to_be_bytes().to_vec().into()),
        gaslimit: gas_limit,
        oneof2: Some(Nonce::Nonce(nonce)),
        oneof8: code.map(|c| Code::Code(c.as_bytes().to_vec())),
        oneof9: data.map(|d| Data::Data(d.as_bytes().to_vec())),
    };
    let txn_data = proto.encode_to_vec();
    let signature = schnorr::sign(&txn_data, secret_key);

    let mut request = json!({
        "version": version,
        "nonce": nonce,
        "toAddr": to_addr_string,
        "amount": amount.to_string(),
        "pubKey": hex::encode(public_key.to_sec1_bytes()),
        "gasPrice": gas_price.to_string(),
        "gasLimit": gas_limit.to_string(),
        "signature": hex::encode(signature.to_bytes()),
    });

    if let Some(code) = code {
        request["code"] = code.into();
    }
    if let Some(data) = data {
        request["data"] = data.into();
    }

    Ok(wallet
        .provider()
        .request("CreateTransaction", [request])
        .await?)
}

#[allow(clippy::too_many_arguments)]
async fn send_transaction(
    network: &mut Network,
    wallet: &Wallet,
    secret_key: &schnorr::SecretKey,
    nonce: u64,
    to_addr: ToAddr,
    amount: u128,
    gas_limit: u64,
    code: Option<&str>,
    data: Option<&str>,
) -> (Option<H160>, Value) {
    let public_key = secret_key.public_key();

    // Get the gas price via the Zilliqa API.
    let gas_price_str: String = wallet
        .provider()
        .request("GetMinimumGasPrice", ())
        .await
        .unwrap();
    let gas_price: u128 = u128::from_str(&gas_price_str).unwrap();

    let response = issue_create_transaction(
        wallet,
        &public_key,
        gas_price,
        network,
        secret_key,
        nonce,
        to_addr,
        amount,
        gas_limit,
        code,
        data,
    )
    .await
    .unwrap();
    let txn_hash: H256 = response["TranID"].as_str().unwrap().parse().unwrap();

    network
        .run_until_async(
            || async {
                let response: Result<GetTxResponse, _> = wallet
                    .provider()
                    .request("GetTransaction", [txn_hash])
                    .await;
                response.is_ok()
            },
            400,
        )
        .await
        .unwrap();

    let eth_receipt = wallet
        .get_transaction_receipt(txn_hash)
        .await
        .unwrap()
        .unwrap();
    assert_eq!(eth_receipt.status.unwrap().as_u32(), 1);

    (
        eth_receipt.contract_address,
        wallet
            .provider()
            .request("GetTransaction", [txn_hash])
            .await
            .unwrap(),
    )
}

pub fn scilla_test_contract_code() -> String {
    String::from(
        r#"
        scilla_version 0

        library HelloWorld

        let one_msg =
          fun (msg : Message) =>
          let nil_msg = Nil {Message} in
            Cons {Message} msg nil_msg

        let one = Uint32 1
        let two = Uint32 2

        let amnt = Uint128 0

        contract HelloWorld
        (owner: ByStr20)

        field welcome_msg : String = "default"
        field welcome_map : Map Uint32 (Map Uint32 String) = Emp Uint32 (Map Uint32 String)

        (* Test variable which is a prefix of another variable *)
        field foo : Map Uint32 String = Emp Uint32 String
        field foobar : String = "goodbye"

        transition removeHello()
          delete welcome_map[one];
          e = {_eventname : "removeHello"};
          event e
        end

        transition setHello (msg : String)
        is_owner = builtin eq owner _sender;
        match is_owner with
        | False =>
            e = {_eventname : "setHello"; code : "1"};
            event e
        | True =>
            hello = "hello";
            foo[one] := hello;
            welcome_msg := msg;
            welcome_map[one][two] := msg;
            e = {_eventname : "setHello"; code : "2"};
            event e
        end
        end

        transition getHello ()
        r <- welcome_msg;
        e = {_eventname: "getHello"; msg: r};
        event e;
        maybe_s <- welcome_map[one][two];
        match maybe_s with
        | None =>
            e = {_eventname: "getHello"; msg: "failed"};
            event e
        | Some s =>
            e = {_eventname: "getHello"; msg: s};
            event e
        end
        end

        transition getFields ()
        a <- foo;
        a_one = builtin get a one;
        b <- foobar;
        e = {_eventname: "fields"; a_one: a_one; b: b};
        event e
        end

        transition callFailure(addr: ByStr20)
          accept;
          msg = { _tag : "failure"; _recipient : addr; _amount : amnt };
          msgs = one_msg msg;
          send msgs
        end

        transition failure()
            throw
        end
    "#,
    )
}

pub fn scilla_test_contract_data(address: H160) -> String {
    format!(
        r#"[
            {{
                "vname": "_scilla_version",
                "type": "Uint32",
                "value": "0"
            }},
            {{
                "vname": "owner",
                "type": "ByStr20",
                "value": "{address:#x}"
            }}
        ]"#
    )
}

pub async fn deploy_scilla_contract(
    network: &mut Network,
    wallet: &Wallet,
    sender_secret_key: &schnorr::SecretKey,
    code: &str,
    data: &str,
    amount: u128,
) -> H160 {
    let (contract_address, txn) = send_transaction(
        network,
        wallet,
        sender_secret_key,
        1,
        ToAddr::Address(H160::zero()),
        amount,
        50_000,
        Some(code),
        Some(data),
    )
    .await;

    let api_contract_address = wallet
        .provider()
        .request("GetContractAddressFromTransactionID", [&txn["ID"]])
        .await
        .unwrap();
    assert_eq!(contract_address, api_contract_address);

    contract_address.unwrap()
}

// Returns a pair (code, message) if there was one.
#[allow(clippy::too_many_arguments)]
async fn run_create_transaction_api_for_error(
    wallet: &Wallet,
    secret_key: &schnorr::SecretKey,
    nonce: u64,
    to_addr: ToAddr,
    amount: u128,
    gas_limit: u64,
    code: Option<&str>,
    data: Option<&str>,
    chain_id: Option<u32>,
    bad_signature: bool,
) -> Option<(i64, String)> {
    let public_key = secret_key.public_key();

    // Get the gas price via the Zilliqa API.
    let gas_price_str: String = wallet
        .provider()
        .request("GetMinimumGasPrice", ())
        .await
        .unwrap();
    let gas_price: u128 = u128::from_str(&gas_price_str).unwrap();

    let use_chain_id = chain_id.unwrap_or(wallet.get_chainid().await.unwrap().as_u32() - 0x8000);
    let version = (use_chain_id << 16) | 1u32;
    let (to_addr_val, to_addr_string) = match to_addr {
        ToAddr::Address(v) => {
            let vec = v.as_bytes().to_vec();
            (
                vec.clone(),
                Address::from_slice(vec.as_slice()).to_checksum(None),
            )
        }
        ToAddr::StringVal(v) => (
            H160::from_str(&v).unwrap().as_bytes().to_vec(),
            v.to_string(),
        ),
    };
    let proto = ProtoTransactionCoreInfo {
        version,
        toaddr: to_addr_val,
        senderpubkey: Some(public_key.to_sec1_bytes().into()),
        amount: Some(amount.to_be_bytes().to_vec().into()),
        gasprice: Some(gas_price.to_be_bytes().to_vec().into()),
        gaslimit: gas_limit,
        oneof2: Some(Nonce::Nonce(nonce)),
        oneof8: code.map(|c| Code::Code(c.as_bytes().to_vec())),
        oneof9: data.map(|d| Data::Data(d.as_bytes().to_vec())),
    };
    let txn_data = proto.encode_to_vec();
    let mut signature = schnorr::sign(&txn_data, secret_key).to_bytes();
    if bad_signature {
        if let Some(x) = signature.first_mut() {
            *x = x.wrapping_add(1);
        }
    }
    let mut request = json!({
        "version": version,
        "nonce": nonce,
        "toAddr": to_addr_string,
        "amount": amount.to_string(),
        "pubKey": hex::encode(public_key.to_sec1_bytes()),
        "gasPrice": gas_price.to_string(),
        "gasLimit": gas_limit.to_string(),
        "signature": hex::encode(signature)
    });

    if let Some(code) = code {
        request["code"] = code.into();
    }
    if let Some(data) = data {
        request["data"] = data.into();
    }

    let response: Result<Value, ProviderError> = wallet
        .provider()
        .request("CreateTransaction", [request])
        .await;

    if let Err(ProviderError::JsonRpcClientError(rpc_error)) = response {
        if let Some(json_error) = rpc_error.as_error_response() {
            return Some((json_error.code, json_error.message.to_string()));
        }
    }
    None
}

#[zilliqa_macros::test]
async fn create_transaction_bad_checksum(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, _address) = zilliqa_account(&mut network, &wallet).await;
    let public_key = secret_key.public_key();

    // Get the gas price via the Zilliqa API.
    let gas_price_str: String = wallet
        .provider()
        .request("GetMinimumGasPrice", ())
        .await
        .unwrap();
    let gas_price: u128 = u128::from_str(&gas_price_str).unwrap();

    let ans = issue_create_transaction(
        &wallet,
        &public_key,
        gas_price,
        &mut network,
        &secret_key,
        1,
        ToAddr::StringVal("0x00000000000000000000000000000000deaDbeef".to_string()),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;
    assert!(ans.is_err());
}

#[zilliqa_macros::test]
async fn create_transaction_zil_checksum(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (secret_key, address) = zilliqa_account(&mut network, &wallet).await;

    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();

    send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::StringVal("0x00000000000000000000000000000000deADbeef".to_string()),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    // Verify the sender's nonce has increased using the `GetBalance` API.
    let response: Value = wallet
        .provider()
        .request("GetBalance", [address])
        .await
        .unwrap();
    assert_eq!(response["nonce"].as_u64().unwrap(), 1);

    // Verify the receiver's balance has increased using the `GetBalance` API.
    let response: Value = wallet
        .provider()
        .request("GetBalance", [to_addr])
        .await
        .unwrap();
    assert_eq!(response["balance"].as_str().unwrap(), "200000000000000");
}

#[zilliqa_macros::test]
async fn create_transaction(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (secret_key, address) = zilliqa_account(&mut network, &wallet).await;

    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    // Verify the sender's nonce has increased using the `GetBalance` API.
    let response: Value = wallet
        .provider()
        .request("GetBalance", [address])
        .await
        .unwrap();
    assert_eq!(response["nonce"].as_u64().unwrap(), 1);

    // Verify the receiver's balance has increased using the `GetBalance` API.
    let response: Value = wallet
        .provider()
        .request("GetBalance", [to_addr])
        .await
        .unwrap();
    assert_eq!(response["balance"].as_str().unwrap(), "200000000000000");
}

#[zilliqa_macros::test]
async fn get_balance_via_eth_api(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (secret_key, _) = zilliqa_account(&mut network, &wallet).await;

    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    let encoded_bech32 =
        bech32::encode::<Bech32>(Hrp::parse("zil").unwrap(), to_addr.as_bytes()).unwrap();

    let response: Value = wallet
        .provider()
        .request("eth_getBalance", [encoded_bech32, "latest".to_string()])
        .await
        .unwrap();

    let stripped_str = response.as_str().unwrap().strip_prefix("0x").unwrap();
    let returned = u128::from_str_radix(stripped_str, 16).unwrap();
    assert_eq!(returned, 200u128 * 10u128.pow(18));
}

#[zilliqa_macros::test]
async fn create_transaction_errors(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, _) = zilliqa_account(&mut network, &wallet).await;
    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    {
        let (code, msg) = run_create_transaction_api_for_error(
            &wallet,
            &secret_key,
            0,
            ToAddr::Address(to_addr),
            200u128 * 10u128.pow(12),
            50_000,
            None,
            None,
            None,
            false,
        )
        .await
        .unwrap();

        assert!(msg.to_lowercase().contains("invalid nonce"));
        assert_eq!(code, -8)
    }

    {
        let (code, msg) = run_create_transaction_api_for_error(
            &wallet,
            &secret_key,
            1,
            ToAddr::Address(to_addr),
            200u128 * 10u128.pow(12),
            50_000,
            None,
            None,
            Some(1),
            false,
        )
        .await
        .unwrap();

        assert!(msg.to_lowercase().contains("chain id"));
        assert_eq!(code, -26)
    }

    {
        let (code, msg) = run_create_transaction_api_for_error(
            &wallet,
            &secret_key,
            1,
            ToAddr::Address(to_addr),
            200u128 * 10u128.pow(12),
            50_000,
            None,
            None,
            None,
            true,
        )
        .await
        .unwrap();

        assert!(msg.to_lowercase().contains("signature"));
        assert_eq!(code, -26)
    }

    {
        // Too little for the deposit.
        let (no_funds_secret_key, _) =
            zilliqa_account_with_funds(&mut network, &wallet, 10u128.pow(6)).await;
        let (code, msg) = run_create_transaction_api_for_error(
            &wallet,
            &no_funds_secret_key,
            1,
            ToAddr::Address(to_addr),
            200u128 * 10u128.pow(12),
            50_000,
            None,
            None,
            None,
            false,
        )
        .await
        .unwrap();
        assert!(msg.to_lowercase().contains("insufficient"));
        assert_eq!(code, -8)
    }
}

#[zilliqa_macros::test]
async fn get_transaction(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Create a Zilliqa account and get its secret key and address
    let (secret_key, _address) = zilliqa_account(&mut network, &wallet).await;

    // Define the recipient address
    let address_string_w_prefix = "0x00000000000000000000000000000000deadbeef";
    let to_addr: H160 = address_string_w_prefix.parse().unwrap();

    // Send a transaction
    let (_contract_address, returned_transaction) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    // Get the transaction ID from the returned transaction
    let transaction_id = returned_transaction["ID"]
        .as_str()
        .expect("Failed to get ID from response");

    // Wait for the transaction to be mined
    network.run_until_block_finalized(1u64, 100).await.unwrap();

    // Use the GetTransaction API to retrieve the transaction details
    let response: Value = wallet
        .provider()
        .request("GetTransaction", [transaction_id])
        .await
        .expect("Failed to call GetTransaction API");

    // Check for keys
    assert!(response["receipt"]["success"].is_boolean());
    assert!(response["receipt"]["event_logs"].is_array());
    assert!(response["receipt"]["transitions"].is_array());

    // Check the string formats
    assert!(!response["ID"].as_str().unwrap().starts_with("0x"));
    assert!(!response["toAddr"].as_str().unwrap().starts_with("0x"));
    assert!(response["senderPubKey"].as_str().unwrap().starts_with("0x"));
    assert!(response["signature"].as_str().unwrap().starts_with("0x"));

    // Verify the transaction details
    assert_eq!(response["ID"].as_str().unwrap(), transaction_id);
    assert_eq!(response["toAddr"].as_str().unwrap(), hex::encode(to_addr),);
    assert_eq!(response["amount"].as_str().unwrap(), "200000000000000");
    assert_eq!(response["gasLimit"].as_str().unwrap(), "50000");
    assert_eq!(
        response["senderPubKey"].as_str().unwrap(),
        format!("0x{}", hex::encode(secret_key.public_key().to_sec1_bytes()))
    );

    let parsed_response = zilliqa::api::types::zil::GetTxResponse::deserialize(&response)
        .expect("Failed to deserialize response");

    // Verify the transaction details
    assert_eq!(parsed_response.nonce, 1);
    // Logic should be case independent
    assert_eq!(
        parsed_response.to_addr.to_string().to_lowercase(),
        address_string_w_prefix
    );
    assert_eq!(parsed_response.amount.to_string(), "200000000000000");
    assert_eq!(parsed_response.gas_limit.0, 50000);

    let response_soft_confirmed: Value = wallet
        .provider()
        .request("GetSoftConfirmedTransaction", [transaction_id])
        .await
        .expect("Failed to call GetTransaction API");

    assert_eq!(response, response_soft_confirmed);
}

#[zilliqa_macros::test]
async fn create_transaction_high_gas_limit(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (secret_key, address) =
        zilliqa_account_with_funds(&mut network, &wallet, 60 * 10u128.pow(18)).await;

    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();

    let gas_price_str: String = wallet
        .provider()
        .request("GetMinimumGasPrice", ())
        .await
        .unwrap();
    let gas_price: u128 = u128::from_str(&gas_price_str).unwrap();

    println!("gas_price {gas_price}");

    // how much we can actually pay for.
    // 50 = 60-10 (we're transferring 10)
    let max_gas_we_can_pay_for = (50u128 * 10u128.pow(12)) / gas_price;
    println!("max_gas {max_gas_we_can_pay_for}");
    send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        10 * 10u128.pow(12),
        u128::try_into(max_gas_we_can_pay_for * 2).unwrap(),
        None,
        None,
    )
    .await;

    // Verify the sender's nonce has increased using the `GetBalance` API.
    let response: Value = wallet
        .provider()
        .request("GetBalance", [address])
        .await
        .unwrap();
    println!("GetBalance() after transfer = {response:?}");
    assert_eq!(response["nonce"].as_u64().unwrap(), 1);

    // Verify the receiver's balance has increased using the `GetBalance` API.
    let response: Value = wallet
        .provider()
        .request("GetBalance", [to_addr])
        .await
        .unwrap();
    assert_eq!(
        response["balance"]
            .as_str()
            .unwrap()
            .parse::<u128>()
            .unwrap(),
        (10u128 * 10u128.pow(12))
    );
}

// We need to restrict the concurrency level of this test, because each node in the network will spawn a TCP listener
// once it invokes Scilla. When many tests are run in parallel, this results in "Too many open files" errors.
#[zilliqa_macros::test(restrict_concurrency)]
async fn create_contract(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, address) = zilliqa_account(&mut network, &wallet).await;
    let code = scilla_test_contract_code();
    let data = scilla_test_contract_data(address);
    let contract_address =
        deploy_scilla_contract(&mut network, &wallet, &secret_key, &code, &data, 0_u128).await;

    let api_code: Value = wallet
        .provider()
        .request("GetSmartContractCode", [contract_address])
        .await
        .unwrap();
    assert_eq!(code, api_code["code"]);

    let api_data: Vec<Value> = wallet
        .provider()
        .request("GetSmartContractInit", [contract_address])
        .await
        .unwrap();
    // Assert the data returned from the API is a superset of the init data we passed.
    assert!(
        serde_json::from_str::<Vec<Value>>(&data)
            .unwrap()
            .iter()
            .all(|d| api_data.contains(d))
    );

    let old_balance: u128 = {
        let bal_resp: Value = wallet
            .provider()
            .request("GetBalance", [address])
            .await
            .unwrap();
        bal_resp["balance"]
            .as_str()
            .unwrap()
            .parse::<u128>()
            .unwrap()
    };

    let call = r#"{
        "_tag": "setHello",
        "params": [
            {
                "vname": "msg",
                "value": "foobar",
                "type": "String"
            }
        ]
    }"#;
    let (_, txn) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        2,
        ToAddr::Address(contract_address),
        0,
        50_000,
        None,
        Some(call),
    )
    .await;
    let event = &txn["receipt"]["event_logs"][0];
    assert_eq!(event["_eventname"], "setHello");
    assert_eq!(event["params"][0]["value"], "2");
    let new_balance: u128 = {
        let bal_resp: Value = wallet
            .provider()
            .request("GetBalance", [address])
            .await
            .unwrap();
        bal_resp["balance"]
            .as_str()
            .unwrap()
            .parse::<u128>()
            .unwrap()
    };
    // Let's check that we charged the right amount of gas.
    assert_eq!(old_balance - new_balance, 696000005568u128);

    let call = r#"{
        "_tag": "getHello",
        "params": []
    }"#;
    let (_, txn) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        3,
        ToAddr::Address(contract_address),
        0,
        50_000,
        None,
        Some(call),
    )
    .await;
    for event in txn["receipt"]["event_logs"].as_array().unwrap() {
        assert_eq!(event["_eventname"], "getHello");
        assert_eq!(event["params"][0]["value"], "foobar");
    }

    let state: serde_json::Value = wallet
        .provider()
        .request("GetSmartContractState", [contract_address])
        .await
        .unwrap();
    assert_eq!(state["welcome_msg"], "foobar");

    let call = r#"{
        "_tag": "getFields",
        "params": []
    }"#;
    let (_, txn) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        4,
        ToAddr::Address(contract_address),
        0,
        50_000,
        None,
        Some(call),
    )
    .await;
    assert_eq!(
        txn["receipt"]["event_logs"][0]["params"][0]["value"]["arguments"][0],
        "hello"
    );
    assert_eq!(
        txn["receipt"]["event_logs"][0]["params"][1]["value"],
        "goodbye"
    );
}

#[zilliqa_macros::test(restrict_concurrency)]
async fn scilla_precompiles(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, _) = zilliqa_account(&mut network, &wallet).await;

    let code = r#"
        scilla_version 0

        library HelloWorld

        let one = Uint128 1
        let two = Uint128 2
        let big_number = Uint128 1234
        let addr = 0x0123456789012345678901234567890123456789

        contract Hello
        ()

        field num : Uint128 = big_number
        field str : String = "foobar"
        field addr_to_int : Map ByStr20 Uint128 =
          let emp = Emp ByStr20 Uint128 in
          builtin put emp addr one
        field addr_to_addr_to_int : Map ByStr20 (Map ByStr20 Uint128) =
          let emp1 = Emp ByStr20 Uint128 in
          let inner = builtin put emp1 addr one in
          let emp2 = Emp ByStr20 (Map ByStr20 Uint128) in
          builtin put emp2 addr inner

        transition InsertIntoMap(a: ByStr20, b: Uint128)
          addr_to_int[a] := b;
          e = {_eventname : "Inserted"; a : a; b : b};
          event e
        end

        transition LogSender()
          e = {_eventname : "LogSender"; sender : _sender};
          event e
        end
    "#;

    let data = r#"[
        {
            "vname": "_scilla_version",
            "type": "Uint32",
            "value": "0"
        }
    ]"#;

    let (contract_address, _) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(H160::zero()),
        0,
        50_000,
        Some(code),
        Some(data),
    )
    .await;
    let scilla_contract_address = contract_address.unwrap();

    let (hash, abi) = deploy_contract(
        "tests/it/contracts/ScillaInterop.sol",
        "ScillaInterop",
        0u128,
        &wallet,
        &mut network,
    )
    .await;
    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();
    let evm_contract_address = receipt.contract_address.unwrap();

    let read = |fn_name, var_name: &'_ str, keys: &[H160], ty| {
        let abi = &abi;
        let wallet = &wallet;
        let var_name = var_name.to_owned();
        let keys = keys.to_vec();
        async move {
            let function = abi.function(fn_name).unwrap();
            let mut input = vec![
                Token::Address(scilla_contract_address),
                Token::String(var_name),
            ];
            for key in keys {
                input.push(Token::Address(key));
            }
            let call_tx = TransactionRequest::new()
                .to(receipt.contract_address.unwrap())
                .data(function.encode_input(&input).unwrap());

            let response = wallet.call(&call_tx.clone().into(), None).await.unwrap();
            ethabi::decode(&[ty], &response).unwrap().remove(0)
        }
    };

    let num = read("readUint128", "num", &[], ParamType::Uint(128))
        .await
        .into_uint()
        .unwrap();
    assert_eq!(num, 1234.into());

    let str = read("readString", "str", &[], ParamType::String)
        .await
        .into_string()
        .unwrap();
    assert_eq!(str, "foobar");

    let key = "0x0123456789012345678901234567890123456789"
        .parse()
        .unwrap();

    let val = read(
        "readMapUint128",
        "addr_to_int",
        &[key],
        ParamType::Uint(128),
    )
    .await
    .into_uint()
    .unwrap();
    assert_eq!(val, 1.into());

    let val = read(
        "readNestedMapUint128",
        "addr_to_addr_to_int",
        &[key, key],
        ParamType::Uint(128),
    )
    .await
    .into_uint()
    .unwrap();
    assert_eq!(val, 1.into());

    // Construct a transaction which uses the scilla_call precompile.
    let function = abi.function("callScilla").unwrap();
    let input = &[
        Token::Address(scilla_contract_address),
        Token::String("InsertIntoMap".to_owned()),
        Token::String("addr_to_int".to_owned()),
        Token::Address(key),
        Token::Uint(5.into()),
    ];
    let tx = TransactionRequest::new()
        .to(evm_contract_address)
        .data(function.encode_input(input).unwrap())
        .gas(84_000_000);

    // First execute the transaction with `eth_call` and assert that updating a value in a Scilla contract, then
    // reading that value in the same transaction gives us the correct value.
    let response = wallet.call(&tx.clone().into(), None).await.unwrap();
    let response = ethabi::decode(&[ParamType::Uint(128)], &response)
        .unwrap()
        .remove(0)
        .into_uint()
        .unwrap()
        .as_u32();
    assert_eq!(response, 5);

    // Now actually run the transaction and assert that the EVM logs include the Scilla log from the internal Scilla
    // call.
    let tx_hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();
    let receipt = network.run_until_receipt(&wallet, tx_hash, 100).await;
    assert_eq!(receipt.logs.len(), 1);
    let log = &receipt.logs[0];
    assert_eq!(log.address, scilla_contract_address);
    assert_eq!(
        log.topics[0],
        H256(keccak256("Inserted(string)".as_bytes()))
    );
    let data = ethabi::decode(&[ParamType::String], &log.data).unwrap()[0]
        .clone()
        .into_string()
        .unwrap();
    let scilla_log: Value = serde_json::from_str(&data).unwrap();
    assert_eq!(
        scilla_log["address"],
        format!("{scilla_contract_address:?}")
    );
    assert_eq!(scilla_log["_eventname"], "Inserted");
    assert_eq!(scilla_log["params"][0]["type"], "ByStr20");
    assert_eq!(scilla_log["params"][0]["vname"], "a");
    assert_eq!(
        scilla_log["params"][0]["value"]
            .as_str()
            .unwrap()
            .parse::<H160>()
            .unwrap(),
        key
    );
    assert_eq!(scilla_log["params"][1]["type"], "Uint128");
    assert_eq!(scilla_log["params"][1]["vname"], "b");
    assert_eq!(scilla_log["params"][1]["value"], "5");

    // Assert that the value has been permanently updated for good measure.
    let val = read(
        "readMapUint128",
        "addr_to_int",
        &[key],
        ParamType::Uint(128),
    )
    .await
    .into_uint()
    .unwrap();
    assert_eq!(val, 5.into());

    // Construct a transaction which logs the `_sender` from the Scilla call.
    let function = abi.function("callScillaNoArgs").unwrap();
    let input = &[
        Token::Address(scilla_contract_address),
        Token::String("LogSender".to_owned()),
    ];
    let tx = TransactionRequest::new()
        .to(evm_contract_address)
        .data(function.encode_input(input).unwrap())
        .gas(84_000_000);

    // Run the transaction.
    let tx_hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();
    let receipt = network.run_until_receipt(&wallet, tx_hash, 100).await;
    assert_eq!(receipt.logs.len(), 1);
    let log = &receipt.logs[0];
    let data = ethabi::decode(&[ParamType::String], &log.data).unwrap()[0]
        .clone()
        .into_string()
        .unwrap();
    let scilla_log: Value = serde_json::from_str(&data).unwrap();
    assert_eq!(scilla_log["_eventname"], "LogSender");
    assert_eq!(scilla_log["params"][0]["vname"], "sender");
    assert_eq!(
        scilla_log["params"][0]["value"],
        format!("{:?}", wallet.address())
    );
}

#[zilliqa_macros::test(restrict_concurrency)]
async fn mutate_evm_then_read_from_scilla(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, _) = zilliqa_account(&mut network, &wallet).await;

    let code = r#"
        scilla_version 0

        contract Test
        ()

        transition LogBalance(addr: ByStr20 with contract end)
          myBal <- _balance;
          e1 = { _eventname : "MyBalance"; balance : myBal };
          event e1;
          bal <- & addr._balance;
          e2 = { _eventname : "Balance"; balance : bal };
          event e2
        end
    "#;

    let data = r#"[
        {
            "vname": "_scilla_version",
            "type": "Uint32",
            "value": "0"
        }
    ]"#;

    let (contract_address, _) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(H160::zero()),
        0,
        50_000,
        Some(code),
        Some(data),
    )
    .await;
    let scilla_contract_address = contract_address.unwrap();

    let (hash, abi) = deploy_contract(
        "tests/it/contracts/ScillaInterop.sol",
        "ScillaInterop",
        0u128,
        &wallet,
        &mut network,
    )
    .await;
    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();
    let evm_contract_address = receipt.contract_address.unwrap();

    let recipient = Address::random_with(network.rng.lock().unwrap().deref_mut());
    debug!(%recipient);

    let function = abi.function("sendEtherThenCallScilla").unwrap();
    let input = &[
        Token::Address(H160(recipient.0.0)),
        Token::Address(scilla_contract_address),
        Token::String("LogBalance".to_owned()),
        Token::Address(H160(recipient.0.0)),
    ];
    let amount = 1_234_000_000_000_000_000_000;
    let tx = TransactionRequest::new()
        .to(evm_contract_address)
        .data(function.encode_input(input).unwrap())
        .gas(84_000_000)
        .value(amount);

    let my_balance_before = wallet
        .get_balance(scilla_contract_address, None)
        .await
        .unwrap()
        .as_u128();

    // Run the transaction.
    let tx_hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();
    let receipt = network.run_until_receipt(&wallet, tx_hash, 100).await;

    let log = &receipt.logs[0];
    let data = ethabi::decode(&[ParamType::String], &log.data).unwrap()[0]
        .clone()
        .into_string()
        .unwrap();
    let scilla_log: Value = serde_json::from_str(&data).unwrap();
    assert_eq!(scilla_log["_eventname"], "Balance");
    assert_eq!(
        scilla_log["params"][0]["value"],
        (amount / 10u128.pow(6)).to_string()
    );

    let log = &receipt.logs[1];
    let data = ethabi::decode(&[ParamType::String], &log.data).unwrap()[0]
        .clone()
        .into_string()
        .unwrap();
    let scilla_log: Value = serde_json::from_str(&data).unwrap();
    assert_eq!(scilla_log["_eventname"], "MyBalance");
    assert_eq!(
        scilla_log["params"][0]["value"],
        (my_balance_before / 10u128.pow(6)).to_string(),
    );
}

#[zilliqa_macros::test(restrict_concurrency)]
async fn interop_send_funds_from_scilla(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, _) = zilliqa_account(&mut network, &wallet).await;

    let code = r#"
        scilla_version 0

        library HelloWorld
        let one = Uint128 1

        let one_msg =
          fun (msg : Message) =>
          let nil_msg = Nil {Message} in
            Cons {Message} msg nil_msg

        contract Test
        ()

        transition SendTo(addr: ByStr20)
          msg = { _tag : ""; _recipient : addr; _amount : one };
          msgs = one_msg msg;
          send msgs
        end
    "#;

    let data = r#"[
        {
            "vname": "_scilla_version",
            "type": "Uint32",
            "value": "0"
        }
    ]"#;

    let (contract_address, _) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(H160::zero()),
        1,
        50_000,
        Some(code),
        Some(data),
    )
    .await;
    let scilla_contract_address = contract_address.unwrap();

    let (hash, abi) = deploy_contract(
        "tests/it/contracts/ScillaInterop.sol",
        "ScillaInterop",
        0u128,
        &wallet,
        &mut network,
    )
    .await;
    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();
    let evm_contract_address = receipt.contract_address.unwrap();

    let recipient = Address::random_with(network.rng.lock().unwrap().deref_mut());
    debug!(%recipient);

    let function = abi.function("callScillaOneArg").unwrap();
    let input = &[
        Token::Address(scilla_contract_address),
        Token::String("SendTo".to_owned()),
        Token::Address(H160(recipient.0.0)),
    ];
    let tx = TransactionRequest::new()
        .to(evm_contract_address)
        .data(function.encode_input(input).unwrap())
        .gas(84_000_000);

    let tx_count_before = wallet
        .get_transaction_count(wallet.address(), None)
        .await
        .unwrap();

    // transaction sender pays for gas, but the funds are withdrawn from contract that sends a message
    let balance_before = wallet.get_balance(wallet.address(), None).await.unwrap();

    // Run the transaction.
    let tx_hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();
    let receipt = network.run_until_receipt(&wallet, tx_hash, 100).await;
    assert_eq!(receipt.status.unwrap().as_u64(), 1);

    let tx_count_after = wallet
        .get_transaction_count(wallet.address(), None)
        .await
        .unwrap();
    let balance_after = wallet.get_balance(wallet.address(), None).await.unwrap();

    // Sender of the txn pays for gas
    assert_eq!(tx_count_before + 1, tx_count_after);
    assert_eq!(
        balance_before - (receipt.gas_used.unwrap() * receipt.effective_gas_price.unwrap()),
        balance_after
    );

    // Contract doesn't hold any funds
    let contract_final_balance = wallet
        .get_balance(scilla_contract_address, None)
        .await
        .unwrap();
    assert_eq!(contract_final_balance.as_u128(), 0u128);

    assert_eq!(
        wallet
            .get_balance(H160(recipient.0.0), None)
            .await
            .unwrap()
            .as_u128(),
        1_000_000
    );
}
#[zilliqa_macros::test(restrict_concurrency)]
async fn call_scilla_precompile_with_value(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, _) = zilliqa_account(&mut network, &wallet).await;

    let code = r#"
        scilla_version 0

        library HelloWorld
        let one = Uint128 1

        let one_msg =
          fun (msg : Message) =>
          let nil_msg = Nil {Message} in
            Cons {Message} msg nil_msg

        contract Test
        ()

        transition justAccept()
            accept
        end
    "#;

    let data = r#"[
        {
            "vname": "_scilla_version",
            "type": "Uint32",
            "value": "0"
        }
    ]"#;

    let (contract_address, _) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(H160::zero()),
        0,
        50_000,
        Some(code),
        Some(data),
    )
    .await;
    let scilla_contract_address = contract_address.unwrap();

    let evm_contract_value = 10_000_000;
    let value_to_send = evm_contract_value / 2;

    let (hash, abi) = deploy_contract(
        "tests/it/contracts/ScillaInterop.sol",
        "ScillaInterop",
        evm_contract_value,
        &wallet,
        &mut network,
    )
    .await;
    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();
    let evm_contract_address = receipt.contract_address.unwrap();

    // Query evm contract balance
    let evm_contract_zero_balance = wallet
        .get_balance(evm_contract_address, None)
        .await
        .unwrap();
    assert_eq!(evm_contract_zero_balance.as_u128(), evm_contract_value);

    // Scilla contract balance is zero
    let scilla_contract_zero_balance = wallet
        .get_balance(scilla_contract_address, None)
        .await
        .unwrap();
    assert_eq!(scilla_contract_zero_balance.as_u128(), 0);

    // Call precompile that sends the value
    let function = abi.function("callScillaValue").unwrap();
    let input = &[
        Token::Address(scilla_contract_address),
        Token::String("justAccept".to_owned()),
        Token::Uint(value_to_send.into()),
    ];
    let tx = TransactionRequest::new()
        .to(evm_contract_address)
        .data(function.encode_input(input).unwrap())
        .gas(84_000_000);

    // Run the transaction.
    let tx_hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();
    let receipt = network.run_until_receipt(&wallet, tx_hash, 100).await;
    assert_eq!(receipt.status.unwrap().as_u64(), 1);

    // Evm contract balance modified by sent amount
    let evm_contract_zero_balance = wallet
        .get_balance(evm_contract_address, None)
        .await
        .unwrap();
    assert_eq!(
        evm_contract_zero_balance.as_u128(),
        evm_contract_value - value_to_send
    );

    // Scilla contract balance received the value
    let scilla_contract_zero_balance = wallet
        .get_balance(scilla_contract_address, None)
        .await
        .unwrap();
    assert_eq!(scilla_contract_zero_balance.as_u128(), value_to_send);
}

#[zilliqa_macros::test(restrict_concurrency)]
async fn scilla_call_with_bad_gas(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, _) = zilliqa_account(&mut network, &wallet).await;

    let code = r#"
        scilla_version 0

        library HelloWorld

        let one = Uint128 1
        let two = Uint128 2
        let big_number = Uint128 1234
        let addr = 0x0123456789012345678901234567890123456789

        contract Hello
        ()

        field num : Uint128 = big_number
        field str : String = "foobar"
        field addr_to_int : Map ByStr20 Uint128 =
          let emp = Emp ByStr20 Uint128 in
          builtin put emp addr one
        field addr_to_addr_to_int : Map ByStr20 (Map ByStr20 Uint128) =
          let emp1 = Emp ByStr20 Uint128 in
          let inner = builtin put emp1 addr one in
          let emp2 = Emp ByStr20 (Map ByStr20 Uint128) in
          builtin put emp2 addr inner

        transition InsertIntoMap(a: ByStr20, b: Uint128)
          addr_to_int[a] := b;
          e = {_eventname : "Inserted"; a : a; b : b};
          event e
        end
    "#;

    let data = r#"[
        {
            "vname": "_scilla_version",
            "type": "Uint32",
            "value": "0"
        }
    ]"#;

    let (contract_address, _) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(H160::zero()),
        0,
        50_000,
        Some(code),
        Some(data),
    )
    .await;
    let scilla_contract_address = contract_address.unwrap();

    // Bump the genesis wallet's nonce up, so that the next contract we deploy will be exempt from gas charges when
    // calling the `scilla_call` precompile.
    let tx_hash = wallet
        .send_transaction(TransactionRequest::new().to(H160::zero()), None)
        .await
        .unwrap()
        .tx_hash();
    network.run_until_receipt(&wallet, tx_hash, 100).await;

    let (hash, abi) = deploy_contract(
        "tests/it/contracts/ScillaInterop.sol",
        "ScillaInterop",
        0u128,
        &wallet,
        &mut network,
    )
    .await;
    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();

    // Construct a transaction which uses the scilla_call precompile.
    let function = abi.function("callScillaWithBadGas").unwrap();
    let input = &[
        Token::Address(scilla_contract_address),
        Token::String("InsertIntoMap".to_owned()),
        Token::String("addr_to_int".to_owned()),
        Token::Address(wallet.address()),
        Token::Uint(5.into()),
    ];
    let tx = TransactionRequest::new()
        .to(receipt.contract_address.unwrap())
        .data(function.encode_input(input).unwrap())
        .gas(84_000_000);

    // Make sure the transaction succeeds.
    let tx_hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();
    let receipt = network.run_until_receipt(&wallet, tx_hash, 100).await;
    assert_eq!(receipt.status.unwrap().as_u64(), 1);
}

#[zilliqa_macros::test(restrict_concurrency)]
async fn interop_call_then_revert(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, _) = zilliqa_account(&mut network, &wallet).await;

    let code = r#"
        scilla_version 0

        library HelloWorld

        let one = Uint128 1
        let two = Uint128 2
        let big_number = Uint128 1234
        let addr = 0x0123456789012345678901234567890123456789

        contract Hello
        ()

        field num : Uint128 = big_number
        field str : String = "foobar"
        field addr_to_int : Map ByStr20 Uint128 =
          let emp = Emp ByStr20 Uint128 in
          builtin put emp addr one
        field addr_to_addr_to_int : Map ByStr20 (Map ByStr20 Uint128) =
          let emp1 = Emp ByStr20 Uint128 in
          let inner = builtin put emp1 addr one in
          let emp2 = Emp ByStr20 (Map ByStr20 Uint128) in
          builtin put emp2 addr inner

        transition InsertIntoMap(a: ByStr20, b: Uint128)
          addr_to_int[a] := b;
          e = {_eventname : "Inserted"; a : a; b : b};
          event e
        end

        transition GetFromMap(a: ByStr20)
            addr_to_int_o <- addr_to_int[a];

            match addr_to_int_o with
            | Some value =>
                e = {
                    _eventname: "Value";
                    element: value
                };
                event e
            | None =>
            end
        end
    "#;

    let data = r#"[
        {
            "vname": "_scilla_version",
            "type": "Uint32",
            "value": "0"
        }
    ]"#;

    let (contract_address, _) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(H160::zero()),
        0,
        50_000,
        Some(code),
        Some(data),
    )
    .await;
    let scilla_contract_address = contract_address.unwrap();

    // Bump the genesis wallet's nonce up, so that the next contract we deploy will be exempt from gas charges when
    // calling the `scilla_call` precompile.
    let tx_hash = wallet
        .send_transaction(TransactionRequest::new().to(H160::zero()), None)
        .await
        .unwrap()
        .tx_hash();
    network.run_until_receipt(&wallet, tx_hash, 100).await;

    let (hash, abi) = deploy_contract(
        "tests/it/contracts/ScillaInterop.sol",
        "ScillaInterop",
        0u128,
        &wallet,
        &mut network,
    )
    .await;
    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();

    // Construct a transaction which uses the scilla_call precompile.
    let function = abi.function("callScillaRevert").unwrap();
    let input = &[
        Token::Address(scilla_contract_address),
        Token::String("InsertIntoMap".to_owned()),
        Token::Address(scilla_contract_address),
        Token::Uint(5.into()),
    ];
    let tx = TransactionRequest::new()
        .to(receipt.contract_address.unwrap())
        .data(function.encode_input(input).unwrap())
        .gas(84_000_000);

    // Make sure the transaction succeeds.
    let tx_hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();
    let receipt = network.run_until_receipt(&wallet, tx_hash, 100).await;
    assert_eq!(receipt.status.unwrap().as_u64(), 0);

    let call = format!(
        r#"
            {{
            "_tag": "GetFromMap",
            "params": [
                {{
                    "vname": "a",
                    "type": "ByStr20",
                    "value": "{scilla_contract_address:#x}"
                }}
            ]
           }}
        "#
    );

    let (_, txn) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        2,
        ToAddr::Address(scilla_contract_address),
        0,
        50_000,
        None,
        Some(&call),
    )
    .await;

    assert!(txn["receipt"]["event_logs"].as_array().unwrap().is_empty());
}

#[zilliqa_macros::test(restrict_concurrency)]
async fn interop_read_after_write(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, _) = zilliqa_account(&mut network, &wallet).await;

    let code = r#"
        scilla_version 0

        library HelloWorld

        let one = Uint128 1
        let two = Uint128 2
        let big_number = Uint128 1234
        let addr = 0x0123456789012345678901234567890123456789

        contract Hello
        ()

        field num : Uint128 = big_number
        field str : String = "foobar"
        field addr_to_int : Map ByStr20 Uint128 =
          let emp = Emp ByStr20 Uint128 in
          builtin put emp addr one

        transition InsertIntoMap(a: ByStr20, b: Uint128)
          addr_to_int[a] := b;
          e = {_eventname : "Inserted"; a : a; b : b};
          event e
        end
    "#;

    let data = r#"[
        {
            "vname": "_scilla_version",
            "type": "Uint32",
            "value": "0"
        }
    ]"#;

    let (contract_address, _) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(H160::zero()),
        0,
        50_000,
        Some(code),
        Some(data),
    )
    .await;
    let scilla_contract_address = contract_address.unwrap();

    // Bump the genesis wallet's nonce up, so that the next contract we deploy will be exempt from gas charges when
    // calling the `scilla_call` precompile.
    let tx_hash = wallet
        .send_transaction(TransactionRequest::new().to(H160::zero()), None)
        .await
        .unwrap()
        .tx_hash();
    network.run_until_receipt(&wallet, tx_hash, 100).await;

    let (hash, abi) = deploy_contract(
        "tests/it/contracts/ScillaInterop.sol",
        "ScillaInterop",
        0u128,
        &wallet,
        &mut network,
    )
    .await;
    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();

    // Construct a transaction which uses the scilla_call precompile.
    let function = abi.function("readAfterWrite").unwrap();
    let input = &[
        Token::Address(scilla_contract_address),
        Token::String("InsertIntoMap".to_owned()),
        Token::Address(scilla_contract_address),
        Token::Uint(5.into()),
        Token::String("addr_to_int".to_owned()),
    ];
    let tx = TransactionRequest::new()
        .to(receipt.contract_address.unwrap())
        .data(function.encode_input(input).unwrap())
        .gas(84_000_000);

    // Make sure the transaction succeeds.
    let tx_hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();
    let receipt = network.run_until_receipt(&wallet, tx_hash, 100).await;
    assert_eq!(receipt.status.unwrap().as_u64(), 1);
}

#[zilliqa_macros::test(restrict_concurrency)]
async fn interop_nested_call_to_precompile_then_revert(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, _) = zilliqa_account(&mut network, &wallet).await;

    let code = r#"
        scilla_version 0

        library HelloWorld

        let one = Uint128 1
        let two = Uint128 2
        let big_number = Uint128 1234
        let addr = 0x0123456789012345678901234567890123456789

        contract Hello
        ()

        field num : Uint128 = big_number
        field str : String = "foobar"
        field addr_to_int : Map ByStr20 Uint128 =
          let emp = Emp ByStr20 Uint128 in
          builtin put emp addr one

        transition InsertIntoMap(a: ByStr20, b: Uint128)
          addr_to_int[a] := b;
          e = {_eventname : "Inserted"; a : a; b : b};
          event e
        end

        transition GetFromMap(a: ByStr20)
            addr_to_int_o <- addr_to_int[a];

            match addr_to_int_o with
            | Some value =>
                e = {
                    _eventname: "Value";
                    element: value
                };
                event e
            | None =>
            end
        end
    "#;

    let data = r#"[
        {
            "vname": "_scilla_version",
            "type": "Uint32",
            "value": "0"
        }
    ]"#;

    let (contract_address, _) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(H160::zero()),
        0,
        50_000,
        Some(code),
        Some(data),
    )
    .await;
    let scilla_contract_address = contract_address.unwrap();

    // Bump the genesis wallet's nonce up, so that the next contract we deploy will be exempt from gas charges when
    // calling the `scilla_call` precompile.
    let tx_hash = wallet
        .send_transaction(TransactionRequest::new().to(H160::zero()), None)
        .await
        .unwrap()
        .tx_hash();
    network.run_until_receipt(&wallet, tx_hash, 100).await;

    let (hash, abi) = deploy_contract(
        "tests/it/contracts/ScillaInterop.sol",
        "ScillaInterop",
        0u128,
        &wallet,
        &mut network,
    )
    .await;
    let receipt = wallet.get_transaction_receipt(hash).await.unwrap().unwrap();

    // Construct a transaction which uses the scilla_call precompile.
    let function = abi
        .function("makeNestedPrecompileCallWhichReverts")
        .unwrap();
    let input = &[
        Token::Address(scilla_contract_address),
        Token::String("InsertIntoMap".to_owned()),
        Token::Address(scilla_contract_address),
        Token::Uint(5.into()),
        Token::String("addr_to_int".to_owned()),
    ];
    let tx = TransactionRequest::new()
        .to(receipt.contract_address.unwrap())
        .data(function.encode_input(input).unwrap())
        .gas(84_000_000);

    // // Make sure the transaction fails.
    let tx_hash = wallet.send_transaction(tx, None).await.unwrap().tx_hash();

    network
        .run_until_async(
            || async {
                let response: Result<GetTxResponse, _> =
                    wallet.provider().request("GetTransaction", [tx_hash]).await;
                response.is_ok()
            },
            400,
        )
        .await
        .unwrap();

    let eth_receipt = wallet
        .get_transaction_receipt(tx_hash)
        .await
        .unwrap()
        .unwrap();

    assert_eq!(eth_receipt.status.unwrap().as_u64(), 0);

    let call = format!(
        r#"
            {{
            "_tag": "GetFromMap",
            "params": [
                {{
                    "vname": "a",
                    "type": "ByStr20",
                    "value": "{scilla_contract_address:#x}"
                }}
            ]
           }}
        "#
    );

    let (_, txn) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        2,
        ToAddr::Address(scilla_contract_address),
        0,
        50_000,
        None,
        Some(&call),
    )
    .await;

    assert!(txn["receipt"]["event_logs"].as_array().unwrap().is_empty());
}

#[zilliqa_macros::test]
async fn get_tx_block(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Ensure there is at least one block in the chain
    network.run_until_block_finalized(3u64, 100).await.unwrap();

    // Request the first block
    let block_number = "1";

    let response: Value = wallet
        .provider()
        .request("GetTxBlock", [block_number])
        .await
        .expect("Failed to call GetTxBlock API");

    dbg!(&response);

    // Ensure the response is an object
    assert!(response.is_object(), "Expected response to be an object");

    // Verify header fields
    let header = &response["header"];
    assert_eq!(header["BlockNum"].as_str().unwrap(), block_number);
    assert!(
        header["DSBlockNum"].as_str().is_some(),
        "Missing DSBlockNum"
    );
    assert!(header["GasLimit"].as_str().is_some(), "Missing GasLimit");
    assert!(header["GasUsed"].as_str().is_some(), "Missing GasUsed");
    assert!(
        header["MbInfoHash"].as_str().is_some(),
        "Missing MbInfoHash"
    );
    assert!(
        header["NumMicroBlocks"].as_u64().is_some(),
        "Missing NumMicroBlocks"
    );
    assert!(header["NumPages"].as_u64().is_some(), "Missing NumPages");
    assert!(header["NumTxns"].as_u64().is_some(), "Missing NumTxns");
    assert!(
        header["PrevBlockHash"].as_str().is_some(),
        "Missing PrevBlockHash"
    );
    assert!(header["Rewards"].as_str().is_some(), "Missing Rewards");
    assert!(
        header["StateDeltaHash"].as_str().is_some(),
        "Missing StateDeltaHash"
    );
    assert!(
        header["StateRootHash"].as_str().is_some(),
        "Missing StateRootHash"
    );
    assert!(header["Timestamp"].as_str().is_some(), "Missing Timestamp");
    assert!(header["TxnFees"].as_str().is_some(), "Missing TxnFees");
    assert!(header["Version"].as_u64().is_some(), "Missing Version");

    // Verify body fields
    let body = &response["body"];
    let block_hash = body["BlockHash"].as_str().expect("Missing BlockHash");
    assert!(!block_hash.is_empty(), "BlockHash should not be empty");

    assert!(body["HeaderSign"].as_str().is_some(), "Missing HeaderSign");

    // Verify MicroBlockInfos
    let micro_blocks = body["MicroBlockInfos"]
        .as_array()
        .expect("Expected MicroBlockInfos to be an array");
    for micro_block in micro_blocks {
        assert!(
            micro_block["MicroBlockHash"].as_str().is_some(),
            "Missing MicroBlockHash"
        );
        assert!(
            micro_block["MicroBlockShardId"].as_u64().is_some(),
            "Missing MicroBlockShardId"
        );
        assert!(
            micro_block["MicroBlockTxnRootHash"].as_str().is_some(),
            "Missing MicroBlockTxnRootHash"
        );
    }

    // Additional validation of relationships between fields
    let num_micro_blocks = header["NumMicroBlocks"].as_u64().unwrap();
    assert_eq!(
        micro_blocks.len() as u64,
        num_micro_blocks,
        "NumMicroBlocks should match length of MicroBlockInfos array"
    );
}

#[zilliqa_macros::test]
async fn get_tx_block_verbose(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Ensure there is at least one block in the chain
    network.run_until_block_finalized(3u64, 100).await.unwrap();

    // Request the first block
    let block_number = "1";

    let response: Value = wallet
        .provider()
        .request("GetTxBlockVerbose", [block_number])
        .await
        .expect("Failed to call GetTxBlockVerbose API");

    dbg!(&response);

    // Ensure the response is an object
    assert!(response.is_object(), "Expected response to be an object");

    // Verify header fields
    let header = &response["header"];
    assert_eq!(header["BlockNum"].as_str().unwrap(), block_number);
    assert!(
        header["CommitteeHash"].as_str().is_some(),
        "Missing CommitteeHash"
    );
    assert!(
        header["DSBlockNum"].as_str().is_some(),
        "Missing DSBlockNum"
    );
    assert!(header["GasLimit"].as_str().is_some(), "Missing GasLimit");
    assert!(header["GasUsed"].as_str().is_some(), "Missing GasUsed");
    assert!(
        header["MbInfoHash"].as_str().is_some(),
        "Missing MbInfoHash"
    );
    assert!(
        header["MinerPubKey"].as_str().is_some(),
        "Missing MinerPubKey"
    );
    assert!(
        header["NumMicroBlocks"].as_u64().is_some(),
        "Missing NumMicroBlocks"
    );
    assert!(header["NumPages"].as_u64().is_some(), "Missing NumPages");
    assert!(header["NumTxns"].as_u64().is_some(), "Missing NumTxns");
    assert!(
        header["PrevBlockHash"].as_str().is_some(),
        "Missing PrevBlockHash"
    );
    assert!(header["Rewards"].as_str().is_some(), "Missing Rewards");
    assert!(
        header["StateDeltaHash"].as_str().is_some(),
        "Missing StateDeltaHash"
    );
    assert!(
        header["StateRootHash"].as_str().is_some(),
        "Missing StateRootHash"
    );
    assert!(header["Timestamp"].as_str().is_some(), "Missing Timestamp");
    assert!(header["TxnFees"].as_str().is_some(), "Missing TxnFees");
    assert!(header["Version"].as_u64().is_some(), "Missing Version");

    // Verify body fields
    let body = &response["body"];

    // Verify B1 and B2 arrays
    assert!(body["B1"].as_array().is_some(), "Missing B1 array");
    assert!(body["B2"].as_array().is_some(), "Missing B2 array");

    // Verify all B1 and B2 elements are booleans
    for value in body["B1"].as_array().unwrap() {
        assert!(value.is_boolean(), "B1 array element is not a boolean");
    }
    for value in body["B2"].as_array().unwrap() {
        assert!(value.is_boolean(), "B2 array element is not a boolean");
    }

    let block_hash = body["BlockHash"].as_str().expect("Missing BlockHash");
    assert!(!block_hash.is_empty(), "BlockHash should not be empty");

    assert!(body["CS1"].as_str().is_some(), "Missing CS1");
    assert!(body["HeaderSign"].as_str().is_some(), "Missing HeaderSign");

    // Verify MicroBlockInfos
    let micro_blocks = body["MicroBlockInfos"]
        .as_array()
        .expect("Expected MicroBlockInfos to be an array");
    for micro_block in micro_blocks {
        assert!(
            micro_block["MicroBlockHash"].as_str().is_some(),
            "Missing MicroBlockHash"
        );
        assert!(
            micro_block["MicroBlockShardId"].as_u64().is_some(),
            "Missing MicroBlockShardId"
        );
        assert!(
            micro_block["MicroBlockTxnRootHash"].as_str().is_some(),
            "Missing MicroBlockTxnRootHash"
        );
    }

    // Additional validation of relationships between fields
    let num_micro_blocks = header["NumMicroBlocks"].as_u64().unwrap();
    assert_eq!(
        micro_blocks.len() as u64,
        num_micro_blocks,
        "NumMicroBlocks should match length of MicroBlockInfos array"
    );

    // Verify hash formats
    let is_valid_hash = |hash: &str| hash.len() == 64 || hash.starts_with("0x");
    assert!(
        is_valid_hash(header["CommitteeHash"].as_str().unwrap()),
        "Invalid CommitteeHash format"
    );
    assert!(
        is_valid_hash(header["MbInfoHash"].as_str().unwrap()),
        "Invalid MbInfoHash format"
    );
    assert!(
        is_valid_hash(header["PrevBlockHash"].as_str().unwrap()),
        "Invalid PrevBlockHash format"
    );
    assert!(
        is_valid_hash(header["StateDeltaHash"].as_str().unwrap()),
        "Invalid StateDeltaHash format"
    );
    assert!(
        is_valid_hash(header["StateRootHash"].as_str().unwrap()),
        "Invalid StateRootHash format"
    );

    // Verify timestamp is a valid number
    let timestamp = header["Timestamp"].as_str().unwrap();
    assert!(timestamp.parse::<u64>().is_ok(), "Invalid Timestamp format");
}

#[zilliqa_macros::test]
async fn get_smart_contract_init(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Deploy a Scilla contract
    let (secret_key, address) = zilliqa_account(&mut network, &wallet).await;
    let code = scilla_test_contract_code();
    let data = scilla_test_contract_data(address);
    let contract_address =
        deploy_scilla_contract(&mut network, &wallet, &secret_key, &code, &data, 0_u128).await;

    // Test the success case
    let response: Value = wallet
        .provider()
        .request("GetSmartContractInit", [contract_address])
        .await
        .expect("Failed to call GetSmartContractInit API");

    let init_data: Vec<zilliqa::scilla::ParamValue> =
        serde_json::from_value(response).expect("Failed to deserialize response");

    // Assert the data returned from the API is a superset of the init data we passed.
    let expected_data: Vec<Value> = serde_json::from_str(&data).unwrap();
    for expected in expected_data {
        assert!(
            init_data
                .iter()
                .any(|d| serde_json::to_value(d).unwrap() == expected)
        );
    }

    // Test the error case with an invalid contract address
    let invalid_contract_address: H160 = "0x0000000000000000000000000000000000000000"
        .parse()
        .unwrap();
    let response: Result<Value, ProviderError> = wallet
        .provider()
        .request("GetSmartContractInit", [invalid_contract_address])
        .await;

    assert!(response.is_err());
    if let Err(ProviderError::JsonRpcClientError(rpc_error)) = response {
        if let Some(json_error) = rpc_error.as_error_response() {
            assert_eq!(json_error.code, -32603); // Invalid params error code
            assert!(json_error.message.contains("Address does not exist"));
        } else {
            panic!("Expected JSON-RPC error response");
        }
    } else {
        panic!("Expected ProviderError::JsonRpcClientError");
    }
}

#[zilliqa_macros::test]
async fn get_ds_block(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let response: Value = wallet
        .provider()
        .request("GetDSBlock", ["9000"])
        .await
        .expect("Failed to call GetDSBlock API");

    zilliqa::api::types::zil::DSBlock::deserialize(&response).unwrap();
}

#[zilliqa_macros::test]
async fn get_ds_block_verbose(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let response: Value = wallet
        .provider()
        .request("GetDSBlockVerbose", ["9000"])
        .await
        .expect("Failed to call GetDSBlockVerbose API");

    zilliqa::api::types::zil::DSBlockVerbose::deserialize(&response).unwrap();
}

#[zilliqa_macros::test]
async fn get_latest_ds_block(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let response: Value = wallet
        .provider()
        .request("GetLatestDSBlock", [""])
        .await
        .expect("Failed to call GetLatestDSBlock API");

    zilliqa::api::types::zil::DSBlock::deserialize(&response).unwrap();
}

#[zilliqa_macros::test]
async fn get_current_ds_comm(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let response: Value = wallet
        .provider()
        .request("GetCurrentDSComm", [""])
        .await
        .expect("Failed to call GetCurrentDSComm API");

    zilliqa::api::types::zil::GetCurrentDSCommResult::deserialize(&response).unwrap();
}

#[zilliqa_macros::test]
async fn get_current_ds_epoch(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let response: Value = wallet
        .provider()
        .request("GetCurrentDSEpoch", [""])
        .await
        .expect("Failed to call GetCurrentDSEpoch API");

    assert!(response.is_string());
}

#[zilliqa_macros::test]
async fn ds_block_listing(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (secret_key, _address) = zilliqa_account(&mut network, &wallet).await;

    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    network.run_until_block_finalized(8u64, 300).await.unwrap();

    let response: Value = wallet
        .provider()
        .request("DSBlockListing", [1])
        .await
        .expect("Failed to call DSBlockListing API");

    zilliqa::api::types::zil::DSBlockListingResult::deserialize(&response).unwrap();
}

#[zilliqa_macros::test]
async fn get_ds_block_rate(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let response: Value = wallet
        .provider()
        .request("GetDSBlockRate", [""])
        .await
        .expect("Failed to call GetDSBlockRate API");

    let returned = zilliqa::api::types::zil::DSBlockRateResult::deserialize(&response).unwrap();

    assert!(returned.rate >= 0.0, "Block rate should be non-negative");
}

#[zilliqa_macros::test]
async fn get_tx_block_rate_0(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let response: Value = wallet
        .provider()
        .request("GetTxBlockRate", [""])
        .await
        .expect("Failed to call GetTxBlockRate API");

    let returned = zilliqa::api::types::zil::TXBlockRateResult::deserialize(&response).unwrap();

    assert!(returned.rate >= 0.0, "Block rate should be non-negative");
}

#[zilliqa_macros::test]
async fn get_tx_block_rate_1(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, _address) = zilliqa_account(&mut network, &wallet).await;
    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    network.run_until_block_finalized(3u64, 100).await.unwrap();

    let response: Value = wallet
        .provider()
        .request("GetTxBlockRate", [""])
        .await
        .expect("Failed to call GetTxBlockRate API");

    let returned = zilliqa::api::types::zil::TXBlockRateResult::deserialize(&response).unwrap();

    assert!(returned.rate > 0.0, "Block rate should be positive");
}

#[zilliqa_macros::test]
async fn get_num_peers(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let response: Value = wallet
        .provider()
        .request("GetNumPeers", [""])
        .await
        .expect("Failed to call GetNumPeers API");

    assert!(
        response.is_number(),
        "Expected response to be a number, got: {:?}",
        response
    );
}

#[zilliqa_macros::test]
async fn get_tx_rate_0(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    network.run_until_block_finalized(1u64, 100).await.unwrap();

    let response: Value = wallet
        .provider()
        .request("GetTransactionRate", [""])
        .await
        .expect("Failed to call GetTxRate API");

    let tx_rate: f64 = serde_json::from_value(response).expect("Failed to deserialize response");

    assert!(tx_rate >= 0.0, "Transaction rate should be non-negative");

    network.run_until_block_finalized(8u64, 300).await.unwrap();

    let response: Value = wallet
        .provider()
        .request("GetTransactionRate", [""])
        .await
        .expect("Failed to call GetTxRate API");

    let tx_rate: f64 = serde_json::from_value(response).expect("Failed to deserialize response");

    assert!(tx_rate >= 0.0, "Transaction rate should be non-negative");
}

#[zilliqa_macros::test]
async fn get_tx_rate_1(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (secret_key, _address) = zilliqa_account(&mut network, &wallet).await;

    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    network.run_until_block_finalized(2u64, 300).await.unwrap();

    let response: Value = wallet
        .provider()
        .request("GetTransactionRate", [""])
        .await
        .expect("Failed to call GetTxRate API");

    let tx_rate: f64 = serde_json::from_value(response).expect("Failed to deserialize response");

    assert!(tx_rate > 0.0, "Transaction block rate should be positive");
}

#[zilliqa_macros::test]
async fn get_txns_for_tx_block_ex_0(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    network.run_until_block_finalized(1u64, 100).await.unwrap();

    let block_number = "1";
    let page_number = "1";

    let response: Value = wallet
        .provider()
        .request("GetTransactionsForTxBlockEx", [block_number, page_number])
        .await
        .expect("Failed to call GetTransactionsForTxBlockEx API");

    let txns: zilliqa::api::types::zil::TxnsForTxBlockExResponse =
        serde_json::from_value(response).expect("Failed to deserialize response");

    assert_eq!(txns.curr_page, page_number.parse::<u64>().unwrap());
    assert!(
        txns.transactions.len() <= 2500,
        "Expected Transactions length to be less than or equal to 2500"
    );
}

#[zilliqa_macros::test]
async fn test_simulate_transactions(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (secret_key, address) = zilliqa_account(&mut network, &wallet).await;

    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    // Verify the sender's nonce has increased using the `GetBalance` API.
    let response: Value = wallet
        .provider()
        .request("GetBalance", [address])
        .await
        .unwrap();
    assert_eq!(response["nonce"].as_u64().unwrap(), 1);

    // Verify the receiver's balance has increased using the `GetBalance` API.
    let response: Value = wallet
        .provider()
        .request("GetBalance", [to_addr])
        .await
        .unwrap();
    assert_eq!(response["balance"].as_str().unwrap(), "200000000000000");

    let node = network.get_node(0);

    let mut num_transactions = 0;
    let mut i = 0;
    while let Some(b) = node.get_block(i).unwrap() {
        for tx in b.transactions.iter() {
            num_transactions += 1;
            println!("Block {:?}, transaction {:?}", &b, &tx);
        }
        i += 1;
    }

    assert!(num_transactions >= 1);
}

#[zilliqa_macros::test]
async fn get_txns_for_tx_block_ex_1(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (secret_key, _address) = zilliqa_account(&mut network, &wallet).await;
    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    let (_, txn) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    network.run_until_block_finalized(2u64, 300).await.unwrap();

    let result: zilliqa::api::types::zil::GetTxResponse =
        serde_json::from_value(txn).expect("serdes error");

    let block_number = result.receipt.epoch_num;
    let page_number = 0;

    let response: Value = wallet
        .provider()
        .request(
            "GetTransactionsForTxBlockEx",
            [
                block_number.to_string().as_str(),
                page_number.to_string().as_str(),
            ],
        )
        .await
        .expect("Failed to call GetTransactionsForTxBlockEx API");

    let txns: zilliqa::api::types::zil::TxnsForTxBlockExResponse =
        serde_json::from_value(response).expect("Failed to deserialize response");

    assert_eq!(txns.curr_page, page_number);
    assert!(
        txns.transactions.len() <= 2500,
        "Expected Transactions length to be less than or equal to 2500"
    );
    assert!(
        !txns.transactions.is_empty(),
        "Expected Transactions length to be greater than or equal to 1"
    );
}

#[zilliqa_macros::test]
async fn get_txns_for_tx_block_0(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (secret_key, _address) = zilliqa_account(&mut network, &wallet).await;

    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    let (_, txn) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    network.run_until_block_finalized(2u64, 300).await.unwrap();

    let result: zilliqa::api::types::zil::GetTxResponse =
        serde_json::from_value(txn).expect("serdes error");

    let block_number = result.receipt.epoch_num;

    let response: Value = wallet
        .provider()
        .request(
            "GetTransactionsForTxBlock",
            [block_number.to_string().as_str()],
        )
        .await
        .expect("Failed to call GetTransactionsForTxBlock API");

    let txns: Vec<Vec<String>> =
        serde_json::from_value(response.clone()).expect("Failed to deserialize response");

    assert!(
        !txns[0].is_empty(),
        "Expected Transactions length to be greater than or equal to 1"
    );

    // Check it's an array of arrays of transaction hashes
    assert!(response.is_array());
    if let Some(shards) = response.as_array() {
        if !shards.is_empty() {
            assert!(shards[0].is_array());
            if let Some(txns) = shards[0].as_array() {
                if !txns.is_empty() {
                    // Each hash should be a 32 byte hex string
                    assert!(txns[0].is_string());
                    assert_eq!(txns[0].as_str().unwrap().len(), 64);
                }
            }
        }
    }
}

#[zilliqa_macros::test]
async fn get_txn_bodies_for_tx_block_0(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (secret_key, _address) = zilliqa_account(&mut network, &wallet).await;

    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    let (_, txn) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    network.run_until_block_finalized(2u64, 300).await.unwrap();

    let result: zilliqa::api::types::zil::GetTxResponse =
        serde_json::from_value(txn).expect("serdes error");

    let block_number = result.receipt.epoch_num;

    let response: Value = wallet
        .provider()
        .request(
            "GetTxnBodiesForTxBlock",
            [block_number.to_string().as_str()],
        )
        .await
        .expect("Failed to call GetTxnBodiesForTxBlock API");

    let txn_bodies: Vec<zilliqa::api::types::zil::TransactionBody> =
        serde_json::from_value(response).expect("Failed to deserialize response");

    assert!(
        !txn_bodies.is_empty(),
        "Expected Transactions length to be greater than or equal to 1"
    );
}

#[zilliqa_macros::test]
async fn get_txn_bodies_for_tx_block_1(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (secret_key, _address) = zilliqa_account(&mut network, &wallet).await;

    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    let (_, txn) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    network.run_until_block_finalized(2u64, 300).await.unwrap();

    let result: zilliqa::api::types::zil::GetTxResponse =
        serde_json::from_value(txn).expect("serdes error");

    let block_number = result.receipt.epoch_num;

    let response: Value = wallet
        .provider()
        .request(
            "GetTxnBodiesForTxBlock",
            [block_number.to_string().as_str()],
        )
        .await
        .expect("Failed to call GetTxnBodiesForTxBlock API");

    let txn_bodies: Vec<zilliqa::api::types::zil::TransactionBody> =
        serde_json::from_value(response).expect("Failed to deserialize response");

    assert!(
        !txn_bodies.is_empty(),
        "Expected Transactions length to be greater than or equal to 1"
    );
    assert!(
        txn_bodies.len() <= 2500,
        "Expected Transactions length to be less than or equal to 2500"
    );
}

#[zilliqa_macros::test]
async fn get_txn_bodies_for_tx_block_ex_0(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (secret_key, _address) = zilliqa_account(&mut network, &wallet).await;

    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    let (_, txn) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    network.run_until_block_finalized(2u64, 300).await.unwrap();

    let result: zilliqa::api::types::zil::GetTxResponse =
        serde_json::from_value(txn).expect("serdes error");

    let block_number = result.receipt.epoch_num;
    let page_number = 2;

    let response: Value = wallet
        .provider()
        .request(
            "GetTxnBodiesForTxBlockEx",
            [
                block_number.to_string().as_str(),
                page_number.to_string().as_str(),
            ],
        )
        .await
        .expect("Failed to call GetTxnBodiesForTxBlockEx API");

    let txn_bodies: zilliqa::api::types::zil::TxnBodiesForTxBlockExResponse =
        serde_json::from_value(response).expect("Failed to deserialize response");

    assert_eq!(txn_bodies.curr_page, page_number);
    assert!(
        txn_bodies.num_pages > 0,
        "Expected NumPages to be greater than 0"
    );
    assert!(
        txn_bodies.transactions.len() <= 2500,
        "Expected Transactions length to be less than or equal to 2500"
    );
}

#[zilliqa_macros::test]
async fn get_txn_bodies_for_tx_block_ex_1(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (secret_key, _address) = zilliqa_account(&mut network, &wallet).await;

    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    let (_, txn) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    network.run_until_block_finalized(2u64, 300).await.unwrap();

    let result: zilliqa::api::types::zil::GetTxResponse =
        serde_json::from_value(txn).expect("serdes error");

    let block_number = result.receipt.epoch_num;
    let page_number = 0;

    let response: Value = wallet
        .provider()
        .request(
            "GetTxnBodiesForTxBlockEx",
            [
                block_number.to_string().as_str(),
                page_number.to_string().as_str(),
            ],
        )
        .await
        .expect("Failed to call GetTxnBodiesForTxBlockEx API");

    let result = response["result"].clone();

    let txn_bodies: zilliqa::api::types::zil::TxnBodiesForTxBlockExResponse =
        serde_json::from_value(response).expect("Failed to deserialize response");

    assert_eq!(txn_bodies.curr_page, page_number);
    assert!(
        txn_bodies.num_pages > 0,
        "Expected NumPages to be greater than 0"
    );
    assert!(
        txn_bodies.transactions.len() <= 2500,
        "Expected Transactions length to be less than or equal to 2500"
    );
    assert!(
        !txn_bodies.transactions.is_empty(),
        "Expected Transactions length to be greater than or equal to 1"
    );

    // Check transaction array structure
    if let Some(shards) = result["Transactions"].as_array() {
        if !shards.is_empty() && !shards[0].is_null() {
            assert!(shards[0].is_array());
            if let Some(txns) = shards[0].as_array() {
                if !txns.is_empty() {
                    assert!(txns[0].is_string());
                    assert_eq!(txns[0].as_str().unwrap().len(), 64);
                }
            }
        }
    }
}

#[zilliqa_macros::test]
async fn get_num_ds_blocks(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let response: Value = wallet
        .provider()
        .request("GetNumDSBlocks", [""])
        .await
        .expect("Failed to call GetNumDSBlocks API");

    assert!(
        response.is_string(),
        "Expected response to be a string, got: {:?}",
        response
    );
}

#[zilliqa_macros::test]
async fn get_recent_transactions_0(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let response: Value = wallet
        .provider()
        .request("GetRecentTransactions", [""])
        .await
        .expect("Failed to call GetRecentTransactions API");

    let recent_transactions =
        zilliqa::api::types::zil::RecentTransactionsResponse::deserialize(&response)
            .expect("Failed to deserialize response");

    assert_eq!(
        recent_transactions.number as usize,
        recent_transactions.txn_hashes.len()
    );
    assert!(recent_transactions.number < 100);
}

#[zilliqa_macros::test]
async fn get_recent_transactions_1(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (secret_key, _address) = zilliqa_account(&mut network, &wallet).await;

    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    let (secret_key, _address) = zilliqa_account(&mut network, &wallet).await;

    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    network.run_until_block_finalized(1u64, 300).await.unwrap();

    let response: Value = wallet
        .provider()
        .request("GetRecentTransactions", [""])
        .await
        .expect("Failed to call GetRecentTransactions API");

    let recent_transactions =
        zilliqa::api::types::zil::RecentTransactionsResponse::deserialize(&response)
            .expect("Failed to deserialize response");

    assert_eq!(
        recent_transactions.number as usize,
        recent_transactions.txn_hashes.len()
    );
    assert_eq!(recent_transactions.number, 4);
}

// #[zilliqa_macros::test] // Disabled since API is currently not working
// async fn get_num_transactions_0(mut network: Network) {
//     let wallet = network.genesis_wallet().await;

//     let response: Value = wallet
//         .provider()
//         .request("GetNumTransactions", [""])
//         .await
//         .expect("Failed to call GetNumTransactions API");

//     assert!(
//         response.is_string(),
//         "Expected response to be a string, got: {:?}",
//         response
//     );
//     response
//         .as_str()
//         .expect("Expected response to be a string")
//         .parse::<u64>()
//         .expect("Failed to parse response as u64");
// }

// Disabled since API is currently not working
// #[zilliqa_macros::test] // Disabled since API is currently not working
// async fn get_num_transactions_1(mut network: Network) {
//     let wallet = network.random_wallet().await;

//     let (secret_key, _address) = zilliqa_account(&mut network).await;

//     let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
//         .parse()
//         .unwrap();
//     send_transaction(
//         &mut network,
//         &secret_key,
//         1,
//         ToAddr::Address(to_addr),
//         200u128 * 10u128.pow(12),
//         50_000,
//         None,
//         None,
//     )
//     .await;

//     network.run_until_block_finalized(1u64, 100).await.unwrap();

//     let (secret_key, _address) = zilliqa_account(&mut network).await;

//     let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
//         .parse()
//         .unwrap();
//     send_transaction(
//         &mut network,
//         &secret_key,
//         1,
//         ToAddr::Address(to_addr),
//         200u128 * 10u128.pow(12),
//         50_000,
//         None,
//         None,
//     )
//     .await;

//     network.run_until_block_finalized(8u64, 300).await.unwrap();

//     let response: Value = wallet
//         .provider()
//         .request("GetNumTransactions", [""])
//         .await
//         .expect("Failed to call GetNumTransactions API");

//     assert!(
//         response.is_string(),
//         "Expected response to be a string, got: {:?}",
//         response
//     );

//     let response_num = response
//         .as_str()
//         .expect("Expected response to be a string")
//         .parse::<u64>()
//         .expect("Failed to parse response as u64");

//     assert_eq!(response_num, 4);
// }

#[zilliqa_macros::test]
async fn get_num_txns_ds_epoch_0(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let response: Value = wallet
        .provider()
        .request("GetNumTxnsDSEpoch", [""])
        .await
        .expect("Failed to call GetNumTxnsDSEpoch API");

    assert!(
        response.is_string(),
        "Expected response to be a string, got: {:?}",
        response
    );
}

#[zilliqa_macros::test]
async fn get_num_txns_ds_epoch_1(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, _address) = zilliqa_account(&mut network, &wallet).await;

    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    network.run_until_block_finalized(2u64, 100).await.unwrap();

    let (secret_key, _address) = zilliqa_account(&mut network, &wallet).await;

    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    network.run_until_block_finalized(3u64, 300).await.unwrap();

    let response: Value = wallet
        .provider()
        .request("GetNumTxnsDSEpoch", [""])
        .await
        .expect("Failed to call GetNumTxnsDSEpoch API");

    assert!(
        response.is_string(),
        "Expected response to be a string, got: {:?}",
        response
    );

    let response_num = response
        .as_str()
        .expect("Expected response to be a string")
        .parse::<u64>()
        .expect("Failed to parse response as u64");

    assert_eq!(response_num, 3);
}

#[zilliqa_macros::test]
async fn get_num_txns_tx_epoch_0(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let response: Value = wallet
        .provider()
        .request("GetNumTxnsTXEpoch", [""])
        .await
        .expect("Failed to call GetNumTxnsTxEpoch API");

    assert!(
        response.is_string(),
        "Expected response to be a string, got: {:?}",
        response
    );
}

#[zilliqa_macros::test]
async fn get_num_txns_tx_epoch_1(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let (secret_key, _address) = zilliqa_account(&mut network, &wallet).await;

    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    network.run_until_block_finalized(2u64, 100).await.unwrap();

    let (secret_key, _address) = zilliqa_account(&mut network, &wallet).await;

    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();
    send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await;

    network.run_until_block_finalized(3u64, 300).await.unwrap();

    let response: Value = wallet
        .provider()
        .request("GetNumTxnsTXEpoch", [""])
        .await
        .expect("Failed to call GetNumTxnsTXEpoch API");

    assert!(
        response.is_string(),
        "Expected response to be a string, got: {:?}",
        response
    );

    let response_num = response
        .as_str()
        .expect("Expected response to be a string")
        .parse::<u64>()
        .expect("Failed to parse response as u64");

    assert_eq!(response_num, 1);
}

#[zilliqa_macros::test]
async fn combined_total_coin_supply_test(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let response_str: Value = wallet
        .provider()
        .request("GetTotalCoinSupply", [""])
        .await
        .expect("Failed to call GetTotalCoinSupply API");

    assert!(
        response_str.is_string(),
        "Expected response to be a string, got: {:?}",
        response_str
    );

    let total_coin_supply_str = response_str.as_str().expect("Expected string conversion");
    let total_coin_supply_as_f64_from_str: f64 = total_coin_supply_str
        .parse()
        .expect("Expected string to be parsed as an integer");

    let response_int: Value = wallet
        .provider()
        .request("GetTotalCoinSupplyAsInt", [""])
        .await
        .expect("Failed to call GetTotalCoinSupplyAsInt API");

    assert!(
        response_int.is_number(),
        "Expected response to be a number, got: {:?}",
        response_int
    );

    let total_coin_supply_as_int: u128 = response_int
        .as_number()
        .expect("Expected number conversion")
        .as_u128()
        .expect("Expected u128 conversion");

    assert!(
        (total_coin_supply_as_f64_from_str - total_coin_supply_as_int as f64).abs() < 1.0,
        "Total coin supply from string and int APIs should be the same"
    );

    assert_eq!(
        total_coin_supply_as_int, 1000000256,
        "Total coin supply should be 1000000256"
    )
}

#[zilliqa_macros::test]
async fn get_miner_info(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let response: Value = wallet
        .provider()
        .request("GetMinerInfo", ["5500"])
        .await
        .expect("Failed to call GetMinerInfo API");

    zilliqa::api::types::zil::MinerInfo::deserialize(&response).unwrap();
}

#[zilliqa_macros::test]
async fn get_node_type(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let response: Value = wallet
        .provider()
        .request("GetNodeType", [""])
        .await
        .expect("Failed to call GetNodeType API");

    assert!(
        response.is_string(),
        "Expected response to be a string, got: {:?}",
        response
    );

    let allowed_node_types = ["Seed"];
    let response_str = response.as_str().expect("Expected response to be a string");

    assert!(
        allowed_node_types.contains(&response_str),
        "Unexpected node type: {}",
        response_str
    );
}

#[allow(dead_code)]
async fn get_prev_difficulty(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let response: Value = wallet
        .provider()
        .request("GetPrevDifficulty", [""])
        .await
        .expect("Failed to call GetPrevDifficulty API");

    assert!(
        response.is_u64(),
        "Expected response to be a u64, got: {:?}",
        response
    );

    let response_u64 = response.as_u64().expect("Expected response to be a u64");

    assert_eq!(response_u64, 0);
}

#[allow(dead_code)]
async fn get_prev_ds_difficulty(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let response: Value = wallet
        .provider()
        .request("GetPrevDSDifficulty", [""])
        .await
        .expect("Failed to call GetPrevDSDifficulty API");

    assert!(
        response.is_u64(),
        "Expected response to be a u64, got: {:?}",
        response
    );

    let response_u64 = response.as_u64().expect("Expected response to be a u64");

    assert_eq!(response_u64, 0);
}

#[zilliqa_macros::test]
async fn get_sharding_structure(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Get the sharding structure
    let response: Value = wallet
        .provider()
        .request("GetShardingStructure", [""])
        .await
        .expect("Failed to call GetShardingStructure API");

    // Deserialize the response into our expected type
    let sharding_structure: zilliqa::api::types::zil::ShardingStructure =
        serde_json::from_value(response).expect("Failed to deserialize response");

    // Since Zilliqa 2.0 uses XShard instead of traditional sharding,
    // we expect exactly one shard with the number of connected peers
    assert_eq!(
        sharding_structure.num_peers.len(),
        1,
        "Expected exactly one shard in sharding structure"
    );

    // Get the number of peers to verify
    let num_peers_response: Value = wallet
        .provider()
        .request("GetNumPeers", [""])
        .await
        .expect("Failed to call GetNumPeers API");

    let num_peers = num_peers_response
        .as_u64()
        .expect("Expected GetNumPeers to return a number");

    // Verify that the number of peers matches
    assert_eq!(
        sharding_structure.num_peers[0], num_peers,
        "Number of peers in sharding structure doesn't match GetNumPeers"
    );
}

// We need to restrict the concurrency level of this test, because each node in the network will spawn a TCP listener
// once it invokes Scilla. When many tests are run in parallel, this results in "Too many open files" errors.
#[zilliqa_macros::test(restrict_concurrency)]
async fn get_smart_contract_sub_state(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, address) = zilliqa_account(&mut network, &wallet).await;
    let code = scilla_test_contract_code();
    let data = scilla_test_contract_data(address);
    let contract_address =
        deploy_scilla_contract(&mut network, &wallet, &secret_key, &code, &data, 0_u128).await;

    let api_code: Value = wallet
        .provider()
        .request("GetSmartContractCode", [contract_address])
        .await
        .unwrap();
    assert_eq!(code, api_code["code"]);

    let api_data: Vec<Value> = wallet
        .provider()
        .request("GetSmartContractInit", [contract_address])
        .await
        .unwrap();
    // Assert the data returned from the API is a superset of the init data we passed.
    assert!(
        serde_json::from_str::<Vec<Value>>(&data)
            .unwrap()
            .iter()
            .all(|d| api_data.contains(d))
    );

    let call = r#"{
        "_tag": "setHello",
        "params": [
            {
                "vname": "msg",
                "value": "foobar",
                "type": "String"
            }
        ]
    }"#;
    let (_, txn) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        2,
        ToAddr::Address(contract_address),
        0,
        50_000,
        None,
        Some(call),
    )
    .await;
    let event = &txn["receipt"]["event_logs"][0];
    assert_eq!(event["_eventname"], "setHello");
    assert_eq!(event["params"][0]["value"], "2");

    let call = r#"{
        "_tag": "getHello",
        "params": []
    }"#;
    let (_, txn) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        3,
        ToAddr::Address(contract_address),
        0,
        50_000,
        None,
        Some(call),
    )
    .await;
    for event in txn["receipt"]["event_logs"].as_array().unwrap() {
        assert_eq!(event["_eventname"], "getHello");
        assert_eq!(event["params"][0]["value"], "foobar");
    }

    network.run_until_block_finalized(8u64, 300).await.unwrap();

    let state: serde_json::Value = wallet
        .provider()
        .request("GetSmartContractState", [contract_address])
        .await
        .unwrap();
    assert_eq!(state["welcome_msg"], "foobar");

    let empty_string_vec: Vec<String> = vec![]; // Needed for type annotation
    let substate0: serde_json::Value = wallet
        .provider()
        .request(
            "GetSmartContractSubState",
            (contract_address, "", empty_string_vec.clone()),
        )
        .await
        .expect("Failed to call GetSmartContractSubState API");
    assert_eq!(substate0, state);

    let substate1: serde_json::Value = wallet
        .provider()
        .request(
            "GetSmartContractSubState",
            (contract_address, "welcome_msg", empty_string_vec),
        )
        .await
        .expect("Failed to call GetSmartContractSubState API");
    assert_eq!(substate1["welcome_msg"], "foobar");
    assert!(substate1.get("welcome_map").is_none());

    let substate2: serde_json::Value = wallet
        .provider()
        .request(
            "GetSmartContractSubState",
            (contract_address, "welcome_map", ["1", "2"]),
        )
        .await
        .expect("Failed to call GetSmartContractSubState API");
    assert_eq!(
        substate2["welcome_map"]["1"]["2"].as_str().unwrap(),
        "foobar"
    );
    assert!(substate2.get("welcome_msg").is_none());
}

#[zilliqa_macros::test]
async fn get_smart_contract_sub_state_empty_should_return_null(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, address) = zilliqa_account(&mut network, &wallet).await;
    let code = scilla_test_contract_code();
    let data = scilla_test_contract_data(address);
    let contract_address =
        deploy_scilla_contract(&mut network, &wallet, &secret_key, &code, &data, 0_u128).await;

    network.run_until_block_finalized(5u64, 300).await.unwrap();

    // Test querying for a non-existent variable name
    let empty_string_vec: Vec<String> = vec![];
    let substate_nonexistent: serde_json::Value = wallet
        .provider()
        .request(
            "GetSmartContractSubState",
            (
                contract_address,
                "nonexistent_variable",
                empty_string_vec.clone(),
            ),
        )
        .await
        .expect("Failed to call GetSmartContractSubState API");

    // ZQ1 returns null for non-existent variables, ZQ2 should match this behavior
    // This test will fail initially, demonstrating the bug where {} is returned instead of null
    assert_eq!(substate_nonexistent, serde_json::Value::Null);

    // Test querying for non-existent indices in an existing map
    let substate_nonexistent_indices: serde_json::Value = wallet
        .provider()
        .request(
            "GetSmartContractSubState",
            (contract_address, "welcome_map", ["nonexistent_key"]),
        )
        .await
        .expect("Failed to call GetSmartContractSubState API");

    // ZQ1 returns null for non-existent map indices, ZQ2 should match this behavior
    // This test will also fail initially, demonstrating the bug where {} is returned instead of null
    assert_eq!(substate_nonexistent_indices, serde_json::Value::Null);
}

#[zilliqa_macros::test(restrict_concurrency)]
async fn nested_maps_insert_removal(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, address) = zilliqa_account(&mut network, &wallet).await;

    let code = scilla_test_contract_code();
    let data = scilla_test_contract_data(address);
    let contract_address =
        deploy_scilla_contract(&mut network, &wallet, &secret_key, &code, &data, 0_u128).await;

    // Set nested map to some value
    {
        let call = r#"{
        "_tag": "setHello",
        "params": [
            {
                "vname": "msg",
                "value": "foobar",
                "type": "String"
            }
        ]
    }"#;

        let (_, txn) = send_transaction(
            &mut network,
            &wallet,
            &secret_key,
            2,
            ToAddr::Address(contract_address),
            0,
            50_000,
            None,
            Some(call),
        )
        .await;
        let event = &txn["receipt"]["event_logs"][0];
        assert_eq!(event["_eventname"], "setHello");
    }

    // Confirm the value exists in the nested map
    {
        let call = r#"{
        "_tag": "getHello",
        "params": []
    }"#;
        let (_, txn) = send_transaction(
            &mut network,
            &wallet,
            &secret_key,
            3,
            ToAddr::Address(contract_address),
            0,
            50_000,
            None,
            Some(call),
        )
        .await;
        for event in txn["receipt"]["event_logs"].as_array().unwrap() {
            assert_eq!(event["_eventname"], "getHello");
            assert_eq!(event["params"][0]["value"], "foobar");
        }
    }

    // Remove entry from map
    {
        let call = r#"{
        "_tag": "removeHello",
        "params": []
    }"#;

        let (_, txn) = send_transaction(
            &mut network,
            &wallet,
            &secret_key,
            4,
            ToAddr::Address(contract_address),
            0,
            50_000,
            None,
            Some(call),
        )
        .await;
        let event = &txn["receipt"]["event_logs"][0];
        assert_eq!(event["_eventname"], "removeHello");
    }

    // Check and confirm the entry does not exist anymore
    {
        let call = r#"{
        "_tag": "getHello",
        "params": []
    }"#;
        let (_, txn) = send_transaction(
            &mut network,
            &wallet,
            &secret_key,
            5,
            ToAddr::Address(contract_address),
            0,
            50_000,
            None,
            Some(call),
        )
        .await;
        let event = &txn["receipt"]["event_logs"][0];
        assert_eq!(event["params"][0]["value"], "failed");
    }
}

#[zilliqa_macros::test(restrict_concurrency)]
async fn failed_scilla_contract_proper_fee(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, address) = zilliqa_account(&mut network, &wallet).await;

    let code = scilla_test_contract_code();
    let data = scilla_test_contract_data(address);
    let contract_address =
        deploy_scilla_contract(&mut network, &wallet, &secret_key, &code, &data, 0_u128).await;

    let initial_balance = wallet.get_balance(address, None).await.unwrap().as_u128();

    let gas_price_str: String = wallet
        .provider()
        .request("GetMinimumGasPrice", ())
        .await
        .unwrap();

    let gas_price: u128 = u128::from_str(&gas_price_str).unwrap();
    let gas_limit = 50_000;

    let amount_to_transfer = 10 * 10u128.pow(12);

    let call = format!(
        r#"{{
        "_tag": "callFailure",
        "_amount": "0x{amount_to_transfer:x}",
        "params": [
            {{
                "vname": "addr",
                "type": "ByStr20",
                "value": "0x{contract_address:x}"
            }}
        ]
         }}"#
    );

    let response = issue_create_transaction(
        &wallet,
        &secret_key.public_key(),
        gas_price,
        &mut network,
        &secret_key,
        2,
        ToAddr::Address(contract_address),
        amount_to_transfer,
        gas_limit as u64,
        None,
        Some(&call),
    )
    .await
    .unwrap();

    let txn_hash: H256 = response["TranID"].as_str().unwrap().parse().unwrap();

    network
        .run_until_async(
            || async {
                let response: Result<GetTxResponse, _> = wallet
                    .provider()
                    .request("GetTransaction", [txn_hash])
                    .await;
                response.is_ok()
            },
            400,
        )
        .await
        .unwrap();

    let eth_receipt = wallet
        .get_transaction_receipt(txn_hash)
        .await
        .unwrap()
        .unwrap();
    assert_eq!(eth_receipt.status.unwrap().as_u32(), 0);

    // Verify the sender's nonce has increased using the `GetBalance` API.
    let response: Value = wallet
        .provider()
        .request("GetBalance", [address])
        .await
        .unwrap();
    println!("GetBalance() after transfer = {response:?}");
    assert_eq!(response["nonce"].as_u64().unwrap(), 2);

    let transaction_fee: u128 =
        (eth_receipt.cumulative_gas_used * eth_receipt.effective_gas_price.unwrap()).as_u128();

    let balance_after_failed_call = wallet.get_balance(address, None).await.unwrap().as_u128();

    assert_eq!(balance_after_failed_call, initial_balance - transaction_fee);
}

#[zilliqa_macros::test]
async fn get_state_proof(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let contract_address = "6d84363526a2d764835f8cf52dfeefe80a360fac";
    let variable_hash = "A0BD91DE66D97E6930118179BA4F1836C366C4CB3309A6B354D26F52ABB2AAC6";
    let tx_block = "39";

    let response: Value = wallet
        .provider()
        .request("GetStateProof", [contract_address, variable_hash, tx_block])
        .await
        .expect("Failed to call GetStateProof API");

    let _state_proof: zilliqa::api::types::zil::StateProofResponse =
        serde_json::from_value(response).expect("Failed to deserialize response");
}

// LLM generated, may be buggy
#[zilliqa_macros::test]
async fn get_transaction_status(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    // Test 1: Create a transaction and check it while pending/dispatched
    let (secret_key_1, _address_1) = zilliqa_account(&mut network, &wallet).await;
    let to_addr: H160 = "0x00000000000000000000000000000000deadbeef"
        .parse()
        .unwrap();

    // Get the gas price via the Zilliqa API.
    let gas_price_str: String = wallet
        .provider()
        .request("GetMinimumGasPrice", ())
        .await
        .unwrap();
    let gas_price: u128 = u128::from_str(&gas_price_str).unwrap();

    // Send first transaction (nonce 1) - should be dispatched initially
    let response = issue_create_transaction(
        &wallet,
        &secret_key_1.public_key(),
        gas_price,
        &mut network,
        &secret_key_1,
        1,
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await
    .unwrap();
    let txn_hash_1: H256 = response["TranID"].as_str().unwrap().parse().unwrap();

    // Check status immediately - should be dispatched (pending)
    let response_dispatched: Value = wallet
        .provider()
        .request("GetTransactionStatus", [txn_hash_1])
        .await
        .expect("Failed to call GetTransactionStatus API");

    let tx_status_dispatched: zilliqa::api::types::zil::TransactionStatusResponse =
        serde_json::from_value(response_dispatched).expect("Failed to deserialize response");

    assert!(matches!(
        tx_status_dispatched.status,
        zilliqa::api::types::zil::TxnStatusCode::Dispatched
    ));
    assert_eq!(tx_status_dispatched.modification_state, 1);

    // Test 2: Send transaction with future nonce - should be queued
    let response = issue_create_transaction(
        &wallet,
        &secret_key_1.public_key(),
        gas_price,
        &mut network,
        &secret_key_1,
        3, // Skip nonce 2, so this will be queued
        ToAddr::Address(to_addr),
        200u128 * 10u128.pow(12),
        50_000,
        None,
        None,
    )
    .await
    .unwrap();
    let txn_hash_queued: H256 = response["TranID"].as_str().unwrap().parse().unwrap();

    // Check status - should be queued due to high nonce
    let response_queued: Value = wallet
        .provider()
        .request("GetTransactionStatus", [txn_hash_queued])
        .await
        .expect("Failed to call GetTransactionStatus API");

    let tx_status_queued: zilliqa::api::types::zil::TransactionStatusResponse =
        serde_json::from_value(response_queued).expect("Failed to deserialize response");

    assert!(matches!(
        tx_status_queued.status,
        zilliqa::api::types::zil::TxnStatusCode::PresentNonceHigh
    ));
    assert_eq!(tx_status_queued.modification_state, 1);

    // Test 3: Wait for first transaction to be mined and finalized
    network
        .run_until_async(
            || async {
                let response: Result<GetTxResponse, _> = wallet
                    .provider()
                    .request("GetTransaction", [txn_hash_1])
                    .await;
                response.is_ok()
            },
            400,
        )
        .await
        .unwrap();

    // Wait for the block to be finalized
    network.run_until_block_finalized(2u64, 300).await.unwrap();

    // Check status after finalization - should be confirmed
    let response_confirmed: Value = wallet
        .provider()
        .request("GetTransactionStatus", [txn_hash_1])
        .await
        .expect("Failed to call GetTransactionStatus API");

    let tx_status_confirmed: zilliqa::api::types::zil::TransactionStatusResponse =
        serde_json::from_value(response_confirmed).expect("Failed to deserialize response");

    assert!(matches!(
        tx_status_confirmed.status,
        zilliqa::api::types::zil::TxnStatusCode::Confirmed
    ));
    assert_eq!(tx_status_confirmed.modification_state, 2);
    assert!(tx_status_confirmed.success);
    assert!(!tx_status_confirmed.epoch_inserted.is_empty());
    assert!(!tx_status_confirmed.epoch_updated.is_empty());

    // Test 4: Create a transaction that will fail/error
    let (secret_key_error, _) = zilliqa_account(&mut network, &wallet).await;

    // Deploy a contract that will revert
    let revert_code = r#"
        scilla_version 0

        contract RevertContract
        ()

        transition AlwaysRevert()
            throw
        end
    "#;

    let revert_data = r#"[
        {
            "vname": "_scilla_version",
            "type": "Uint32",
            "value": "0"
        }
    ]"#;

    let (revert_contract_address, _) = send_transaction(
        &mut network,
        &wallet,
        &secret_key_error,
        1,
        ToAddr::Address(H160::zero()),
        0,
        50_000,
        Some(revert_code),
        Some(revert_data),
    )
    .await;
    let revert_contract_address = revert_contract_address.unwrap();

    // Call the reverting function
    let call = r#"{
        "_tag": "AlwaysRevert",
        "params": []
    }"#;

    let response_error = issue_create_transaction(
        &wallet,
        &secret_key_error.public_key(),
        gas_price,
        &mut network,
        &secret_key_error,
        2,
        ToAddr::Address(revert_contract_address),
        0,
        50_000,
        None,
        Some(call),
    )
    .await
    .unwrap();
    let txn_hash_error: H256 = response_error["TranID"].as_str().unwrap().parse().unwrap();

    // Wait for the error transaction to be mined
    network
        .run_until_async(
            || async {
                let response: Result<GetTxResponse, _> = wallet
                    .provider()
                    .request("GetTransaction", [txn_hash_error])
                    .await;
                response.is_ok()
            },
            400,
        )
        .await
        .unwrap();

    // Wait for finalization
    network.run_until_block_finalized(4u64, 300).await.unwrap();

    // Check status of error transaction - should be confirmed but with success=false
    let response_error_status: Value = wallet
        .provider()
        .request("GetTransactionStatus", [txn_hash_error])
        .await
        .expect("Failed to call GetTransactionStatus API");

    let tx_status_error: zilliqa::api::types::zil::TransactionStatusResponse =
        serde_json::from_value(response_error_status).expect("Failed to deserialize response");

    // Even failed transactions show as "Confirmed" once they're in a finalized block
    assert!(matches!(
        tx_status_error.status,
        zilliqa::api::types::zil::TxnStatusCode::Error
    ));
    assert_eq!(tx_status_error.modification_state, 2);
    assert!(!tx_status_error.success); // This should be false for failed transactions

    // Verify all basic fields are properly formatted
    assert!(tx_status_confirmed.amount.parse::<u128>().is_ok());
    assert!(tx_status_confirmed.gas_limit.parse::<u64>().is_ok());
    assert!(tx_status_confirmed.gas_price.parse::<u64>().is_ok());
    assert!(tx_status_confirmed.nonce.parse::<u64>().is_ok());
    assert!(!tx_status_confirmed.to_addr.is_empty());
    assert!(!tx_status_confirmed.version.is_empty());
}

#[zilliqa_macros::test]
async fn get_blockchain_info_structure(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let result: Value = wallet
        .provider()
        .request("GetBlockchainInfo", [""])
        .await
        .expect("Failed to call GetBlockchainInfo API");

    // Verify all required fields exist and have correct types
    assert!(result["CurrentDSEpoch"].is_string());
    assert!(result["CurrentMiniEpoch"].is_string());
    assert!(result["DSBlockRate"].is_number());
    assert!(result["NumDSBlocks"].is_string());
    assert!(result["NumPeers"].is_number());
    assert!(result["NumTransactions"].is_string());
    assert!(result["NumTxBlocks"].is_string());
    assert!(result["NumTxnsDSEpoch"].is_string());
    assert!(result["NumTxnsTxEpoch"].is_string());
    assert!(result["TransactionRate"].is_number());
    assert!(result["TxBlockRate"].is_number());

    // Verify ShardingStructure
    assert!(result["ShardingStructure"]["NumPeers"].is_array());
}

#[zilliqa_macros::test]
async fn get_num_tx_blocks_structure(mut network: Network) {
    let wallet = network.genesis_wallet().await;

    let response: Value = wallet
        .provider()
        .request("GetNumTxBlocks", [""])
        .await
        .expect("Failed to call GetNumTxBlocks API");

    // Should be a string containing a number
    assert!(response.is_string());
    assert!(response.as_str().unwrap().parse::<u64>().is_ok());
}

#[zilliqa_macros::test(restrict_concurrency)]
async fn return_map_and_parse(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, _) = zilliqa_account(&mut network, &wallet).await;

    let code = r#"
        scilla_version 0

        contract ReturnMap
        ()

        field complex_map : Map ByStr20 (Map BNum Uint128) = Emp ByStr20 (Map BNum Uint128)

        transition AddToMap(a: ByStr20, b: BNum, c: Uint128)
            complex_map[a][b] := c
        end

        transition GetFromMap(a: ByStr20)
            complex_map_o <- complex_map[a];

            match complex_map_o with
            | Some complex_map =>
                values_list = builtin to_list complex_map;

                e = {
                    _eventname: "MapValues";
                    a: a;
                    values_list: values_list
                };
                event e
            | None =>
            end
        end
    "#;

    let data = r#"[
        {
            "vname": "_scilla_version",
            "type": "Uint32",
            "value": "0"
        }
    ]"#;

    let contract_address =
        deploy_scilla_contract(&mut network, &wallet, &secret_key, code, data, 0_u128).await;

    // Set nested map to some value
    let call = r#"{
        "_tag": "AddToMap",
        "params": [
            {
                "vname": "a",
                "type": "ByStr20",
                "value": "0x964d9004b1ba9f362766cd681e9f97837a5cbb85"
            },
            {
                "vname": "b",
                "value": "1",
                "type": "BNum"
            },
            {
                "vname": "c",
                "value": "100",
                "type": "Uint128"
            }
        ]
    }"#;

    let (_, _) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        2,
        ToAddr::Address(contract_address),
        0,
        50_000,
        None,
        Some(call),
    )
    .await;

    // Parse returned nested map
    let call = r#"{
        "_tag": "GetFromMap",
        "params": [
            {
                "vname": "a",
                "type": "ByStr20",
                "value": "0x964d9004b1ba9f362766cd681e9f97837a5cbb85"
            }
        ]
    }"#;

    let (_, txn) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        3,
        ToAddr::Address(contract_address),
        0,
        50_000,
        None,
        Some(call),
    )
    .await;
    let event = &txn["receipt"]["event_logs"][0];
    assert_eq!(event["_eventname"], "MapValues");
    assert_eq!(
        event["params"][1]["value"][0]["arguments"]
            .as_array()
            .unwrap()
            .clone(),
        vec![Value::from("1"), Value::from("100")]
    );
}

#[zilliqa_macros::test(restrict_concurrency)]
async fn withdraw_from_contract(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, _) = zilliqa_account(&mut network, &wallet).await;

    let code = r#"
        scilla_version 0

        library WithdrawLib

        let one_msg =
            fun (msg : Message) =>
            let nil_msg = Nil {Message} in
            Cons {Message} msg nil_msg

        contract Withdraw
        ()

        transition Withdraw(recipient: ByStr20, amount: Uint128)
            msg = {_tag : "SomeMessage"; _recipient: recipient; _amount: amount};
            msgs = one_msg msg;
            send msgs
        end

    "#;

    let data = r#"[
        {
            "vname": "_scilla_version",
            "type": "Uint32",
            "value": "0"
        }
    ]"#;

    let deploy_contract_balance = 1_000_000_u128;
    let contract_address = deploy_scilla_contract(
        &mut network,
        &wallet,
        &secret_key,
        code,
        data,
        deploy_contract_balance,
    )
    .await;

    let queried_balance = wallet.get_balance(contract_address, None).await.unwrap();
    assert_eq!(
        deploy_contract_balance,
        queried_balance.as_u128() / 10u128.pow(6)
    );

    let random_wallet_address = network.random_wallet().await.address();

    assert_eq!(
        0_u128,
        wallet
            .get_balance(random_wallet_address, None)
            .await
            .unwrap()
            .as_u128()
    );

    // Simulate withdrawal from contract
    let call = format!(
        r#"{{
        "_tag": "Withdraw",
        "params": [
            {{
                "vname": "recipient",
                "type": "ByStr20",
                "value": "0x{random_wallet_address:x}"
            }},
            {{
                "vname": "amount",
                "value": "{deploy_contract_balance}",
                "type": "Uint128"
            }}
        ]
    }}"#
    );

    let (_, _) = send_transaction(
        &mut network,
        &wallet,
        &secret_key,
        2,
        ToAddr::Address(contract_address),
        0,
        50_000,
        None,
        Some(&call),
    )
    .await;

    let random_wallet_balance = wallet
        .get_balance(random_wallet_address, None)
        .await
        .unwrap()
        .as_u128();
    assert_eq!(
        random_wallet_balance / 10u128.pow(6),
        deploy_contract_balance
    );

    let contract_zero_balance = wallet
        .get_balance(contract_address, None)
        .await
        .unwrap()
        .as_u128();
    assert_eq!(0_u128, contract_zero_balance);
}

/// This test is for hardfork scilla_fix_contract_code_removal_on_evm_tx's behaviour
#[zilliqa_macros::test(restrict_concurrency)]
async fn create_scilla_contract_send_evm_tx(mut network: Network) {
    let wallet = network.genesis_wallet().await;
    let (secret_key, address) = zilliqa_account(&mut network, &wallet).await;
    let code = scilla_test_contract_code();
    let data = scilla_test_contract_data(address);
    let contract_address =
        deploy_scilla_contract(&mut network, &wallet, &secret_key, &code, &data, 0_u128).await;

    let account_code_before = network
        .get_node(0)
        .consensus
        .state()
        .get_account(Address::from(contract_address.to_fixed_bytes()))
        .unwrap()
        .code;

    // Send type 0 tx
    let hash = wallet
        .send_transaction(TransactionRequest::pay(contract_address, 0), None)
        .await
        .unwrap()
        .tx_hash();
    network.run_until_receipt(&wallet, hash, 200).await;

    let account_code_after = network
        .get_node(0)
        .consensus
        .state()
        .get_account(Address::from(contract_address.to_fixed_bytes()))
        .unwrap()
        .code;
    assert_eq!(
        serde_json::to_string(&account_code_before).unwrap(),
        serde_json::to_string(&account_code_after).unwrap()
    );
}

```